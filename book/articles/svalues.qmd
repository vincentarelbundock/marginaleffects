---
title: "S Values"
---

```{r, include = FALSE}
options(width = 1000)
## this vignette is in .Rbuildignore because lme4 is not available on old CRAN
## test machines.

knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 9,
  fig.asp = .4,
  out.width = "100%",
  warning = FALSE,
  message = FALSE,
  comment = "#>"
)
```

The _S_ value --- "Shannon transform" or "binary surprisal value" --- is a cognitive tool to help analysts make intuitive sense of p values [@RafGre2020]. It allows us to compare a p value to the outcome of a familiar game of chance.

Consider this: We toss a coin 4 times to see if we can reject the null hypothesis that the coin toss is fair. If the null is true, the probability of drawing *Heads* on any single toss is $\frac{1}{2}$. The probability of observing 4 *Heads* in a row is $\left (\frac{1}{2} \right )^4=\frac{1}{16}=0.0625$. This probability characterizes the "surprise" caused by observing 4 straight heads in a world where the null holds, that is, where the coin toss is fair.

Now consider a different exercise: We estimate a model and use `marginaleffects::hypotheses()` to test if two of the estimated coefficients are equal:

```{r}
library(marginaleffects)
dat <- transform(mtcars, cyl = factor(cyl))
mod <- lm(mpg ~ cyl, dat)
hyp <- hypotheses(mod, "cyl6 = cyl8")
hyp
```

The difference between `cyl6` and `cyl8` is `r sprintf("%.2f", hyp$estimate)`, and the associated p value is `r hyp$p.value`. Again, the p value can be interpreted as a measure of the surprise caused by the data if the null were true (i.e., if the two coefficients were in fact equal).

How many consecutive *Heads* tosses would be as surprising as this test of equality? To answer this question, we solve for $s$ in $p=\left (\frac{1}{2} \right )^s$. The solution is the negative $log_2$ of p:

```{r}
#| include: false
attr(hyp$p.value, "label") <- attr(hyp$p.value, "jacobian") <- NULL
```
```{r}
-log2(hyp$p.value)
```

Indeed, the probability of obtaining 9 straight *Heads* with fair coin tosses is $\left (\frac{1}{2} \right )^9=`r .5^9`$, which is very close to the p value we observed in the test of coefficient equality (see the _S_ column in the `marginaleffects` printout above). Comparing our p value to the outcome of such a familiar game of chance gives us a nice intuitive interpretation:

> If the `cyl6` and `cyl8` coefficients were truly equal, finding an absolute difference greater than `r sprintf("%.2f", hyp$estimate)` purely by chance would be as surprising as tossing 9 straight *Heads* with a fair coin toss.

The benefits of _S_ values include [@ColEdwGre2021]:

1. Calibrates the analyst's intuitions by reference to a well-known physical process (coin flips).
1. Avoids the problematic dichotomization of findings as "significant" and "not significant" [@Rot2021].
1. Reduces the reliance on arbitrary thresholds of significance like $\alpha=0.05$.
1. Guards against the common *mis*interpretation of p values as the "probability that the null hypothesis is true" or as the probability of the alternative hypothesis. This is in part because S is above 1 whenever p<0.5.^[Thanks to Sander Greenland for this note.]
1. Refers to a more natural scale: "The difference between a p value of 0.99 and 0.90 in terms of how surprising the observed test statistic is, is not the same as the difference between 0.10 and 0.01."^[Thanks to Zad Rafi for noting this and for linking to [@RafGre2020].]

```{r, echo=FALSE, fig.asp=1, fig.width = 5}
# Create a sequence of p values from 0 to 1
p_values <- seq(0, 1, length.out = 100)

# Compute the S values using -log2(p)
S_values <- -log2(p_values)

# Create the plot
plot(p_values, S_values, type = "l",
     main = "Deterministic relationship between p and S",
     xlab = "p",
     ylab = "S")

text(x = 0.15, y = 6, labels = "Surprising")
text(x = 0.85, y = .75, labels = "Unsurprising")
```