[
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite marginaleffects in publications, please use:\n\nArel-Bundock V, Greifer N, Heiss A (Forthcoming). “How to Interpret Statistical Models Using in and .” Journal of Statistical Software. https://marginaleffects.com.",
    "crumbs": [
      "Get started",
      "Citation"
    ]
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\ntype=\"invlink(link)\" is no longer default in avg_predictions() or when calling predictions() with the by argument. It is still default in predictions() without the by argument. The backtransform strategy is still available with by setting type=\"invlink(link)\" explicitly.\nThe type argument in plot_comparisons() now defaults to NULL, which is now consistent with comparisons() and avg_comparisons(). Before, the default was type=\"response\". Thanks to @giakhang1906 for report #1202.\n\nNew models supported:\n\nstpm2, pstpm2, gsm, and aft models from rstpm2. Thanks to @aghaynes and @mclements.\nglm_weightit, coxph_weightit, multinom_weightit, and ordinal_weightit models from Weightit. Thanks to @ngreifer.\nglmmgee from the glmtoolbox package. Thanks to @adrianolszewski for the request and @lhvanegasp for help with implementation.\n\nNew features:\n\nParallel computation with future is more efficient by chunking tasks to avoid passing large objects to every worker for every future. Issue #1158.\nAll columns of newdata are passed to the hypothesis function when newdata is supplied explicitly. Thanks to @gravesti for report #1175.\nhypotheses(joint=TRUE): do not call stats::nobs() unless necessary.\nhypotheses() supports formulas in the hypothesis argument: hypotheses(model, hypothesis = ratio ~ reference)\nGlobal option: options(\"marginaleffects_print_omit\" = \"s.value\")\nRound significant digits for labels in plot_predictions(mod, condition = list(x = \"fivenum\"))\nprint() no longer prints contrast and term columns when values are unique. The labels were often very long, and the content is already explicit in the call itself, so there’s no ambiguity.\nNo warning raised when discrete argument is used with mgcv::bam and mgcv::gam models objects. Thanks to @Aariq for the request.\ntidymodels support is improved. Users can now directly feed some of them without specifying newdata explicitly. Thanks to @davidkane9 for the feature request.\n\nBugs:\n\nAverage lift and average comparisons with user-supplied functions could be be calculated incorrectly when all predictors were categorical. Thanks to @Dpananos for Issue #1151.\nIndexing bug returned NA for some commands in survey models. Thanks to @weikang9009 for report #1161.\nRespect default tinytable theme.\nInverted confidence interval bounds with some inverse link functions. Thanks to @strengejacke for report #1204.\n\n\n\n\nNew:\n\nhypothesis accepts formulas like: ratio ~ sequential | group\nAllow reverse binary contrasts: comparisons(mod, variables = list(am = 1:0, vs = 0:1)). Thanks to K. Henry for report #1137.\noptions(marginaleffects_safe = FALSE) disables some safety checks and allows unadvisable (but potentially) useful features like many pairwise comparisons. Thanks to D.Locke for the feature request.\nnewdata=\"balanced\" is a shortcut to produce estimates at combinations of all categorical predictors, holding numeric predictors at their means. Equivalent to datagrid(grid_type=\"balanced\")\n\nMisc:\n\nDeprecation warning for specify_hypothesis(). This function was clearly marked as experimental, and has been available only for one release. It was a bad idea. Users should supply a custom function or a formula to the hypothesis argument. The new formula interface, in particular, makes it very easy to conduct group-wise hypothesis tests.\nType checks are a bit looser to accommodate custom models.\n\nBugs:\n\nFix regression in mlogit models due to factor conversion. This raised an error before returning result, so there is no numerical danger.\nsurvey package models work when row.names(model) is not coercible to integers. Thanks to @ngreifer for report #1131.\n\n\n\n\n\nThe comparison argument of the comparisons() function is automatically switched to the avg version of the function shortcuts when calling avg_comparisons() or setting by=TRUE. For example, comparison=\"ratio\" becomes comparison=\"ratioavg\" when calling avg_comparisons(). Note that comparison=\"ratioavg\" is equivalent to: comparison = \\(hi,lo) mean(hi)/mean(lo)\nFixed a bug (“non-conformable arguments”) when using survreg objects from survival::survreg().\nFixed bug in inferences() for GLM models and type=\"invlink\", where the wrong scale would be reported for confidence intervals.\n\n\n\n\nBreaking changes:\n\nThe order of the group column is preserved when the original variable is a factor. This may change the order of output, which could have an effect on hypothesis tests using the hypothesis=\"b1=b3\" syntax.\n\nNew:\n\nNew experimental function: specify_hypothesis() returns functions to be used in the hypothesis argument of predictions(), comparisons(), and slopes(). This convenience function can be used to specify complex aggregations and estimands for hypothesis tests (ex: by subgroups or with custom functions).\nhypothesis argument accepts “meandev” and “meanotherdev” to compute deviations from the mean estimate.\nDo not raise extraneous warning for survey package models when the by argument is not used.\nInformative error when hypotheses() is called twice on the same object.\nprint(\"tinytable\") adds footnotes to the table with columns and type information.\n\nBugs:\n\nmlogit predict() method does not play well with data.table. Thanks to @andrewheiss for report #1086.\nAvoid merging newdata in predictions() when hypothesis can change the meaning of rows. Avoid Issue #1105 reported by @strengejacke.\ninferences() did not work with the transform argument. Thanks to Demetri Pananos for report #1115.\n\n\n\n\nBreaking changes:\n\ndatagrid() no longer includes the response variable by default when it is not explicitly specified by the user. Use the new response argument to include it.\ndatagrid(grid_type=\"balanced\") returns factors ordered by level rather than by order of appearance in the original data.\nOrder of some rows in the output may differ when using datagrid(). Necessary to fix issue #1079 (see below).\n\nNew modeling packages supported:\n\nflexsurv: Thanks to @mattwarkentin for code contributions in PR #781. https://cran.r-project.org/web/packages/flexsurv/index.html\nREndo: https://cran.r-project.org/web/packages/REndo/index.html\n\nNew:\n\nwts=TRUE tries to retrieves weights used in a weighted fit such as lm() with the weights argument or a model fitted using the survey package. Thanks to @ngreifer for feature request\nprint.marginaleffects() supports style=\"tinytable\", which returns a tinytable object. Call print(avg_slopes(model)) to get a nice printed table in Quarto or Rmarkdown documents, via Typst, LaTeX or HTML. Default print format can be set using: options(marginaleffects_print_style=\"tinytable\")\nhypothesis argument accepts a function which takes a marginaleffects data frame and returns a transformed data frame with term and estimate columns.\ndatagrid() gets a response argument (default is FALSE) to control if the response variable is included or excluded from the grid-building process.\nThe base::subset() and dplyr::filter() functions can be called with a single argument in newdata to select a subset of rows from the dataset used to fit the model.\n\nEx: avg_comparisons(fit, variables = “treatment”, newdata = subset(treatment == 1))`\n\nBetter warning for unsupported arguments.\ndf argument in hypotheses() accepts a vector of length 2 to control degrees of freedom in F tests.\nnlme::lme() objects raise a warning about degrees of freedom. Thanks to and @stefgehrig and @huftis for discussion in Issue #960.\n\nMajor bugs:\n\nSome results could be mislabelled with factor variables used in combination with datagrid() or condition. Thanks to @snhansen for report #1079.\nglmmTMB models now report correct standard errors, and raise a warning that these standard errors only account for uncertainty in fixed effect parameters. Thanks to contributors to Issue #1024 and especially to @bbolker for discussion and solution.\n\nMinor bugs:\n\nUninformative error when a custom comparison function returns NA in bayesian models. Thanks to @Sandhu-SS for report #1017.\ndatagrid() returns an object with full attributes when by is used. Thanks to @Sandhu-SS for report #1058.\ninferences(method=\"simulation\") with inferences() function. Thanks to @davidarmstrong for report #1054.\n\n\n\n\nThis release represents a major step towards 1.0.0. Some functions are renamed and now raise deprecation warnings. After 1.0.0, the API will become much more stable, and any change will have to be very deliberate with much lead time and deprecation delays.\nBreaking changes:\n\ntidy() no longer takes the average of estimates in the original model object. Users who want an aggregate estimate should call the relevant avg_*() function, or use the by argument explicitly. The previous behavior led to unexpected behavior and increased code complexity a lot.\nsummary() methods are removed. These have never provided any additional information; they just reprinted the output already available with the standard print method. At least the default summary() for data frames (which is now triggered on marginaleffects object) provides a different view on the content of the object.\nplot_cco(), plot_cme(), and plot_cap() were renamed in version 0.9.0, one year ago. They are now fully removed from the package.\n\nNew:\n\ndatagrid(grid_type = \"balanced\") creates a balanced grid with all unique values of categorical predictors. This can be used with predictions() to compute marginal means as in the emmeans package.\nmvgam package support (multivariate generalized additive models)\n\nDeprecation warnings:\n\ndeltamethod() has been named hypotheses() for a while. We now issue a deprecation warning and it will be removed eventually.\ndatagridcf() will eventually be deprecated and removed from the package. We will raise a warning for at least one year before removing the function. Identical results can be obtained with datagrid(..., grid_type=\"counterfactual\")\nmarginal_means() will eventually be deprecated and removed from the package. We will raise a warning for at least one year before removing the function. Identical results can be obtained using the predictions() function and the grid_type=\"balanced\" argument of datagrid(). Examples are in the marginal means vignette on the website.\n\nMinor:\n\nBetter warning messages for unsupported matrix columns, enhancing user experience and troubleshooting.\nVarious improvements to documentation.\nTypos\nRepository hosts model objects for easier testing.\n\nBug fixes:\n\nError on hypotheses(joint = \"string\") for comparisons() objects (no result was returned). Thanks to @BorgeJorge for report #981.\nEnhanced support for multi-equation Bayesian models with brms models. Thanks to @winterstat for report #1006.\nParameter names with spaces could break standard errors. Thanks to @Lefty2021 for report #1005.\n\n\n\n\nBreaking changes:\n\nThe comparisons() now uses “forward contrasts” by default for numeric predictors, instead of “centered contrasts”. This can lead to small numerical differences in non-linear models.\nThe variables argument of the comparisons() function no longer accepts numeric vectors unless they are of length 2, specifying the low and high contrast values. This is to avoid ambiguity between the two vector version. Users should supply a data frame or a function instead. This is nearly as easy, and removes ambiguity.\n\nNew supported packages:\n\ndbarts: https://cran.r-project.org/package=dbarts\nmvgam: https://nicholasjclark.github.io/mvgam/ Not available on CRAN yet, but this package maintains its own marginaleffects support function.\nrms::Gls: https://cran.r-project.org/package=rms\n\nMisc:\n\ncomparisons(): The variables argument now accepts functions and data frames for factor, character, and logical variables.\nDeprecation warning for: plot_cap(), plot_cme(), and plot_cco(). These function names will be removed in version 1.0.0.\noptions(modelsummary_factory_default=...) is respected in Quarto and Rmarkdown documents.\n\nBugs:\n\nwts argument now respected in avg_slopes() for binary variables. Thanks to @trose64 for report #961\nCustom functions in the comparison argument of comparisons() did not supply the correct x vector length for bayesian models when the by argument is used. Thanks to @Sandhu-SS for report #931.\nAdd support for two facet variables (through facet_grid) when plotting using condition\ncomparisons(): When variables is a vector of length two and newdata has exactly two columns, there was ambiguity between custom vectors and length two vector of contrasts. Bug reported by C. Rainey on Twitter.\nSuperfluous warning with fixest::fenegbin.\n\n\n\n\nMachine learning support:\n\ntidymodels package\nmlr3 package\n\nMisc:\n\nNew vignettes:\n\nInverse Probability Weighting\nMachine Learning\nMatching\n\nAdd support for hypotheses() to inferences(). Thanks to @Tristan-Siegfried for code contribution #908.\nSupport survival::survreg(). Thanks to Carlisle Rainey for Report #911.\ncolumn_names argument in print.marginaleffects() to suppress the printed column names at the bottom of the printout.\nThe function supplied to the comparison argument of the comparisons() function can now operate on x and on newdata directly (e.g., to check the number of observations).\nMore informative errors from predict().\n\nBugs:\n\nSome gamlss models generated an error related to the what argument. Thanks to @DHLocke for Issue #933\n\n\n\n\n\nhypotheses(): The FUN argument handles group columns gracefully.\nNative support for Amelia for multiple imputation.\n\nDocumentation:\n\nNew section on “Complex aggregations” in the Hypothesis testing vignette.\n\nBug fix:\n\nResults of the predictions() function could be inaccurate when (a) running version 0.15.0, (b) type is NULL or invlink(link), (c) model is glm(), and (d) the hypothesis argument is non-numeric. Thanks to @strengejacke for report #903\n\n\n\n\nNew:\n\nConformal prediction via inferences()\nhypothesis argument now accepts multiple string formulas.\nThe type argument now accepts an explicit invlink(link) value instead of silently back-transforming. Users are no longer pointed to type_dictionary. Instead, they should call their function with a bad type value, and they will obtain a list of valid types. The default type value is printed in the output. This is useful because the default type value is NULL, so the user often does not explicitly decide.\nAllow install with Rcpp 1.0.0 and greater.\n\nSupport new models:\n\nsurvey::svyolr()\n\nMisc:\n\ninferences(method=\"simulation\") uses the original point estimate rather than the mean of the simulation distribution. Issue #851.\nBetter documentation and error messages for newdata=NULL\nSome performance improvements for predictions() and marginalmeans() (#880, #882, @etiennebacher).\n\nBug fix:\n\nnewdata=\"median\" returned mean of binary variables. Thanks to @jkhanson1970 for report #896.\n\n\n\n\nBreaking changes:\n\nRow order of the output changes for some objects. Rows are not sorted alphabetically by term, by, and variables explicitly supplied to datagrid. This can affect hypothesis tests computed using the b1, b2, b3, and other indices.\nNew procedure numderiv argument use a different procedure to select the step size used in the finite difference numeric derivative used to compute standard errors: abs(x) * sqrt(.Machine$double.eps). The numerical results may not be exactly identical to previous versions of marginaleffects, but the step size should be adequate in a broader variety of cases. Note that users can use the numderiv argument for more control on numeric differentiation, as documented.\nbife models are no longer supported pending investigation in weird results in the tests. Looking for volunteers write more thorough tests.\n\nNew:\n\nSupport: logistf package.\nSupport: DCchoice package.\nSupport: stats::nls\nhypotheses() can now accept raw data frame, which gives a lot of flexibility for custom contrasts and functions. See the Hypothesis vignette for an example.\nnumderiv argument allows users to use finite difference (center or forward) or Richardson’s method to compute the numerical derivatives used in the calculation of standard errors.\n\nBug fixes:\n\ninferences() supports the cross argument for comparisons() objects. Thanks to Kirill Solovev for report #856.\nsplines::bs() in formulas could produce incorrect results due to weirdness in stats::model.matrix(). Thanks to @chiungming for report #831.\nmgcv with ocat are now supported. Thanks to Lorenzo Fabbri for Issue #844.\nquantreg problem with rowid merge did not affect estimates but did not return the full original data. Issue #829.\nget_modeldata() extracts weights variable when available.\npredictions() is no longer broken in some inferences() calls. Issue #853\nInaccurate averaging with comparison=differenceavg some models where all predictors are categorical. Thanks to Karl Ove Hufthammer for report #865.\n\nMisc:\n\nMajor refactor to simplify the code base and make maintenance easier.\n\n\n\n\nBreaking change:\n\nglmmTMB: Standard errors are no longer supported because they may have been erroneous. Follow Issue #810 on Github for developments: https://github.com/vincentarelbundock/marginaleffects/issues/810\n\nNew:\n\nhypothesis argument accepts wildcards: hypothesis = \"b*=b1\"\ns.value column in all output: Shannon transforms for p values. See Greenland (2019).\nmarginal_means supports mira (mice objects).\ncomparisons(): The variables arguments now accepts arbitrary numeric vectors of length equal to the number of rows in newdata. This allows users to specify fully custom treatment sizes. In the documentation examples, we show how to estimate the difference for a 1 standard deviation shift in a regressor, where the standard deviation is calculated on a group-wise basis.\ncomparisons(): the variables argument now accepts “revpairwise”, “revsequential”, “revreference” for factor and character variables.\ncomparisons(): the comparison argument now accept “lift” and “liftavg”.\n\nPerformance:\n\nComputing elasticities for linear models is now up to 30% faster (#787, @etiennebacher).\n\nBug fixes:\n\nBetter handling of environments when newdata is a function call. Thanks to @jcccf for report #814 and to @capnrefsmmat for the proposed fix using the rlang package.\nDegrees of freedom mismatch for joint hypothesis tests. Thanks to @snhansen for report #789.\n\n\n\n\nBreaking change:\n\nRow order of output has changed for many calls, especially those using the by argument. This may break hypothesis tests conducted by indexing b1, b2, etc. This was necessary to fix Issue #776. Thanks to @marcora for the report.\n\nNew:\n\nhypotheses(): Joint hypothesis tests (F and Chi-square) with the joint and joint_test arguments.\nvcov.hypotheses method.\nwts is now available in plot_predictions(), plot_comparisons(), and plot_slopes().\n\nBug:\n\nWrong order of rows in bayesian models with by argument. Thanks to @shirdekel for report #782.\n\n\n\n\n\nvcov() and coef() methods for marginaleffects objects.\nStrings in wts are accepted with the by argument.\npredictions() and avg_predictions() no longer use an automatic backtransformation for GLM models unless hypothesis is NULL.\nvcov() can be used to retrieve a full variance-covariance matrix from objects produced by comparisons(), slopes(), predictions(), or marginal_means() objects.\nWhen processing objects obtained using mice multiple imputation, the pooled model using mice::pool is attached to the model attribute of the output. This means that functions like modelsummary::modelsummary() will not erroneously report goodness-of-fit statistics from just a single model and will instead appropriately report the statistics for the pooled model. Thanks to @Tristan-Siegfried for PR #740.\nMore informative error messages on some prediction problems. Thanks to @andymilne for Report #751.\n\nPerformance:\n\ninferences() is now up to 17x faster and much more memory-efficient when method is \"boot\" or \"rsample\" (#770, #771, @etiennebacher).\n\nBugs:\n\nbrms models with nl=TRUE and a single predictor generated an error. Thanks to @Tristan-Siegried for Report #759.\navg_predictions(): Incorrect group-wise averaging when all predictors are categorical, the variables variable is used, and we are averaging with avg_ or the by argument. Thanks to BorgeJorge for report #766.\nBug when datagrid() when called inside a user-written function. Thanks to @NickCH-K for report #769 and to @capnrefsmmat for the diagnostics.\n\n\n\n\nBreaking change:\n\nRow orders are now more consistent, but may have changed from previous version. This could affect results from hypothesis with b1, b2, … indexing.\n\nSupport new models:\n\nnlme::lme()\nphylolm::phylolm()\nphylolm::phyloglm()\n\nNew:\n\nVignette on 2x2 experimental designs. Thanks to Demetri Pananos.\ncomparisons() accepts data frames with two numeric columns (“low” and “high”) to specify fully customizable contrasts.\ndatagrid() gets a new by argument to create apply grid-making functions within groups.\nplot_*() gain a newdata argument for use with by.\n\nBug:\n\ncomparisons(comparison = \"lnratioavg\") ignored wts argument. Thanks to Demetri Pananos for report #737.\nordinal::clm(): incorrect standard errors when location and scale parameters are the same. Thanks to MrJerryTAO for report #718.\nIncorrect label for “2sd” comparisons. Thanks to Andy Milne for report #720.\nInvalid factor levels in datagrid() means newdata argument gets ignored. Thanks to Josh Errickson for report #721.\nError in models with only categorical predictors and the by argument. Thanks to Sam Brilleman for report #723.\nElasticities are now supported for ordinal::clm() models. Thanks to MrJerryTAO for report #729.\nglmmTMB models with zero-inflated components are supported. Thanks to @Helsinki-Ronan and @strengejacke for report #734.\n\n\n\n\nBreaking changes:\n\ntype column is replaced by type attribute.\npredictions() only works with officially supported model types (same list as comparisons() and slopes()).\n\nRenamed arguments (backward compatibility is preserved):\n\ntransform_pre -&gt; comparison\ntransform_post -&gt; transform\n\nNew:\n\np_adjust argument: Adjust p-values for multiple comparisons.\nequivalence argument available everywhere.\n\nPerformance:\n\nMuch faster results in avg_*() functions for models with only categorical predictors and many rows of data, using deduplication and weights instead of unit-level estimates.\nFaster predictions in lm() and glm() models using RcppEigen.\nBayesian models with many rows. Thanks to Etienne Bacher. #694\nFaster predictions, especially with standard errors and large datasets.\n\nBugs:\n\nMultiple imputation with mira objects was not pooling all datasets. Thanks to @Generalized for report #711.\nSupport for more models with offsets. Thanks to @mariofiorini for report #705.\nError on predictions() with by and wts. Thanks to Noah Greifer for report #695.\nafex: some models generated errors. Thanks to Daniel Lüdecke for report #696.\ngroup column name is always forbidden. Thanks to Daniel Lüdecke for report #697.\nBlank graphs in plot_comparisons() with a list in variables.\ntype=\"link\" produced an error with some categorical brms models. Thanks to @shirdekel for report #703.\nError on predictions(variables = ...) for glmmTMB models. Thanks to Daniel Lüdecke for report #707.\nby with user-specified function in comparison and factor predictor did not aggregate correctly. Thanks to @joaotedde for report #715.\nordinal::clm: Support cum.prob and linear.predictor prediction types. Thanks to @MrJerryTAO for report #717.\n\n\n\n\nPerformance:\n\n2-4x faster execution for many calls. Thanks to Etienne Bacher.\n\nNew models supported:\n\nMCMCglmm::MCMCglmm\nRchoice::hetprob\nRchoice::ivpml\nMultiple imputation using mice and any package which can return a list of imputed data frames (e.g., Amelia, missRanger, etc.)\n\nPlot improvements:\n\nNew by argument to display marginal estimates by subgroup.\nNew rug argument to display tick marks in the margins.\nNew points argument in plot_predictions() to display a scatter plot.\nNew gray argument to plot in grayscale using line types and shapes instead of color.\nThe effect argument is renamed to variables in plot_slopes() and plot_comparisons(). This improves consistency with the analogous slopes() and comparisons() functions.\nThe plotting vignette was re-written.\n\nOther:\n\nSupport multiple imputation with mice mira objects. The multiple imputation vignette was rewritten.\nThe variables_grid argument in marginal_means() is renamed newdata. Backward compatibility is maintained.\navg_*() returns an informative error when vcov is “satterthwaite” or “kenward-roger”\n“satterthwaite” and “kenward-roger” are now supported when newdata is not NULL\nInformative error when hypothesis includes a b# larger than the available number of estimates.\navg_predictions(model, variables = \"x\") computes average counterfactual predictions by subgroups of x\ndatagrid() and plot_*() functions are faster in datasets with many extraneous columns.\nIn predictions(type = NULL) with glm() and Gam() we first make predictions on the link scale and then backtransform them. Setting type=\"response\" explicitly makes predictions directly on the response scale without backtransformation.\nStandard errors now supported for more glmmTMB models.\nUse the numDeriv package for numeric differentiation in the calculation of delta method standard error. A global option can now be passed to numDeriv::jacobian:\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6)))\noptions(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-6)))\noptions(marginaleffects_numDeriv = NULL)\n\nPrint:\n\nPrint fewer significant digits.\nprint.marginaleffects now prints all columns supplied to newdata\nLess redundant labels when using hypothesis\n\nMany improvements to documentation.\n\nBugfixes:\n\nStandard errors could be inaccurate in models with non-linear components (and interactions) when some of the coefficients were very small. This was related to the step size used for numerical differentiation for the delta method. Issue #684.\navg_predictions(by =) did not work when the dataset included a column named term. Issue #683.\nbrms models with multivariate outcome collapsed categories in comparisons(). Issue #639.\nhypotheses() now works on lists and in calls to lapply(), purrr::map(), etc. Issue #660.\n\n\n\n\nBreaking changes:\n\nAll functions return an estimate column instead of the function-specific predicted, comparisons, dydx, etc. This change only affects unit-level estimates, and not average estimates, which already used the estimate column name.\nThe transform_avg argument in tidy() deprecated. Use transform_post instead.\nplot_*(draw=FALSE) now return the actual variable names supplied to the condition argument, rather than the opaque “condition1”, “condition2”, etc.\n\nNew models supported:\n\nblme package.\n\nNew features:\n\nNew functions: avg_predictions(), avg_comparisons(), avg_slopes()\nEquivalence, non-inferiority, and non-superiority tests with the hypotheses() function and equivalence argument.\nNew experimental inferences() function: simulation-based inferences and bootstrap using the boot, rsample, and fwb package.\nNew df argument to set degrees of freedom manually for p and CI.\nPretty print() for all objects.\nby argument\n\nTRUE returns average (marginal) predictions, comparisons, or slopes.\nSupports bayesian models.\n\nhypothesis argument\n\nNumeric value sets the null used in calculating Z and p.\nExample: comparisons(mod, transform_pre = \"ratio\", hypothesis = 1)\n\nAll arguments from the main functions are now available through tidy(), and summary(): conf_level, transform_post, etc.\nBayesian posterior distribution summaries (median, mean, HDI, quantiles) can be customized using global options. See ?comparisons\n\nRenamed functions (backward-compatibility is maintained by keeping the old function names as aliases):\n\nmarginaleffects() -&gt; slopes()\nposteriordraws() -&gt; posterior_draws()\nmarginalmeans() -&gt; marginal_means()\nplot_cap() -&gt; plot_predictions()\nplot_cme() -&gt; plot_slopes()\nplot_cco() -&gt; plot_comparisons()\n\nBug fixes:\n\nIncorrect results: In 0.8.1, plot_*() the threenum and minmax labels did not correspond to the correct numeric values.\nFix corner case for slopes when the dataset includes infinite values.\nmlogit error with factors.\nThe vcov argument now accepts functions for most models.\n\nOther:\n\nRemoved major performance bottleneck for slopes()\n\n\n\n\n\ndeltamethod() can run hypothesis tests on objects produced by the comparisons(), marginaleffects(), predictions(), and marginalmeans() functions. This feature relies on match.call(), which means it may not always work when used programmatically, inside functions and nested environments. It is generally safer and more efficient to use the hypothesis argument.\nplot_cme() and plot_cco() accept lists with user-specified values for the regressors, and can display nice labels for shortcut string-functions like “threenum” or “quartile”.\nposterior_draws: new shape argument to return MCMC draws in various formats, including the new rvar structure from the posterior package.\ntransform_avg function gets printed in summary() output.\ntransform_post and transform_avg support string shortcuts: “exp” and “ln”\nAdded support for mlm models from lm(). Thanks to Noah Greifer.\n\nBug fixes:\n\nhypothesis argument with bayesian models and tidy() used to raise an error.\nMissing values for some regressors in the comparisons() output for brms models.\n\n\n\n\nBreaking change:\n\nThe interaction argument is deprecated and replaced by the cross argument. This is to reduce ambiguity with respect to the interaction argument in emmeans, which does something completely different, akin to the difference-in-differences illustrated in the Interactions vignette.\n\n71 classes of models supported, including the new:\n\nrms::ols\nrms::lrm\nrms::orm\n\nNew features:\n\nPlots: plot_cme(), plot_cap(), and plot_cco() are now much more flexible in specifying the comparisons to display. The condition argument accepts lists, functions, and shortcuts for common reference values, such as “minmax”, “threenum”, etc.\nvariables argument of the comparisons() function is more flexible:\n\nAccepts functions to specify custom differences in numeric variables (e.g., forward and backward differencing).\nCan specify pairs of factors to compare in the variables argument of the comparisons function.\n\nvariables argument of the predictions() function is more flexible:\n\nAccepts shortcut strings, functions, and vectors of arbitrary length.\n\nIntegrate out random effects in bayesian brms models (see Bayesian analysis vignette)\n\nNew vignettes:\n\nExperiments\nExtending marginal effects\nIntegrating out random effects in bayesian models\n\nBug fixes and minor improvements:\n\nThe default value of conf_level in summary() and tidy() is now NULL, which inherits the conf_level value in the original comparisons/marginaleffects/predictions calls.\nFix typo in function names for missing “lnratioavgwts”\nInteractions with fixest::i() are parsed properly as categorical variables\nFor betareg objects, inference can now be done on all coefficients using deltamethod(). previously only the location coefficients were available.\nFor objects from crch package, a number of bugs have been fixed; standard errors should now be correct for deltamethod(), marginaleffects(), etc.\nFixed a bug in the tidy() function for glmmTMB models without random effects, which caused all t statistics to be identical.\n\n\n\n\n\nNew supported model class: gamlss. Thanks to Marcio Augusto Diniz.\nmarginalmeans() accepts a wts argument with values: “equal”, “proportional”, “cells”.\nby argument\n\naccepts data frames for complex groupings.\nin marginalmeans only accepts data frames.\naccepts “group” to group by response level.\nworks with bayesian models.\n\nbyfun argument for the predictions() function to aggregate using different functions.\nhypothesis argument\n\nThe matrix column names are used as labels for hypothesis tests.\nBetter labels with “sequential”, “reference”, “pairwise”.\nnew shortcuts “revpairwise”, “revsequential”, “revreference”\n\nwts argument is respected in by argument and with *avg shortcuts in the transform_pre argument.\ntidy.predictions() and tidy.marginalmeans() get a new transform_avg argument.\nNew vignettes:\n\nUnit-level contrasts in logistic regressions. Thanks to @arthur-albuquerque.\nPython Numpy models in marginaleffects. Thanks to timpipeseek.\nBootstrap example in standard errors vignette.\n\n\n\n\n\nBreaking changes:\n\nby is deprecated in summary() and tidy(). Use the same by argument in the main functions instead: comparisons(), marginaleffects(), predictions()\nCharacter vectors are no longer supported in the variables argument of the predictions() function. Use newdata=\"fivenum\" or “grid”, “mean”, or “median” instead.\n\nCritical bug fix:\n\nContrasts with interactions were incorrect in version 0.6.0. The error should have been obvious to most analysts in most cases (weird-looking alignment). Thanks to @vmikk.\n\nNew supported packages and models:\n\nsurvival::clogit\nbiglm: The main quantities can be computed, but not the delta method standard errors. See https://github.com/vincentarelbundock/marginaleffects/issues/387\n\nNew vignette:\n\nElasticity\nFrequently Asked Questions\n\nNew features:\n\nElasticity and semi-elasticity using the new slope argument in marginaleffects(): eyex, dyex, eydx\ndatagrid() accepts functions: datagrid(newdata = mtcars, hp = range, mpg = fivenum, wt = sd)\nNew datagridcf() function to create counterfactual datasets. This is a shortcut to the datagrid() function with default to grid_type = \"counterfactual\"\nNew by arguments in predictions(), comparisons(), marginaleffects()\nNew newdata shortcuts: “tukey”, “grid”\nNew string shortcuts for transform_pre in comparisons()\nmarginalmeans() now back transforms confidence intervals when possible.\nvcov argument string shortcuts are now case-insensitive\nThe default contrast in comparisons() for binary predictors is now a difference between 1 and 0, rather than +1 relative to baseline.\ndocumentation improvements\n\n\n\n\nNew supported packages and models:\n\ntidymodels objects of class tidy_model are supported if the fit engine is supported by marginaleffects.\n\nNew function:\n\ndeltamethod(): Hypothesis tests on functions of parameters\nplot_cco(): Plot conditional contrasts\n\nNew arguments:\n\nhypothesis for hypothesis tests and custom contrasts\ntransform_post in predictions()\nwts argument in predictions() only affects average predictions in tidy() or summary().\n\nNew or improved vignettes:\n\nHypothesis Tests and Custom Contrasts using the Delta Method: https://marginaleffects.com/vignettes/hypothesis.html\nMultiple Imputation: https://marginaleffects.com/vignettes/multiple_imputation.html\nCausal Inference with the g-Formula: https://marginaleffects.com/vignettes/gcomputation.html (Thanks to Rohan Kapre for the idea)\n\nDeprecated or renamed arguments:\n\ncontrast_factor and contrast_numeric arguments are deprecated in comparisons(). Use a named list in the variables argument instead. Backward compatibility is maintained.\nThe transform_post argument in tidy() and summary() is renamed to transform_avg to disambiguate against the argument of the same name in comparisons(). Backward compatibility is preserved.\n\nMisc:\n\ntidy.predictions() computes standard errors using the delta method for average predictions\nSupport gam models with matrix columns.\neps in marginaleffects() is now “adaptive” by default: it equals 0.0001 multiplied the range of the predictor variable\ncomparisons() now supports “log of marginal odds ratio” in the transform_pre argument. Thanks to Noah Greifer.\nNew transform_pre shortcuts: dydx, expdydx\ntidy.predictions() computes standard errors and confidence intervals for linear models or GLM on the link scale.\n\n\n\n\nBreaking changes:\n\ntype no longer accepts a character vector. Must be a single string.\nconf.int argument deprecated. Use vcov = FALSE instead.\n\nNew supported packages and models:\n\nmlogit\nmhurdle\ntobit1\nglmmTMB\n\nNew features:\n\ninteraction argument in comparisons() to compute interactions between contrasts (cross-contrasts).\nby argument in tidy() and summary() computes group-average marginal effects and comparisons.\ntransform_pre argument can define custom contrasts between adjusted predictions (e.g., log adjusted risk ratios). Available in comparisons().\ntransform_post argument allows back transformation before returning the final results. Available in comparisons(), marginalmeans(), summary(), tidy().\nThe variables argument of the comparisons() function accepts a named list to specify variable-specific contrast types.\nRobust standard errors with the vcov argument. This requires version 0.17.1 of the insight package.\n\nsandwich package shortcuts: vcov = \"HC3\", \"HC2\", \"NeweyWest\", and more.\nMixed effects models: vcov = \"satterthwaite\" or \"kenward-roger\"\nOne-sided formula to clusters: vcov = ~cluster_variable\nVariance-covariance matrix\nFunction which returns a named squared matrix\n\nmarginalmeans() allows interactions\nBayesian Model Averaging for brms models using type = \"average\". See vignette on the marginaleffects website.\neps argument for step size of numerical derivative\nmarginaleffects and comparisons now report confidence intervals by default.\nNew dependency on the data.table package yields substantial performance improvements.\nMore informative error messages and warnings\nBug fixes and performance improvements\n\nNew pages on the marginaleffects website: https://marginaleffects.com/\n\nAlternative software packages\nRobust standard errors (and more)\nPerformance tips\nTables and plots\nMultinomial Logit and Discrete Choice Models\nGeneralized Additive Models\nMixed effects models (Bayesian and Frequentist)\nTransformations and Custom Contrasts: Adjusted Risk Ratio Example\n\nArgument name changes (backward compatibility is preserved:\n\nEverywhere:\n\nconf.level -&gt; conf_level\n\ndatagrid():\n\nFUN.factor -&gt; FUN_factor (same for related arguments)\ngrid.type -&gt; grid_type\n\n\n\n\n\nNew supported packages and models:\n\nstats::loess\nsampleSelection::selection\nsampleSelection::heckit\n\nMisc:\n\nmgcv::bam models allow exclude argument.\nGam models allow include_smooth argument.\nNew tests\nBug fixes\n\n\n\n\nNew function:\n\ncomparisons() computes contrasts\n\nMisc:\n\nSpeed optimizations\npredictions() and plot_cap() include confidence intervals for linear models\nMore robust handling of in-formula functions: factor(), strata(), mo()\nDo not overwrite user’s ggplot2::theme_set() call\n\n\n\n\n\nBug fixes\n\n\n\n\nNew supported models:\n\nmclogit::mclogit\nrobust::lmRob\nrobustlmm::rlmer\nfixest confidence intervals in predictions\n\nMisc:\n\nSupport modelbased::visualisation_matrix in newdata without having to specify x explicitly.\ntidy.predictions() and summary.predictions() methods.\nDocumentation improvements.\nCRAN test fixes\n\n\n\n\nSupport for new models and packages:\n\nbrglm2::bracl\nmclogit::mblogit\nscam::scam\nlmerTest::lmer\n\nMisc:\n\nDrop numDeriv dependency, but make it available via a global option: options(“marginaleffects_numDeriv” = list(method = “Richardson”, method.args = list(eps = 1e-5, d = 0.0001)))\nBugfixes\nDocumentation improvements\nCRAN tests\n\n\n\n\ndocumentation bugfix\n\n\n\nBreaking changes:\n\npredictions returns predictions for every observation in the original dataset instead of newdata=datagrid().\nmarginalmeans objects have new column names, as do the corresponding tidy and summary outputs.\n\nNew supported packages and models:\n\nbrms::brm\nrstanarm::stanglm\nbrglm2::brmultinom\nMASS::glmmPQL\naod::betabin\n\nMisc:\n\ndatagrid function supersedes typical and counterfactual with the grid.type argument. The typical and counterfactual functions will remain available and exported, but their use is not encouraged.\nposterior_draws function can be applied to a predictions or a marginaleffects object to extract draws from the posterior distribution.\nmarginalmeans standard errors are now computed using the delta method.\npredictions standard errors are now computed using the delta method when they are not available from insight::get_predicted.\nNew vignette on Bayesian models with brms\nNew vignette on Mixed effects models with lme4\nIf the data.table package is installed, marginaleffects will automatically use it to speed things up.\nContrast definition reported in a separate column of marginaleffects output.\nSafer handling of the type argument.\nComprehensive list of supported and tests models on the website.\nMany bug fixes\nMany new tests, including several against emmeans\n\n\n\n\nBreaking change:\n\ndata argument becomes newdata in all functions.\n\nNew supported packages and models:\n\nlme4:glmer.nb\nmgcv::gam\nordinal::clm\nmgcv\n\nmarginalmeans:\n\nNew variables_grid argument\n\npredictions:\n\nSupport mgcv\n\nplot_cap\n\nNew type argument\n\nMisc:\n\nNew validity checks and tests\n\n\n\n\nFirst release. Bravo!\nThanks to Marco Avina Mendoza, Resul Umit, and all those who offered comments and suggestions.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section",
    "href": "NEWS.html#section",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\ntype=\"invlink(link)\" is no longer default in avg_predictions() or when calling predictions() with the by argument. It is still default in predictions() without the by argument. The backtransform strategy is still available with by setting type=\"invlink(link)\" explicitly.\nThe type argument in plot_comparisons() now defaults to NULL, which is now consistent with comparisons() and avg_comparisons(). Before, the default was type=\"response\". Thanks to @giakhang1906 for report #1202.\n\nNew models supported:\n\nstpm2, pstpm2, gsm, and aft models from rstpm2. Thanks to @aghaynes and @mclements.\nglm_weightit, coxph_weightit, multinom_weightit, and ordinal_weightit models from Weightit. Thanks to @ngreifer.\nglmmgee from the glmtoolbox package. Thanks to @adrianolszewski for the request and @lhvanegasp for help with implementation.\n\nNew features:\n\nParallel computation with future is more efficient by chunking tasks to avoid passing large objects to every worker for every future. Issue #1158.\nAll columns of newdata are passed to the hypothesis function when newdata is supplied explicitly. Thanks to @gravesti for report #1175.\nhypotheses(joint=TRUE): do not call stats::nobs() unless necessary.\nhypotheses() supports formulas in the hypothesis argument: hypotheses(model, hypothesis = ratio ~ reference)\nGlobal option: options(\"marginaleffects_print_omit\" = \"s.value\")\nRound significant digits for labels in plot_predictions(mod, condition = list(x = \"fivenum\"))\nprint() no longer prints contrast and term columns when values are unique. The labels were often very long, and the content is already explicit in the call itself, so there’s no ambiguity.\nNo warning raised when discrete argument is used with mgcv::bam and mgcv::gam models objects. Thanks to @Aariq for the request.\ntidymodels support is improved. Users can now directly feed some of them without specifying newdata explicitly. Thanks to @davidkane9 for the feature request.\n\nBugs:\n\nAverage lift and average comparisons with user-supplied functions could be be calculated incorrectly when all predictors were categorical. Thanks to @Dpananos for Issue #1151.\nIndexing bug returned NA for some commands in survey models. Thanks to @weikang9009 for report #1161.\nRespect default tinytable theme.\nInverted confidence interval bounds with some inverse link functions. Thanks to @strengejacke for report #1204.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-1",
    "href": "NEWS.html#section-1",
    "title": "News",
    "section": "",
    "text": "New:\n\nhypothesis accepts formulas like: ratio ~ sequential | group\nAllow reverse binary contrasts: comparisons(mod, variables = list(am = 1:0, vs = 0:1)). Thanks to K. Henry for report #1137.\noptions(marginaleffects_safe = FALSE) disables some safety checks and allows unadvisable (but potentially) useful features like many pairwise comparisons. Thanks to D.Locke for the feature request.\nnewdata=\"balanced\" is a shortcut to produce estimates at combinations of all categorical predictors, holding numeric predictors at their means. Equivalent to datagrid(grid_type=\"balanced\")\n\nMisc:\n\nDeprecation warning for specify_hypothesis(). This function was clearly marked as experimental, and has been available only for one release. It was a bad idea. Users should supply a custom function or a formula to the hypothesis argument. The new formula interface, in particular, makes it very easy to conduct group-wise hypothesis tests.\nType checks are a bit looser to accommodate custom models.\n\nBugs:\n\nFix regression in mlogit models due to factor conversion. This raised an error before returning result, so there is no numerical danger.\nsurvey package models work when row.names(model) is not coercible to integers. Thanks to @ngreifer for report #1131.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-2",
    "href": "NEWS.html#section-2",
    "title": "News",
    "section": "",
    "text": "The comparison argument of the comparisons() function is automatically switched to the avg version of the function shortcuts when calling avg_comparisons() or setting by=TRUE. For example, comparison=\"ratio\" becomes comparison=\"ratioavg\" when calling avg_comparisons(). Note that comparison=\"ratioavg\" is equivalent to: comparison = \\(hi,lo) mean(hi)/mean(lo)\nFixed a bug (“non-conformable arguments”) when using survreg objects from survival::survreg().\nFixed bug in inferences() for GLM models and type=\"invlink\", where the wrong scale would be reported for confidence intervals.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-3",
    "href": "NEWS.html#section-3",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\nThe order of the group column is preserved when the original variable is a factor. This may change the order of output, which could have an effect on hypothesis tests using the hypothesis=\"b1=b3\" syntax.\n\nNew:\n\nNew experimental function: specify_hypothesis() returns functions to be used in the hypothesis argument of predictions(), comparisons(), and slopes(). This convenience function can be used to specify complex aggregations and estimands for hypothesis tests (ex: by subgroups or with custom functions).\nhypothesis argument accepts “meandev” and “meanotherdev” to compute deviations from the mean estimate.\nDo not raise extraneous warning for survey package models when the by argument is not used.\nInformative error when hypotheses() is called twice on the same object.\nprint(\"tinytable\") adds footnotes to the table with columns and type information.\n\nBugs:\n\nmlogit predict() method does not play well with data.table. Thanks to @andrewheiss for report #1086.\nAvoid merging newdata in predictions() when hypothesis can change the meaning of rows. Avoid Issue #1105 reported by @strengejacke.\ninferences() did not work with the transform argument. Thanks to Demetri Pananos for report #1115.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-4",
    "href": "NEWS.html#section-4",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\ndatagrid() no longer includes the response variable by default when it is not explicitly specified by the user. Use the new response argument to include it.\ndatagrid(grid_type=\"balanced\") returns factors ordered by level rather than by order of appearance in the original data.\nOrder of some rows in the output may differ when using datagrid(). Necessary to fix issue #1079 (see below).\n\nNew modeling packages supported:\n\nflexsurv: Thanks to @mattwarkentin for code contributions in PR #781. https://cran.r-project.org/web/packages/flexsurv/index.html\nREndo: https://cran.r-project.org/web/packages/REndo/index.html\n\nNew:\n\nwts=TRUE tries to retrieves weights used in a weighted fit such as lm() with the weights argument or a model fitted using the survey package. Thanks to @ngreifer for feature request\nprint.marginaleffects() supports style=\"tinytable\", which returns a tinytable object. Call print(avg_slopes(model)) to get a nice printed table in Quarto or Rmarkdown documents, via Typst, LaTeX or HTML. Default print format can be set using: options(marginaleffects_print_style=\"tinytable\")\nhypothesis argument accepts a function which takes a marginaleffects data frame and returns a transformed data frame with term and estimate columns.\ndatagrid() gets a response argument (default is FALSE) to control if the response variable is included or excluded from the grid-building process.\nThe base::subset() and dplyr::filter() functions can be called with a single argument in newdata to select a subset of rows from the dataset used to fit the model.\n\nEx: avg_comparisons(fit, variables = “treatment”, newdata = subset(treatment == 1))`\n\nBetter warning for unsupported arguments.\ndf argument in hypotheses() accepts a vector of length 2 to control degrees of freedom in F tests.\nnlme::lme() objects raise a warning about degrees of freedom. Thanks to and @stefgehrig and @huftis for discussion in Issue #960.\n\nMajor bugs:\n\nSome results could be mislabelled with factor variables used in combination with datagrid() or condition. Thanks to @snhansen for report #1079.\nglmmTMB models now report correct standard errors, and raise a warning that these standard errors only account for uncertainty in fixed effect parameters. Thanks to contributors to Issue #1024 and especially to @bbolker for discussion and solution.\n\nMinor bugs:\n\nUninformative error when a custom comparison function returns NA in bayesian models. Thanks to @Sandhu-SS for report #1017.\ndatagrid() returns an object with full attributes when by is used. Thanks to @Sandhu-SS for report #1058.\ninferences(method=\"simulation\") with inferences() function. Thanks to @davidarmstrong for report #1054.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-5",
    "href": "NEWS.html#section-5",
    "title": "News",
    "section": "",
    "text": "This release represents a major step towards 1.0.0. Some functions are renamed and now raise deprecation warnings. After 1.0.0, the API will become much more stable, and any change will have to be very deliberate with much lead time and deprecation delays.\nBreaking changes:\n\ntidy() no longer takes the average of estimates in the original model object. Users who want an aggregate estimate should call the relevant avg_*() function, or use the by argument explicitly. The previous behavior led to unexpected behavior and increased code complexity a lot.\nsummary() methods are removed. These have never provided any additional information; they just reprinted the output already available with the standard print method. At least the default summary() for data frames (which is now triggered on marginaleffects object) provides a different view on the content of the object.\nplot_cco(), plot_cme(), and plot_cap() were renamed in version 0.9.0, one year ago. They are now fully removed from the package.\n\nNew:\n\ndatagrid(grid_type = \"balanced\") creates a balanced grid with all unique values of categorical predictors. This can be used with predictions() to compute marginal means as in the emmeans package.\nmvgam package support (multivariate generalized additive models)\n\nDeprecation warnings:\n\ndeltamethod() has been named hypotheses() for a while. We now issue a deprecation warning and it will be removed eventually.\ndatagridcf() will eventually be deprecated and removed from the package. We will raise a warning for at least one year before removing the function. Identical results can be obtained with datagrid(..., grid_type=\"counterfactual\")\nmarginal_means() will eventually be deprecated and removed from the package. We will raise a warning for at least one year before removing the function. Identical results can be obtained using the predictions() function and the grid_type=\"balanced\" argument of datagrid(). Examples are in the marginal means vignette on the website.\n\nMinor:\n\nBetter warning messages for unsupported matrix columns, enhancing user experience and troubleshooting.\nVarious improvements to documentation.\nTypos\nRepository hosts model objects for easier testing.\n\nBug fixes:\n\nError on hypotheses(joint = \"string\") for comparisons() objects (no result was returned). Thanks to @BorgeJorge for report #981.\nEnhanced support for multi-equation Bayesian models with brms models. Thanks to @winterstat for report #1006.\nParameter names with spaces could break standard errors. Thanks to @Lefty2021 for report #1005.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-6",
    "href": "NEWS.html#section-6",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\nThe comparisons() now uses “forward contrasts” by default for numeric predictors, instead of “centered contrasts”. This can lead to small numerical differences in non-linear models.\nThe variables argument of the comparisons() function no longer accepts numeric vectors unless they are of length 2, specifying the low and high contrast values. This is to avoid ambiguity between the two vector version. Users should supply a data frame or a function instead. This is nearly as easy, and removes ambiguity.\n\nNew supported packages:\n\ndbarts: https://cran.r-project.org/package=dbarts\nmvgam: https://nicholasjclark.github.io/mvgam/ Not available on CRAN yet, but this package maintains its own marginaleffects support function.\nrms::Gls: https://cran.r-project.org/package=rms\n\nMisc:\n\ncomparisons(): The variables argument now accepts functions and data frames for factor, character, and logical variables.\nDeprecation warning for: plot_cap(), plot_cme(), and plot_cco(). These function names will be removed in version 1.0.0.\noptions(modelsummary_factory_default=...) is respected in Quarto and Rmarkdown documents.\n\nBugs:\n\nwts argument now respected in avg_slopes() for binary variables. Thanks to @trose64 for report #961\nCustom functions in the comparison argument of comparisons() did not supply the correct x vector length for bayesian models when the by argument is used. Thanks to @Sandhu-SS for report #931.\nAdd support for two facet variables (through facet_grid) when plotting using condition\ncomparisons(): When variables is a vector of length two and newdata has exactly two columns, there was ambiguity between custom vectors and length two vector of contrasts. Bug reported by C. Rainey on Twitter.\nSuperfluous warning with fixest::fenegbin.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-7",
    "href": "NEWS.html#section-7",
    "title": "News",
    "section": "",
    "text": "Machine learning support:\n\ntidymodels package\nmlr3 package\n\nMisc:\n\nNew vignettes:\n\nInverse Probability Weighting\nMachine Learning\nMatching\n\nAdd support for hypotheses() to inferences(). Thanks to @Tristan-Siegfried for code contribution #908.\nSupport survival::survreg(). Thanks to Carlisle Rainey for Report #911.\ncolumn_names argument in print.marginaleffects() to suppress the printed column names at the bottom of the printout.\nThe function supplied to the comparison argument of the comparisons() function can now operate on x and on newdata directly (e.g., to check the number of observations).\nMore informative errors from predict().\n\nBugs:\n\nSome gamlss models generated an error related to the what argument. Thanks to @DHLocke for Issue #933",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-8",
    "href": "NEWS.html#section-8",
    "title": "News",
    "section": "",
    "text": "hypotheses(): The FUN argument handles group columns gracefully.\nNative support for Amelia for multiple imputation.\n\nDocumentation:\n\nNew section on “Complex aggregations” in the Hypothesis testing vignette.\n\nBug fix:\n\nResults of the predictions() function could be inaccurate when (a) running version 0.15.0, (b) type is NULL or invlink(link), (c) model is glm(), and (d) the hypothesis argument is non-numeric. Thanks to @strengejacke for report #903",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-9",
    "href": "NEWS.html#section-9",
    "title": "News",
    "section": "",
    "text": "New:\n\nConformal prediction via inferences()\nhypothesis argument now accepts multiple string formulas.\nThe type argument now accepts an explicit invlink(link) value instead of silently back-transforming. Users are no longer pointed to type_dictionary. Instead, they should call their function with a bad type value, and they will obtain a list of valid types. The default type value is printed in the output. This is useful because the default type value is NULL, so the user often does not explicitly decide.\nAllow install with Rcpp 1.0.0 and greater.\n\nSupport new models:\n\nsurvey::svyolr()\n\nMisc:\n\ninferences(method=\"simulation\") uses the original point estimate rather than the mean of the simulation distribution. Issue #851.\nBetter documentation and error messages for newdata=NULL\nSome performance improvements for predictions() and marginalmeans() (#880, #882, @etiennebacher).\n\nBug fix:\n\nnewdata=\"median\" returned mean of binary variables. Thanks to @jkhanson1970 for report #896.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-10",
    "href": "NEWS.html#section-10",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\nRow order of the output changes for some objects. Rows are not sorted alphabetically by term, by, and variables explicitly supplied to datagrid. This can affect hypothesis tests computed using the b1, b2, b3, and other indices.\nNew procedure numderiv argument use a different procedure to select the step size used in the finite difference numeric derivative used to compute standard errors: abs(x) * sqrt(.Machine$double.eps). The numerical results may not be exactly identical to previous versions of marginaleffects, but the step size should be adequate in a broader variety of cases. Note that users can use the numderiv argument for more control on numeric differentiation, as documented.\nbife models are no longer supported pending investigation in weird results in the tests. Looking for volunteers write more thorough tests.\n\nNew:\n\nSupport: logistf package.\nSupport: DCchoice package.\nSupport: stats::nls\nhypotheses() can now accept raw data frame, which gives a lot of flexibility for custom contrasts and functions. See the Hypothesis vignette for an example.\nnumderiv argument allows users to use finite difference (center or forward) or Richardson’s method to compute the numerical derivatives used in the calculation of standard errors.\n\nBug fixes:\n\ninferences() supports the cross argument for comparisons() objects. Thanks to Kirill Solovev for report #856.\nsplines::bs() in formulas could produce incorrect results due to weirdness in stats::model.matrix(). Thanks to @chiungming for report #831.\nmgcv with ocat are now supported. Thanks to Lorenzo Fabbri for Issue #844.\nquantreg problem with rowid merge did not affect estimates but did not return the full original data. Issue #829.\nget_modeldata() extracts weights variable when available.\npredictions() is no longer broken in some inferences() calls. Issue #853\nInaccurate averaging with comparison=differenceavg some models where all predictors are categorical. Thanks to Karl Ove Hufthammer for report #865.\n\nMisc:\n\nMajor refactor to simplify the code base and make maintenance easier.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-11",
    "href": "NEWS.html#section-11",
    "title": "News",
    "section": "",
    "text": "Breaking change:\n\nglmmTMB: Standard errors are no longer supported because they may have been erroneous. Follow Issue #810 on Github for developments: https://github.com/vincentarelbundock/marginaleffects/issues/810\n\nNew:\n\nhypothesis argument accepts wildcards: hypothesis = \"b*=b1\"\ns.value column in all output: Shannon transforms for p values. See Greenland (2019).\nmarginal_means supports mira (mice objects).\ncomparisons(): The variables arguments now accepts arbitrary numeric vectors of length equal to the number of rows in newdata. This allows users to specify fully custom treatment sizes. In the documentation examples, we show how to estimate the difference for a 1 standard deviation shift in a regressor, where the standard deviation is calculated on a group-wise basis.\ncomparisons(): the variables argument now accepts “revpairwise”, “revsequential”, “revreference” for factor and character variables.\ncomparisons(): the comparison argument now accept “lift” and “liftavg”.\n\nPerformance:\n\nComputing elasticities for linear models is now up to 30% faster (#787, @etiennebacher).\n\nBug fixes:\n\nBetter handling of environments when newdata is a function call. Thanks to @jcccf for report #814 and to @capnrefsmmat for the proposed fix using the rlang package.\nDegrees of freedom mismatch for joint hypothesis tests. Thanks to @snhansen for report #789.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-12",
    "href": "NEWS.html#section-12",
    "title": "News",
    "section": "",
    "text": "Breaking change:\n\nRow order of output has changed for many calls, especially those using the by argument. This may break hypothesis tests conducted by indexing b1, b2, etc. This was necessary to fix Issue #776. Thanks to @marcora for the report.\n\nNew:\n\nhypotheses(): Joint hypothesis tests (F and Chi-square) with the joint and joint_test arguments.\nvcov.hypotheses method.\nwts is now available in plot_predictions(), plot_comparisons(), and plot_slopes().\n\nBug:\n\nWrong order of rows in bayesian models with by argument. Thanks to @shirdekel for report #782.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-13",
    "href": "NEWS.html#section-13",
    "title": "News",
    "section": "",
    "text": "vcov() and coef() methods for marginaleffects objects.\nStrings in wts are accepted with the by argument.\npredictions() and avg_predictions() no longer use an automatic backtransformation for GLM models unless hypothesis is NULL.\nvcov() can be used to retrieve a full variance-covariance matrix from objects produced by comparisons(), slopes(), predictions(), or marginal_means() objects.\nWhen processing objects obtained using mice multiple imputation, the pooled model using mice::pool is attached to the model attribute of the output. This means that functions like modelsummary::modelsummary() will not erroneously report goodness-of-fit statistics from just a single model and will instead appropriately report the statistics for the pooled model. Thanks to @Tristan-Siegfried for PR #740.\nMore informative error messages on some prediction problems. Thanks to @andymilne for Report #751.\n\nPerformance:\n\ninferences() is now up to 17x faster and much more memory-efficient when method is \"boot\" or \"rsample\" (#770, #771, @etiennebacher).\n\nBugs:\n\nbrms models with nl=TRUE and a single predictor generated an error. Thanks to @Tristan-Siegried for Report #759.\navg_predictions(): Incorrect group-wise averaging when all predictors are categorical, the variables variable is used, and we are averaging with avg_ or the by argument. Thanks to BorgeJorge for report #766.\nBug when datagrid() when called inside a user-written function. Thanks to @NickCH-K for report #769 and to @capnrefsmmat for the diagnostics.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-14",
    "href": "NEWS.html#section-14",
    "title": "News",
    "section": "",
    "text": "Breaking change:\n\nRow orders are now more consistent, but may have changed from previous version. This could affect results from hypothesis with b1, b2, … indexing.\n\nSupport new models:\n\nnlme::lme()\nphylolm::phylolm()\nphylolm::phyloglm()\n\nNew:\n\nVignette on 2x2 experimental designs. Thanks to Demetri Pananos.\ncomparisons() accepts data frames with two numeric columns (“low” and “high”) to specify fully customizable contrasts.\ndatagrid() gets a new by argument to create apply grid-making functions within groups.\nplot_*() gain a newdata argument for use with by.\n\nBug:\n\ncomparisons(comparison = \"lnratioavg\") ignored wts argument. Thanks to Demetri Pananos for report #737.\nordinal::clm(): incorrect standard errors when location and scale parameters are the same. Thanks to MrJerryTAO for report #718.\nIncorrect label for “2sd” comparisons. Thanks to Andy Milne for report #720.\nInvalid factor levels in datagrid() means newdata argument gets ignored. Thanks to Josh Errickson for report #721.\nError in models with only categorical predictors and the by argument. Thanks to Sam Brilleman for report #723.\nElasticities are now supported for ordinal::clm() models. Thanks to MrJerryTAO for report #729.\nglmmTMB models with zero-inflated components are supported. Thanks to @Helsinki-Ronan and @strengejacke for report #734.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-15",
    "href": "NEWS.html#section-15",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\ntype column is replaced by type attribute.\npredictions() only works with officially supported model types (same list as comparisons() and slopes()).\n\nRenamed arguments (backward compatibility is preserved):\n\ntransform_pre -&gt; comparison\ntransform_post -&gt; transform\n\nNew:\n\np_adjust argument: Adjust p-values for multiple comparisons.\nequivalence argument available everywhere.\n\nPerformance:\n\nMuch faster results in avg_*() functions for models with only categorical predictors and many rows of data, using deduplication and weights instead of unit-level estimates.\nFaster predictions in lm() and glm() models using RcppEigen.\nBayesian models with many rows. Thanks to Etienne Bacher. #694\nFaster predictions, especially with standard errors and large datasets.\n\nBugs:\n\nMultiple imputation with mira objects was not pooling all datasets. Thanks to @Generalized for report #711.\nSupport for more models with offsets. Thanks to @mariofiorini for report #705.\nError on predictions() with by and wts. Thanks to Noah Greifer for report #695.\nafex: some models generated errors. Thanks to Daniel Lüdecke for report #696.\ngroup column name is always forbidden. Thanks to Daniel Lüdecke for report #697.\nBlank graphs in plot_comparisons() with a list in variables.\ntype=\"link\" produced an error with some categorical brms models. Thanks to @shirdekel for report #703.\nError on predictions(variables = ...) for glmmTMB models. Thanks to Daniel Lüdecke for report #707.\nby with user-specified function in comparison and factor predictor did not aggregate correctly. Thanks to @joaotedde for report #715.\nordinal::clm: Support cum.prob and linear.predictor prediction types. Thanks to @MrJerryTAO for report #717.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-16",
    "href": "NEWS.html#section-16",
    "title": "News",
    "section": "",
    "text": "Performance:\n\n2-4x faster execution for many calls. Thanks to Etienne Bacher.\n\nNew models supported:\n\nMCMCglmm::MCMCglmm\nRchoice::hetprob\nRchoice::ivpml\nMultiple imputation using mice and any package which can return a list of imputed data frames (e.g., Amelia, missRanger, etc.)\n\nPlot improvements:\n\nNew by argument to display marginal estimates by subgroup.\nNew rug argument to display tick marks in the margins.\nNew points argument in plot_predictions() to display a scatter plot.\nNew gray argument to plot in grayscale using line types and shapes instead of color.\nThe effect argument is renamed to variables in plot_slopes() and plot_comparisons(). This improves consistency with the analogous slopes() and comparisons() functions.\nThe plotting vignette was re-written.\n\nOther:\n\nSupport multiple imputation with mice mira objects. The multiple imputation vignette was rewritten.\nThe variables_grid argument in marginal_means() is renamed newdata. Backward compatibility is maintained.\navg_*() returns an informative error when vcov is “satterthwaite” or “kenward-roger”\n“satterthwaite” and “kenward-roger” are now supported when newdata is not NULL\nInformative error when hypothesis includes a b# larger than the available number of estimates.\navg_predictions(model, variables = \"x\") computes average counterfactual predictions by subgroups of x\ndatagrid() and plot_*() functions are faster in datasets with many extraneous columns.\nIn predictions(type = NULL) with glm() and Gam() we first make predictions on the link scale and then backtransform them. Setting type=\"response\" explicitly makes predictions directly on the response scale without backtransformation.\nStandard errors now supported for more glmmTMB models.\nUse the numDeriv package for numeric differentiation in the calculation of delta method standard error. A global option can now be passed to numDeriv::jacobian:\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6)))\noptions(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-6)))\noptions(marginaleffects_numDeriv = NULL)\n\nPrint:\n\nPrint fewer significant digits.\nprint.marginaleffects now prints all columns supplied to newdata\nLess redundant labels when using hypothesis\n\nMany improvements to documentation.\n\nBugfixes:\n\nStandard errors could be inaccurate in models with non-linear components (and interactions) when some of the coefficients were very small. This was related to the step size used for numerical differentiation for the delta method. Issue #684.\navg_predictions(by =) did not work when the dataset included a column named term. Issue #683.\nbrms models with multivariate outcome collapsed categories in comparisons(). Issue #639.\nhypotheses() now works on lists and in calls to lapply(), purrr::map(), etc. Issue #660.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-17",
    "href": "NEWS.html#section-17",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\nAll functions return an estimate column instead of the function-specific predicted, comparisons, dydx, etc. This change only affects unit-level estimates, and not average estimates, which already used the estimate column name.\nThe transform_avg argument in tidy() deprecated. Use transform_post instead.\nplot_*(draw=FALSE) now return the actual variable names supplied to the condition argument, rather than the opaque “condition1”, “condition2”, etc.\n\nNew models supported:\n\nblme package.\n\nNew features:\n\nNew functions: avg_predictions(), avg_comparisons(), avg_slopes()\nEquivalence, non-inferiority, and non-superiority tests with the hypotheses() function and equivalence argument.\nNew experimental inferences() function: simulation-based inferences and bootstrap using the boot, rsample, and fwb package.\nNew df argument to set degrees of freedom manually for p and CI.\nPretty print() for all objects.\nby argument\n\nTRUE returns average (marginal) predictions, comparisons, or slopes.\nSupports bayesian models.\n\nhypothesis argument\n\nNumeric value sets the null used in calculating Z and p.\nExample: comparisons(mod, transform_pre = \"ratio\", hypothesis = 1)\n\nAll arguments from the main functions are now available through tidy(), and summary(): conf_level, transform_post, etc.\nBayesian posterior distribution summaries (median, mean, HDI, quantiles) can be customized using global options. See ?comparisons\n\nRenamed functions (backward-compatibility is maintained by keeping the old function names as aliases):\n\nmarginaleffects() -&gt; slopes()\nposteriordraws() -&gt; posterior_draws()\nmarginalmeans() -&gt; marginal_means()\nplot_cap() -&gt; plot_predictions()\nplot_cme() -&gt; plot_slopes()\nplot_cco() -&gt; plot_comparisons()\n\nBug fixes:\n\nIncorrect results: In 0.8.1, plot_*() the threenum and minmax labels did not correspond to the correct numeric values.\nFix corner case for slopes when the dataset includes infinite values.\nmlogit error with factors.\nThe vcov argument now accepts functions for most models.\n\nOther:\n\nRemoved major performance bottleneck for slopes()",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-18",
    "href": "NEWS.html#section-18",
    "title": "News",
    "section": "",
    "text": "deltamethod() can run hypothesis tests on objects produced by the comparisons(), marginaleffects(), predictions(), and marginalmeans() functions. This feature relies on match.call(), which means it may not always work when used programmatically, inside functions and nested environments. It is generally safer and more efficient to use the hypothesis argument.\nplot_cme() and plot_cco() accept lists with user-specified values for the regressors, and can display nice labels for shortcut string-functions like “threenum” or “quartile”.\nposterior_draws: new shape argument to return MCMC draws in various formats, including the new rvar structure from the posterior package.\ntransform_avg function gets printed in summary() output.\ntransform_post and transform_avg support string shortcuts: “exp” and “ln”\nAdded support for mlm models from lm(). Thanks to Noah Greifer.\n\nBug fixes:\n\nhypothesis argument with bayesian models and tidy() used to raise an error.\nMissing values for some regressors in the comparisons() output for brms models.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-19",
    "href": "NEWS.html#section-19",
    "title": "News",
    "section": "",
    "text": "Breaking change:\n\nThe interaction argument is deprecated and replaced by the cross argument. This is to reduce ambiguity with respect to the interaction argument in emmeans, which does something completely different, akin to the difference-in-differences illustrated in the Interactions vignette.\n\n71 classes of models supported, including the new:\n\nrms::ols\nrms::lrm\nrms::orm\n\nNew features:\n\nPlots: plot_cme(), plot_cap(), and plot_cco() are now much more flexible in specifying the comparisons to display. The condition argument accepts lists, functions, and shortcuts for common reference values, such as “minmax”, “threenum”, etc.\nvariables argument of the comparisons() function is more flexible:\n\nAccepts functions to specify custom differences in numeric variables (e.g., forward and backward differencing).\nCan specify pairs of factors to compare in the variables argument of the comparisons function.\n\nvariables argument of the predictions() function is more flexible:\n\nAccepts shortcut strings, functions, and vectors of arbitrary length.\n\nIntegrate out random effects in bayesian brms models (see Bayesian analysis vignette)\n\nNew vignettes:\n\nExperiments\nExtending marginal effects\nIntegrating out random effects in bayesian models\n\nBug fixes and minor improvements:\n\nThe default value of conf_level in summary() and tidy() is now NULL, which inherits the conf_level value in the original comparisons/marginaleffects/predictions calls.\nFix typo in function names for missing “lnratioavgwts”\nInteractions with fixest::i() are parsed properly as categorical variables\nFor betareg objects, inference can now be done on all coefficients using deltamethod(). previously only the location coefficients were available.\nFor objects from crch package, a number of bugs have been fixed; standard errors should now be correct for deltamethod(), marginaleffects(), etc.\nFixed a bug in the tidy() function for glmmTMB models without random effects, which caused all t statistics to be identical.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-20",
    "href": "NEWS.html#section-20",
    "title": "News",
    "section": "",
    "text": "New supported model class: gamlss. Thanks to Marcio Augusto Diniz.\nmarginalmeans() accepts a wts argument with values: “equal”, “proportional”, “cells”.\nby argument\n\naccepts data frames for complex groupings.\nin marginalmeans only accepts data frames.\naccepts “group” to group by response level.\nworks with bayesian models.\n\nbyfun argument for the predictions() function to aggregate using different functions.\nhypothesis argument\n\nThe matrix column names are used as labels for hypothesis tests.\nBetter labels with “sequential”, “reference”, “pairwise”.\nnew shortcuts “revpairwise”, “revsequential”, “revreference”\n\nwts argument is respected in by argument and with *avg shortcuts in the transform_pre argument.\ntidy.predictions() and tidy.marginalmeans() get a new transform_avg argument.\nNew vignettes:\n\nUnit-level contrasts in logistic regressions. Thanks to @arthur-albuquerque.\nPython Numpy models in marginaleffects. Thanks to timpipeseek.\nBootstrap example in standard errors vignette.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-21",
    "href": "NEWS.html#section-21",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\nby is deprecated in summary() and tidy(). Use the same by argument in the main functions instead: comparisons(), marginaleffects(), predictions()\nCharacter vectors are no longer supported in the variables argument of the predictions() function. Use newdata=\"fivenum\" or “grid”, “mean”, or “median” instead.\n\nCritical bug fix:\n\nContrasts with interactions were incorrect in version 0.6.0. The error should have been obvious to most analysts in most cases (weird-looking alignment). Thanks to @vmikk.\n\nNew supported packages and models:\n\nsurvival::clogit\nbiglm: The main quantities can be computed, but not the delta method standard errors. See https://github.com/vincentarelbundock/marginaleffects/issues/387\n\nNew vignette:\n\nElasticity\nFrequently Asked Questions\n\nNew features:\n\nElasticity and semi-elasticity using the new slope argument in marginaleffects(): eyex, dyex, eydx\ndatagrid() accepts functions: datagrid(newdata = mtcars, hp = range, mpg = fivenum, wt = sd)\nNew datagridcf() function to create counterfactual datasets. This is a shortcut to the datagrid() function with default to grid_type = \"counterfactual\"\nNew by arguments in predictions(), comparisons(), marginaleffects()\nNew newdata shortcuts: “tukey”, “grid”\nNew string shortcuts for transform_pre in comparisons()\nmarginalmeans() now back transforms confidence intervals when possible.\nvcov argument string shortcuts are now case-insensitive\nThe default contrast in comparisons() for binary predictors is now a difference between 1 and 0, rather than +1 relative to baseline.\ndocumentation improvements",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-22",
    "href": "NEWS.html#section-22",
    "title": "News",
    "section": "",
    "text": "New supported packages and models:\n\ntidymodels objects of class tidy_model are supported if the fit engine is supported by marginaleffects.\n\nNew function:\n\ndeltamethod(): Hypothesis tests on functions of parameters\nplot_cco(): Plot conditional contrasts\n\nNew arguments:\n\nhypothesis for hypothesis tests and custom contrasts\ntransform_post in predictions()\nwts argument in predictions() only affects average predictions in tidy() or summary().\n\nNew or improved vignettes:\n\nHypothesis Tests and Custom Contrasts using the Delta Method: https://marginaleffects.com/vignettes/hypothesis.html\nMultiple Imputation: https://marginaleffects.com/vignettes/multiple_imputation.html\nCausal Inference with the g-Formula: https://marginaleffects.com/vignettes/gcomputation.html (Thanks to Rohan Kapre for the idea)\n\nDeprecated or renamed arguments:\n\ncontrast_factor and contrast_numeric arguments are deprecated in comparisons(). Use a named list in the variables argument instead. Backward compatibility is maintained.\nThe transform_post argument in tidy() and summary() is renamed to transform_avg to disambiguate against the argument of the same name in comparisons(). Backward compatibility is preserved.\n\nMisc:\n\ntidy.predictions() computes standard errors using the delta method for average predictions\nSupport gam models with matrix columns.\neps in marginaleffects() is now “adaptive” by default: it equals 0.0001 multiplied the range of the predictor variable\ncomparisons() now supports “log of marginal odds ratio” in the transform_pre argument. Thanks to Noah Greifer.\nNew transform_pre shortcuts: dydx, expdydx\ntidy.predictions() computes standard errors and confidence intervals for linear models or GLM on the link scale.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-23",
    "href": "NEWS.html#section-23",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\ntype no longer accepts a character vector. Must be a single string.\nconf.int argument deprecated. Use vcov = FALSE instead.\n\nNew supported packages and models:\n\nmlogit\nmhurdle\ntobit1\nglmmTMB\n\nNew features:\n\ninteraction argument in comparisons() to compute interactions between contrasts (cross-contrasts).\nby argument in tidy() and summary() computes group-average marginal effects and comparisons.\ntransform_pre argument can define custom contrasts between adjusted predictions (e.g., log adjusted risk ratios). Available in comparisons().\ntransform_post argument allows back transformation before returning the final results. Available in comparisons(), marginalmeans(), summary(), tidy().\nThe variables argument of the comparisons() function accepts a named list to specify variable-specific contrast types.\nRobust standard errors with the vcov argument. This requires version 0.17.1 of the insight package.\n\nsandwich package shortcuts: vcov = \"HC3\", \"HC2\", \"NeweyWest\", and more.\nMixed effects models: vcov = \"satterthwaite\" or \"kenward-roger\"\nOne-sided formula to clusters: vcov = ~cluster_variable\nVariance-covariance matrix\nFunction which returns a named squared matrix\n\nmarginalmeans() allows interactions\nBayesian Model Averaging for brms models using type = \"average\". See vignette on the marginaleffects website.\neps argument for step size of numerical derivative\nmarginaleffects and comparisons now report confidence intervals by default.\nNew dependency on the data.table package yields substantial performance improvements.\nMore informative error messages and warnings\nBug fixes and performance improvements\n\nNew pages on the marginaleffects website: https://marginaleffects.com/\n\nAlternative software packages\nRobust standard errors (and more)\nPerformance tips\nTables and plots\nMultinomial Logit and Discrete Choice Models\nGeneralized Additive Models\nMixed effects models (Bayesian and Frequentist)\nTransformations and Custom Contrasts: Adjusted Risk Ratio Example\n\nArgument name changes (backward compatibility is preserved:\n\nEverywhere:\n\nconf.level -&gt; conf_level\n\ndatagrid():\n\nFUN.factor -&gt; FUN_factor (same for related arguments)\ngrid.type -&gt; grid_type",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-24",
    "href": "NEWS.html#section-24",
    "title": "News",
    "section": "",
    "text": "New supported packages and models:\n\nstats::loess\nsampleSelection::selection\nsampleSelection::heckit\n\nMisc:\n\nmgcv::bam models allow exclude argument.\nGam models allow include_smooth argument.\nNew tests\nBug fixes",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-25",
    "href": "NEWS.html#section-25",
    "title": "News",
    "section": "",
    "text": "New function:\n\ncomparisons() computes contrasts\n\nMisc:\n\nSpeed optimizations\npredictions() and plot_cap() include confidence intervals for linear models\nMore robust handling of in-formula functions: factor(), strata(), mo()\nDo not overwrite user’s ggplot2::theme_set() call",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-26",
    "href": "NEWS.html#section-26",
    "title": "News",
    "section": "",
    "text": "Bug fixes",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-27",
    "href": "NEWS.html#section-27",
    "title": "News",
    "section": "",
    "text": "New supported models:\n\nmclogit::mclogit\nrobust::lmRob\nrobustlmm::rlmer\nfixest confidence intervals in predictions\n\nMisc:\n\nSupport modelbased::visualisation_matrix in newdata without having to specify x explicitly.\ntidy.predictions() and summary.predictions() methods.\nDocumentation improvements.\nCRAN test fixes",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-28",
    "href": "NEWS.html#section-28",
    "title": "News",
    "section": "",
    "text": "Support for new models and packages:\n\nbrglm2::bracl\nmclogit::mblogit\nscam::scam\nlmerTest::lmer\n\nMisc:\n\nDrop numDeriv dependency, but make it available via a global option: options(“marginaleffects_numDeriv” = list(method = “Richardson”, method.args = list(eps = 1e-5, d = 0.0001)))\nBugfixes\nDocumentation improvements\nCRAN tests",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-29",
    "href": "NEWS.html#section-29",
    "title": "News",
    "section": "",
    "text": "documentation bugfix",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-30",
    "href": "NEWS.html#section-30",
    "title": "News",
    "section": "",
    "text": "Breaking changes:\n\npredictions returns predictions for every observation in the original dataset instead of newdata=datagrid().\nmarginalmeans objects have new column names, as do the corresponding tidy and summary outputs.\n\nNew supported packages and models:\n\nbrms::brm\nrstanarm::stanglm\nbrglm2::brmultinom\nMASS::glmmPQL\naod::betabin\n\nMisc:\n\ndatagrid function supersedes typical and counterfactual with the grid.type argument. The typical and counterfactual functions will remain available and exported, but their use is not encouraged.\nposterior_draws function can be applied to a predictions or a marginaleffects object to extract draws from the posterior distribution.\nmarginalmeans standard errors are now computed using the delta method.\npredictions standard errors are now computed using the delta method when they are not available from insight::get_predicted.\nNew vignette on Bayesian models with brms\nNew vignette on Mixed effects models with lme4\nIf the data.table package is installed, marginaleffects will automatically use it to speed things up.\nContrast definition reported in a separate column of marginaleffects output.\nSafer handling of the type argument.\nComprehensive list of supported and tests models on the website.\nMany bug fixes\nMany new tests, including several against emmeans",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-31",
    "href": "NEWS.html#section-31",
    "title": "News",
    "section": "",
    "text": "Breaking change:\n\ndata argument becomes newdata in all functions.\n\nNew supported packages and models:\n\nlme4:glmer.nb\nmgcv::gam\nordinal::clm\nmgcv\n\nmarginalmeans:\n\nNew variables_grid argument\n\npredictions:\n\nSupport mgcv\n\nplot_cap\n\nNew type argument\n\nMisc:\n\nNew validity checks and tests",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "NEWS.html#section-32",
    "href": "NEWS.html#section-32",
    "title": "News",
    "section": "",
    "text": "First release. Bravo!\nThanks to Marco Avina Mendoza, Resul Umit, and all those who offered comments and suggestions.",
    "crumbs": [
      "Get started",
      "News"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html",
    "href": "vignettes/hypothesis.html",
    "title": "Hypothesis Tests",
    "section": "",
    "text": "The marginaleffects package can conduct linear or non-linear hypothesis tests on the coefficients of any supported model class, or on the quantities generated by any of the other functions of the package: predictions(), comparisons(), or slopes().\nThere are two main entry points for hypothesis tests:\nBoth the hypothesis argument and the hypotheses() function accept several input types, which allow a lot of flexibility in the specification of hypothesis tests:\nThis vignette shows how to use each of these strategies to conduct hypothesis tests on model coefficients or on the quantities estimated by the marginaleffects package. After reading it, you will be able to specify custom hypothesis tests and contrasts to assess statements like:",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#coefficients",
    "href": "vignettes/hypothesis.html#coefficients",
    "title": "Hypothesis Tests",
    "section": "Coefficients",
    "text": "Coefficients\nConsider a simple logistic regression model:\n\nlibrary(marginaleffects)\nmod &lt;- glm(am ~ hp + drat, data = mtcars, family = binomial)\n\nBy default, the summary() function will report the results of hypothesis tests where the null is set to 0:\n\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = am ~ hp + drat, family = binomial, data = mtcars)\n#&gt; \n#&gt; Coefficients:\n#&gt;               Estimate Std. Error z value Pr(&gt;|z|)  \n#&gt; (Intercept) -29.076080  12.416916  -2.342   0.0192 *\n#&gt; hp            0.010793   0.009328   1.157   0.2473  \n#&gt; drat          7.309781   3.046597   2.399   0.0164 *\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 43.230  on 31  degrees of freedom\n#&gt; Residual deviance: 20.144  on 29  degrees of freedom\n#&gt; AIC: 26.144\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 7\n\nUsing hypotheses(), we can easily change the null hypothesis:\n\nhypotheses(mod, hypothesis = 6)\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n(Intercept)\n                  -29.0761\n                  12.41692\n                    -2.82\n                  0.00473\n                  7.7\n                  -53.41279\n                  -4.7394\n                \n\nhp         \n                    0.0108\n                   0.00933\n                  -642.04\n                  \n                  \nInf\n                   -0.00749\n                   0.0291\n                \n\ndrat       \n                    7.3098\n                   3.04660\n                     0.43\n                  0.66726\n                  0.6\n                    1.33856\n                  13.2810",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#predictions",
    "href": "vignettes/hypothesis.html#predictions",
    "title": "Hypothesis Tests",
    "section": "Predictions",
    "text": "Predictions\nChanging the value of the null is particularly important in the context of predictions, where the 0 baseline may not be particularly meaningful. For example, here we compute the predicted outcome for a hypothetical unit where all regressors are fixed to their sample means:\n\npredictions(mod, newdata = \"mean\")\n\n\n\n    \n\n      \n\nEstimate\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n                drat\n              \n\nType:  invlink(link) \n\nColumns: rowid, estimate, p.value, s.value, conf.low, conf.high, hp, drat, am \n\n\n\n0.231\n                  0.135\n                  2.9\n                  0.0584\n                  0.592\n                  147\n                  3.6\n                \n\n\n\n\n\nThe Z statistic and p value reported above assume that the null hypothesis equals zero. We can change the null with the hypothesis argument:\n\npredictions(mod, newdata = \"mean\", hypothesis = .5)\n\n\n\n    \n\n      \n\nEstimate\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n                drat\n              \n\nType:  invlink(link) \n\nColumns: rowid, estimate, p.value, s.value, conf.low, conf.high, hp, drat, am \n\n\n\n0.231\n                  0.0343\n                  4.9\n                  0.0584\n                  0.592\n                  147\n                  3.6",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#comparisons-and-slopes",
    "href": "vignettes/hypothesis.html#comparisons-and-slopes",
    "title": "Hypothesis Tests",
    "section": "Comparisons and slopes",
    "text": "Comparisons and slopes\nWhen computing different quantities of interest like risk ratios, it can make sense to set the null hypothesis to 1 rather than 0:\n\navg_comparisons(\n    mod,\n    variables = \"hp\",\n    comparison = \"ratio\",\n    hypothesis = 1) |&gt;\n    print(digits = 5)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n1.0027\n                  0.0021743\n                  1.2515\n                  0.21074\n                  2.2\n                  0.99846\n                  1.007",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#coefficients-1",
    "href": "vignettes/hypothesis.html#coefficients-1",
    "title": "Hypothesis Tests",
    "section": "Coefficients",
    "text": "Coefficients\nLet’s start by estimating a simple model:\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)\n\nWhen the FUN and hypothesis arguments of hypotheses() equal NULL (the default), the function returns a data.frame of raw estimates:\n\nhypotheses(mod)\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n(Intercept) \n                  35.8460\n                  2.041\n                  17.56\n                  \n                  \n227.0\n                  31.8457\n                  39.846319\n                \n\nhp          \n                  -0.0231\n                  0.012\n                  -1.93\n                  0.0531\n                  4.2  \n                  -0.0465\n                   0.000306\n                \n\nwt          \n                  -3.1814\n                  0.720\n                  -4.42\n                  \n                  \n16.6 \n                  -4.5918\n                  -1.771012\n                \n\nfactor(cyl)6\n                  -3.3590\n                  1.402\n                  -2.40\n                  0.0166\n                  5.9  \n                  -6.1062\n                  -0.611803\n                \n\nfactor(cyl)8\n                  -3.1859\n                  2.170\n                  -1.47\n                  0.1422\n                  2.8  \n                  -7.4399\n                   1.068169\n                \n\n\n\n\n\n\nTest of equality between coefficients:\n\nhypotheses(mod, \"hp = wt\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n3.16\n                  0.72\n                  4.39\n                  \n                  \n16.4\n                  1.75\n                  4.57\n                \n\n\n\n\n\nNon-linear function of coefficients\n\nhypotheses(mod, \"exp(hp + wt) = 0.1\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-0.0594\n                  0.0292\n                  -2.04\n                  0.0418\n                  4.6\n                  -0.117\n                  -0.0022\n                \n\n\n\n\n\nThe vcov argument behaves in the same was as in all the other marginaleffects functions, allowing us to easily compute robust standard errors:\n\nhypotheses(mod, \"hp = wt\", vcov = \"HC3\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n3.16\n                  0.805\n                  3.92\n                  \n                  \n13.5\n                  1.58\n                  4.74\n                \n\n\n\n\n\nWe can use shortcuts like b1, b2, ... to identify the position of each parameter in the output of FUN. For example, b2=b3 is equivalent to hp=wt because those term names appear in the 2nd and 3rd row when we call hypotheses(mod).\n\nhypotheses(mod, \"b2 = b3\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n3.16\n                  0.72\n                  4.39\n                  \n                  \n16.4\n                  1.75\n                  4.57\n                \n\n\n\n\n\n\nhypotheses(mod, hypothesis = \"b* / b3 = 1\")\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\nb1 / b3 = 1\n                  -12.26735\n                  2.07340\n                    -5.9165\n                  \n                  \n28.2\n                  -16.33\n                  -8.204\n                \n\nb2 / b3 = 1\n                   -0.99273\n                  0.00413\n                  -240.5537\n                  \n                  \nInf \n                   -1.00\n                  -0.985\n                \n\nb3 / b3 = 1\n                    0.00000\n                       NA\n                         NA\n                  NA    \n                  NA  \n                      NA\n                      NA\n                \n\nb4 / b3 = 1\n                    0.05583\n                  0.58287\n                     0.0958\n                  0.924 \n                  0.1 \n                   -1.09\n                   1.198\n                \n\nb5 / b3 = 1\n                    0.00141\n                  0.82981\n                     0.0017\n                  0.999 \n                  0.0 \n                   -1.62\n                   1.628\n                \n\n\n\n\n\n\nTerm names with special characters must be enclosed in backticks:\n\nhypotheses(mod, \"`factor(cyl)6` = `factor(cyl)8`\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-0.173\n                  1.65\n                  -0.105\n                  0.917\n                  0.1\n                  -3.41\n                  3.07",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#predictions-1",
    "href": "vignettes/hypothesis.html#predictions-1",
    "title": "Hypothesis Tests",
    "section": "Predictions",
    "text": "Predictions\nNow consider the case of adjusted predictions:\n\nmod &lt;- lm(mpg ~ am + vs, data = mtcars)\n\np &lt;- predictions(\n    mod,\n    newdata = datagrid(am = 0:1, vs = 0:1))\np\n\n\n\n    \n\n      \n\nam\n                vs\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, vs, mpg \n\n\n\n\n0\n                  0\n                  14.6\n                  0.926\n                  15.8\n                  \n                  \n183.4\n                  12.8\n                  16.4\n                \n\n0\n                  1\n                  21.5\n                  1.130\n                  19.0\n                  \n                  \n266.3\n                  19.3\n                  23.7\n                \n\n1\n                  0\n                  20.7\n                  1.183\n                  17.5\n                  \n                  \n224.5\n                  18.3\n                  23.0\n                \n\n1\n                  1\n                  27.6\n                  1.130\n                  24.4\n                  \n                  \n435.0\n                  25.4\n                  29.8\n                \n\n\n\n\n\n\nSince there is no term column in the output of the predictions function, we must use parameter identifiers like b1, b2, etc. to determine which estimates we want to compare:\n\nhypotheses(p, hypothesis = \"b1 = b2\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-6.93\n                  1.26\n                  -5.49\n                  \n                  \n24.6\n                  -9.4\n                  -4.46\n                \n\n\n\n\n\nOr directly:\n\npredictions(\n    mod,\n    hypothesis = \"b1 = b2\",\n    newdata = datagrid(am = 0:1, vs = 0:1))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-6.93\n                  1.26\n                  -5.49\n                  \n                  \n24.6\n                  -9.4\n                  -4.46\n                \n\n\n\n\n\np$estimate[1] - p$estimate[2]\n#&gt; [1] -6.929365\n\nThere are many more possibilities:\n\npredictions(\n    mod,\n    hypothesis = \"b1 + b2 = 30\",\n    newdata = datagrid(am = 0:1, vs = 0:1))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n6.12\n                  1.64\n                  3.74\n                  \n                  \n12.4\n                  2.91\n                  9.32\n                \n\n\n\n\n\np$estimate[1] + p$estimate[2] - 30\n#&gt; [1] 6.118254\n\npredictions(\n    mod,\n    hypothesis = \"(b2 - b1) / (b3 - b2) = 0\",\n    newdata = datagrid(am = 0:1, vs = 0:1))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-8.03\n                  17\n                  -0.473\n                  0.636\n                  0.7\n                  -41.3\n                  25.2",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#comparisons-and-slopes-1",
    "href": "vignettes/hypothesis.html#comparisons-and-slopes-1",
    "title": "Hypothesis Tests",
    "section": "Comparisons and slopes",
    "text": "Comparisons and slopes\nThe avg_comparisons() function allows us to answer questions of this form: On average, how does the expected outcome change when I change one regressor by some amount? Consider this:\n\nmod &lt;- lm(mpg ~ am + vs, data = mtcars)\n\ncmp &lt;- avg_comparisons(mod)\ncmp\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nam\n                  6.07\n                  1.27\n                  4.76\n                  \n                  \n19.0\n                  3.57\n                  8.57\n                \n\nvs\n                  6.93\n                  1.26\n                  5.49\n                  \n                  \n24.6\n                  4.46\n                  9.40\n                \n\n\n\n\n\n\nThis tells us that, on average, moving from 0 to 1 on the am changes the predicted outcome by about 6.1, and changing .vs from 0 to 1 changes the predicted outcome by about 6.9.\nIs the difference between those two estimates statistically significant? In other words, Is the effect of am equal to the effect of vs? To answer this question, we use the hypothesis argument:\n\navg_comparisons(mod, hypothesis = \"am = vs\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-0.863\n                  1.94\n                  -0.445\n                  0.656\n                  0.6\n                  -4.66\n                  2.94\n                \n\n\n\n\n\nThe hypothesis string can include any valid R expression, so we can run some silly non-linear tests:\n\navg_comparisons(mod, hypothesis = \"exp(am) - 2 * vs = -400\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n817\n                  550\n                  1.49\n                  0.137\n                  2.9\n                  -261\n                  1896\n                \n\n\n\n\n\nNote that the p values and confidence intervals are calculated using the delta method and are thus based on the assumption that the hypotheses expression is approximately normally distributed. For (very) non-linear functions of the parameters, this is not realistic, and we get p values with incorrect error rates and confidence intervals with incorrect coverage probabilities. For such hypotheses, it’s better to calculate the confidence intervals using the bootstrap (see inferences for details):\nWhile the confidence interval from the delta method is symmetric, equal to the estimate ± 1.96 times the standard error, the (perhaps) more reliable confidence interval from the bootstrap is highly skewed.\n\nset.seed(1234)\n\navg_comparisons(mod, hypothesis = \"exp(am) - 2 * vs = -400\") |&gt;\n  inferences(method = \"boot\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, conf.low, conf.high \n\n\n\n817\n                  1854\n                  414\n                  6990\n                \n\n\n\n\n\nThe same approach can be taken to compare slopes:\n\nmod &lt;- lm(mpg ~ qsec * hp, data = mtcars)\n\navg_slopes(mod, hypothesis = \"10 * hp - qsec = 0\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n0.262\n                  0.353\n                  0.742\n                  0.458\n                  1.1\n                  -0.43\n                  0.954",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#predictions-2",
    "href": "vignettes/hypothesis.html#predictions-2",
    "title": "Hypothesis Tests",
    "section": "Predictions",
    "text": "Predictions\nWhen supplying a function to the hypothesis argument, that function must accept an argument x which is a data frame with columns rowid and estimate (and optional columns for other elements of newdata). That function must return a data frame with columns term (or hypothesis) and estimate.\nIn this example, we test if the mean predicted value is different from 2:\n\ndat &lt;- transform(mtcars, gear = factor(gear), cyl = factor(cyl))\n\nmod &lt;- lm(wt ~ mpg * hp * cyl, data = dat)\n\nhyp &lt;- function(x) {\n    data.frame(\n        hypothesis = \"Avg(Ŷ) = 2\",\n        estimate = mean(x$estimate) - 2\n    )\n}\npredictions(mod, hypothesis = hyp)\n\n\n\n    \n\n      \n\nHypothesis\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: hypothesis, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\nAvg(Ŷ) = 2\n                  1.22\n                  0.0914\n                  13.3\n                  \n                  \n132.0\n                  1.04\n                  1.4\n                \n\n\n\n\n\nIn this ordinal logit model, the predictions() function returns one row per observation and per level of the outcome variable:\n\nlibrary(MASS)\nlibrary(dplyr)\n\nmod &lt;- polr(gear ~ cyl + hp, dat)\n\navg_predictions(mod)\n\n\n\n    \n\n      \n\nGroup\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n3\n                  0.471\n                  0.0584\n                  8.05\n                  \n                  \n50.2\n                  0.3561\n                  0.585\n                \n\n4\n                  0.366\n                  0.0715\n                  5.12\n                  \n                  \n21.7\n                  0.2263\n                  0.507\n                \n\n5\n                  0.163\n                  0.0478\n                  3.41\n                  \n                  \n10.6\n                  0.0692\n                  0.257\n                \n\n\n\n\n\n\nWe can use a function in the hypothesis argument to collapse the rows, displaying the average predicted values in groups 3-4 vs. 5:\n\nfun &lt;- function(x) {\n    out &lt;- x |&gt; \n        mutate(term = ifelse(group %in% 3:4, \"3 & 4\", \"5\")) |&gt;\n        summarize(estimate = mean(estimate), .by = term)\n    return(out)\n}\navg_predictions(mod, hypothesis = fun)\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n3 & 4\n                  0.419\n                  0.0239\n                  17.51\n                  \n                  \n225.5\n                  0.3717\n                  0.465\n                \n\n5    \n                  0.163\n                  0.0478\n                   3.41\n                  \n                  \n10.6 \n                  0.0692\n                  0.257\n                \n\n\n\n\n\n\nAnd we can compare the two categories by doing:\n\nfun &lt;- function(x) {\n    out &lt;- x |&gt; \n        mutate(term = ifelse(group %in% 3:4, \"3 & 4\", \"5\")) |&gt;\n        summarize(estimate = mean(estimate), .by = term) |&gt;\n        summarize(estimate = diff(estimate), term = \"5 - (3 & 4)\")\n    return(out)\n}\navg_predictions(mod, hypothesis = fun)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-0.256\n                  0.0717\n                  -3.56\n                  \n                  \n11.4\n                  -0.396\n                  -0.115",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#comparisons-and-slopes-2",
    "href": "vignettes/hypothesis.html#comparisons-and-slopes-2",
    "title": "Hypothesis Tests",
    "section": "Comparisons and slopes",
    "text": "Comparisons and slopes\nIn the same ordinal logit model, we can estimate the average effect of an increase of 1 unit in hp on the expected probability of every level of the outcome:\n\navg_comparisons(mod, variables = \"hp\")\n\n\n\n    \n\n      \n\nGroup\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n3\n                  -0.00774\n                  0.002294\n                  -3.38\n                  \n                  \n10.4\n                  -0.01224\n                  -0.00325\n                \n\n4\n                   0.00258\n                  0.002201\n                   1.17\n                  0.24  \n                  2.1 \n                  -0.00173\n                   0.00690\n                \n\n5\n                   0.00516\n                  0.000882\n                   5.85\n                  \n                  \n27.6\n                   0.00343\n                   0.00689\n                \n\n\n\n\n\n\nCompare estimate for different outcome levels:\n\nfun &lt;- function(x) {\n    x |&gt; \n    mutate(estimate = (estimate - lag(estimate)),\n           group = sprintf(\"%s - %s\", group, lag(group))) |&gt;\n    filter(!is.na(estimate))\n}\navg_comparisons(mod, variables = \"hp\", hypothesis = fun)\n\n\n\n    \n\n      \n\nGroup\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n4 - 3\n                  0.01033\n                  0.00441\n                  2.34\n                  0.0191\n                  5.7\n                   0.00169\n                  0.01897\n                \n\n5 - 4\n                  0.00258\n                  0.00245\n                  1.05\n                  0.2922\n                  1.8\n                  -0.00222\n                  0.00737\n                \n\n\n\n\n\n\nNow suppose we want to compare the effect of hp for different levels of the outcome, but this time we do the computation within levels of cyl:\n\navg_comparisons(mod, variables = \"hp\", by = \"cyl\")\n\n\n\n    \n\n      \n\nGroup\n                cyl\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: term, group, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n3\n                  4\n                  -0.007862\n                  0.003445\n                  -2.282\n                  0.02248\n                  5.5 \n                  -1.46e-02\n                  -0.00111\n                \n\n3\n                  6\n                  -0.013282\n                  0.005038\n                  -2.637\n                  0.00838\n                  6.9 \n                  -2.32e-02\n                  -0.00341\n                \n\n3\n                  8\n                  -0.004882\n                  0.001457\n                  -3.350\n                  \n                  \n10.3\n                  -7.74e-03\n                  -0.00203\n                \n\n4\n                  4\n                  -0.003024\n                  0.003714\n                  -0.814\n                  0.41560\n                  1.3 \n                  -1.03e-02\n                   0.00426\n                \n\n4\n                  6\n                   0.008573\n                  0.006431\n                   1.333\n                  0.18251\n                  2.5 \n                  -4.03e-03\n                   0.02118\n                \n\n4\n                  8\n                   0.003995\n                  0.001627\n                   2.455\n                  0.01409\n                  6.1 \n                   8.06e-04\n                   0.00719\n                \n\n5\n                  4\n                   0.010886\n                  0.002652\n                   4.104\n                  \n                  \n14.6\n                   5.69e-03\n                   0.01608\n                \n\n5\n                  6\n                   0.004709\n                  0.001929\n                   2.442\n                  0.01462\n                  6.1 \n                   9.29e-04\n                   0.00849\n                \n\n5\n                  8\n                   0.000887\n                  0.000431\n                   2.059\n                  0.03947\n                  4.7 \n                   4.27e-05\n                   0.00173\n                \n\n\n\n\n\n\n\nfun &lt;- function(x) {\n    x |&gt; \n    mutate(estimate = (estimate - lag(estimate)),\n           group = sprintf(\"%s - %s\", group, lag(group)), \n           .by = \"cyl\") |&gt;\n    filter(!is.na(estimate))\n}\navg_comparisons(mod, variables = \"hp\", by = \"cyl\", hypothesis = fun)\n\n\n\n    \n\n      \n\nGroup\n                cyl\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: term, group, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n4 - 3\n                  4\n                   0.00484\n                  0.00666\n                   0.727\n                  0.46719\n                  1.1\n                  -0.008205\n                  0.017882\n                \n\n4 - 3\n                  6\n                   0.02185\n                  0.01139\n                   1.919\n                  0.05503\n                  4.2\n                  -0.000471\n                  0.044180\n                \n\n4 - 3\n                  8\n                   0.00888\n                  0.00306\n                   2.902\n                  0.00371\n                  8.1\n                   0.002882\n                  0.014874\n                \n\n5 - 4\n                  4\n                   0.01391\n                  0.00546\n                   2.548\n                  0.01082\n                  6.5\n                   0.003211\n                  0.024607\n                \n\n5 - 4\n                  6\n                  -0.00386\n                  0.00805\n                  -0.480\n                  0.63117\n                  0.7\n                  -0.019638\n                  0.011911\n                \n\n5 - 4\n                  8\n                  -0.00311\n                  0.00188\n                  -1.651\n                  0.09869\n                  3.3\n                  -0.006798\n                  0.000581",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#fitted-models",
    "href": "vignettes/hypothesis.html#fitted-models",
    "title": "Hypothesis Tests",
    "section": "Fitted models",
    "text": "Fitted models\nThe hypothesis argument can be used to compute standard errors for arbitrary functions of model parameters. This user-supplied function must accept a single model object, and return a data.frame with two columns named term and estimate.\nHere, we test if the sum of the hp and mpg coefficients is equal to 2:\n\nmod &lt;- glm(am ~ hp + mpg, data = mtcars, family = binomial)\n\nfun &lt;- function(x) {\n    b &lt;- coef(x)\n    out &lt;- data.frame(\n        term = \"hp + mpg = 2\",\n        estimate = b[\"hp\"] + b[\"mpg\"] - 2,\n        row.names = NULL\n    )\n    return(out)\n}\n\nhypotheses(mod, hypothesis = fun)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-0.685\n                  0.593\n                  -1.16\n                  0.248\n                  2.0\n                  -1.85\n                  0.476\n                \n\n\n\n\n\nTest of equality between two two predictions:\n\nfun &lt;- function(x) {\n    p &lt;- predict(x, newdata = mtcars)\n    out &lt;- data.frame(term = \"pred[2] = pred[3]\", estimate = p[2] - p[3])\n    return(out)\n}\nhypotheses(mod, hypothesis = fun)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-1.33\n                  0.616\n                  -2.16\n                  0.0305\n                  5.0\n                  -2.54\n                  -0.125\n                \n\n\n\n\n\nWe can also use more complex aggregation patterns. In this ordinal logistic regression model, we model the number of gears for each ar. If we compute fitted values with the predictions() function, we obtain one predicted probability for each individual car and for each level of the response variable:\n\nlibrary(MASS)\nlibrary(dplyr)\n\ndat &lt;- transform(mtcars, \n    gear = factor(gear),\n    cyl = factor(cyl))\nmod &lt;- polr(gear ~ cyl + hp, dat)\n\npredictions(mod)\n\n\n\n    \n\n      \n\nGroup\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  probs \n\nColumns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, gear, cyl, hp \n\n\n\n\n3\n                  0.3931\n                  0.19125\n                    2.06\n                  0.03982\n                  4.7 \n                   0.0183\n                  0.768\n                \n\n3\n                  0.3931\n                  0.19125\n                    2.06\n                  0.03982\n                  4.7 \n                   0.0183\n                  0.768\n                \n\n3\n                  0.0440\n                  0.04256\n                    1.03\n                  0.30081\n                  1.7 \n                  -0.0394\n                  0.127\n                \n\n3\n                  0.3931\n                  0.19125\n                    2.06\n                  0.03982\n                  4.7 \n                   0.0183\n                  0.768\n                \n\n3\n                  0.9963\n                  0.00721\n                  138.17\n                  \n                  \nInf \n                   0.9822\n                  1.010\n                \n\n5\n                  0.6969\n                  0.18931\n                    3.68\n                  \n                  \n12.1\n                   0.3258\n                  1.068\n                \n\n5\n                  0.0555\n                  0.06851\n                    0.81\n                  0.41775\n                  1.3 \n                  -0.0788\n                  0.190\n                \n\n5\n                  0.8115\n                  0.20626\n                    3.93\n                  \n                  \n13.5\n                   0.4073\n                  1.216\n                \n\n5\n                  0.9111\n                  0.16818\n                    5.42\n                  \n                  \n24.0\n                   0.5815\n                  1.241\n                \n\n5\n                  0.6322\n                  0.19648\n                    3.22\n                  0.00129\n                  9.6 \n                   0.2471\n                  1.017\n                \n\n\n\n\n\n\nThere are three levels to the outcome: 3, 4, and 5. Imagine that, for each car in the dataset, we want to collapse categories of the output variable into two categories (“3 & 4” and “5”) by taking sums of predicted probabilities. Then, we want to take the average of those predicted probabilities for each level of cyl. To do so, we define a custom function, and pass it to the hypothesis argument of the hypotheses() function:\n\nfun &lt;- function(x) {\n    predictions(x, vcov = FALSE) |&gt;\n        # label the new categories of outcome levels\n        mutate(group = ifelse(group %in% c(\"3\", \"4\"), \"3 & 4\", \"5\")) |&gt;\n        # sum of probabilities at the individual level\n        summarize(estimate = sum(estimate), .by = c(\"rowid\", \"cyl\", \"group\")) |&gt;\n        # average probabilities for each value of `cyl`\n        summarize(estimate = mean(estimate), .by = c(\"cyl\", \"group\")) |&gt;\n        # the `FUN` argument requires a `term` column\n        rename(term = cyl)\n}\n\nhypotheses(mod, hypothesis = fun)\n\n\n\n    \n\n      \n\nGroup\n                Term\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n3 & 4\n                  6\n                  0.8390\n                  0.0651\n                  12.89\n                  \n                  \n123.9\n                  0.7115\n                  0.967\n                \n\n3 & 4\n                  4\n                  0.7197\n                  0.1099\n                   6.55\n                  \n                  \n34.0 \n                  0.5044\n                  0.935\n                \n\n3 & 4\n                  8\n                  0.9283\n                  0.0174\n                  53.45\n                  \n                  \nInf  \n                  0.8943\n                  0.962\n                \n\n5    \n                  6\n                  0.1610\n                  0.0651\n                   2.47\n                  0.0134\n                  6.2  \n                  0.0334\n                  0.289\n                \n\n5    \n                  4\n                  0.2803\n                  0.1099\n                   2.55\n                  0.0108\n                  6.5  \n                  0.0649\n                  0.496\n                \n\n5    \n                  8\n                  0.0717\n                  0.0174\n                   4.13\n                  \n                  \n14.7 \n                  0.0377\n                  0.106\n                \n\n\n\n\n\n\nNote that this workflow will not work for bayesian models or with bootstrap. However, with those models it is trivial to do the same kind of aggregation by calling posterior_draws() and operating directly on draws from the posterior distribution. See the vignette on bayesian analysis for examples with the posterior_draws() function.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#simple-contrast",
    "href": "vignettes/hypothesis.html#simple-contrast",
    "title": "Hypothesis Tests",
    "section": "Simple contrast",
    "text": "Simple contrast\nConsider a simple example:\n\nlibrary(marginaleffects)\nlibrary(emmeans)\nlibrary(nnet)\n\ndat &lt;- mtcars\ndat$carb &lt;- factor(dat$carb)\ndat$cyl &lt;- factor(dat$cyl)\ndat$am &lt;- as.logical(dat$am)\ndat &lt;- sort_by(dat, ~carb)\n\nmod &lt;- lm(mpg ~ carb + cyl, dat)\n\nmm &lt;- predictions(mod,\n    by = \"carb\",\n    newdata = \"balanced\")\nmm\n\n\n\n    \n\n      \n\ncarb\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: carb, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n1\n                  21.7\n                  1.44\n                  15.06\n                  \n                  \n167.8\n                  18.8\n                  24.5\n                \n\n2\n                  21.3\n                  1.23\n                  17.29\n                  \n                  \n220.0\n                  18.9\n                  23.8\n                \n\n3\n                  21.4\n                  2.19\n                   9.77\n                  \n                  \n72.5 \n                  17.1\n                  25.7\n                \n\n4\n                  18.9\n                  1.21\n                  15.59\n                  \n                  \n179.7\n                  16.5\n                  21.3\n                \n\n6\n                  19.8\n                  3.55\n                   5.56\n                  \n                  \n25.2 \n                  12.8\n                  26.7\n                \n\n8\n                  20.1\n                  3.51\n                   5.73\n                  \n                  \n26.6 \n                  13.2\n                  27.0\n                \n\n\n\n\n\n\nThe contrast between marginal means for carb==1 and carb==2 is:\n\n21.66232 - 21.34058 \n#&gt; [1] 0.32174\n\nor\n\n21.66232 + -(21.34058)\n#&gt; [1] 0.32174\n\nor\n\nsum(c(21.66232, 21.34058) * c(1, -1))\n#&gt; [1] 0.32174\n\nor\n\nc(21.66232, 21.34058) %*% c(1, -1)\n#&gt;         [,1]\n#&gt; [1,] 0.32174\n\nThe last two commands express the contrast of interest as a linear combination of marginal means.\nIn the predictions() function, we can supply a hypothesis argument to compute linear combinations of marginal means. This argument must be a numeric vector of the same length as the number of rows in the output. For example, in the previous there were six rows, and the two marginal means we want to compare are at in the first two positions:\n\nlc &lt;- c(1, -1, 0, 0, 0, 0)\npredictions(mod,\n    by = \"carb\",\n    newdata = \"balanced\",\n    hypothesis = lc)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n0.322\n                  1.77\n                  0.181\n                  0.856\n                  0.2\n                  -3.15\n                  3.8",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#complex-contrast",
    "href": "vignettes/hypothesis.html#complex-contrast",
    "title": "Hypothesis Tests",
    "section": "Complex contrast",
    "text": "Complex contrast\nOf course, we can also estimate more complex contrasts:\n\nlc &lt;- c(0, -2, 1, 1, -1, 1)\npredictions(mod,\n    by = \"carb\",\n    newdata = \"balanced\",\n    hypothesis = lc)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-2.02\n                  6.32\n                  -0.32\n                  0.749\n                  0.4\n                  -14.4\n                  10.4\n                \n\n\n\n\n\nemmeans produces similar results:\n\nlibrary(emmeans)\nem &lt;- emmeans(mod, \"carb\")\nlc &lt;- data.frame(custom_contrast = c(0, -2, 1, 1, -1, 1))\ncontrast(em, method = lc)\n#&gt;  contrast        estimate   SE df t.ratio p.value\n#&gt;  custom_contrast    -2.02 6.32 24  -0.320  0.7516\n#&gt; \n#&gt; Results are averaged over the levels of: cyl",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#multiple-contrasts",
    "href": "vignettes/hypothesis.html#multiple-contrasts",
    "title": "Hypothesis Tests",
    "section": "Multiple contrasts",
    "text": "Multiple contrasts\nUsers can also compute multiple linear combinations simultaneously by supplying a numeric matrix to hypotheses. This matrix must have the same number of rows as the output of slopes(), and each column represents a distinct set of weights for different linear combinations. The column names of the matrix become labels in the output. For example:\n\nlc &lt;- matrix(c(\n    -2, 1, 1, 0, -1, 1,\n    1, -1, 0, 0, 0, 0\n    ), ncol = 2)\ncolnames(lc) &lt;- c(\"Contrast A\", \"Contrast B\")\nlc\n#&gt;      Contrast A Contrast B\n#&gt; [1,]         -2          1\n#&gt; [2,]          1         -1\n#&gt; [3,]          1          0\n#&gt; [4,]          0          0\n#&gt; [5,]         -1          0\n#&gt; [6,]          1          0\n\npredictions(mod,\n    by = \"carb\",\n    newdata = \"balanced\",\n    hypothesis = lc)\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nContrast A\n                  -0.211\n                  6.93\n                  -0.0304\n                  0.976\n                  0.0\n                  -13.79\n                  13.4\n                \n\nContrast B\n                   0.322\n                  1.77\n                   0.1814\n                  0.856\n                  0.2\n                   -3.15\n                   3.8",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/hypothesis.html#difference-in-differences",
    "href": "vignettes/hypothesis.html#difference-in-differences",
    "title": "Hypothesis Tests",
    "section": "Difference-in-Differences",
    "text": "Difference-in-Differences\nNow we illustrate how to use the machinery described above to do pairwise comparisons between contrasts, a type of analysis often associated with a “Difference-in-Differences” research design.\nFirst, we simulate data with two treatment groups and pre/post periods:\n\nlibrary(data.table)\n\nN &lt;- 1000\ndid &lt;- data.table(\n    id = 1:N,\n    pre = rnorm(N),\n    trt = sample(0:1, N, replace = TRUE))\ndid$post &lt;- did$pre + did$trt * 0.3 + rnorm(N)\ndid &lt;- melt(\n    did,\n    value.name = \"y\",\n    variable.name = \"time\",\n    id.vars = c(\"id\", \"trt\"))\nhead(did)\n#&gt;       id   trt   time           y\n#&gt;    &lt;int&gt; &lt;int&gt; &lt;fctr&gt;       &lt;num&gt;\n#&gt; 1:     1     0    pre  0.04532029\n#&gt; 2:     2     1    pre  0.89903020\n#&gt; 3:     3     1    pre  0.10170682\n#&gt; 4:     4     0    pre  0.16498400\n#&gt; 5:     5     1    pre -0.16122438\n#&gt; 6:     6     0    pre -1.45044182\n\nThen, we estimate a linear model with a multiple interaction between the time and the treatment indicators. We also compute contrasts at the mean for each treatment level:\n\ndid_model &lt;- lm(y ~ time * trt, data = did)\n\ncomparisons(\n    did_model,\n    newdata = datagrid(trt = 0:1),\n    variables = \"time\")\n\n\n\n    \n\n      \n\ntrt\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, trt, predicted_lo, predicted_hi, predicted, time, y \n\n\n\n\n0\n                  0.0636\n                  0.0801\n                  0.795\n                  0.427 \n                  1.2 \n                  -0.0933\n                  0.221\n                \n\n1\n                  0.3229\n                  0.0782\n                  4.132\n                  \n                  \n14.8\n                   0.1698\n                  0.476\n                \n\n\n\n\n\n\nFinally, we compute pairwise differences between contrasts. This is the Diff-in-Diff estimate:\n\ncomparisons(\n    did_model,\n    variables = \"time\",\n    newdata = datagrid(trt = 0:1),\n    hypothesis = \"pairwise\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-0.259\n                  0.112\n                  -2.32\n                  0.0205\n                  5.6\n                  -0.479\n                  -0.04",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Hypothesis Tests"
    ]
  },
  {
    "objectID": "vignettes/lme4.html",
    "href": "vignettes/lme4.html",
    "title": "Mixed Effects",
    "section": "",
    "text": "Mixed Effects\nThis vignette replicates some of the analyses in this excellent blog post by Solomon Kurz: Use emmeans() to include 95% CIs around your lme4-based fitted lines\nLoad libraries and fit two models of chick weights:\n\nlibrary(lme4)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(marginaleffects)\n\n## unconditional linear growth model\nfit1 &lt;- lmer(\n  weight ~ 1 + Time + (1 + Time | Chick),\n  data = ChickWeight)\n\n## conditional quadratic growth model\nfit2 &lt;- lmer(\n  weight ~ 1 + Time + I(Time^2) + Diet + Time:Diet + I(Time^2):Diet + (1 + Time + I(Time^2) | Chick),\n  data = ChickWeight)\n\nUnit-level predictions\nPredict weight of each chick over time:\n\npred1 &lt;- predictions(fit1,\n                     newdata = datagrid(Chick = ChickWeight$Chick,\n                                        Time = 0:21))\n\np1 &lt;- ggplot(pred1, aes(Time, estimate, level = Chick)) +\n      geom_line() +\n      labs(y = \"Predicted weight\", x = \"Time\", title = \"Linear growth model\")\n\npred2 &lt;- predictions(fit2,\n                     newdata = datagrid(Chick = ChickWeight$Chick,\n                                        Time = 0:21))\n\np2 &lt;- ggplot(pred2, aes(Time, estimate, level = Chick)) +\n      geom_line() +\n      labs(y = \"Predicted weight\", x = \"Time\", title = \"Quadratic growth model\")\n\np1 + p2\n\n\n\n\n\n\n\nPredictions for each chick, in the 4 counterfactual worlds with different values for the Diet variable:\n\npred &lt;- predictions(fit2)\n\nggplot(pred, aes(Time, estimate, level = Chick)) +\n    geom_line() +\n    ylab(\"Predicted Weight\") +\n    facet_wrap(~ Diet, labeller = label_both)\n\n\n\n\n\n\n\nPopulation-level predictions\nTo make population-level predictions, we set the Chick variable to NA, and set re.form=NA. This last argument is offered by the lme4::predict function which is used behind the scenes to compute predictions:\n\npred &lt;- predictions(\n    fit2,\n    newdata = datagrid(Chick = NA,\n                       Diet = 1:4,\n                       Time = 0:21),\n    re.form = NA)\n\nggplot(pred, aes(x = Time, y = estimate, ymin = conf.low, ymax = conf.high)) +\n    geom_ribbon(alpha = .1, fill = \"red\") +\n    geom_line() +\n    facet_wrap(~ Diet, labeller = label_both) +\n    labs(title = \"Population-level trajectories\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "Mixed Effects"
    ]
  },
  {
    "objectID": "vignettes/tables.html",
    "href": "vignettes/tables.html",
    "title": "Tables",
    "section": "",
    "text": "We can summarize the results of the comparisons() or slopes() functions using the modelsummary package.\n\nlibrary(modelsummary)\nlibrary(marginaleffects)\n\nmod &lt;- glm(am ~ wt + drat, family = binomial, data = mtcars)\nmfx &lt;- avg_slopes(mod)\n\nmodelsummary(mfx)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\ndrat    \n                  0.278  \n                \n\n        \n                  (0.168)\n                \n\nwt      \n                  -0.217 \n                \n\n        \n                  (0.080)\n                \n\nNum.Obs.\n                  32     \n                \n\nAIC     \n                  22.0   \n                \n\nBIC     \n                  26.4   \n                \n\nLog.Lik.\n                  -8.011 \n                \n\nF       \n                  3.430  \n                \n\nRMSE    \n                  0.28   \n                \n\n\n\n\n\n\nThe same results can be visualized with modelplot():\n\nmodelplot(mfx)\n\n\n\n\n\n\n\n\nWhen using the comparisons() function (or the slopes() function with categorical variables), the output will include two columns to uniquely identify the quantities of interest: term and contrast.\n\ndat &lt;- mtcars\ndat$gear &lt;- as.factor(dat$gear)\nmod &lt;- glm(vs ~ gear + mpg, data = dat, family = binomial)\n\ncmp &lt;- comparisons(mod)\nget_estimates(cmp)\n#&gt; # A tibble: 96 × 16\n#&gt;    rowid term  contrast estimate std.error statistic p.value s.value conf.low conf.high predicted_lo predicted_hi predicted    vs gear    mpg\n#&gt;    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n#&gt;  1     1 gear  4 - 3      0.0736    0.264      0.279   0.780   0.358  -0.443      0.590       0.707        0.781     0.781      0 4      21  \n#&gt;  2     2 gear  4 - 3      0.0736    0.264      0.279   0.780   0.358  -0.443      0.590       0.707        0.781     0.781      0 4      21  \n#&gt;  3     3 gear  4 - 3      0.0321    0.125      0.257   0.797   0.327  -0.213      0.277       0.892        0.924     0.924      1 4      22.8\n#&gt;  4     4 gear  4 - 3      0.0636    0.231      0.275   0.783   0.352  -0.389      0.517       0.761        0.824     0.761      1 3      21.4\n#&gt;  5     5 gear  4 - 3      0.0913    0.324      0.282   0.778   0.362  -0.543      0.725       0.334        0.425     0.334      0 3      18.7\n#&gt;  6     6 gear  4 - 3      0.0796    0.288      0.276   0.782   0.354  -0.485      0.645       0.250        0.329     0.250      1 3      18.1\n#&gt;  7     7 gear  4 - 3      0.0111    0.0489     0.227   0.820   0.286  -0.0847     0.107       0.0242       0.0353    0.0242     0 3      14.3\n#&gt;  8     8 gear  4 - 3      0.0122    0.0517     0.236   0.813   0.298  -0.0891     0.114       0.961        0.973     0.973      1 4      24.4\n#&gt;  9     9 gear  4 - 3      0.0321    0.125      0.257   0.797   0.327  -0.213      0.277       0.892        0.924     0.924      1 4      22.8\n#&gt; 10    10 gear  4 - 3      0.0964    0.338      0.285   0.776   0.367  -0.566      0.759       0.414        0.510     0.510      1 4      19.2\n#&gt; # ℹ 86 more rows\n\nWe can use the shape argument of the modelsummary function to structure the table properly:\n\nmodelsummary(cmp, shape = term + contrast ~ model)\n\n\n\n    \n\n      \n\n \n                  \n                (1)\n              \n\n\ngear    \n                  4 - 3\n                  32    \n                \n\n        \n                       \n                  32    \n                \n\n        \n                  5 - 3\n                  32    \n                \n\n        \n                       \n                  32    \n                \n\nmpg     \n                  +1   \n                  32    \n                \n\n        \n                       \n                  32    \n                \n\nNum.Obs.\n                       \n                  32    \n                \n\nAIC     \n                       \n                  26.2  \n                \n\nBIC     \n                       \n                  32.1  \n                \n\nLog.Lik.\n                       \n                  -9.101\n                \n\nF       \n                       \n                  2.389 \n                \n\nRMSE    \n                       \n                  0.31  \n                \n\n\n\n\n\n\nCross-contrasts can be a bit trickier, since there are multiple simultaneous groups. Consider this example:\n\nmod &lt;- lm(mpg ~ factor(cyl) + factor(gear), data = mtcars)\ncmp &lt;- comparisons(\n  mod,\n  variables = c(\"gear\", \"cyl\"),\n  cross = TRUE)\nget_estimates(cmp)\n#&gt; # A tibble: 128 × 17\n#&gt;    rowid term  contrast_cyl contrast_gear estimate std.error statistic p.value s.value conf.low conf.high predicted_lo predicted_hi predicted   mpg   cyl  gear\n#&gt;    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1     1 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      20.1  21       6     4\n#&gt;  2     2 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      20.1  21       6     4\n#&gt;  3     3 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      26.8  22.8     4     4\n#&gt;  4     4 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      18.8  21.4     6     3\n#&gt;  5     5 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      14.9  18.7     8     3\n#&gt;  6     6 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      18.8  18.1     6     3\n#&gt;  7     7 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      14.9  14.3     8     3\n#&gt;  8     8 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      26.8  24.4     4     4\n#&gt;  9     9 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      26.8  22.8     4     4\n#&gt; 10    10 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      20.1  19.2     6     4\n#&gt; # ℹ 118 more rows\n\nAs we can see above, there are two relevant grouping columns: contrast_gear and contrast_cyl. We can simply plug those names in the shape argument:\n\nmodelsummary(\n  cmp,\n  shape = contrast_gear + contrast_cyl ~ model)\n\n\n\n    \n\n      \n\ngear\n                cyl\n                (1)\n              \n\n\n4 - 3   \n                  6 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\n        \n                  8 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\n5 - 3   \n                  6 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\n        \n                  8 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\nNum.Obs.\n                       \n                  32     \n                \n\nR2      \n                       \n                  0.740  \n                \n\nR2 Adj. \n                       \n                  0.701  \n                \n\nAIC     \n                       \n                  173.7  \n                \n\nBIC     \n                       \n                  182.5  \n                \n\nLog.Lik.\n                       \n                  -80.838\n                \n\nF       \n                       \n                  19.190 \n                \n\nRMSE    \n                       \n                  3.03",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Tables"
    ]
  },
  {
    "objectID": "vignettes/tables.html#marginal-effects",
    "href": "vignettes/tables.html#marginal-effects",
    "title": "Tables",
    "section": "",
    "text": "We can summarize the results of the comparisons() or slopes() functions using the modelsummary package.\n\nlibrary(modelsummary)\nlibrary(marginaleffects)\n\nmod &lt;- glm(am ~ wt + drat, family = binomial, data = mtcars)\nmfx &lt;- avg_slopes(mod)\n\nmodelsummary(mfx)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\ndrat    \n                  0.278  \n                \n\n        \n                  (0.168)\n                \n\nwt      \n                  -0.217 \n                \n\n        \n                  (0.080)\n                \n\nNum.Obs.\n                  32     \n                \n\nAIC     \n                  22.0   \n                \n\nBIC     \n                  26.4   \n                \n\nLog.Lik.\n                  -8.011 \n                \n\nF       \n                  3.430  \n                \n\nRMSE    \n                  0.28   \n                \n\n\n\n\n\n\nThe same results can be visualized with modelplot():\n\nmodelplot(mfx)",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Tables"
    ]
  },
  {
    "objectID": "vignettes/tables.html#contrasts",
    "href": "vignettes/tables.html#contrasts",
    "title": "Tables",
    "section": "",
    "text": "When using the comparisons() function (or the slopes() function with categorical variables), the output will include two columns to uniquely identify the quantities of interest: term and contrast.\n\ndat &lt;- mtcars\ndat$gear &lt;- as.factor(dat$gear)\nmod &lt;- glm(vs ~ gear + mpg, data = dat, family = binomial)\n\ncmp &lt;- comparisons(mod)\nget_estimates(cmp)\n#&gt; # A tibble: 96 × 16\n#&gt;    rowid term  contrast estimate std.error statistic p.value s.value conf.low conf.high predicted_lo predicted_hi predicted    vs gear    mpg\n#&gt;    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n#&gt;  1     1 gear  4 - 3      0.0736    0.264      0.279   0.780   0.358  -0.443      0.590       0.707        0.781     0.781      0 4      21  \n#&gt;  2     2 gear  4 - 3      0.0736    0.264      0.279   0.780   0.358  -0.443      0.590       0.707        0.781     0.781      0 4      21  \n#&gt;  3     3 gear  4 - 3      0.0321    0.125      0.257   0.797   0.327  -0.213      0.277       0.892        0.924     0.924      1 4      22.8\n#&gt;  4     4 gear  4 - 3      0.0636    0.231      0.275   0.783   0.352  -0.389      0.517       0.761        0.824     0.761      1 3      21.4\n#&gt;  5     5 gear  4 - 3      0.0913    0.324      0.282   0.778   0.362  -0.543      0.725       0.334        0.425     0.334      0 3      18.7\n#&gt;  6     6 gear  4 - 3      0.0796    0.288      0.276   0.782   0.354  -0.485      0.645       0.250        0.329     0.250      1 3      18.1\n#&gt;  7     7 gear  4 - 3      0.0111    0.0489     0.227   0.820   0.286  -0.0847     0.107       0.0242       0.0353    0.0242     0 3      14.3\n#&gt;  8     8 gear  4 - 3      0.0122    0.0517     0.236   0.813   0.298  -0.0891     0.114       0.961        0.973     0.973      1 4      24.4\n#&gt;  9     9 gear  4 - 3      0.0321    0.125      0.257   0.797   0.327  -0.213      0.277       0.892        0.924     0.924      1 4      22.8\n#&gt; 10    10 gear  4 - 3      0.0964    0.338      0.285   0.776   0.367  -0.566      0.759       0.414        0.510     0.510      1 4      19.2\n#&gt; # ℹ 86 more rows\n\nWe can use the shape argument of the modelsummary function to structure the table properly:\n\nmodelsummary(cmp, shape = term + contrast ~ model)\n\n\n\n    \n\n      \n\n \n                  \n                (1)\n              \n\n\ngear    \n                  4 - 3\n                  32    \n                \n\n        \n                       \n                  32    \n                \n\n        \n                  5 - 3\n                  32    \n                \n\n        \n                       \n                  32    \n                \n\nmpg     \n                  +1   \n                  32    \n                \n\n        \n                       \n                  32    \n                \n\nNum.Obs.\n                       \n                  32    \n                \n\nAIC     \n                       \n                  26.2  \n                \n\nBIC     \n                       \n                  32.1  \n                \n\nLog.Lik.\n                       \n                  -9.101\n                \n\nF       \n                       \n                  2.389 \n                \n\nRMSE    \n                       \n                  0.31  \n                \n\n\n\n\n\n\nCross-contrasts can be a bit trickier, since there are multiple simultaneous groups. Consider this example:\n\nmod &lt;- lm(mpg ~ factor(cyl) + factor(gear), data = mtcars)\ncmp &lt;- comparisons(\n  mod,\n  variables = c(\"gear\", \"cyl\"),\n  cross = TRUE)\nget_estimates(cmp)\n#&gt; # A tibble: 128 × 17\n#&gt;    rowid term  contrast_cyl contrast_gear estimate std.error statistic p.value s.value conf.low conf.high predicted_lo predicted_hi predicted   mpg   cyl  gear\n#&gt;    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1     1 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      20.1  21       6     4\n#&gt;  2     2 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      20.1  21       6     4\n#&gt;  3     3 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      26.8  22.8     4     4\n#&gt;  4     4 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      18.8  21.4     6     3\n#&gt;  5     5 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      14.9  18.7     8     3\n#&gt;  6     6 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      18.8  18.1     6     3\n#&gt;  7     7 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      14.9  14.3     8     3\n#&gt;  8     8 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      26.8  24.4     4     4\n#&gt;  9     9 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      26.8  22.8     4     4\n#&gt; 10    10 cross 6 - 4        4 - 3            -5.33      2.77     -1.93  0.0542    4.21    -10.8    0.0953         25.4         20.1      20.1  19.2     6     4\n#&gt; # ℹ 118 more rows\n\nAs we can see above, there are two relevant grouping columns: contrast_gear and contrast_cyl. We can simply plug those names in the shape argument:\n\nmodelsummary(\n  cmp,\n  shape = contrast_gear + contrast_cyl ~ model)\n\n\n\n    \n\n      \n\ngear\n                cyl\n                (1)\n              \n\n\n4 - 3   \n                  6 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\n        \n                  8 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\n5 - 3   \n                  6 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\n        \n                  8 - 4\n                  32     \n                \n\n        \n                       \n                  32     \n                \n\nNum.Obs.\n                       \n                  32     \n                \n\nR2      \n                       \n                  0.740  \n                \n\nR2 Adj. \n                       \n                  0.701  \n                \n\nAIC     \n                       \n                  173.7  \n                \n\nBIC     \n                       \n                  182.5  \n                \n\nLog.Lik.\n                       \n                  -80.838\n                \n\nF       \n                       \n                  19.190 \n                \n\nRMSE    \n                       \n                  3.03",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Tables"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#prediction-type-scale",
    "href": "vignettes/predictions.html#prediction-type-scale",
    "title": "Predictions",
    "section": "Prediction type (scale)",
    "text": "Prediction type (scale)\nFor most models, predictions() generates adjusted predictions on the “response” scale, so the adjusted predictions should be interpreted on that scale. However, users can pass a string to the type argument, and predictions will consider different outcomes.\nUsing the type argument of the predictions() function we can specify the “scale” on which to make predictions. This refers to either the scale used to estimate the model (i.e., link scale) or to a more interpretable scale (e.g., response scale). For example, when fitting a linear regression model using the lm() function, the \"link\" scale and the response scale are identical. An “Adjusted Prediction” computed on either scale will be expressed as the mean value of the response variable at the given values of the predictor variables.\nOn the other hand, when fitting a binary logistic regression model using the glm() function (which uses a binomial family and a logit link ), the link scale and the response scale will be different: an “Adjusted Prediction” computed on the \"link\" scale will be expressed as a log odds of a “successful” response at the given values of the predictor variables, whereas an “Adjusted Prediction” computed on the \"response\" scale will be expressed as a probability that the response variable equals 1.\n\nglm_mod &lt;- glm(am ~ mpg, family = binomial, data = mtcars)\npred &lt;- predictions(glm_mod, type = \"response\")\nhead(pred)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;     0.461     0.1158 3.98  &lt; 0.001 13.8 0.2341  0.688\n#&gt;     0.461     0.1158 3.98  &lt; 0.001 13.8 0.2341  0.688\n#&gt;     0.598     0.1324 4.52  &lt; 0.001 17.3 0.3384  0.857\n#&gt;     0.492     0.1196 4.11  &lt; 0.001 14.6 0.2573  0.726\n#&gt;     0.297     0.1005 2.95  0.00314  8.3 0.0999  0.494\n#&gt;     0.260     0.0978 2.66  0.00788  7.0 0.0682  0.452\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, mpg\n\npred &lt;- predictions(glm_mod, type = \"link\")\nhead(pred)\n#&gt; \n#&gt;  Estimate Std. Error       z Pr(&gt;|z|)   S  2.5 %  97.5 %\n#&gt;   -0.1559      0.466 -0.3345   0.7380 0.4 -1.070  0.7578\n#&gt;   -0.1559      0.466 -0.3345   0.7380 0.4 -1.070  0.7578\n#&gt;    0.3967      0.551  0.7204   0.4713 1.1 -0.683  1.4761\n#&gt;   -0.0331      0.479 -0.0692   0.9448 0.1 -0.971  0.9049\n#&gt;   -0.8621      0.482 -1.7903   0.0734 3.8 -1.806  0.0817\n#&gt;   -1.0463      0.509 -2.0575   0.0396 4.7 -2.043 -0.0496\n#&gt; \n#&gt; Type:  link \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, mpg\n\nThe default value of the type argument for most models is \"response\", which means that the predictions() function will compute predicted probabilities (binomial family), Poisson means (poisson family), etc. Users should refer to the documentation of the predict of the package they used to fit the model to know what values are allowable.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#average-adjusted-predictions-aap",
    "href": "vignettes/predictions.html#average-adjusted-predictions-aap",
    "title": "Predictions",
    "section": "Average Adjusted Predictions (AAP)",
    "text": "Average Adjusted Predictions (AAP)\nAn “Average Adjusted Prediction” is the outcome of a two step process:\n\nCreate a new dataset with each of the original regressor values, but fixing some regressors to values of interest.\nTake the average of the predicted values in this new dataset.\n\nWe can obtain AAPs by applying the avg_predictions() functions or by argument:\n\nmodlin &lt;- lm(mpg ~ hp + factor(cyl), mtcars)\navg_predictions(modlin)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      20.1      0.556 36.1   &lt;0.001 946.7    19   21.2\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThis is equivalent to:\n\npred &lt;- predictions(modlin)\nmean(pred$estimate)\n#&gt; [1] 20.09062\n\nNote that in GLM models with a non-linear link function, the default type is invlink(link). This means that predictions are first made on the link scale, averaged, and then back transformed. Thus, the average prediction may not be exactly identical to the average of predictions:\n\nglm_mod &lt;- glm(vs ~ hp + am, data = mtcars, family = binomial)\n\navg_predictions(glm_mod)$estimate\n#&gt; [1] 0.4375\n\n## Step 1: predict on the link scale\np &lt;- predictions(glm_mod, type = \"link\")$estimate\n## Step 2: average\np &lt;- mean(p)\n## Step 3: backtransform\nglm_mod$family$linkinv(p)\n#&gt; [1] 0.06308965\n\nUsers who want the average of individual-level predictions on the response scale can specify the type argument explicitly:\n\navg_predictions(glm_mod, type = \"response\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;     0.437     0.0429 10.2   &lt;0.001 78.8 0.353  0.522\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#average-adjusted-predictions-by-group",
    "href": "vignettes/predictions.html#average-adjusted-predictions-by-group",
    "title": "Predictions",
    "section": "Average Adjusted Predictions by Group",
    "text": "Average Adjusted Predictions by Group\nWe can compute average adjusted predictions for different subsets of the data with the by argument.\n\npredictions(glm_mod, by = \"am\")\n#&gt; \n#&gt;  am Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;   1    0.538     0.0848 6.35   &lt;0.001 32.1 0.372  0.705\n#&gt;   0    0.368     0.0430 8.56   &lt;0.001 56.3 0.284  0.453\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nIn the next example, we create a “counterfactual” data grid where each observation of the dataset is repeated twice, with different values of the am variable, and all other variables held at the observed values. We also show the equivalent results using dplyr:\n\npredictions(\n    glm_mod,\n    type = \"response\",\n    by = \"am\",\n    newdata = datagrid(am = 0:1, grid_type = \"counterfactual\"))\n#&gt; \n#&gt;  am Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;   0    0.526     0.0330 15.93   &lt;0.001 187.3 0.461  0.591\n#&gt;   1    0.330     0.0646  5.11   &lt;0.001  21.6 0.204  0.457\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\npredictions(\n    glm_mod,\n    type = \"response\",\n    newdata = datagrid(am = 0:1, grid_type = \"counterfactual\")) |&gt;\n    group_by(am) |&gt;\n    summarize(AAP = mean(estimate))\n#&gt; # A tibble: 2 × 2\n#&gt;      am   AAP\n#&gt;   &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     0 0.526\n#&gt; 2     1 0.330\n\nNote that the two results are exactly identical when we specify type=\"response\" explicitly. However, they will differ slightly when we leave type unspecified, because marginaleffects will then automatically make predictions and average on the link scale, before backtransforming (\"invlink(link)\"):\n\npredictions(\n    glm_mod,\n    by = \"am\",\n    newdata = datagrid(am = 0:1, grid_type = \"counterfactual\"))\n#&gt; \n#&gt;  am Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;   0    0.526     0.0330 15.93   &lt;0.001 187.3 0.461  0.591\n#&gt;   1    0.330     0.0646  5.11   &lt;0.001  21.6 0.204  0.457\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\npredictions(\n    glm_mod,\n    type = \"link\",\n    newdata = datagrid(am = 0:1, grid_type = \"counterfactual\")) |&gt;\n    group_by(am) |&gt;\n    summarize(AAP = glm_mod$family$linkinv(mean(estimate)))\n#&gt; # A tibble: 2 × 2\n#&gt;      am     AAP\n#&gt;   &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1     0 0.240  \n#&gt; 2     1 0.00696",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#conditional-adjusted-predictions",
    "href": "vignettes/predictions.html#conditional-adjusted-predictions",
    "title": "Predictions",
    "section": "Conditional Adjusted Predictions",
    "text": "Conditional Adjusted Predictions\nFirst, we download the ggplot2movies dataset from the RDatasets archive. Then, we create a variable called certified_fresh for movies with a rating of at least 8. Finally, we discard some outliers and fit a logistic regression model:\n\nlibrary(tidyverse)\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\") |&gt;\n    mutate(style = case_when(Action == 1 ~ \"Action\",\n                             Comedy == 1 ~ \"Comedy\",\n                             Drama == 1 ~ \"Drama\",\n                             TRUE ~ \"Other\"),\n           style = factor(style),\n           certified_fresh = rating &gt;= 8) |&gt;\n    dplyr::filter(length &lt; 240)\n\nmod &lt;- glm(certified_fresh ~ length * style, data = dat, family = binomial)\n\nWe can plot adjusted predictions, conditional on the length variable using the plot_predictions function:\n\nmod &lt;- glm(certified_fresh ~ length, data = dat, family = binomial)\n\nplot_predictions(mod, condition = \"length\")\n\n\n\n\n\n\n\nWe can also introduce another condition which will display a categorical variable like style in different colors. This can be useful in models with interactions:\n\nmod &lt;- glm(certified_fresh ~ length * style, data = dat, family = binomial)\n\nplot_predictions(mod, condition = c(\"length\", \"style\"))\n\n\n\n\n\n\n\nWith the plot_predictions() function, we can plot predictions on different outcome scales:\n\nmod &lt;- glm(certified_fresh ~ length * style, data = dat, family = binomial)\n\nplot_predictions(mod, condition = \"length\", type = \"response\")\n\n\n\n\n\n\n\n\nplot_predictions(mod, condition = \"length\", type = \"link\")",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#marginal-adjusted-predictions",
    "href": "vignettes/predictions.html#marginal-adjusted-predictions",
    "title": "Predictions",
    "section": "Marginal Adjusted Predictions",
    "text": "Marginal Adjusted Predictions\nThe predictions displayed in the previous section by the plot_predictions() function, using the condition argument, can be said to be “conditional” in the sense that they are conditional on the values of the predictors in a constructed grid of “representative” values.\nAn alternative is plot “marginal” predictions using the by argument. The underlying process is to (1) compute predictions for each observation in the actually observed dataset, and then (2) average these predictions across some variable(s). This is equivalent to plotting the avg_predictions(model, by='z') call.\nFor example:\n\nplot_predictions(mod, by = \"style\")",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#prediction-types",
    "href": "vignettes/predictions.html#prediction-types",
    "title": "Predictions",
    "section": "Prediction types",
    "text": "Prediction types\nThe predictions function computes model-adjusted means on the scale of the output of the predict(model) function. By default, predict produces predictions on the “response” scale, so the adjusted predictions should be interpreted on that scale. However, users can pass a string to the type argument, and predictions will consider different outcomes.\nWe can plot predictions on different outcome scales:\n\nmod &lt;- glm(am ~ mpg, family = binomial, data = mtcars)\n\nplot_predictions(mod, condition = \"mpg\", type = \"response\")\n\n\n\n\n\n\n\n\nplot_predictions(mod, condition = \"mpg\", type = \"link\")",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#themes-and-styles",
    "href": "vignettes/predictions.html#themes-and-styles",
    "title": "Predictions",
    "section": "Themes and styles",
    "text": "Themes and styles\nSince the output of plot_predictions() is a ggplot2 object, it is very easy to customize. For example, we can add points for the actual observations of our dataset like so:\n\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nmt &lt;- mtcars\nmt$label &lt;- row.names(mt)\n\nmod &lt;- lm(mpg ~ hp, data = mt)\n\nplot_predictions(mod, condition = \"hp\") +\n    geom_point(aes(x = hp, y = mpg), data = mt) +\n    geom_rug(aes(x = hp, y = mpg), data = mt) +\n    geom_text_repel(aes(x = hp, y = mpg, label = label),\n                    data = subset(mt, hp &gt; 250),\n                    nudge_y = 2) +\n    theme_classic()",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#customization",
    "href": "vignettes/predictions.html#customization",
    "title": "Predictions",
    "section": "Customization",
    "text": "Customization\nThe plot customization section of the Plots vignette illustrates two more ways to customize plots. In addition to using the plot_*() function arguments, users can:\n\nModify the plot objects using ggplot2 functions or add-on packages.\nExtract the underlying plotting data with the draw=FALSE argument, and feed that data to their preferred plotting software.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#custom-aggregation",
    "href": "vignettes/predictions.html#custom-aggregation",
    "title": "Predictions",
    "section": "Custom aggregation",
    "text": "Custom aggregation\nWe can use custom aggregations by supplying a data frame to the by argument. All columns of this data frame must be present in the output of predictions(), and the data frame must also include a by column of labels. In this example, we “collapse” response groups:\n\nby &lt;- data.frame(\n    group = c(\"3\", \"4\", \"5\"),\n    by = c(\"3,4\", \"3,4\", \"5\"))\n\npredictions(nom, type = \"probs\", by = by)\n#&gt; \n#&gt;   By Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;  3,4    0.422     0.0231 18.25   &lt;0.001 244.7 0.3766  0.467\n#&gt;  5      0.156     0.0462  3.38   &lt;0.001  10.4 0.0656  0.247\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, by\n\nThis can be very useful in combination with the hypothesis argument. For example, here we compute the difference between average adjusted predictions for the 3 and 4 response levels, compared to the 5 response level:\n\npredictions(nom, type = \"probs\", by = by, hypothesis = \"sequential\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    -0.266     0.0694 -3.83   &lt;0.001 12.9 -0.402  -0.13\n#&gt; \n#&gt; Term: 5 - 3,4\n#&gt; Type:  probs \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nWe can also use more complicated aggregations. Here, we compute the predicted probability of outcome levels for each value of cyl, by collapsing the “3” and “4” outcome levels:\n\nnom &lt;- multinom(factor(gear) ~ mpg + factor(cyl), data = mtcars, trace = FALSE)\n\nby &lt;- expand.grid(\n    group = 3:5,\n    cyl = c(4, 6, 8),\n    stringsAsFactors = TRUE) |&gt;\n    # define labels\n    transform(by = ifelse(\n        group %in% 3:4,\n        sprintf(\"3/4 Gears & %s Cylinders\", cyl),\n        sprintf(\"5 Gears & %s Cylinders\", cyl)))\n\npredictions(nom, by = by)\n#&gt; \n#&gt;                       By Estimate Std. Error    z Pr(&gt;|z|)    S   2.5 % 97.5 %\n#&gt;  3/4 Gears & 6 Cylinders    0.429     0.0661 6.49   &lt;0.001 33.4  0.2991  0.558\n#&gt;  3/4 Gears & 4 Cylinders    0.409     0.0580 7.06   &lt;0.001 39.1  0.2956  0.523\n#&gt;  3/4 Gears & 8 Cylinders    0.429     0.0458 9.35   &lt;0.001 66.6  0.3387  0.518\n#&gt;  5 Gears & 6 Cylinders      0.143     0.1321 1.08    0.280  1.8 -0.1161  0.402\n#&gt;  5 Gears & 4 Cylinders      0.182     0.1159 1.57    0.117  3.1 -0.0457  0.409\n#&gt;  5 Gears & 8 Cylinders      0.143     0.0917 1.56    0.119  3.1 -0.0368  0.323\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, by\n\nAnd we can then compare the different groups using the hypothesis argument:\n\npredictions(nom, by = by, hypothesis = \"pairwise\")\n#&gt; \n#&gt;                                               Term  Estimate Std. Error         z Pr(&gt;|z|)   S    2.5 % 97.5 %\n#&gt;  3/4 Gears & 6 Cylinders - 3/4 Gears & 4 Cylinders  1.93e-02     0.0879  0.219839   0.8260 0.3 -0.15294  0.192\n#&gt;  3/4 Gears & 6 Cylinders - 3/4 Gears & 8 Cylinders  2.84e-05     0.0804  0.000353   0.9997 0.0 -0.15757  0.158\n#&gt;  3/4 Gears & 6 Cylinders - 5 Gears & 6 Cylinders    2.86e-01     0.1982  1.441538   0.1494 2.7 -0.10275  0.674\n#&gt;  3/4 Gears & 6 Cylinders - 5 Gears & 4 Cylinders    2.47e-01     0.1334  1.851412   0.0641 4.0 -0.01449  0.509\n#&gt;  3/4 Gears & 6 Cylinders - 5 Gears & 8 Cylinders    2.86e-01     0.1130  2.527636   0.0115 6.4  0.06415  0.507\n#&gt;  3/4 Gears & 4 Cylinders - 3/4 Gears & 8 Cylinders -1.93e-02     0.0739 -0.261054   0.7941 0.3 -0.16415  0.126\n#&gt;  3/4 Gears & 4 Cylinders - 5 Gears & 6 Cylinders    2.66e-01     0.1443  1.846188   0.0649 3.9 -0.01642  0.549\n#&gt;  3/4 Gears & 4 Cylinders - 5 Gears & 4 Cylinders    2.28e-01     0.1739  1.309481   0.1904 2.4 -0.11312  0.569\n#&gt;  3/4 Gears & 4 Cylinders - 5 Gears & 8 Cylinders    2.66e-01     0.1085  2.455119   0.0141 6.1  0.05371  0.479\n#&gt;  3/4 Gears & 8 Cylinders - 5 Gears & 6 Cylinders    2.86e-01     0.1399  2.042632   0.0411 4.6  0.01156  0.560\n#&gt;  3/4 Gears & 8 Cylinders - 5 Gears & 4 Cylinders    2.47e-01     0.1247  1.981367   0.0476 4.4  0.00267  0.491\n#&gt;  3/4 Gears & 8 Cylinders - 5 Gears & 8 Cylinders    2.86e-01     0.1375  2.076745   0.0378 4.7  0.01606  0.555\n#&gt;  5 Gears & 6 Cylinders - 5 Gears & 4 Cylinders     -3.86e-02     0.1758 -0.219838   0.8260 0.3 -0.38317  0.306\n#&gt;  5 Gears & 6 Cylinders - 5 Gears & 8 Cylinders     -5.68e-05     0.1608 -0.000353   0.9997 0.0 -0.31526  0.315\n#&gt;  5 Gears & 4 Cylinders - 5 Gears & 8 Cylinders      3.86e-02     0.1478  0.261054   0.7941 0.3 -0.25112  0.328\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/predictions.html#themes-and-styles-1",
    "href": "vignettes/predictions.html#themes-and-styles-1",
    "title": "Predictions",
    "section": "Themes and styles",
    "text": "Themes and styles\nWe can also use plot_predictions() in models with multinomial outcomes or grouped coefficients. For example, notice that when we call draw=FALSE, the result includes a group column:\n\nlibrary(MASS)\nlibrary(ggplot2)\n\nmod &lt;- nnet::multinom(factor(gear) ~ mpg, data = mtcars, trace = FALSE)\n\np &lt;- plot_predictions(\n    mod,\n    type = \"probs\",\n    condition = \"mpg\",\n    draw = FALSE)\n\nhead(p)\n#&gt;   rowid group  estimate  std.error statistic       p.value  s.value  conf.low conf.high      mpg gear\n#&gt; 1     1     3 0.9714990 0.03873404  25.08127 7.962555e-139 458.7548 0.8955817  1.047416 10.40000    4\n#&gt; 2     2     3 0.9656724 0.04394086  21.97664 4.818284e-107 353.1778 0.8795499  1.051795 10.87959    4\n#&gt; 3     3     3 0.9586759 0.04964165  19.31193  4.263532e-83 273.6280 0.8613801  1.055972 11.35918    4\n#&gt; 4     4     3 0.9502914 0.05581338  17.02623  5.247849e-65 213.5336 0.8408992  1.059684 11.83878    4\n#&gt; 5     5     3 0.9402691 0.06240449  15.06733  2.656268e-51 168.0089 0.8179586  1.062580 12.31837    4\n#&gt; 6     6     3 0.9283274 0.06932768  13.39043  6.878233e-41 133.4170 0.7924476  1.064207 12.79796    4\n\nNow we use the group column:\n\nplot_predictions(\n    mod,\n    type = \"probs\",\n    condition = \"mpg\") +\n    facet_wrap(~group)",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Predictions"
    ]
  },
  {
    "objectID": "vignettes/references.html",
    "href": "vignettes/references.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Predictions\n\npredictions\navg_predictions\nplot_predictions\n\nComparisons: Contrasts, Diffrences, Ratios, Odds, etc.\n\ncomparisons\navg_comparisons\nplot_comparisons\n\nSlopes, marginal effects, partial derivatives: * slopes * avg_slopes * plot_slopes\nOther:\n\nhypotheses\ninferences\nposterior_draws"
  },
  {
    "objectID": "vignettes/references.html#references",
    "href": "vignettes/references.html#references",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Predictions\n\npredictions\navg_predictions\nplot_predictions\n\nComparisons: Contrasts, Diffrences, Ratios, Odds, etc.\n\ncomparisons\navg_comparisons\nplot_comparisons\n\nSlopes, marginal effects, partial derivatives: * slopes * avg_slopes * plot_slopes\nOther:\n\nhypotheses\ninferences\nposterior_draws"
  },
  {
    "objectID": "vignettes/help.html",
    "href": "vignettes/help.html",
    "title": "Help",
    "section": "",
    "text": "Giving help\nThe marginaleffects package and the Marginal Effects Zoo online book will always be free. If you like this project, you can contribute in four ways:\n\nMake a donation to the Native Women’s Shelter of Montreal or to Give Directly, and send me (Vincent) a quick note. You’ll make my day.\nSubmit bug reports, documentation improvements, or code contributions to the Github repositories of the R version or the Python version of the package.\nCite the marginaleffects package in your work and tell your friends about it.\nCreate a new entry for the Meme Gallery!\n\n\n\nGetting help\nIf you need help with marginaleffects, there are several possible venues:\n\nStatistical question: Ask on Cross Validated, using the marginal-effect tag.\nProgramming question: Ask on Stack Overflow, using the r-marginaleffects tag.\nPost on the marginaleffects discussions forum on Github. Warning: Stack Overflow and Cross Validate have much more traffic than the forum. So you have a greater chance of getting an answer there.\n\nIt is considered polite to avoid posting on multiple sites at once.\nWhen you ask for help, you will have a much better chance of obtaining useful answers if you provide an example with these characteristics:\n\nPublic data:\n\nUse a publicly available dataset like mtcars or a CSV from the Rdatasets archive.\n\nMinimal:\n\nAvoid loading irrelevant libraries and extra code. Only show the relevant bits.\n\nErrors & warnings:\n\nShow the complete errors and warnings. They are usually informative.\n\nCut & paste:\n\nMake sure we can just copy your entire code and paste it directly into an R console to reproduce your problem. People are much less likely to take the time to investigate if they have to clean up your code before they can use it. For example, do not supply the console output with + at the start of each line. This output is not executable.\n\nsessionInfo()\n\nPaste the output of this command at the bottom of your question so we know in what environment the code is run and what package versions are used.\n\n\nFor more information about asking good questions about software, see this classic post on Stack Overflow: https://stackoverflow.com/a/5963610/342331\nFinally, remember that the people who maintain, contribute, and answer questions about marginaleffects do it for free, on nights and weekends. Please be patient. And please be forgiving if we do not find the time to answer your question at all.\n\n\nBugs and feature requests\nTo report bugs or feature requests, please visit the Github issue tracker here:\nhttps://github.com/vincentarelbundock/marginaleffects/issues",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Help"
    ]
  },
  {
    "objectID": "vignettes/categorical.html",
    "href": "vignettes/categorical.html",
    "title": "Categorical outcomes",
    "section": "",
    "text": "Several packages in the R ecosystem allow users to estimate models for ordered or discrete choice, such as ordered probit or multinomial logit. This case study illustrates the use of marginaleffects with the MASS, nnet, and mlogit packages.\nWe begin by loading two libraries:\n\nlibrary(marginaleffects)\nlibrary(tidyverse)\n\n\nConsider a simple ordered logit model in which we predict the number of gears of a car based its miles per gallon and horsepower:\n\nlibrary(MASS)\nmod &lt;- polr(factor(gear) ~ mpg + hp, data = mtcars, Hess = TRUE)\n\nNow, consider a car with 25 miles per gallon and 110 horsepower. The expected predicted probability for each outcome level (gear) for this car is:\n\npredictions(mod, newdata = datagrid(mpg = 25, hp = 110))\n#&gt; \n#&gt;  Group mpg  hp Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;      3  25 110    0.203     0.0959 2.12   0.0339  4.9 0.0155  0.391\n#&gt;      4  25 110    0.578     0.1229 4.70   &lt;0.001 18.6 0.3373  0.819\n#&gt;      5  25 110    0.218     0.1007 2.17   0.0302  5.1 0.0209  0.416\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, gear\n\nSince the gear is categorical, we make one prediction for each level of the outcome.\nNow consider the marginal effects (aka slopes or partial derivatives) for the same car:\n\nslopes(mod, variables = \"mpg\", newdata = datagrid(mpg = 25, hp = 110))\n#&gt; \n#&gt;  Group Term mpg  hp Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %  97.5 %\n#&gt;      3  mpg  25 110 -0.06042     0.0169 -3.5810   &lt;0.001 11.5 -0.09349 -0.0274\n#&gt;      4  mpg  25 110 -0.00318     0.0335 -0.0949   0.9244  0.1 -0.06892  0.0625\n#&gt;      5  mpg  25 110  0.06361     0.0301  2.1130   0.0346  4.9  0.00461  0.1226\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: rowid, term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, predicted_lo, predicted_hi, predicted, gear\n\nAgain, marginaleffects produces one estimate of the slope for each outcome level. For a small step size \\(\\varepsilon\\), the printed quantities are estimated as:\n\\[\\frac{P(gear=3|mpg=25+\\varepsilon, hp=110)-P(gear=3|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] \\[\\frac{P(gear=4|mpg=25+\\varepsilon, hp=110)-P(gear=4|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] \\[\\frac{P(gear=5|mpg=25+\\varepsilon, hp=110)-P(gear=5|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\]\nWhen we call avg_slopes(), marginaleffects will repeat the same computation for every row of the original dataset, and then report the average slope for each level of the outcome:\n\navg_slopes(mod)\n#&gt; \n#&gt;  Group Term Estimate Std. Error     z Pr(&gt;|z|)    S     2.5 %   97.5 %\n#&gt;      3  hp  -0.00377   0.001514 -2.49  0.01284  6.3 -0.006735 -0.00080\n#&gt;      3  mpg -0.07014   0.015484 -4.53  &lt; 0.001 17.4 -0.100487 -0.03979\n#&gt;      4  hp   0.00201   0.000958  2.10  0.03553  4.8  0.000136  0.00389\n#&gt;      4  mpg  0.03748   0.013860  2.70  0.00685  7.2  0.010311  0.06464\n#&gt;      5  hp   0.00175   0.000833  2.11  0.03517  4.8  0.000122  0.00339\n#&gt;      5  mpg  0.03266   0.009570  3.41  &lt; 0.001 10.6  0.013905  0.05142\n#&gt; \n#&gt; Type:  probs \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nThe multinom function of the nnet package allows users to fit log-linear models via neural networks. The data used for this function is a data frame with one observation per row, and the response variable is coded a factor. All the marginaleffects package function work seamlessly with this model. For example, we can estimate a model and compute average marginal effects as follows:\n\nlibrary(nnet)\n\nhead(mtcars)\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nmod &lt;- multinom(factor(gear) ~ hp + mpg, data = mtcars, trace = FALSE)\n\navg_slopes(mod, type = \"probs\")\n#&gt; \n#&gt;  Group Term  Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %    97.5 %\n#&gt;      3  hp  -3.36e-05    0.00225 -0.0149  0.98809  0.0 -0.00444  0.004372\n#&gt;      3  mpg -7.13e-02    0.02646 -2.6951  0.00704  7.2 -0.12315 -0.019448\n#&gt;      4  hp  -4.67e-03    0.00221 -2.1126  0.03463  4.9 -0.00900 -0.000337\n#&gt;      4  mpg  1.59e-02    0.02010  0.7917  0.42851  1.2 -0.02348  0.055316\n#&gt;      5  hp   4.70e-03    0.00130  3.6170  &lt; 0.001 11.7  0.00215  0.007247\n#&gt;      5  mpg  5.54e-02    0.01642  3.3732  &lt; 0.001 10.4  0.02320  0.087563\n#&gt; \n#&gt; Type:  probs \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNotice that in such models, we get one marginal effect for each term, for each level of the response variable. For this reason, we should use \"group\" in the condition argument (or facet_*() function) when calling one of the plotting functions:\n\nlibrary(ggplot2)\n\nplot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\")\n\n\n\n\n\n\n\nplot_predictions(mod, condition = \"mpg\", type = \"probs\") + facet_wrap(~group)\n\n\n\n\n\n\n\nplot_comparisons(\n    mod,\n    variables = list(mpg = c(15, 30)),\n    condition = \"group\",\n    type = \"probs\")\n\n\n\n\n\n\n\n\nThe mlogit package uses data in a slightly different structure, with one row per observation-choice combination. For example, this data on choice of travel mode includes 4 rows per individual, one for each mode of transportation:\n\nlibrary(\"AER\")\nlibrary(\"mlogit\")\nlibrary(\"tidyverse\")\ndata(\"TravelMode\", package = \"AER\")\n\nhead(TravelMode)\n#&gt;   individual  mode choice wait vcost travel gcost income size\n#&gt; 1          1   air     no   69    59    100    70     35    1\n#&gt; 2          1 train     no   34    31    372    71     35    1\n#&gt; 3          1   bus     no   35    25    417    70     35    1\n#&gt; 4          1   car    yes    0    10    180    30     35    1\n#&gt; 5          2   air     no   64    58     68    68     30    2\n#&gt; 6          2 train     no   44    31    354    84     30    2\n\nmod &lt;- mlogit(choice ~ wait + gcost | income + size, TravelMode)\n\navg_slopes(mod, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %   97.5 %\n#&gt;  air   income  0.002786    0.00122  2.289  0.02208  5.5  0.000400  0.00517\n#&gt;  air   size   -0.126477    0.02892 -4.373  &lt; 0.001 16.3 -0.183160 -0.06979\n#&gt;  bus   income -0.000372    0.00110 -0.338  0.73557  0.4 -0.002531  0.00179\n#&gt;  bus   size    0.011349    0.02586  0.439  0.66083  0.6 -0.039345  0.06204\n#&gt;  car   income  0.003373    0.00137  2.456  0.01405  6.2  0.000681  0.00607\n#&gt;  car   size    0.045887    0.02476  1.854  0.06381  4.0 -0.002635  0.09441\n#&gt;  train income -0.005787    0.00132 -4.389  &lt; 0.001 16.4 -0.008371 -0.00320\n#&gt;  train size    0.069241    0.02478  2.794  0.00521  7.6  0.020667  0.11782\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that the slopes function will always return estimates of zero for regressors before the vertical bar in the formula. This is because marginaleffects increments all rows of the prediction dataset in the same way to compute slopes and contrast. Because mlogit data are in “long” format, this means that alternatives are incremented in the same way, which does not produce alternative-specific changes in the predictors.\nOne strategy to circumvent this problem is to supply a data frame of numeric values to compare, with alternative specific changes. In this example, we test what happens to the probability of selecting each mode of transportation if we only increase the wait time of air travel:\n\naltspec &lt;- data.frame(\n  low = TravelMode$wait,\n  high = ifelse(TravelMode$mode == \"air\", TravelMode$wait + 15, TravelMode$wait)\n)\n\navg_comparisons(mod, variables = list(wait = altspec))\n#&gt; \n#&gt;  Group Estimate Std. Error      z Pr(&gt;|z|)     S   2.5 %  97.5 %\n#&gt;  air    -0.1321    0.01070 -12.35   &lt;0.001 114.0 -0.1531 -0.1111\n#&gt;  bus     0.0251    0.00460   5.45   &lt;0.001  24.2  0.0160  0.0341\n#&gt;  car     0.0701    0.00834   8.41   &lt;0.001  54.5  0.0538  0.0865\n#&gt;  train   0.0369    0.00528   6.99   &lt;0.001  38.4  0.0266  0.0473\n#&gt; \n#&gt; Term: wait\n#&gt; Type:  response \n#&gt; Comparison: manual\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nWe can compute yet more kinds of marginal effects, we can construct customized data frames and feed them to the newdata argument of the slopes function.\nIf we want to compute the slope of the response function (marginal effects) when each of the predictors is fixed to its global mean, we can do:\n\nnd &lt;- TravelMode |&gt;\n    summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"),\n              function(x) rep(mean(x), 4)))\nnd\n#&gt;       wait    gcost   income     size\n#&gt; 1 34.58929 110.8798 34.54762 1.742857\n#&gt; 2 34.58929 110.8798 34.54762 1.742857\n#&gt; 3 34.58929 110.8798 34.54762 1.742857\n#&gt; 4 34.58929 110.8798 34.54762 1.742857\n\navg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error     z Pr(&gt;|z|)   S     2.5 %    97.5 %\n#&gt;  air   income  6.66e-03   2.42e-03  2.75  0.00600 7.4  1.91e-03  1.14e-02\n#&gt;  air   size   -1.69e-01   5.88e-02 -2.88  0.00394 8.0 -2.85e-01 -5.42e-02\n#&gt;  bus   income -1.14e-03   9.44e-04 -1.21  0.22655 2.1 -2.99e-03  7.08e-04\n#&gt;  bus   size    4.67e-02   2.72e-02  1.72  0.08622 3.5 -6.65e-03  1.00e-01\n#&gt;  car   income  6.48e-06   2.02e-05  0.32  0.74885 0.4 -3.32e-05  4.62e-05\n#&gt;  car   size    1.36e-03   8.81e-04  1.54  0.12305 3.0 -3.68e-04  3.08e-03\n#&gt;  train income -5.52e-03   1.91e-03 -2.89  0.00384 8.0 -9.26e-03 -1.78e-03\n#&gt;  train size    1.21e-01   4.44e-02  2.73  0.00634 7.3  3.42e-02  2.08e-01\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: rowid, term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nIf we want to compute marginal effects with the gcost and wait fixed at their mean value, conditional on the choice of transportation mode:\n\nnd &lt;- TravelMode |&gt;\n    group_by(mode) |&gt;\n    summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"), mean))\nnd\n#&gt; # A tibble: 4 × 5\n#&gt;   mode   wait gcost income  size\n#&gt;   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 air    61.0 103.    34.5  1.74\n#&gt; 2 train  35.7 130.    34.5  1.74\n#&gt; 3 bus    41.7 115.    34.5  1.74\n#&gt; 4 car     0    95.4   34.5  1.74\n\navg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %   97.5 %\n#&gt;  air   income  0.006015    0.00233  2.585  0.00973  6.7  0.001455  0.01058\n#&gt;  air   size   -0.232955    0.05660 -4.116  &lt; 0.001 14.7 -0.343893 -0.12202\n#&gt;  bus   income -0.000713    0.00146 -0.489  0.62500  0.7 -0.003570  0.00214\n#&gt;  bus   size    0.020447    0.03436  0.595  0.55184  0.9 -0.046906  0.08780\n#&gt;  car   income  0.005445    0.00229  2.382  0.01721  5.9  0.000965  0.00993\n#&gt;  car   size    0.067839    0.04122  1.646  0.09984  3.3 -0.012957  0.14864\n#&gt;  train income -0.010748    0.00256 -4.201  &lt; 0.001 15.2 -0.015762 -0.00573\n#&gt;  train size    0.144669    0.04773  3.031  0.00244  8.7  0.051126  0.23821\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: rowid, term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nWe can also explore more complex alternatives. Here, for example, only one alternative is affected by cost reduction:\n\nnd &lt;- datagrid(mode = TravelMode$mode, newdata = TravelMode)\nnd &lt;- lapply(1:4, function(i) mutate(nd, gcost = ifelse(1:4 == i, 30, gcost)))\nnd &lt;- bind_rows(nd)\nnd\n#&gt;    individual choice wait vcost travel gcost income size  mode rowid\n#&gt; 1           1     no   35    48    486    30     35    2   air     1\n#&gt; 2           1     no   35    48    486   111     35    2 train     2\n#&gt; 3           1     no   35    48    486   111     35    2   bus     3\n#&gt; 4           1     no   35    48    486   111     35    2   car     4\n#&gt; 5           1     no   35    48    486   111     35    2   air     1\n#&gt; 6           1     no   35    48    486    30     35    2 train     2\n#&gt; 7           1     no   35    48    486   111     35    2   bus     3\n#&gt; 8           1     no   35    48    486   111     35    2   car     4\n#&gt; 9           1     no   35    48    486   111     35    2   air     1\n#&gt; 10          1     no   35    48    486   111     35    2 train     2\n#&gt; 11          1     no   35    48    486    30     35    2   bus     3\n#&gt; 12          1     no   35    48    486   111     35    2   car     4\n#&gt; 13          1     no   35    48    486   111     35    2   air     1\n#&gt; 14          1     no   35    48    486   111     35    2 train     2\n#&gt; 15          1     no   35    48    486   111     35    2   bus     3\n#&gt; 16          1     no   35    48    486    30     35    2   car     4\n\navg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %    97.5 %\n#&gt;  air   income  8.24e-03   2.46e-03  3.352   &lt;0.001 10.3  3.42e-03  0.013058\n#&gt;  air   size   -2.12e-01   6.02e-02 -3.526   &lt;0.001 11.2 -3.30e-01 -0.094353\n#&gt;  bus   income -1.33e-03   1.30e-03 -1.020    0.308  1.7 -3.88e-03  0.001223\n#&gt;  bus   size    6.06e-02   3.79e-02  1.600    0.110  3.2 -1.37e-02  0.134900\n#&gt;  car   income  2.66e-05   4.31e-05  0.617    0.537  0.9 -5.78e-05  0.000111\n#&gt;  car   size    2.38e-03   1.57e-03  1.512    0.131  2.9 -7.05e-04  0.005459\n#&gt;  train income -6.94e-03   1.86e-03 -3.734   &lt;0.001 12.4 -1.06e-02 -0.003297\n#&gt;  train size    1.49e-01   4.28e-02  3.489   &lt;0.001 11.0  6.55e-02  0.233367\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nImportant: The newdata argument for mlogit models must be a “balanced” data frame, that is, it must have a number of rows that is a multiple of the number of choices.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Categorical outcomes"
    ]
  },
  {
    "objectID": "vignettes/categorical.html#masspolr-function",
    "href": "vignettes/categorical.html#masspolr-function",
    "title": "Categorical outcomes",
    "section": "",
    "text": "Consider a simple ordered logit model in which we predict the number of gears of a car based its miles per gallon and horsepower:\n\nlibrary(MASS)\nmod &lt;- polr(factor(gear) ~ mpg + hp, data = mtcars, Hess = TRUE)\n\nNow, consider a car with 25 miles per gallon and 110 horsepower. The expected predicted probability for each outcome level (gear) for this car is:\n\npredictions(mod, newdata = datagrid(mpg = 25, hp = 110))\n#&gt; \n#&gt;  Group mpg  hp Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;      3  25 110    0.203     0.0959 2.12   0.0339  4.9 0.0155  0.391\n#&gt;      4  25 110    0.578     0.1229 4.70   &lt;0.001 18.6 0.3373  0.819\n#&gt;      5  25 110    0.218     0.1007 2.17   0.0302  5.1 0.0209  0.416\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, gear\n\nSince the gear is categorical, we make one prediction for each level of the outcome.\nNow consider the marginal effects (aka slopes or partial derivatives) for the same car:\n\nslopes(mod, variables = \"mpg\", newdata = datagrid(mpg = 25, hp = 110))\n#&gt; \n#&gt;  Group Term mpg  hp Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %  97.5 %\n#&gt;      3  mpg  25 110 -0.06042     0.0169 -3.5810   &lt;0.001 11.5 -0.09349 -0.0274\n#&gt;      4  mpg  25 110 -0.00318     0.0335 -0.0949   0.9244  0.1 -0.06892  0.0625\n#&gt;      5  mpg  25 110  0.06361     0.0301  2.1130   0.0346  4.9  0.00461  0.1226\n#&gt; \n#&gt; Type:  probs \n#&gt; Columns: rowid, term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, predicted_lo, predicted_hi, predicted, gear\n\nAgain, marginaleffects produces one estimate of the slope for each outcome level. For a small step size \\(\\varepsilon\\), the printed quantities are estimated as:\n\\[\\frac{P(gear=3|mpg=25+\\varepsilon, hp=110)-P(gear=3|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] \\[\\frac{P(gear=4|mpg=25+\\varepsilon, hp=110)-P(gear=4|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] \\[\\frac{P(gear=5|mpg=25+\\varepsilon, hp=110)-P(gear=5|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\]\nWhen we call avg_slopes(), marginaleffects will repeat the same computation for every row of the original dataset, and then report the average slope for each level of the outcome:\n\navg_slopes(mod)\n#&gt; \n#&gt;  Group Term Estimate Std. Error     z Pr(&gt;|z|)    S     2.5 %   97.5 %\n#&gt;      3  hp  -0.00377   0.001514 -2.49  0.01284  6.3 -0.006735 -0.00080\n#&gt;      3  mpg -0.07014   0.015484 -4.53  &lt; 0.001 17.4 -0.100487 -0.03979\n#&gt;      4  hp   0.00201   0.000958  2.10  0.03553  4.8  0.000136  0.00389\n#&gt;      4  mpg  0.03748   0.013860  2.70  0.00685  7.2  0.010311  0.06464\n#&gt;      5  hp   0.00175   0.000833  2.11  0.03517  4.8  0.000122  0.00339\n#&gt;      5  mpg  0.03266   0.009570  3.41  &lt; 0.001 10.6  0.013905  0.05142\n#&gt; \n#&gt; Type:  probs \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Case studies",
      "Categorical outcomes"
    ]
  },
  {
    "objectID": "vignettes/categorical.html#nnet-package",
    "href": "vignettes/categorical.html#nnet-package",
    "title": "Categorical outcomes",
    "section": "",
    "text": "The multinom function of the nnet package allows users to fit log-linear models via neural networks. The data used for this function is a data frame with one observation per row, and the response variable is coded a factor. All the marginaleffects package function work seamlessly with this model. For example, we can estimate a model and compute average marginal effects as follows:\n\nlibrary(nnet)\n\nhead(mtcars)\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nmod &lt;- multinom(factor(gear) ~ hp + mpg, data = mtcars, trace = FALSE)\n\navg_slopes(mod, type = \"probs\")\n#&gt; \n#&gt;  Group Term  Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %    97.5 %\n#&gt;      3  hp  -3.36e-05    0.00225 -0.0149  0.98809  0.0 -0.00444  0.004372\n#&gt;      3  mpg -7.13e-02    0.02646 -2.6951  0.00704  7.2 -0.12315 -0.019448\n#&gt;      4  hp  -4.67e-03    0.00221 -2.1126  0.03463  4.9 -0.00900 -0.000337\n#&gt;      4  mpg  1.59e-02    0.02010  0.7917  0.42851  1.2 -0.02348  0.055316\n#&gt;      5  hp   4.70e-03    0.00130  3.6170  &lt; 0.001 11.7  0.00215  0.007247\n#&gt;      5  mpg  5.54e-02    0.01642  3.3732  &lt; 0.001 10.4  0.02320  0.087563\n#&gt; \n#&gt; Type:  probs \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNotice that in such models, we get one marginal effect for each term, for each level of the response variable. For this reason, we should use \"group\" in the condition argument (or facet_*() function) when calling one of the plotting functions:\n\nlibrary(ggplot2)\n\nplot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\")\n\n\n\n\n\n\n\nplot_predictions(mod, condition = \"mpg\", type = \"probs\") + facet_wrap(~group)\n\n\n\n\n\n\n\nplot_comparisons(\n    mod,\n    variables = list(mpg = c(15, 30)),\n    condition = \"group\",\n    type = \"probs\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "Categorical outcomes"
    ]
  },
  {
    "objectID": "vignettes/categorical.html#mlogit-package",
    "href": "vignettes/categorical.html#mlogit-package",
    "title": "Categorical outcomes",
    "section": "",
    "text": "The mlogit package uses data in a slightly different structure, with one row per observation-choice combination. For example, this data on choice of travel mode includes 4 rows per individual, one for each mode of transportation:\n\nlibrary(\"AER\")\nlibrary(\"mlogit\")\nlibrary(\"tidyverse\")\ndata(\"TravelMode\", package = \"AER\")\n\nhead(TravelMode)\n#&gt;   individual  mode choice wait vcost travel gcost income size\n#&gt; 1          1   air     no   69    59    100    70     35    1\n#&gt; 2          1 train     no   34    31    372    71     35    1\n#&gt; 3          1   bus     no   35    25    417    70     35    1\n#&gt; 4          1   car    yes    0    10    180    30     35    1\n#&gt; 5          2   air     no   64    58     68    68     30    2\n#&gt; 6          2 train     no   44    31    354    84     30    2\n\nmod &lt;- mlogit(choice ~ wait + gcost | income + size, TravelMode)\n\navg_slopes(mod, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %   97.5 %\n#&gt;  air   income  0.002786    0.00122  2.289  0.02208  5.5  0.000400  0.00517\n#&gt;  air   size   -0.126477    0.02892 -4.373  &lt; 0.001 16.3 -0.183160 -0.06979\n#&gt;  bus   income -0.000372    0.00110 -0.338  0.73557  0.4 -0.002531  0.00179\n#&gt;  bus   size    0.011349    0.02586  0.439  0.66083  0.6 -0.039345  0.06204\n#&gt;  car   income  0.003373    0.00137  2.456  0.01405  6.2  0.000681  0.00607\n#&gt;  car   size    0.045887    0.02476  1.854  0.06381  4.0 -0.002635  0.09441\n#&gt;  train income -0.005787    0.00132 -4.389  &lt; 0.001 16.4 -0.008371 -0.00320\n#&gt;  train size    0.069241    0.02478  2.794  0.00521  7.6  0.020667  0.11782\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that the slopes function will always return estimates of zero for regressors before the vertical bar in the formula. This is because marginaleffects increments all rows of the prediction dataset in the same way to compute slopes and contrast. Because mlogit data are in “long” format, this means that alternatives are incremented in the same way, which does not produce alternative-specific changes in the predictors.\nOne strategy to circumvent this problem is to supply a data frame of numeric values to compare, with alternative specific changes. In this example, we test what happens to the probability of selecting each mode of transportation if we only increase the wait time of air travel:\n\naltspec &lt;- data.frame(\n  low = TravelMode$wait,\n  high = ifelse(TravelMode$mode == \"air\", TravelMode$wait + 15, TravelMode$wait)\n)\n\navg_comparisons(mod, variables = list(wait = altspec))\n#&gt; \n#&gt;  Group Estimate Std. Error      z Pr(&gt;|z|)     S   2.5 %  97.5 %\n#&gt;  air    -0.1321    0.01070 -12.35   &lt;0.001 114.0 -0.1531 -0.1111\n#&gt;  bus     0.0251    0.00460   5.45   &lt;0.001  24.2  0.0160  0.0341\n#&gt;  car     0.0701    0.00834   8.41   &lt;0.001  54.5  0.0538  0.0865\n#&gt;  train   0.0369    0.00528   6.99   &lt;0.001  38.4  0.0266  0.0473\n#&gt; \n#&gt; Term: wait\n#&gt; Type:  response \n#&gt; Comparison: manual\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nWe can compute yet more kinds of marginal effects, we can construct customized data frames and feed them to the newdata argument of the slopes function.\nIf we want to compute the slope of the response function (marginal effects) when each of the predictors is fixed to its global mean, we can do:\n\nnd &lt;- TravelMode |&gt;\n    summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"),\n              function(x) rep(mean(x), 4)))\nnd\n#&gt;       wait    gcost   income     size\n#&gt; 1 34.58929 110.8798 34.54762 1.742857\n#&gt; 2 34.58929 110.8798 34.54762 1.742857\n#&gt; 3 34.58929 110.8798 34.54762 1.742857\n#&gt; 4 34.58929 110.8798 34.54762 1.742857\n\navg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error     z Pr(&gt;|z|)   S     2.5 %    97.5 %\n#&gt;  air   income  6.66e-03   2.42e-03  2.75  0.00600 7.4  1.91e-03  1.14e-02\n#&gt;  air   size   -1.69e-01   5.88e-02 -2.88  0.00394 8.0 -2.85e-01 -5.42e-02\n#&gt;  bus   income -1.14e-03   9.44e-04 -1.21  0.22655 2.1 -2.99e-03  7.08e-04\n#&gt;  bus   size    4.67e-02   2.72e-02  1.72  0.08622 3.5 -6.65e-03  1.00e-01\n#&gt;  car   income  6.48e-06   2.02e-05  0.32  0.74885 0.4 -3.32e-05  4.62e-05\n#&gt;  car   size    1.36e-03   8.81e-04  1.54  0.12305 3.0 -3.68e-04  3.08e-03\n#&gt;  train income -5.52e-03   1.91e-03 -2.89  0.00384 8.0 -9.26e-03 -1.78e-03\n#&gt;  train size    1.21e-01   4.44e-02  2.73  0.00634 7.3  3.42e-02  2.08e-01\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: rowid, term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nIf we want to compute marginal effects with the gcost and wait fixed at their mean value, conditional on the choice of transportation mode:\n\nnd &lt;- TravelMode |&gt;\n    group_by(mode) |&gt;\n    summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"), mean))\nnd\n#&gt; # A tibble: 4 × 5\n#&gt;   mode   wait gcost income  size\n#&gt;   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 air    61.0 103.    34.5  1.74\n#&gt; 2 train  35.7 130.    34.5  1.74\n#&gt; 3 bus    41.7 115.    34.5  1.74\n#&gt; 4 car     0    95.4   34.5  1.74\n\navg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %   97.5 %\n#&gt;  air   income  0.006015    0.00233  2.585  0.00973  6.7  0.001455  0.01058\n#&gt;  air   size   -0.232955    0.05660 -4.116  &lt; 0.001 14.7 -0.343893 -0.12202\n#&gt;  bus   income -0.000713    0.00146 -0.489  0.62500  0.7 -0.003570  0.00214\n#&gt;  bus   size    0.020447    0.03436  0.595  0.55184  0.9 -0.046906  0.08780\n#&gt;  car   income  0.005445    0.00229  2.382  0.01721  5.9  0.000965  0.00993\n#&gt;  car   size    0.067839    0.04122  1.646  0.09984  3.3 -0.012957  0.14864\n#&gt;  train income -0.010748    0.00256 -4.201  &lt; 0.001 15.2 -0.015762 -0.00573\n#&gt;  train size    0.144669    0.04773  3.031  0.00244  8.7  0.051126  0.23821\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: rowid, term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nWe can also explore more complex alternatives. Here, for example, only one alternative is affected by cost reduction:\n\nnd &lt;- datagrid(mode = TravelMode$mode, newdata = TravelMode)\nnd &lt;- lapply(1:4, function(i) mutate(nd, gcost = ifelse(1:4 == i, 30, gcost)))\nnd &lt;- bind_rows(nd)\nnd\n#&gt;    individual choice wait vcost travel gcost income size  mode rowid\n#&gt; 1           1     no   35    48    486    30     35    2   air     1\n#&gt; 2           1     no   35    48    486   111     35    2 train     2\n#&gt; 3           1     no   35    48    486   111     35    2   bus     3\n#&gt; 4           1     no   35    48    486   111     35    2   car     4\n#&gt; 5           1     no   35    48    486   111     35    2   air     1\n#&gt; 6           1     no   35    48    486    30     35    2 train     2\n#&gt; 7           1     no   35    48    486   111     35    2   bus     3\n#&gt; 8           1     no   35    48    486   111     35    2   car     4\n#&gt; 9           1     no   35    48    486   111     35    2   air     1\n#&gt; 10          1     no   35    48    486   111     35    2 train     2\n#&gt; 11          1     no   35    48    486    30     35    2   bus     3\n#&gt; 12          1     no   35    48    486   111     35    2   car     4\n#&gt; 13          1     no   35    48    486   111     35    2   air     1\n#&gt; 14          1     no   35    48    486   111     35    2 train     2\n#&gt; 15          1     no   35    48    486   111     35    2   bus     3\n#&gt; 16          1     no   35    48    486    30     35    2   car     4\n\navg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\"))\n#&gt; \n#&gt;  Group   Term  Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %    97.5 %\n#&gt;  air   income  8.24e-03   2.46e-03  3.352   &lt;0.001 10.3  3.42e-03  0.013058\n#&gt;  air   size   -2.12e-01   6.02e-02 -3.526   &lt;0.001 11.2 -3.30e-01 -0.094353\n#&gt;  bus   income -1.33e-03   1.30e-03 -1.020    0.308  1.7 -3.88e-03  0.001223\n#&gt;  bus   size    6.06e-02   3.79e-02  1.600    0.110  3.2 -1.37e-02  0.134900\n#&gt;  car   income  2.66e-05   4.31e-05  0.617    0.537  0.9 -5.78e-05  0.000111\n#&gt;  car   size    2.38e-03   1.57e-03  1.512    0.131  2.9 -7.05e-04  0.005459\n#&gt;  train income -6.94e-03   1.86e-03 -3.734   &lt;0.001 12.4 -1.06e-02 -0.003297\n#&gt;  train size    1.49e-01   4.28e-02  3.489   &lt;0.001 11.0  6.55e-02  0.233367\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nImportant: The newdata argument for mlogit models must be a “balanced” data frame, that is, it must have a number of rows that is a multiple of the number of choices.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Categorical outcomes"
    ]
  },
  {
    "objectID": "vignettes/get_started.html",
    "href": "vignettes/get_started.html",
    "title": "Get started",
    "section": "",
    "text": "This page explains how to interpret statistical results using the marginaleffects package for R and Python. The workflow that we propose rests on 5 conceptual pillars:\n\n\nQuantity: What is the quantity of interest? Do we want to estimate a prediction or a function of predictions (average, difference, ratio, derivative, etc.)?\n\nGrid: What regressor values are we interested in? Do we want to produce estimates for the units in our dataset, or for hypothetical or representative individuals?\n\nAggregation: Do we report estimates for every observation in the grid or a global summary?\n\nUncertainty: How do we quantify uncertainty about our estimates?\n\nTest: Which (non-)linear hypothesis or equivalence tests do we conduct?\n\n\nBefore we begin, let’s install the marginaleffects package, available for R and Python:\n\n\nR\nPython\n\n\n\nInstall from CRAN:\n\ninstall.packages(\"marginaleffects\")\n\n\n\nInstall from PyPI:\n\npip install marginaleffects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe marginaleffects package allows R users to compute and plot three principal quantities of interest: (1) predictions, (2) comparisons, and (3) slopes. In addition, the package includes a convenience function to compute a fourth quantity of interest, “marginal means”, which is a special case of averaged predictions. marginaleffects can also average (or “marginalize”) unit-level (or “conditional”) estimates of all those quantities, and conduct hypothesis tests on them.\nPredictions:\n\nThe outcome predicted by a fitted model on a specified scale for a given combination of values of the predictor variables, such as their observed values, their means, or factor levels. a.k.a. Fitted values, adjusted predictions. predictions(), avg_predictions(), plot_predictions().\n\nComparisons:\n\nCompare the predictions made by a model for different regressor values (e.g., college graduates vs. others): contrasts, differences, risk ratios, odds, etc. comparisons(), avg_comparisons(), plot_comparisons().\n\nSlopes:\n\nPartial derivative of the regression equation with respect to a regressor of interest. a.k.a. Marginal effects, trends. slopes(), avg_slopes(), plot_slopes().\n\nMarginal Means:\n\nPredictions of a model, averaged across a “reference grid” of categorical predictors. marginalmeans().\n\nHypothesis and Equivalence Tests:\n\nHypothesis and equivalence tests can be conducted on linear or non-linear functions of model coefficients, or on any of the quantities computed by the marginaleffects packages (predictions, slopes, comparisons, marginal means, etc.). Uncertainy estimates can be obtained via the delta method (with or without robust standard errors), bootstrap, or simulation.\n\nPredictions, comparisons, and slopes are fundamentally unit-level (or “conditional”) quantities. Except in the simplest linear case, estimates will typically vary based on the values of all the regressors in a model. Each of the observations in a dataset is thus associated with its own prediction, comparison, and slope estimates. Below, we will see that it can be useful to marginalize (or “average over”) unit-level estimates to report an “average prediction”, “average comparison”, or “average slope”.\nOne ambiguous aspect of the definitions above is that the word “marginal” comes up in two different and opposite ways:\n\nIn “marginal effects,” we refer to the effect of a tiny (marginal) change in the regressor on the outcome. This is a slope, or derivative.\nIn “marginal means,” we refer to the process of marginalizing across rows of a prediction grid. This is an average, or integral.\n\nOn this website and in this package, we reserve the expression “marginal effect” to mean a “slope” or “partial derivative”.\nThe marginaleffects package includes functions to estimate, average, plot, and summarize all of the estimands described above. The objects produced by marginaleffects are “tidy”: they produce simple data frames in “long” format. They are also “standards-compliant” and work seamlessly with standard functions like summary(), head(), tidy(), and glance(), as well with external packages like modelsummary or ggplot2.\nWe now apply marginaleffects functions to compute each of the quantities of interest described above. First, we fit a linear regression model with multiplicative interactions:\n\n\nR\nPython\n\n\n\n\nlibrary(marginaleffects)\n\nmod &lt;- lm(mpg ~ hp * wt * am, data = mtcars)\n\n\n\n\nimport polars as pl\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nmtcars = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\")\n\nmod = smf.ols(\"mpg ~ hp * wt * am\", data = mtcars).fit()\n\n\n\n\nThen, we call the predictions() function. As noted above, predictions are unit-level estimates, so there is one specific prediction per observation. By default, the predictions() function makes one prediction per observation in the dataset that was used to fit the original model. Since mtcars has 32 rows, the predictions() outcome also has 32 rows:\n\n\nR\nPython\n\n\n\n\npre &lt;- predictions(mod)\n\nnrow(mtcars)\n\n[1] 32\n\nnrow(pre)\n\n[1] 32\n\npre\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, wt, am \n\n\n\n\n22.5\n                  0.884\n                  25.44\n                  \n                  \n471.7\n                  20.8\n                  24.2\n                \n\n20.8\n                  1.194\n                  17.42\n                  \n                  \n223.3\n                  18.5\n                  23.1\n                \n\n25.3\n                  0.709\n                  35.66\n                  \n                  \n922.7\n                  23.9\n                  26.7\n                \n\n20.3\n                  0.704\n                  28.75\n                  \n                  \n601.5\n                  18.9\n                  21.6\n                \n\n17.0\n                  0.712\n                  23.88\n                  \n                  \n416.2\n                  15.6\n                  18.4\n                \n\n29.6\n                  1.874\n                  15.80\n                  \n                  \n184.3\n                  25.9\n                  33.3\n                \n\n15.9\n                  1.311\n                  12.13\n                  \n                  \n110.0\n                  13.3\n                  18.5\n                \n\n19.4\n                  1.145\n                  16.95\n                  \n                  \n211.6\n                  17.2\n                  21.7\n                \n\n14.8\n                  2.017\n                   7.33\n                  \n                  \n42.0 \n                  10.8\n                  18.7\n                \n\n21.5\n                  1.072\n                  20.02\n                  \n                  \n293.8\n                  19.4\n                  23.6\n                \n\n\n\n\n\n\n\n\n\npre = predictions(mod)\n\nmtcars.shape\n\n(32, 12)\n\npre.shape\n\n(32, 20)\n\nprint(pre)\n\nshape: (32, 7)\n┌──────────┬───────────┬──────┬──────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|)  ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---      ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str      ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪══════════╪═════╪══════╪═══════╡\n│ 22.5     ┆ 0.884     ┆ 25.4 ┆ 0        ┆ inf ┆ 20.8 ┆ 24.2  │\n│ 20.8     ┆ 1.19      ┆ 17.4 ┆ 0        ┆ inf ┆ 18.5 ┆ 23.1  │\n│ 25.3     ┆ 0.709     ┆ 35.7 ┆ 0        ┆ inf ┆ 23.9 ┆ 26.7  │\n│ 20.3     ┆ 0.704     ┆ 28.8 ┆ 0        ┆ inf ┆ 18.9 ┆ 21.6  │\n│ 17       ┆ 0.712     ┆ 23.9 ┆ 0        ┆ inf ┆ 15.6 ┆ 18.4  │\n│ …        ┆ …         ┆ …    ┆ …        ┆ …   ┆ …    ┆ …     │\n│ 29.6     ┆ 1.87      ┆ 15.8 ┆ 0        ┆ inf ┆ 25.9 ┆ 33.3  │\n│ 15.9     ┆ 1.31      ┆ 12.1 ┆ 0        ┆ inf ┆ 13.3 ┆ 18.5  │\n│ 19.4     ┆ 1.15      ┆ 16.9 ┆ 0        ┆ inf ┆ 17.2 ┆ 21.7  │\n│ 14.8     ┆ 2.02      ┆ 7.33 ┆ 2.29e-13 ┆ 42  ┆ 10.8 ┆ 18.7  │\n│ 21.5     ┆ 1.07      ┆ 20   ┆ 0        ┆ inf ┆ 19.4 ┆ 23.6  │\n└──────────┴───────────┴──────┴──────────┴─────┴──────┴───────┘\n\nColumns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nNow, we use the comparisons() function to compute the difference in predicted outcome when each of the predictors is incremented by 1 unit (one predictor at a time, holding all others constant). Once again, comparisons are unit-level quantities. And since there are 3 predictors in the model and our data has 32 rows, we obtain 96 comparisons:\n\n\nR\nPython\n\n\n\n\ncmp &lt;- comparisons(mod)\n\nnrow(cmp)\n\n[1] 96\n\ncmp\n\n\n\n    \n\n      \n\nTerm\n                Contrast\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\nam\n                  1 - 0\n                   0.325\n                  1.68\n                   0.193\n                  0.8467\n                  0.2 \n                   -2.97\n                   3.622\n                \n\nam\n                  1 - 0\n                  -0.544\n                  1.57\n                  -0.347\n                  0.7287\n                  0.5 \n                   -3.62\n                   2.530\n                \n\nam\n                  1 - 0\n                   1.201\n                  2.35\n                   0.511\n                  0.6090\n                  0.7 \n                   -3.40\n                   5.802\n                \n\nam\n                  1 - 0\n                  -1.703\n                  1.87\n                  -0.912\n                  0.3618\n                  1.5 \n                   -5.36\n                   1.957\n                \n\nam\n                  1 - 0\n                  -0.615\n                  1.68\n                  -0.366\n                  0.7146\n                  0.5 \n                   -3.91\n                   2.680\n                \n\nwt\n                  +1   \n                  -6.518\n                  1.88\n                  -3.462\n                  \n                  \n10.9\n                  -10.21\n                  -2.828\n                \n\nwt\n                  +1   \n                  -1.653\n                  3.74\n                  -0.442\n                  0.6588\n                  0.6 \n                   -8.99\n                   5.683\n                \n\nwt\n                  +1   \n                  -4.520\n                  2.47\n                  -1.830\n                  0.0672\n                  3.9 \n                   -9.36\n                   0.321\n                \n\nwt\n                  +1   \n                   0.635\n                  4.89\n                   0.130\n                  0.8966\n                  0.2 \n                   -8.95\n                  10.216\n                \n\nwt\n                  +1   \n                  -6.647\n                  1.86\n                  -3.572\n                  \n                  \n11.5\n                  -10.29\n                  -2.999\n                \n\n\n\n\n\n\n\n\n\ncmp = comparisons(mod)\n\ncmp.shape\n\n(96, 25)\n\nprint(cmp)\n\nshape: (96, 9)\n┌──────┬──────────────┬──────────┬───────────┬───┬──────────┬───────┬───────┬───────┐\n│ Term ┆ Contrast     ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---          ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---   ┆ ---   ┆ ---   │\n│ str  ┆ str          ┆ str      ┆ str       ┆   ┆ str      ┆ str   ┆ str   ┆ str   │\n╞══════╪══════════════╪══════════╪═══════════╪═══╪══════════╪═══════╪═══════╪═══════╡\n│ am   ┆ True - False ┆ 0.325    ┆ 1.68      ┆ … ┆ 0.847    ┆ 0.24  ┆ -2.97 ┆ 3.62  │\n│ am   ┆ True - False ┆ -0.544   ┆ 1.57      ┆ … ┆ 0.729    ┆ 0.457 ┆ -3.62 ┆ 2.53  │\n│ am   ┆ True - False ┆ 1.2      ┆ 2.35      ┆ … ┆ 0.609    ┆ 0.715 ┆ -3.4  ┆ 5.8   │\n│ am   ┆ True - False ┆ -1.7     ┆ 1.87      ┆ … ┆ 0.362    ┆ 1.47  ┆ -5.36 ┆ 1.96  │\n│ am   ┆ True - False ┆ -0.615   ┆ 1.68      ┆ … ┆ 0.715    ┆ 0.485 ┆ -3.91 ┆ 2.68  │\n│ …    ┆ …            ┆ …        ┆ …         ┆ … ┆ …        ┆ …     ┆ …     ┆ …     │\n│ wt   ┆ +1           ┆ -6.52    ┆ 1.88      ┆ … ┆ 0.000537 ┆ 10.9  ┆ -10.2 ┆ -2.83 │\n│ wt   ┆ +1           ┆ -1.65    ┆ 3.74      ┆ … ┆ 0.659    ┆ 0.602 ┆ -8.99 ┆ 5.68  │\n│ wt   ┆ +1           ┆ -4.52    ┆ 2.47      ┆ … ┆ 0.0672   ┆ 3.89  ┆ -9.36 ┆ 0.321 │\n│ wt   ┆ +1           ┆ 0.635    ┆ 4.89      ┆ … ┆ 0.897    ┆ 0.157 ┆ -8.95 ┆ 10.2  │\n│ wt   ┆ +1           ┆ -6.65    ┆ 1.86      ┆ … ┆ 0.000355 ┆ 11.5  ┆ -10.3 ┆ -3    │\n└──────┴──────────────┴──────────┴───────────┴───┴──────────┴───────┴───────┴───────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nThe comparisons() function allows customized queries. For example, what happens to the predicted outcome when the hp variable increases from 100 to 120?\n\n\nR\nPython\n\n\n\n\ncomparisons(mod, variables = list(hp = c(120, 100)))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\n-0.738\n                  0.370\n                  -1.995\n                  0.04607\n                  4.4\n                  -1.463\n                  -0.0129\n                \n\n-0.574\n                  0.313\n                  -1.836\n                  0.06640\n                  3.9\n                  -1.186\n                   0.0388\n                \n\n-0.931\n                  0.452\n                  -2.062\n                  0.03922\n                  4.7\n                  -1.817\n                  -0.0460\n                \n\n-0.845\n                  0.266\n                  -3.182\n                  0.00146\n                  9.4\n                  -1.366\n                  -0.3248\n                \n\n-0.780\n                  0.268\n                  -2.909\n                  0.00362\n                  8.1\n                  -1.306\n                  -0.2547\n                \n\n-1.451\n                  0.705\n                  -2.058\n                  0.03958\n                  4.7\n                  -2.834\n                  -0.0692\n                \n\n-0.384\n                  0.270\n                  -1.422\n                  0.15498\n                  2.7\n                  -0.912\n                   0.1451\n                \n\n-0.641\n                  0.334\n                  -1.918\n                  0.05513\n                  4.2\n                  -1.297\n                   0.0141\n                \n\n-0.126\n                  0.272\n                  -0.463\n                  0.64360\n                  0.6\n                  -0.659\n                   0.4075\n                \n\n-0.635\n                  0.332\n                  -1.911\n                  0.05598\n                  4.2\n                  -1.286\n                   0.0162\n                \n\n\n\n\n\n\n\n\n\ncmp = comparisons(mod, variables = {\"hp\": [120, 100]})\nprint(cmp)\n\nshape: (32, 9)\n┌──────┬───────────┬──────────┬───────────┬───┬─────────┬───────┬─────────┬───────┐\n│ Term ┆ Contrast  ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%    ┆ 97.5% │\n│ ---  ┆ ---       ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---   ┆ ---     ┆ ---   │\n│ str  ┆ str       ┆ str      ┆ str       ┆   ┆ str     ┆ str   ┆ str     ┆ str   │\n╞══════╪═══════════╪══════════╪═══════════╪═══╪═════════╪═══════╪═════════╪═══════╡\n│ hp   ┆ 100 - 120 ┆ 0.738    ┆ 0.37      ┆ … ┆ 0.0461  ┆ 4.44  ┆ 0.0129  ┆ 1.46  │\n│ hp   ┆ 100 - 120 ┆ 0.574    ┆ 0.313     ┆ … ┆ 0.0664  ┆ 3.91  ┆ -0.0388 ┆ 1.19  │\n│ hp   ┆ 100 - 120 ┆ 0.931    ┆ 0.452     ┆ … ┆ 0.0392  ┆ 4.67  ┆ 0.046   ┆ 1.82  │\n│ hp   ┆ 100 - 120 ┆ 0.845    ┆ 0.266     ┆ … ┆ 0.00146 ┆ 9.42  ┆ 0.325   ┆ 1.37  │\n│ hp   ┆ 100 - 120 ┆ 0.78     ┆ 0.268     ┆ … ┆ 0.00362 ┆ 8.11  ┆ 0.255   ┆ 1.31  │\n│ …    ┆ …         ┆ …        ┆ …         ┆ … ┆ …       ┆ …     ┆ …       ┆ …     │\n│ hp   ┆ 100 - 120 ┆ 1.45     ┆ 0.705     ┆ … ┆ 0.0396  ┆ 4.66  ┆ 0.0692  ┆ 2.83  │\n│ hp   ┆ 100 - 120 ┆ 0.384    ┆ 0.27      ┆ … ┆ 0.155   ┆ 2.69  ┆ -0.145  ┆ 0.912 │\n│ hp   ┆ 100 - 120 ┆ 0.641    ┆ 0.334     ┆ … ┆ 0.0551  ┆ 4.18  ┆ -0.0141 ┆ 1.3   │\n│ hp   ┆ 100 - 120 ┆ 0.126    ┆ 0.272     ┆ … ┆ 0.644   ┆ 0.636 ┆ -0.408  ┆ 0.659 │\n│ hp   ┆ 100 - 120 ┆ 0.635    ┆ 0.332     ┆ … ┆ 0.056   ┆ 4.16  ┆ -0.0162 ┆ 1.29  │\n└──────┴───────────┴──────────┴───────────┴───┴─────────┴───────┴─────────┴───────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nWhat happens to the predicted outcome when the hp variable increases by 1 standard deviation about its mean?\n\n\nR\nPython\n\n\n\n\ncomparisons(mod, variables = list(hp = \"sd\"))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\n-2.530\n                  1.269\n                  -1.995\n                  0.04607\n                  4.4\n                  -5.02\n                  -0.0441\n                \n\n-1.967\n                  1.072\n                  -1.836\n                  0.06640\n                  3.9\n                  -4.07\n                   0.1332\n                \n\n-3.193\n                  1.549\n                  -2.062\n                  0.03922\n                  4.7\n                  -6.23\n                  -0.1578\n                \n\n-2.898\n                  0.911\n                  -3.182\n                  0.00146\n                  9.4\n                  -4.68\n                  -1.1133\n                \n\n-2.675\n                  0.919\n                  -2.909\n                  0.00362\n                  8.1\n                  -4.48\n                  -0.8731\n                \n\n-4.976\n                  2.418\n                  -2.058\n                  0.03958\n                  4.7\n                  -9.71\n                  -0.2373\n                \n\n-1.315\n                  0.925\n                  -1.422\n                  0.15498\n                  2.7\n                  -3.13\n                   0.4974\n                \n\n-2.199\n                  1.147\n                  -1.918\n                  0.05513\n                  4.2\n                  -4.45\n                   0.0483\n                \n\n-0.432\n                  0.933\n                  -0.463\n                  0.64360\n                  0.6\n                  -2.26\n                   1.3970\n                \n\n-2.177\n                  1.139\n                  -1.911\n                  0.05598\n                  4.2\n                  -4.41\n                   0.0556\n                \n\n\n\n\n\n\n\n\n\ncmp = comparisons(mod, variables = {\"hp\": \"sd\"})\nprint(cmp)\n\nshape: (32, 9)\n┌──────┬─────────────────────┬──────────┬───────────┬───┬─────────┬───────┬───────┬─────────┐\n│ Term ┆ Contrast            ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%  ┆ 97.5%   │\n│ ---  ┆ ---                 ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---   ┆ ---   ┆ ---     │\n│ str  ┆ str                 ┆ str      ┆ str       ┆   ┆ str     ┆ str   ┆ str   ┆ str     │\n╞══════╪═════════════════════╪══════════╪═══════════╪═══╪═════════╪═══════╪═══════╪═════════╡\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.53    ┆ 1.27      ┆ … ┆ 0.0461  ┆ 4.44  ┆ -5.02 ┆ -0.0441 │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -1.97    ┆ 1.07      ┆ … ┆ 0.0664  ┆ 3.91  ┆ -4.07 ┆ 0.133   │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -3.19    ┆ 1.55      ┆ … ┆ 0.0392  ┆ 4.67  ┆ -6.23 ┆ -0.158  │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.9     ┆ 0.911     ┆ … ┆ 0.00146 ┆ 9.42  ┆ -4.68 ┆ -1.11   │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.68    ┆ 0.919     ┆ … ┆ 0.00362 ┆ 8.11  ┆ -4.48 ┆ -0.873  │\n│ …    ┆ …                   ┆ …        ┆ …         ┆ … ┆ …       ┆ …     ┆ …     ┆ …       │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -4.98    ┆ 2.42      ┆ … ┆ 0.0396  ┆ 4.66  ┆ -9.71 ┆ -0.237  │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -1.32    ┆ 0.925     ┆ … ┆ 0.155   ┆ 2.69  ┆ -3.13 ┆ 0.497   │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.2     ┆ 1.15      ┆ … ┆ 0.0551  ┆ 4.18  ┆ -4.45 ┆ 0.0483  │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -0.432   ┆ 0.933     ┆ … ┆ 0.644   ┆ 0.636 ┆ -2.26 ┆ 1.4     │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.18    ┆ 1.14      ┆ … ┆ 0.056   ┆ 4.16  ┆ -4.41 ┆ 0.0556  │\n└──────┴─────────────────────┴──────────┴───────────┴───┴─────────┴───────┴───────┴─────────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nThe comparisons() function also allows users to specify arbitrary functions of predictions, with the comparison argument. For example, what is the average ratio between predicted Miles per Gallon after an increase of 50 units in Horsepower?\n\n\nR\nPython\n\n\n\n\ncomparisons(\n  mod,\n  variables = list(hp = 50),\n  comparison = \"ratioavg\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n0.905\n                  0.0319\n                  28.4\n                  \n                  \n586.8\n                  0.843\n                  0.968\n                \n\n\n\n\n\n\n\n\ncmp = comparisons(\n  mod,\n  variables = {\"hp\": 50},\n  comparison = \"ratioavg\")\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────┬──────────┬───────────┬───┬─────────┬─────┬───────┬───────┐\n│ Term ┆ Contrast ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S   ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---      ┆ ---      ┆ ---       ┆   ┆ ---     ┆ --- ┆ ---   ┆ ---   │\n│ str  ┆ str      ┆ str      ┆ str       ┆   ┆ str     ┆ str ┆ str   ┆ str   │\n╞══════╪══════════╪══════════╪═══════════╪═══╪═════════╪═════╪═══════╪═══════╡\n│ hp   ┆ +50      ┆ 0.91     ┆ 0.0291    ┆ … ┆ 0       ┆ inf ┆ 0.853 ┆ 0.966 │\n└──────┴──────────┴──────────┴───────────┴───┴─────────┴─────┴───────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nSee the Comparisons vignette for detailed explanations and more options.\nThe slopes() function allows us to compute the partial derivative of the outcome equation with respect to each of the predictors. Once again, we obtain a data frame with 96 rows:\n\n\nR\nPython\n\n\n\n\nmfx &lt;- slopes(mod)\n\nnrow(mfx)\n\n[1] 96\n\nmfx\n\n\n\n    \n\n      \n\nTerm\n                Contrast\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\nam\n                  1 - 0\n                   0.325\n                  1.68\n                   0.193\n                  0.8467\n                  0.2 \n                   -2.97\n                   3.622\n                \n\nam\n                  1 - 0\n                  -0.544\n                  1.57\n                  -0.347\n                  0.7287\n                  0.5 \n                   -3.62\n                   2.530\n                \n\nam\n                  1 - 0\n                   1.201\n                  2.35\n                   0.511\n                  0.6090\n                  0.7 \n                   -3.40\n                   5.802\n                \n\nam\n                  1 - 0\n                  -1.703\n                  1.87\n                  -0.912\n                  0.3618\n                  1.5 \n                   -5.36\n                   1.957\n                \n\nam\n                  1 - 0\n                  -0.615\n                  1.68\n                  -0.366\n                  0.7146\n                  0.5 \n                   -3.91\n                   2.680\n                \n\nwt\n                  dY/dX\n                  -6.518\n                  1.88\n                  -3.462\n                  \n                  \n10.9\n                  -10.21\n                  -2.828\n                \n\nwt\n                  dY/dX\n                  -1.653\n                  3.74\n                  -0.442\n                  0.6588\n                  0.6 \n                   -8.99\n                   5.683\n                \n\nwt\n                  dY/dX\n                  -4.520\n                  2.47\n                  -1.830\n                  0.0673\n                  3.9 \n                   -9.36\n                   0.321\n                \n\nwt\n                  dY/dX\n                   0.635\n                  4.89\n                   0.130\n                  0.8966\n                  0.2 \n                   -8.95\n                  10.216\n                \n\nwt\n                  dY/dX\n                  -6.647\n                  1.86\n                  -3.572\n                  \n                  \n11.5\n                  -10.29\n                  -2.999\n                \n\n\n\n\n\n\n\n\n\nmfx = slopes(mod)\n\nmfx.shape\n\n(96, 25)\n\nprint(mfx)\n\nshape: (96, 9)\n┌──────┬──────────────┬──────────┬───────────┬───┬──────────┬───────┬───────┬───────┐\n│ Term ┆ Contrast     ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---          ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---   ┆ ---   ┆ ---   │\n│ str  ┆ str          ┆ str      ┆ str       ┆   ┆ str      ┆ str   ┆ str   ┆ str   │\n╞══════╪══════════════╪══════════╪═══════════╪═══╪══════════╪═══════╪═══════╪═══════╡\n│ am   ┆ True - False ┆ 0.325    ┆ 1.68      ┆ … ┆ 0.847    ┆ 0.24  ┆ -2.97 ┆ 3.62  │\n│ am   ┆ True - False ┆ -0.544   ┆ 1.57      ┆ … ┆ 0.729    ┆ 0.457 ┆ -3.62 ┆ 2.53  │\n│ am   ┆ True - False ┆ 1.2      ┆ 2.35      ┆ … ┆ 0.609    ┆ 0.715 ┆ -3.4  ┆ 5.8   │\n│ am   ┆ True - False ┆ -1.7     ┆ 1.87      ┆ … ┆ 0.362    ┆ 1.47  ┆ -5.36 ┆ 1.96  │\n│ am   ┆ True - False ┆ -0.615   ┆ 1.68      ┆ … ┆ 0.715    ┆ 0.485 ┆ -3.91 ┆ 2.68  │\n│ …    ┆ …            ┆ …        ┆ …         ┆ … ┆ …        ┆ …     ┆ …     ┆ …     │\n│ wt   ┆ dY/dX        ┆ -6.52    ┆ 1.88      ┆ … ┆ 0.000532 ┆ 10.9  ┆ -10.2 ┆ -2.83 │\n│ wt   ┆ dY/dX        ┆ -1.65    ┆ 3.74      ┆ … ┆ 0.659    ┆ 0.602 ┆ -8.98 ┆ 5.68  │\n│ wt   ┆ dY/dX        ┆ -4.52    ┆ 2.47      ┆ … ┆ 0.0675   ┆ 3.89  ┆ -9.37 ┆ 0.325 │\n│ wt   ┆ dY/dX        ┆ 0.635    ┆ 4.89      ┆ … ┆ 0.897    ┆ 0.157 ┆ -8.95 ┆ 10.2  │\n│ wt   ┆ dY/dX        ┆ -6.65    ┆ 1.86      ┆ … ┆ 0.000349 ┆ 11.5  ┆ -10.3 ┆ -3    │\n└──────┴──────────────┴──────────┴───────────┴───┴──────────┴───────┴───────┴───────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\n\nPredictions, comparisons, and slopes are typically “conditional” quantities which depend on the values of all the predictors in the model. By default, marginaleffects functions estimate quantities of interest for the empirical distribution of the data (i.e., for each row of the original dataset). However, users can specify the exact values of the predictors they want to investigate by using the newdata argument.\nnewdata accepts data frames, shortcut strings, or a call to the datagrid() function. For example, to compute the predicted outcome for a hypothetical car with all predictors equal to the sample mean or median, we can do:\n\n\nR\nPython\n\n\n\n\npredictions(mod, newdata = \"mean\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n                wt\n                am\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, wt, am, mpg \n\n\n\n18.7\n                  0.649\n                  28.8\n                  \n                  \n603.8\n                  17.4\n                  20\n                  147\n                  3.22\n                  0\n                \n\n\n\n\npredictions(mod, newdata = \"median\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n                wt\n                am\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, wt, am, mpg \n\n\n\n19.4\n                  0.646\n                  30\n                  \n                  \n653.2\n                  18.1\n                  20.6\n                  123\n                  3.33\n                  0\n                \n\n\n\n\n\n\n\n\np = predictions(mod, newdata = \"mean\")\nprint(p)\n\nshape: (1, 7)\n┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n│ 20.2     ┆ 0.704     ┆ 28.8 ┆ 0       ┆ inf ┆ 18.9 ┆ 21.6  │\n└──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n\nColumns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\np = predictions(mod, newdata = \"median\")\nprint(p)\n\nshape: (1, 7)\n┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n│ 17.3     ┆ 0.766     ┆ 22.5 ┆ 0       ┆ inf ┆ 15.8 ┆ 18.8  │\n└──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n\nColumns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nThe datagrid function gives us a powerful way to define a grid of predictors. All the variables not mentioned explicitly in datagrid() are fixed to their mean or mode:\n\n\nR\nPython\n\n\n\n\npredictions(\n  mod,\n  newdata = datagrid(\n    am = c(0, 1),\n    wt = range))\n\n\n\n    \n\n      \n\nam\n                wt\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, am, wt, mpg \n\n\n\n\n0\n                  1.51\n                  23.3\n                  2.71\n                  8.60\n                  \n                  \n56.7\n                  17.96\n                  28.6\n                  147\n                \n\n0\n                  5.42\n                  12.8\n                  2.98\n                  4.30\n                  \n                  \n15.8\n                   6.96\n                  18.6\n                  147\n                \n\n1\n                  1.51\n                  27.1\n                  2.85\n                  9.52\n                  \n                  \n69.0\n                  21.56\n                  32.7\n                  147\n                \n\n1\n                  5.42\n                   5.9\n                  5.81\n                  1.01\n                  0.31  \n                  1.7 \n                  -5.50\n                  17.3\n                  147\n                \n\n\n\n\n\n\n\n\n\np = predictions(\n  mod,\n  newdata = datagrid(\n    am = [0, 1],\n    wt = [mtcars[\"wt\"].min(), mtcars[\"wt\"].max()]))\nprint(p)\n\nshape: (4, 9)\n┌─────┬──────┬──────────┬───────────┬───┬──────────┬──────┬───────┬───────┐\n│ am  ┆ wt   ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ --- ┆ ---  ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---   ┆ ---   │\n│ str ┆ str  ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str   ┆ str   │\n╞═════╪══════╪══════════╪═══════════╪═══╪══════════╪══════╪═══════╪═══════╡\n│ 0   ┆ 1.51 ┆ 21.4     ┆ 2.41      ┆ … ┆ 0        ┆ inf  ┆ 16.7  ┆ 26.1  │\n│ 0   ┆ 5.42 ┆ 12.5     ┆ 1.96      ┆ … ┆ 1.75e-10 ┆ 32.4 ┆ 8.66  ┆ 16.3  │\n│ 1   ┆ 1.51 ┆ 25.1     ┆ 3.77      ┆ … ┆ 2.76e-11 ┆ 35.1 ┆ 17.7  ┆ 32.5  │\n│ 1   ┆ 5.42 ┆ 7.41     ┆ 6.12      ┆ … ┆ 0.225    ┆ 2.15 ┆ -4.57 ┆ 19.4  │\n└─────┴──────┴──────────┴───────────┴───┴──────────┴──────┴───────┴───────┘\n\nColumns: am, wt, rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, qsec, vs, gear, carb\n\n\n\n\n\nThe same mechanism is available in comparisons() and slopes(). To estimate the partial derivative of mpg with respect to wt, when am is equal to 0 and 1, while other predictors are held at their means:\n\n\nR\nPython\n\n\n\n\nslopes(\n  mod,\n  variables = \"wt\",\n  newdata = datagrid(am = 0:1))\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, predicted_lo, predicted_hi, predicted, hp, wt, mpg \n\n\n\n\n0\n                  -2.68\n                  1.42\n                  -1.89\n                  0.0594\n                  4.1\n                  -5.46\n                   0.106\n                \n\n1\n                  -5.43\n                  2.15\n                  -2.52\n                  0.0116\n                  6.4\n                  -9.65\n                  -1.213\n                \n\n\n\n\n\n\n\n\n\ns = slopes(\n  mod,\n  variables = \"wt\",\n  newdata = datagrid(mod, am = [0, 1]))\nprint(s)\n\nshape: (2, 10)\n┌─────┬──────┬──────────┬──────────┬───┬─────────┬──────┬───────┬────────┐\n│ am  ┆ Term ┆ Contrast ┆ Estimate ┆ … ┆ P(&gt;|z|) ┆ S    ┆ 2.5%  ┆ 97.5%  │\n│ --- ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---     ┆ ---  ┆ ---   ┆ ---    │\n│ str ┆ str  ┆ str      ┆ str      ┆   ┆ str     ┆ str  ┆ str   ┆ str    │\n╞═════╪══════╪══════════╪══════════╪═══╪═════════╪══════╪═══════╪════════╡\n│ 0   ┆ wt   ┆ dY/dX    ┆ -2.27    ┆ … ┆ 0.033   ┆ 4.92 ┆ -4.35 ┆ -0.183 │\n│ 1   ┆ wt   ┆ dY/dX    ┆ -4.52    ┆ … ┆ 0.0668  ┆ 3.9  ┆ -9.35 ┆ 0.314  │\n└─────┴──────┴──────────┴──────────┴───┴─────────┴──────┴───────┴────────┘\n\nColumns: am, rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, gear, carb\n\n\n\n\n\nWe can also plot how predictions, comparisons, or slopes change across different values of the predictors using three powerful plotting functions:\n\n\nplot_predictions: Conditional Adjusted Predictions\n\nplot_comparisons: Conditional Comparisons\n\nplot_slopes: Conditional Marginal Effects\n\nFor example, this plot shows the outcomes predicted by our model for different values of the wt and am variables:\n\n\nR\nPython\n\n\n\n\nplot_predictions(mod, condition = list(\"hp\", \"wt\" = \"threenum\", \"am\"))\n\n\n\n\n\n\n\n\n\n\ncond = {\n  \"hp\": None,\n  \"wt\": [mtcars[\"wt\"].mean() - mtcars[\"wt\"].std(),\n         mtcars[\"wt\"].mean(),\n         mtcars[\"wt\"].mean() + mtcars[\"wt\"].std()],\n  \"am\": None\n}\nplot_predictions(mod, condition = cond)\n\n&lt;string&gt;:1: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\n\nThis plot shows how the derivative of mpg with respect to am varies as a function of wt and hp:\n\n\nR\nPython\n\n\n\n\nplot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"wt\" = \"minmax\"))\n\n\n\n\n\n\n\n\n\n\nplot_slopes(mod,\n  variables = \"am\",\n  condition = {\"hp\": None, \"wt\": [mtcars[\"wt\"].min(), mtcars[\"wt\"].max()]}\n)\n\n&lt;string&gt;:1: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\n\nSee this vignette for more information: Plots, interactions, predictions, contrasts, and slopes\n\nSince predictions, comparisons, and slopes are conditional quantities, they can be a bit unwieldy. Often, it can be useful to report a one-number summary instead of one estimate per observation. Instead of presenting “conditional” estimates, some methodologists recommend reporting “marginal” estimates, that is, an average of unit-level estimates.\n(This use of the word “marginal” as “averaging” should not be confused with the term “marginal effect” which, in the econometrics tradition, corresponds to a partial derivative, or the effect of a “small/marginal” change.)\nTo marginalize (average over) our unit-level estimates, we can use the by argument or the one of the convenience functions: avg_predictions(), avg_comparisons(), or avg_slopes(). For example, both of these commands give us the same result: the average predicted outcome in the mtcars dataset:\n\n\nR\nPython\n\n\n\n\navg_predictions(mod)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n20.1\n                  0.39\n                  51.5\n                  \n                  \nInf\n                  19.3\n                  20.9\n                \n\n\n\n\n\n\n\n\np = avg_predictions(mod)\nprint(p)\n\nshape: (1, 7)\n┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n│ 20.1     ┆ 0.39      ┆ 51.5 ┆ 0       ┆ inf ┆ 19.3 ┆ 20.9  │\n└──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n\nColumns: estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nThis is equivalent to manual computation by:\n\n\nR\nPython\n\n\n\n\nmean(predict(mod))\n\n[1] 20.09062\n\n\n\n\n\nnp.mean(mod.predict())\n\n20.090625000000024\n\n\n\n\n\nThe main marginaleffects functions all include a by argument, which allows us to marginalize within sub-groups of the data. For example,\n\n\nR\nPython\n\n\n\n\navg_comparisons(mod, by = \"am\")\n\n\n\n    \n\n      \n\nTerm\n                Contrast\n                am\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nam\n                  mean(1) - mean(0)\n                  0\n                  -1.3830\n                  2.5250\n                  -0.548\n                  0.58388\n                  0.8\n                  -6.3319\n                   3.56589\n                \n\nam\n                  mean(1) - mean(0)\n                  1\n                   1.9029\n                  2.3086\n                   0.824\n                  0.40980\n                  1.3\n                  -2.6219\n                   6.42773\n                \n\nhp\n                  mean(+1)         \n                  0\n                  -0.0343\n                  0.0159\n                  -2.160\n                  0.03079\n                  5.0\n                  -0.0654\n                  -0.00317\n                \n\nhp\n                  mean(+1)         \n                  1\n                  -0.0436\n                  0.0213\n                  -2.050\n                  0.04039\n                  4.6\n                  -0.0854\n                  -0.00191\n                \n\nwt\n                  mean(+1)         \n                  0\n                  -2.4799\n                  1.2316\n                  -2.014\n                  0.04406\n                  4.5\n                  -4.8939\n                  -0.06595\n                \n\nwt\n                  mean(+1)         \n                  1\n                  -6.0718\n                  1.9762\n                  -3.072\n                  0.00212\n                  8.9\n                  -9.9451\n                  -2.19846\n                \n\n\n\n\n\n\n\n\n\ncmp = avg_comparisons(mod, by = \"am\")\nprint(cmp)\n\nshape: (6, 10)\n┌─────┬──────┬──────────────────────────┬──────────┬───┬─────────┬───────┬─────────┬──────────┐\n│ am  ┆ Term ┆ Contrast                 ┆ Estimate ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%    ┆ 97.5%    │\n│ --- ┆ ---  ┆ ---                      ┆ ---      ┆   ┆ ---     ┆ ---   ┆ ---     ┆ ---      │\n│ str ┆ str  ┆ str                      ┆ str      ┆   ┆ str     ┆ str   ┆ str     ┆ str      │\n╞═════╪══════╪══════════════════════════╪══════════╪═══╪═════════╪═══════╪═════════╪══════════╡\n│ 0   ┆ am   ┆ mean(True) - mean(False) ┆ -1.38    ┆ … ┆ 0.584   ┆ 0.776 ┆ -6.33   ┆ 3.57     │\n│ 1   ┆ am   ┆ mean(True) - mean(False) ┆ 1.9      ┆ … ┆ 0.41    ┆ 1.29  ┆ -2.62   ┆ 6.43     │\n│ 0   ┆ hp   ┆ +1                       ┆ -0.0343  ┆ … ┆ 0.0308  ┆ 5.02  ┆ -0.0654 ┆ -0.00317 │\n│ 1   ┆ hp   ┆ +1                       ┆ -0.0436  ┆ … ┆ 0.0404  ┆ 4.63  ┆ -0.0854 ┆ -0.00191 │\n│ 0   ┆ wt   ┆ +1                       ┆ -2.48    ┆ … ┆ 0.0441  ┆ 4.5   ┆ -4.89   ┆ -0.066   │\n│ 1   ┆ wt   ┆ +1                       ┆ -6.07    ┆ … ┆ 0.00212 ┆ 8.88  ┆ -9.95   ┆ -2.2     │\n└─────┴──────┴──────────────────────────┴──────────┴───┴─────────┴───────┴─────────┴──────────┘\n\nColumns: am, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nMarginal Means are a special case of predictions, which are marginalized (or averaged) across a balanced grid of categorical predictors. To illustrate, we estimate a new model with categorical predictors:\n\n\nR\nPython\n\n\n\n\ndat &lt;- mtcars\ndat$am &lt;- as.logical(dat$am)\ndat$cyl &lt;- as.factor(dat$cyl)\nmod_cat &lt;- lm(mpg ~ am + cyl + hp, data = dat)\n\n\n\n\ndat = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\") \\\n  .with_columns(pl.col(\"am\").cast(pl.Boolean),\n                pl.col(\"cyl\").cast(pl.Utf8))\nmod_cat = smf.ols('mpg ~ am + cyl + hp', data=dat.to_pandas()).fit()\n\n\n\n\nWe can compute marginal means manually using the functions already described:\n\n\nR\nPython\n\n\n\n\navg_predictions(\n  mod_cat,\n  newdata = \"balanced\",\n  by = \"am\")\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n TRUE\n                  22.5\n                  0.834\n                  26.9\n                  \n                  \n528.6\n                  20.8\n                  24.1\n                \n\nFALSE\n                  18.3\n                  0.785\n                  23.3\n                  \n                  \n397.4\n                  16.8\n                  19.9\n                \n\n\n\n\n\n\n\n\n\npredictions(\n  mod_cat,\n  newdata = datagrid(grid_type = \"balanced\"),\n  by = \"am\")\nprint(p)\n\n\n\n\nThe Marginal Means vignette offers more detail.\n\nThe marginaleffects package reports uncertainty estimates for all the quantities it computes: predictions, comparisons, slopes, etc. By default, standard errors are computed using the delta method and classical standard errors. These standard errors are fast to compute, and have appealing properties in some, but not all cases. marginaleffects supports several alternatives, including: Huber-White Heteroskedasticity Robust, Cluster-Robust, Bootstrap, and Simulation-based uncertainty estimates.\nThe Standard Errors vignette offers more detail. For now, it suffices to show two examples. First, we use the vcov argument to report “HC3” (heteroskedasticity-consistent) standard errors.\n\n\nR\nPython\n\n\n\n\navg_predictions(mod, by = \"am\", vcov = \"HC3\")\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n1\n                  24.4\n                  0.782\n                  31.2\n                  \n                  \n707.3\n                  22.9\n                  25.9\n                \n\n0\n                  17.1\n                  0.614\n                  27.9\n                  \n                  \n568.5\n                  15.9\n                  18.3\n                \n\n\n\n\n\n\n\n\nNot supported yet.\n\n\n\nSecond, we use the inferences() function to compute bootstrap intervals using 500 resamples:\n\n\nR\nPython\n\n\n\n\navg_predictions(mod, by = \"am\") |&gt;\n  inferences(method = \"boot\", R = 500)\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: am, estimate, std.error, conf.low, conf.high \n\n\n\n\n1\n                  24.4\n                  4.854\n                  21.3\n                  26.5\n                \n\n0\n                  17.1\n                  0.607\n                  16.3\n                  19.1\n                \n\n\n\n\n\n\n\n\nNot supported yet.\n\n\n\n\nThe hypotheses() function and the hypothesis argument can be used to conduct linear and non-linear hypothesis tests on model coefficients, or on any of the quantities computed by the functions introduced above.\nConsider this model:\n\n\nR\nPython\n\n\n\n\nmod &lt;- lm(mpg ~ qsec * drat, data = mtcars)\ncoef(mod)\n\n(Intercept)        qsec        drat   qsec:drat \n 12.3371987  -1.0241183  -3.4371461   0.5973153 \n\n\n\n\n\nmod = smf.ols('mpg ~ qsec * drat', data=mtcars).fit()\nprint(mod.params)\n\nIntercept    12.337199\nqsec         -1.024118\ndrat         -3.437146\nqsec:drat     0.597315\ndtype: float64\n\n\n\n\n\nCan we reject the null hypothesis that the drat coefficient is 2 times the size of the qsec coefficient?\n\nhypotheses(mod, \"drat = 2 * qsec\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-1.39\n                  10.8\n                  -0.129\n                  0.897\n                  0.2\n                  -22.5\n                  19.7\n                \n\n\n\n\n\nWe can ask the same question but refer to parameters by position, with indices b1, b2, b3, etc.:\n\n\nR\nPython\n\n\n\n\nhypotheses(mod, \"b3 = 2 * b2\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-1.39\n                  10.8\n                  -0.129\n                  0.897\n                  0.2\n                  -22.5\n                  19.7\n                \n\n\n\n\n\n\n\n\nh = hypotheses(mod, \"b3 = 2 * b2\")\nprint(h)\n\nshape: (1, 8)\n┌─────────┬──────────┬───────────┬────────┬─────────┬───────┬───────┬───────┐\n│ Term    ┆ Estimate ┆ Std.Error ┆ z      ┆ P(&gt;|z|) ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---     ┆ ---      ┆ ---       ┆ ---    ┆ ---     ┆ ---   ┆ ---   ┆ ---   │\n│ str     ┆ str      ┆ str       ┆ str    ┆ str     ┆ str   ┆ str   ┆ str   │\n╞═════════╪══════════╪═══════════╪════════╪═════════╪═══════╪═══════╪═══════╡\n│ b3=2*b2 ┆ -1.39    ┆ 10.8      ┆ -0.129 ┆ 0.897   ┆ 0.156 ┆ -22.5 ┆ 19.7  │\n└─────────┴──────────┴───────────┴────────┴─────────┴───────┴───────┴───────┘\n\nColumns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nThe main functions in marginaleffects all have a hypothesis argument, which means that we can do complex model testing. For example, consider two slope estimates:\n\n\nR\nPython\n\n\n\n\nslopes(\n  mod,\n  variables = \"drat\",\n  newdata = datagrid(qsec = range))\n\n\n\n    \n\n      \n\nqsec\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, qsec, predicted_lo, predicted_hi, predicted, drat, mpg \n\n\n\n\n14.5\n                   5.22\n                  3.79\n                  1.38\n                  0.1682\n                  2.6\n                  -2.206\n                  12.7\n                \n\n22.9\n                  10.24\n                  5.15\n                  1.99\n                  0.0469\n                  4.4\n                   0.139\n                  20.3\n                \n\n\n\n\n\n\n\n\n\ns = slopes(\n  mod,\n  variables = \"drat\",\n  newdata = datagrid(qsec = [mtcars[\"qsec\"].min(), mtcars[\"qsec\"].max()]))\nprint(s)\n\nshape: (2, 10)\n┌──────┬──────┬──────────┬──────────┬───┬─────────┬──────┬───────┬───────┐\n│ qsec ┆ Term ┆ Contrast ┆ Estimate ┆ … ┆ P(&gt;|z|) ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---     ┆ ---  ┆ ---   ┆ ---   │\n│ str  ┆ str  ┆ str      ┆ str      ┆   ┆ str     ┆ str  ┆ str   ┆ str   │\n╞══════╪══════╪══════════╪══════════╪═══╪═════════╪══════╪═══════╪═══════╡\n│ 14.5 ┆ drat ┆ dY/dX    ┆ 5.22     ┆ … ┆ 0.168   ┆ 2.57 ┆ -2.2  ┆ 12.7  │\n│ 22.9 ┆ drat ┆ dY/dX    ┆ 10.2     ┆ … ┆ 0.0469  ┆ 4.42 ┆ 0.143 ┆ 20.3  │\n└──────┴──────┴──────────┴──────────┴───┴─────────┴──────┴───────┴───────┘\n\nColumns: qsec, rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, vs, am, gear, carb\n\n\n\n\n\nAre these two slopes significantly different from one another? To test this, we can use the hypothesis argument:\n\n\nR\nPython\n\n\n\n\nslopes(\n  mod,\n  hypothesis = \"b1 = b2\",\n  variables = \"drat\",\n  newdata = datagrid(qsec = range))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-5.02\n                  8.51\n                  -0.589\n                  0.556\n                  0.8\n                  -21.7\n                  11.7\n                \n\n\n\n\n\n\n\n\ns = slopes(\n  mod,\n  hypothesis = \"b1 = b2\",\n  variables = \"drat\",\n  newdata = datagrid(qsec = [mtcars[\"qsec\"].min(), mtcars[\"qsec\"].max()]))\nprint(s)\n\nshape: (1, 8)\n┌───────┬──────────┬───────────┬───────┬─────────┬───────┬───────┬───────┐\n│ Term  ┆ Estimate ┆ Std.Error ┆ z     ┆ P(&gt;|z|) ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---   ┆ ---      ┆ ---       ┆ ---   ┆ ---     ┆ ---   ┆ ---   ┆ ---   │\n│ str   ┆ str      ┆ str       ┆ str   ┆ str     ┆ str   ┆ str   ┆ str   │\n╞═══════╪══════════╪═══════════╪═══════╪═════════╪═══════╪═══════╪═══════╡\n│ b1=b2 ┆ -5.02    ┆ 8.51      ┆ -0.59 ┆ 0.555   ┆ 0.848 ┆ -21.7 ┆ 11.7  │\n└───────┴──────────┴───────────┴───────┴─────────┴───────┴───────┴───────┘\n\nColumns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nAlternatively, we can also refer to values with term names (when they are unique):\n\n\nR\nPython\n\n\n\n\navg_slopes(mod)\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\ndrat\n                  7.22\n                  1.365\n                  5.29\n                  \n                  \n23.0\n                  4.548\n                  9.90\n                \n\nqsec\n                  1.12\n                  0.433\n                  2.60\n                  0.00945\n                  6.7 \n                  0.275\n                  1.97\n                \n\n\n\n\n\navg_slopes(mod, hypothesis = \"drat = qsec\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n6.1\n                  1.45\n                  4.2\n                  \n                  \n15.2\n                  3.25\n                  8.95\n                \n\n\n\n\n\n\n\n\ns = avg_slopes(mod)\nprint(s)\n\nshape: (2, 9)\n┌──────┬─────────────┬──────────┬───────────┬───┬──────────┬──────┬───────┬───────┐\n│ Term ┆ Contrast    ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---         ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---   ┆ ---   │\n│ str  ┆ str         ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str   ┆ str   │\n╞══════╪═════════════╪══════════╪═══════════╪═══╪══════════╪══════╪═══════╪═══════╡\n│ drat ┆ mean(dY/dX) ┆ 7.22     ┆ 1.37      ┆ … ┆ 1.21e-07 ┆ 23   ┆ 4.55  ┆ 9.9   │\n│ qsec ┆ mean(dY/dX) ┆ 1.12     ┆ 0.432     ┆ … ┆ 0.00927  ┆ 6.75 ┆ 0.277 ┆ 1.97  │\n└──────┴─────────────┴──────────┴───────────┴───┴──────────┴──────┴───────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\ns = avg_slopes(mod, hypothesis = \"drat = qsec\")\nprint(s)\n\nshape: (1, 8)\n┌───────────┬──────────┬───────────┬─────┬──────────┬──────┬──────┬───────┐\n│ Term      ┆ Estimate ┆ Std.Error ┆ z   ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---       ┆ ---      ┆ ---       ┆ --- ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str       ┆ str      ┆ str       ┆ str ┆ str      ┆ str  ┆ str  ┆ str   │\n╞═══════════╪══════════╪═══════════╪═════╪══════════╪══════╪══════╪═══════╡\n│ drat=qsec ┆ 6.1      ┆ 1.45      ┆ 4.2 ┆ 2.66e-05 ┆ 15.2 ┆ 3.25 ┆ 8.95  │\n└───────────┴──────────┴───────────┴─────┴──────────┴──────┴──────┴───────┘\n\nColumns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nNow, imagine that for theoretical (or substantive or clinical) reasons, we only care about slopes larger than 2. We can use the equivalence argument to conduct an equivalence test:\n\n\nR\nPython\n\n\n\n\navg_slopes(mod, equivalence = c(-2, 2))\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                p (NonSup)\n                p (NonInf)\n                p (Equiv)\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\n\n\n\ndrat\n                  7.22\n                  1.365\n                  5.29\n                  \n                  \n23.0\n                  4.548\n                  9.90\n                  0.9999\n                  \n                  \n0.9999\n                \n\nqsec\n                  1.12\n                  0.433\n                  2.60\n                  0.00945\n                  6.7 \n                  0.275\n                  1.97\n                  0.0216\n                  \n                  \n0.0216\n                \n\n\n\n\n\n\n\n\n\ns = avg_slopes(mod, equivalence = [-2., 2.])\nprint(s)\n\nshape: (2, 9)\n┌──────┬─────────────┬──────────┬───────────┬───┬──────────┬──────┬───────┬───────┐\n│ Term ┆ Contrast    ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---         ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---   ┆ ---   │\n│ str  ┆ str         ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str   ┆ str   │\n╞══════╪═════════════╪══════════╪═══════════╪═══╪══════════╪══════╪═══════╪═══════╡\n│ drat ┆ mean(dY/dX) ┆ 7.22     ┆ 1.37      ┆ … ┆ 1.21e-07 ┆ 23   ┆ 4.55  ┆ 9.9   │\n│ qsec ┆ mean(dY/dX) ┆ 1.12     ┆ 0.432     ┆ … ┆ 0.00927  ┆ 6.75 ┆ 0.277 ┆ 1.97  │\n└──────┴─────────────┴──────────┴───────────┴───┴──────────┴──────┴───────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, statistic_noninf, statistic_nonsup, p_value_noninf, p_value_nonsup, p_value_equiv\n\n\n\n\n\nSee the Hypothesis Tests and Custom Contrasts vignette for background, details, and for instructions on how to conduct hypothesis tests in more complex situations.",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/get_started.html#installation",
    "href": "vignettes/get_started.html#installation",
    "title": "Get started",
    "section": "",
    "text": "Before we begin, let’s install the marginaleffects package, available for R and Python:\n\n\nR\nPython\n\n\n\nInstall from CRAN:\n\ninstall.packages(\"marginaleffects\")\n\n\n\nInstall from PyPI:\n\npip install marginaleffects",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/get_started.html#quantity",
    "href": "vignettes/get_started.html#quantity",
    "title": "Get started",
    "section": "",
    "text": "The marginaleffects package allows R users to compute and plot three principal quantities of interest: (1) predictions, (2) comparisons, and (3) slopes. In addition, the package includes a convenience function to compute a fourth quantity of interest, “marginal means”, which is a special case of averaged predictions. marginaleffects can also average (or “marginalize”) unit-level (or “conditional”) estimates of all those quantities, and conduct hypothesis tests on them.\nPredictions:\n\nThe outcome predicted by a fitted model on a specified scale for a given combination of values of the predictor variables, such as their observed values, their means, or factor levels. a.k.a. Fitted values, adjusted predictions. predictions(), avg_predictions(), plot_predictions().\n\nComparisons:\n\nCompare the predictions made by a model for different regressor values (e.g., college graduates vs. others): contrasts, differences, risk ratios, odds, etc. comparisons(), avg_comparisons(), plot_comparisons().\n\nSlopes:\n\nPartial derivative of the regression equation with respect to a regressor of interest. a.k.a. Marginal effects, trends. slopes(), avg_slopes(), plot_slopes().\n\nMarginal Means:\n\nPredictions of a model, averaged across a “reference grid” of categorical predictors. marginalmeans().\n\nHypothesis and Equivalence Tests:\n\nHypothesis and equivalence tests can be conducted on linear or non-linear functions of model coefficients, or on any of the quantities computed by the marginaleffects packages (predictions, slopes, comparisons, marginal means, etc.). Uncertainy estimates can be obtained via the delta method (with or without robust standard errors), bootstrap, or simulation.\n\nPredictions, comparisons, and slopes are fundamentally unit-level (or “conditional”) quantities. Except in the simplest linear case, estimates will typically vary based on the values of all the regressors in a model. Each of the observations in a dataset is thus associated with its own prediction, comparison, and slope estimates. Below, we will see that it can be useful to marginalize (or “average over”) unit-level estimates to report an “average prediction”, “average comparison”, or “average slope”.\nOne ambiguous aspect of the definitions above is that the word “marginal” comes up in two different and opposite ways:\n\nIn “marginal effects,” we refer to the effect of a tiny (marginal) change in the regressor on the outcome. This is a slope, or derivative.\nIn “marginal means,” we refer to the process of marginalizing across rows of a prediction grid. This is an average, or integral.\n\nOn this website and in this package, we reserve the expression “marginal effect” to mean a “slope” or “partial derivative”.\nThe marginaleffects package includes functions to estimate, average, plot, and summarize all of the estimands described above. The objects produced by marginaleffects are “tidy”: they produce simple data frames in “long” format. They are also “standards-compliant” and work seamlessly with standard functions like summary(), head(), tidy(), and glance(), as well with external packages like modelsummary or ggplot2.\nWe now apply marginaleffects functions to compute each of the quantities of interest described above. First, we fit a linear regression model with multiplicative interactions:\n\n\nR\nPython\n\n\n\n\nlibrary(marginaleffects)\n\nmod &lt;- lm(mpg ~ hp * wt * am, data = mtcars)\n\n\n\n\nimport polars as pl\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nmtcars = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\")\n\nmod = smf.ols(\"mpg ~ hp * wt * am\", data = mtcars).fit()\n\n\n\n\nThen, we call the predictions() function. As noted above, predictions are unit-level estimates, so there is one specific prediction per observation. By default, the predictions() function makes one prediction per observation in the dataset that was used to fit the original model. Since mtcars has 32 rows, the predictions() outcome also has 32 rows:\n\n\nR\nPython\n\n\n\n\npre &lt;- predictions(mod)\n\nnrow(mtcars)\n\n[1] 32\n\nnrow(pre)\n\n[1] 32\n\npre\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, wt, am \n\n\n\n\n22.5\n                  0.884\n                  25.44\n                  \n                  \n471.7\n                  20.8\n                  24.2\n                \n\n20.8\n                  1.194\n                  17.42\n                  \n                  \n223.3\n                  18.5\n                  23.1\n                \n\n25.3\n                  0.709\n                  35.66\n                  \n                  \n922.7\n                  23.9\n                  26.7\n                \n\n20.3\n                  0.704\n                  28.75\n                  \n                  \n601.5\n                  18.9\n                  21.6\n                \n\n17.0\n                  0.712\n                  23.88\n                  \n                  \n416.2\n                  15.6\n                  18.4\n                \n\n29.6\n                  1.874\n                  15.80\n                  \n                  \n184.3\n                  25.9\n                  33.3\n                \n\n15.9\n                  1.311\n                  12.13\n                  \n                  \n110.0\n                  13.3\n                  18.5\n                \n\n19.4\n                  1.145\n                  16.95\n                  \n                  \n211.6\n                  17.2\n                  21.7\n                \n\n14.8\n                  2.017\n                   7.33\n                  \n                  \n42.0 \n                  10.8\n                  18.7\n                \n\n21.5\n                  1.072\n                  20.02\n                  \n                  \n293.8\n                  19.4\n                  23.6\n                \n\n\n\n\n\n\n\n\n\npre = predictions(mod)\n\nmtcars.shape\n\n(32, 12)\n\npre.shape\n\n(32, 20)\n\nprint(pre)\n\nshape: (32, 7)\n┌──────────┬───────────┬──────┬──────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|)  ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---      ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str      ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪══════════╪═════╪══════╪═══════╡\n│ 22.5     ┆ 0.884     ┆ 25.4 ┆ 0        ┆ inf ┆ 20.8 ┆ 24.2  │\n│ 20.8     ┆ 1.19      ┆ 17.4 ┆ 0        ┆ inf ┆ 18.5 ┆ 23.1  │\n│ 25.3     ┆ 0.709     ┆ 35.7 ┆ 0        ┆ inf ┆ 23.9 ┆ 26.7  │\n│ 20.3     ┆ 0.704     ┆ 28.8 ┆ 0        ┆ inf ┆ 18.9 ┆ 21.6  │\n│ 17       ┆ 0.712     ┆ 23.9 ┆ 0        ┆ inf ┆ 15.6 ┆ 18.4  │\n│ …        ┆ …         ┆ …    ┆ …        ┆ …   ┆ …    ┆ …     │\n│ 29.6     ┆ 1.87      ┆ 15.8 ┆ 0        ┆ inf ┆ 25.9 ┆ 33.3  │\n│ 15.9     ┆ 1.31      ┆ 12.1 ┆ 0        ┆ inf ┆ 13.3 ┆ 18.5  │\n│ 19.4     ┆ 1.15      ┆ 16.9 ┆ 0        ┆ inf ┆ 17.2 ┆ 21.7  │\n│ 14.8     ┆ 2.02      ┆ 7.33 ┆ 2.29e-13 ┆ 42  ┆ 10.8 ┆ 18.7  │\n│ 21.5     ┆ 1.07      ┆ 20   ┆ 0        ┆ inf ┆ 19.4 ┆ 23.6  │\n└──────────┴───────────┴──────┴──────────┴─────┴──────┴───────┘\n\nColumns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nNow, we use the comparisons() function to compute the difference in predicted outcome when each of the predictors is incremented by 1 unit (one predictor at a time, holding all others constant). Once again, comparisons are unit-level quantities. And since there are 3 predictors in the model and our data has 32 rows, we obtain 96 comparisons:\n\n\nR\nPython\n\n\n\n\ncmp &lt;- comparisons(mod)\n\nnrow(cmp)\n\n[1] 96\n\ncmp\n\n\n\n    \n\n      \n\nTerm\n                Contrast\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\nam\n                  1 - 0\n                   0.325\n                  1.68\n                   0.193\n                  0.8467\n                  0.2 \n                   -2.97\n                   3.622\n                \n\nam\n                  1 - 0\n                  -0.544\n                  1.57\n                  -0.347\n                  0.7287\n                  0.5 \n                   -3.62\n                   2.530\n                \n\nam\n                  1 - 0\n                   1.201\n                  2.35\n                   0.511\n                  0.6090\n                  0.7 \n                   -3.40\n                   5.802\n                \n\nam\n                  1 - 0\n                  -1.703\n                  1.87\n                  -0.912\n                  0.3618\n                  1.5 \n                   -5.36\n                   1.957\n                \n\nam\n                  1 - 0\n                  -0.615\n                  1.68\n                  -0.366\n                  0.7146\n                  0.5 \n                   -3.91\n                   2.680\n                \n\nwt\n                  +1   \n                  -6.518\n                  1.88\n                  -3.462\n                  \n                  \n10.9\n                  -10.21\n                  -2.828\n                \n\nwt\n                  +1   \n                  -1.653\n                  3.74\n                  -0.442\n                  0.6588\n                  0.6 \n                   -8.99\n                   5.683\n                \n\nwt\n                  +1   \n                  -4.520\n                  2.47\n                  -1.830\n                  0.0672\n                  3.9 \n                   -9.36\n                   0.321\n                \n\nwt\n                  +1   \n                   0.635\n                  4.89\n                   0.130\n                  0.8966\n                  0.2 \n                   -8.95\n                  10.216\n                \n\nwt\n                  +1   \n                  -6.647\n                  1.86\n                  -3.572\n                  \n                  \n11.5\n                  -10.29\n                  -2.999\n                \n\n\n\n\n\n\n\n\n\ncmp = comparisons(mod)\n\ncmp.shape\n\n(96, 25)\n\nprint(cmp)\n\nshape: (96, 9)\n┌──────┬──────────────┬──────────┬───────────┬───┬──────────┬───────┬───────┬───────┐\n│ Term ┆ Contrast     ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---          ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---   ┆ ---   ┆ ---   │\n│ str  ┆ str          ┆ str      ┆ str       ┆   ┆ str      ┆ str   ┆ str   ┆ str   │\n╞══════╪══════════════╪══════════╪═══════════╪═══╪══════════╪═══════╪═══════╪═══════╡\n│ am   ┆ True - False ┆ 0.325    ┆ 1.68      ┆ … ┆ 0.847    ┆ 0.24  ┆ -2.97 ┆ 3.62  │\n│ am   ┆ True - False ┆ -0.544   ┆ 1.57      ┆ … ┆ 0.729    ┆ 0.457 ┆ -3.62 ┆ 2.53  │\n│ am   ┆ True - False ┆ 1.2      ┆ 2.35      ┆ … ┆ 0.609    ┆ 0.715 ┆ -3.4  ┆ 5.8   │\n│ am   ┆ True - False ┆ -1.7     ┆ 1.87      ┆ … ┆ 0.362    ┆ 1.47  ┆ -5.36 ┆ 1.96  │\n│ am   ┆ True - False ┆ -0.615   ┆ 1.68      ┆ … ┆ 0.715    ┆ 0.485 ┆ -3.91 ┆ 2.68  │\n│ …    ┆ …            ┆ …        ┆ …         ┆ … ┆ …        ┆ …     ┆ …     ┆ …     │\n│ wt   ┆ +1           ┆ -6.52    ┆ 1.88      ┆ … ┆ 0.000537 ┆ 10.9  ┆ -10.2 ┆ -2.83 │\n│ wt   ┆ +1           ┆ -1.65    ┆ 3.74      ┆ … ┆ 0.659    ┆ 0.602 ┆ -8.99 ┆ 5.68  │\n│ wt   ┆ +1           ┆ -4.52    ┆ 2.47      ┆ … ┆ 0.0672   ┆ 3.89  ┆ -9.36 ┆ 0.321 │\n│ wt   ┆ +1           ┆ 0.635    ┆ 4.89      ┆ … ┆ 0.897    ┆ 0.157 ┆ -8.95 ┆ 10.2  │\n│ wt   ┆ +1           ┆ -6.65    ┆ 1.86      ┆ … ┆ 0.000355 ┆ 11.5  ┆ -10.3 ┆ -3    │\n└──────┴──────────────┴──────────┴───────────┴───┴──────────┴───────┴───────┴───────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nThe comparisons() function allows customized queries. For example, what happens to the predicted outcome when the hp variable increases from 100 to 120?\n\n\nR\nPython\n\n\n\n\ncomparisons(mod, variables = list(hp = c(120, 100)))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\n-0.738\n                  0.370\n                  -1.995\n                  0.04607\n                  4.4\n                  -1.463\n                  -0.0129\n                \n\n-0.574\n                  0.313\n                  -1.836\n                  0.06640\n                  3.9\n                  -1.186\n                   0.0388\n                \n\n-0.931\n                  0.452\n                  -2.062\n                  0.03922\n                  4.7\n                  -1.817\n                  -0.0460\n                \n\n-0.845\n                  0.266\n                  -3.182\n                  0.00146\n                  9.4\n                  -1.366\n                  -0.3248\n                \n\n-0.780\n                  0.268\n                  -2.909\n                  0.00362\n                  8.1\n                  -1.306\n                  -0.2547\n                \n\n-1.451\n                  0.705\n                  -2.058\n                  0.03958\n                  4.7\n                  -2.834\n                  -0.0692\n                \n\n-0.384\n                  0.270\n                  -1.422\n                  0.15498\n                  2.7\n                  -0.912\n                   0.1451\n                \n\n-0.641\n                  0.334\n                  -1.918\n                  0.05513\n                  4.2\n                  -1.297\n                   0.0141\n                \n\n-0.126\n                  0.272\n                  -0.463\n                  0.64360\n                  0.6\n                  -0.659\n                   0.4075\n                \n\n-0.635\n                  0.332\n                  -1.911\n                  0.05598\n                  4.2\n                  -1.286\n                   0.0162\n                \n\n\n\n\n\n\n\n\n\ncmp = comparisons(mod, variables = {\"hp\": [120, 100]})\nprint(cmp)\n\nshape: (32, 9)\n┌──────┬───────────┬──────────┬───────────┬───┬─────────┬───────┬─────────┬───────┐\n│ Term ┆ Contrast  ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%    ┆ 97.5% │\n│ ---  ┆ ---       ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---   ┆ ---     ┆ ---   │\n│ str  ┆ str       ┆ str      ┆ str       ┆   ┆ str     ┆ str   ┆ str     ┆ str   │\n╞══════╪═══════════╪══════════╪═══════════╪═══╪═════════╪═══════╪═════════╪═══════╡\n│ hp   ┆ 100 - 120 ┆ 0.738    ┆ 0.37      ┆ … ┆ 0.0461  ┆ 4.44  ┆ 0.0129  ┆ 1.46  │\n│ hp   ┆ 100 - 120 ┆ 0.574    ┆ 0.313     ┆ … ┆ 0.0664  ┆ 3.91  ┆ -0.0388 ┆ 1.19  │\n│ hp   ┆ 100 - 120 ┆ 0.931    ┆ 0.452     ┆ … ┆ 0.0392  ┆ 4.67  ┆ 0.046   ┆ 1.82  │\n│ hp   ┆ 100 - 120 ┆ 0.845    ┆ 0.266     ┆ … ┆ 0.00146 ┆ 9.42  ┆ 0.325   ┆ 1.37  │\n│ hp   ┆ 100 - 120 ┆ 0.78     ┆ 0.268     ┆ … ┆ 0.00362 ┆ 8.11  ┆ 0.255   ┆ 1.31  │\n│ …    ┆ …         ┆ …        ┆ …         ┆ … ┆ …       ┆ …     ┆ …       ┆ …     │\n│ hp   ┆ 100 - 120 ┆ 1.45     ┆ 0.705     ┆ … ┆ 0.0396  ┆ 4.66  ┆ 0.0692  ┆ 2.83  │\n│ hp   ┆ 100 - 120 ┆ 0.384    ┆ 0.27      ┆ … ┆ 0.155   ┆ 2.69  ┆ -0.145  ┆ 0.912 │\n│ hp   ┆ 100 - 120 ┆ 0.641    ┆ 0.334     ┆ … ┆ 0.0551  ┆ 4.18  ┆ -0.0141 ┆ 1.3   │\n│ hp   ┆ 100 - 120 ┆ 0.126    ┆ 0.272     ┆ … ┆ 0.644   ┆ 0.636 ┆ -0.408  ┆ 0.659 │\n│ hp   ┆ 100 - 120 ┆ 0.635    ┆ 0.332     ┆ … ┆ 0.056   ┆ 4.16  ┆ -0.0162 ┆ 1.29  │\n└──────┴───────────┴──────────┴───────────┴───┴─────────┴───────┴─────────┴───────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nWhat happens to the predicted outcome when the hp variable increases by 1 standard deviation about its mean?\n\n\nR\nPython\n\n\n\n\ncomparisons(mod, variables = list(hp = \"sd\"))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\n-2.530\n                  1.269\n                  -1.995\n                  0.04607\n                  4.4\n                  -5.02\n                  -0.0441\n                \n\n-1.967\n                  1.072\n                  -1.836\n                  0.06640\n                  3.9\n                  -4.07\n                   0.1332\n                \n\n-3.193\n                  1.549\n                  -2.062\n                  0.03922\n                  4.7\n                  -6.23\n                  -0.1578\n                \n\n-2.898\n                  0.911\n                  -3.182\n                  0.00146\n                  9.4\n                  -4.68\n                  -1.1133\n                \n\n-2.675\n                  0.919\n                  -2.909\n                  0.00362\n                  8.1\n                  -4.48\n                  -0.8731\n                \n\n-4.976\n                  2.418\n                  -2.058\n                  0.03958\n                  4.7\n                  -9.71\n                  -0.2373\n                \n\n-1.315\n                  0.925\n                  -1.422\n                  0.15498\n                  2.7\n                  -3.13\n                   0.4974\n                \n\n-2.199\n                  1.147\n                  -1.918\n                  0.05513\n                  4.2\n                  -4.45\n                   0.0483\n                \n\n-0.432\n                  0.933\n                  -0.463\n                  0.64360\n                  0.6\n                  -2.26\n                   1.3970\n                \n\n-2.177\n                  1.139\n                  -1.911\n                  0.05598\n                  4.2\n                  -4.41\n                   0.0556\n                \n\n\n\n\n\n\n\n\n\ncmp = comparisons(mod, variables = {\"hp\": \"sd\"})\nprint(cmp)\n\nshape: (32, 9)\n┌──────┬─────────────────────┬──────────┬───────────┬───┬─────────┬───────┬───────┬─────────┐\n│ Term ┆ Contrast            ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%  ┆ 97.5%   │\n│ ---  ┆ ---                 ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---   ┆ ---   ┆ ---     │\n│ str  ┆ str                 ┆ str      ┆ str       ┆   ┆ str     ┆ str   ┆ str   ┆ str     │\n╞══════╪═════════════════════╪══════════╪═══════════╪═══╪═════════╪═══════╪═══════╪═════════╡\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.53    ┆ 1.27      ┆ … ┆ 0.0461  ┆ 4.44  ┆ -5.02 ┆ -0.0441 │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -1.97    ┆ 1.07      ┆ … ┆ 0.0664  ┆ 3.91  ┆ -4.07 ┆ 0.133   │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -3.19    ┆ 1.55      ┆ … ┆ 0.0392  ┆ 4.67  ┆ -6.23 ┆ -0.158  │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.9     ┆ 0.911     ┆ … ┆ 0.00146 ┆ 9.42  ┆ -4.68 ┆ -1.11   │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.68    ┆ 0.919     ┆ … ┆ 0.00362 ┆ 8.11  ┆ -4.48 ┆ -0.873  │\n│ …    ┆ …                   ┆ …        ┆ …         ┆ … ┆ …       ┆ …     ┆ …     ┆ …       │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -4.98    ┆ 2.42      ┆ … ┆ 0.0396  ┆ 4.66  ┆ -9.71 ┆ -0.237  │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -1.32    ┆ 0.925     ┆ … ┆ 0.155   ┆ 2.69  ┆ -3.13 ┆ 0.497   │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.2     ┆ 1.15      ┆ … ┆ 0.0551  ┆ 4.18  ┆ -4.45 ┆ 0.0483  │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -0.432   ┆ 0.933     ┆ … ┆ 0.644   ┆ 0.636 ┆ -2.26 ┆ 1.4     │\n│ hp   ┆ (x+sd/2) - (x-sd/2) ┆ -2.18    ┆ 1.14      ┆ … ┆ 0.056   ┆ 4.16  ┆ -4.41 ┆ 0.0556  │\n└──────┴─────────────────────┴──────────┴───────────┴───┴─────────┴───────┴───────┴─────────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nThe comparisons() function also allows users to specify arbitrary functions of predictions, with the comparison argument. For example, what is the average ratio between predicted Miles per Gallon after an increase of 50 units in Horsepower?\n\n\nR\nPython\n\n\n\n\ncomparisons(\n  mod,\n  variables = list(hp = 50),\n  comparison = \"ratioavg\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n0.905\n                  0.0319\n                  28.4\n                  \n                  \n586.8\n                  0.843\n                  0.968\n                \n\n\n\n\n\n\n\n\ncmp = comparisons(\n  mod,\n  variables = {\"hp\": 50},\n  comparison = \"ratioavg\")\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────┬──────────┬───────────┬───┬─────────┬─────┬───────┬───────┐\n│ Term ┆ Contrast ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S   ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---      ┆ ---      ┆ ---       ┆   ┆ ---     ┆ --- ┆ ---   ┆ ---   │\n│ str  ┆ str      ┆ str      ┆ str       ┆   ┆ str     ┆ str ┆ str   ┆ str   │\n╞══════╪══════════╪══════════╪═══════════╪═══╪═════════╪═════╪═══════╪═══════╡\n│ hp   ┆ +50      ┆ 0.91     ┆ 0.0291    ┆ … ┆ 0       ┆ inf ┆ 0.853 ┆ 0.966 │\n└──────┴──────────┴──────────┴───────────┴───┴─────────┴─────┴───────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nSee the Comparisons vignette for detailed explanations and more options.\nThe slopes() function allows us to compute the partial derivative of the outcome equation with respect to each of the predictors. Once again, we obtain a data frame with 96 rows:\n\n\nR\nPython\n\n\n\n\nmfx &lt;- slopes(mod)\n\nnrow(mfx)\n\n[1] 96\n\nmfx\n\n\n\n    \n\n      \n\nTerm\n                Contrast\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, hp, wt, am \n\n\n\n\nam\n                  1 - 0\n                   0.325\n                  1.68\n                   0.193\n                  0.8467\n                  0.2 \n                   -2.97\n                   3.622\n                \n\nam\n                  1 - 0\n                  -0.544\n                  1.57\n                  -0.347\n                  0.7287\n                  0.5 \n                   -3.62\n                   2.530\n                \n\nam\n                  1 - 0\n                   1.201\n                  2.35\n                   0.511\n                  0.6090\n                  0.7 \n                   -3.40\n                   5.802\n                \n\nam\n                  1 - 0\n                  -1.703\n                  1.87\n                  -0.912\n                  0.3618\n                  1.5 \n                   -5.36\n                   1.957\n                \n\nam\n                  1 - 0\n                  -0.615\n                  1.68\n                  -0.366\n                  0.7146\n                  0.5 \n                   -3.91\n                   2.680\n                \n\nwt\n                  dY/dX\n                  -6.518\n                  1.88\n                  -3.462\n                  \n                  \n10.9\n                  -10.21\n                  -2.828\n                \n\nwt\n                  dY/dX\n                  -1.653\n                  3.74\n                  -0.442\n                  0.6588\n                  0.6 \n                   -8.99\n                   5.683\n                \n\nwt\n                  dY/dX\n                  -4.520\n                  2.47\n                  -1.830\n                  0.0673\n                  3.9 \n                   -9.36\n                   0.321\n                \n\nwt\n                  dY/dX\n                   0.635\n                  4.89\n                   0.130\n                  0.8966\n                  0.2 \n                   -8.95\n                  10.216\n                \n\nwt\n                  dY/dX\n                  -6.647\n                  1.86\n                  -3.572\n                  \n                  \n11.5\n                  -10.29\n                  -2.999\n                \n\n\n\n\n\n\n\n\n\nmfx = slopes(mod)\n\nmfx.shape\n\n(96, 25)\n\nprint(mfx)\n\nshape: (96, 9)\n┌──────┬──────────────┬──────────┬───────────┬───┬──────────┬───────┬───────┬───────┐\n│ Term ┆ Contrast     ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---          ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---   ┆ ---   ┆ ---   │\n│ str  ┆ str          ┆ str      ┆ str       ┆   ┆ str      ┆ str   ┆ str   ┆ str   │\n╞══════╪══════════════╪══════════╪═══════════╪═══╪══════════╪═══════╪═══════╪═══════╡\n│ am   ┆ True - False ┆ 0.325    ┆ 1.68      ┆ … ┆ 0.847    ┆ 0.24  ┆ -2.97 ┆ 3.62  │\n│ am   ┆ True - False ┆ -0.544   ┆ 1.57      ┆ … ┆ 0.729    ┆ 0.457 ┆ -3.62 ┆ 2.53  │\n│ am   ┆ True - False ┆ 1.2      ┆ 2.35      ┆ … ┆ 0.609    ┆ 0.715 ┆ -3.4  ┆ 5.8   │\n│ am   ┆ True - False ┆ -1.7     ┆ 1.87      ┆ … ┆ 0.362    ┆ 1.47  ┆ -5.36 ┆ 1.96  │\n│ am   ┆ True - False ┆ -0.615   ┆ 1.68      ┆ … ┆ 0.715    ┆ 0.485 ┆ -3.91 ┆ 2.68  │\n│ …    ┆ …            ┆ …        ┆ …         ┆ … ┆ …        ┆ …     ┆ …     ┆ …     │\n│ wt   ┆ dY/dX        ┆ -6.52    ┆ 1.88      ┆ … ┆ 0.000532 ┆ 10.9  ┆ -10.2 ┆ -2.83 │\n│ wt   ┆ dY/dX        ┆ -1.65    ┆ 3.74      ┆ … ┆ 0.659    ┆ 0.602 ┆ -8.98 ┆ 5.68  │\n│ wt   ┆ dY/dX        ┆ -4.52    ┆ 2.47      ┆ … ┆ 0.0675   ┆ 3.89  ┆ -9.37 ┆ 0.325 │\n│ wt   ┆ dY/dX        ┆ 0.635    ┆ 4.89      ┆ … ┆ 0.897    ┆ 0.157 ┆ -8.95 ┆ 10.2  │\n│ wt   ┆ dY/dX        ┆ -6.65    ┆ 1.86      ┆ … ┆ 0.000349 ┆ 11.5  ┆ -10.3 ┆ -3    │\n└──────┴──────────────┴──────────┴───────────┴───┴──────────┴───────┴───────┴───────┘\n\nColumns: rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/get_started.html#grid",
    "href": "vignettes/get_started.html#grid",
    "title": "Get started",
    "section": "",
    "text": "Predictions, comparisons, and slopes are typically “conditional” quantities which depend on the values of all the predictors in the model. By default, marginaleffects functions estimate quantities of interest for the empirical distribution of the data (i.e., for each row of the original dataset). However, users can specify the exact values of the predictors they want to investigate by using the newdata argument.\nnewdata accepts data frames, shortcut strings, or a call to the datagrid() function. For example, to compute the predicted outcome for a hypothetical car with all predictors equal to the sample mean or median, we can do:\n\n\nR\nPython\n\n\n\n\npredictions(mod, newdata = \"mean\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n                wt\n                am\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, wt, am, mpg \n\n\n\n18.7\n                  0.649\n                  28.8\n                  \n                  \n603.8\n                  17.4\n                  20\n                  147\n                  3.22\n                  0\n                \n\n\n\n\npredictions(mod, newdata = \"median\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n                wt\n                am\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, wt, am, mpg \n\n\n\n19.4\n                  0.646\n                  30\n                  \n                  \n653.2\n                  18.1\n                  20.6\n                  123\n                  3.33\n                  0\n                \n\n\n\n\n\n\n\n\np = predictions(mod, newdata = \"mean\")\nprint(p)\n\nshape: (1, 7)\n┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n│ 20.2     ┆ 0.704     ┆ 28.8 ┆ 0       ┆ inf ┆ 18.9 ┆ 21.6  │\n└──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n\nColumns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\np = predictions(mod, newdata = \"median\")\nprint(p)\n\nshape: (1, 7)\n┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n│ 17.3     ┆ 0.766     ┆ 22.5 ┆ 0       ┆ inf ┆ 15.8 ┆ 18.8  │\n└──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n\nColumns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\n\nThe datagrid function gives us a powerful way to define a grid of predictors. All the variables not mentioned explicitly in datagrid() are fixed to their mean or mode:\n\n\nR\nPython\n\n\n\n\npredictions(\n  mod,\n  newdata = datagrid(\n    am = c(0, 1),\n    wt = range))\n\n\n\n    \n\n      \n\nam\n                wt\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                hp\n              \n\nType:  response \n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, am, wt, mpg \n\n\n\n\n0\n                  1.51\n                  23.3\n                  2.71\n                  8.60\n                  \n                  \n56.7\n                  17.96\n                  28.6\n                  147\n                \n\n0\n                  5.42\n                  12.8\n                  2.98\n                  4.30\n                  \n                  \n15.8\n                   6.96\n                  18.6\n                  147\n                \n\n1\n                  1.51\n                  27.1\n                  2.85\n                  9.52\n                  \n                  \n69.0\n                  21.56\n                  32.7\n                  147\n                \n\n1\n                  5.42\n                   5.9\n                  5.81\n                  1.01\n                  0.31  \n                  1.7 \n                  -5.50\n                  17.3\n                  147\n                \n\n\n\n\n\n\n\n\n\np = predictions(\n  mod,\n  newdata = datagrid(\n    am = [0, 1],\n    wt = [mtcars[\"wt\"].min(), mtcars[\"wt\"].max()]))\nprint(p)\n\nshape: (4, 9)\n┌─────┬──────┬──────────┬───────────┬───┬──────────┬──────┬───────┬───────┐\n│ am  ┆ wt   ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ --- ┆ ---  ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---   ┆ ---   │\n│ str ┆ str  ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str   ┆ str   │\n╞═════╪══════╪══════════╪═══════════╪═══╪══════════╪══════╪═══════╪═══════╡\n│ 0   ┆ 1.51 ┆ 21.4     ┆ 2.41      ┆ … ┆ 0        ┆ inf  ┆ 16.7  ┆ 26.1  │\n│ 0   ┆ 5.42 ┆ 12.5     ┆ 1.96      ┆ … ┆ 1.75e-10 ┆ 32.4 ┆ 8.66  ┆ 16.3  │\n│ 1   ┆ 1.51 ┆ 25.1     ┆ 3.77      ┆ … ┆ 2.76e-11 ┆ 35.1 ┆ 17.7  ┆ 32.5  │\n│ 1   ┆ 5.42 ┆ 7.41     ┆ 6.12      ┆ … ┆ 0.225    ┆ 2.15 ┆ -4.57 ┆ 19.4  │\n└─────┴──────┴──────────┴───────────┴───┴──────────┴──────┴───────┴───────┘\n\nColumns: am, wt, rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, qsec, vs, gear, carb\n\n\n\n\n\nThe same mechanism is available in comparisons() and slopes(). To estimate the partial derivative of mpg with respect to wt, when am is equal to 0 and 1, while other predictors are held at their means:\n\n\nR\nPython\n\n\n\n\nslopes(\n  mod,\n  variables = \"wt\",\n  newdata = datagrid(am = 0:1))\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, predicted_lo, predicted_hi, predicted, hp, wt, mpg \n\n\n\n\n0\n                  -2.68\n                  1.42\n                  -1.89\n                  0.0594\n                  4.1\n                  -5.46\n                   0.106\n                \n\n1\n                  -5.43\n                  2.15\n                  -2.52\n                  0.0116\n                  6.4\n                  -9.65\n                  -1.213\n                \n\n\n\n\n\n\n\n\n\ns = slopes(\n  mod,\n  variables = \"wt\",\n  newdata = datagrid(mod, am = [0, 1]))\nprint(s)\n\nshape: (2, 10)\n┌─────┬──────┬──────────┬──────────┬───┬─────────┬──────┬───────┬────────┐\n│ am  ┆ Term ┆ Contrast ┆ Estimate ┆ … ┆ P(&gt;|z|) ┆ S    ┆ 2.5%  ┆ 97.5%  │\n│ --- ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---     ┆ ---  ┆ ---   ┆ ---    │\n│ str ┆ str  ┆ str      ┆ str      ┆   ┆ str     ┆ str  ┆ str   ┆ str    │\n╞═════╪══════╪══════════╪══════════╪═══╪═════════╪══════╪═══════╪════════╡\n│ 0   ┆ wt   ┆ dY/dX    ┆ -2.27    ┆ … ┆ 0.033   ┆ 4.92 ┆ -4.35 ┆ -0.183 │\n│ 1   ┆ wt   ┆ dY/dX    ┆ -4.52    ┆ … ┆ 0.0668  ┆ 3.9  ┆ -9.35 ┆ 0.314  │\n└─────┴──────┴──────────┴──────────┴───┴─────────┴──────┴───────┴────────┘\n\nColumns: am, rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, gear, carb\n\n\n\n\n\nWe can also plot how predictions, comparisons, or slopes change across different values of the predictors using three powerful plotting functions:\n\n\nplot_predictions: Conditional Adjusted Predictions\n\nplot_comparisons: Conditional Comparisons\n\nplot_slopes: Conditional Marginal Effects\n\nFor example, this plot shows the outcomes predicted by our model for different values of the wt and am variables:\n\n\nR\nPython\n\n\n\n\nplot_predictions(mod, condition = list(\"hp\", \"wt\" = \"threenum\", \"am\"))\n\n\n\n\n\n\n\n\n\n\ncond = {\n  \"hp\": None,\n  \"wt\": [mtcars[\"wt\"].mean() - mtcars[\"wt\"].std(),\n         mtcars[\"wt\"].mean(),\n         mtcars[\"wt\"].mean() + mtcars[\"wt\"].std()],\n  \"am\": None\n}\nplot_predictions(mod, condition = cond)\n\n&lt;string&gt;:1: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\n\nThis plot shows how the derivative of mpg with respect to am varies as a function of wt and hp:\n\n\nR\nPython\n\n\n\n\nplot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"wt\" = \"minmax\"))\n\n\n\n\n\n\n\n\n\n\nplot_slopes(mod,\n  variables = \"am\",\n  condition = {\"hp\": None, \"wt\": [mtcars[\"wt\"].min(), mtcars[\"wt\"].max()]}\n)\n\n&lt;string&gt;:1: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\n\nSee this vignette for more information: Plots, interactions, predictions, contrasts, and slopes",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/get_started.html#aggregation",
    "href": "vignettes/get_started.html#aggregation",
    "title": "Get started",
    "section": "",
    "text": "Since predictions, comparisons, and slopes are conditional quantities, they can be a bit unwieldy. Often, it can be useful to report a one-number summary instead of one estimate per observation. Instead of presenting “conditional” estimates, some methodologists recommend reporting “marginal” estimates, that is, an average of unit-level estimates.\n(This use of the word “marginal” as “averaging” should not be confused with the term “marginal effect” which, in the econometrics tradition, corresponds to a partial derivative, or the effect of a “small/marginal” change.)\nTo marginalize (average over) our unit-level estimates, we can use the by argument or the one of the convenience functions: avg_predictions(), avg_comparisons(), or avg_slopes(). For example, both of these commands give us the same result: the average predicted outcome in the mtcars dataset:\n\n\nR\nPython\n\n\n\n\navg_predictions(mod)\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n20.1\n                  0.39\n                  51.5\n                  \n                  \nInf\n                  19.3\n                  20.9\n                \n\n\n\n\n\n\n\n\np = avg_predictions(mod)\nprint(p)\n\nshape: (1, 7)\n┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n│ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n│ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n│ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n│ 20.1     ┆ 0.39      ┆ 51.5 ┆ 0       ┆ inf ┆ 19.3 ┆ 20.9  │\n└──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n\nColumns: estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nThis is equivalent to manual computation by:\n\n\nR\nPython\n\n\n\n\nmean(predict(mod))\n\n[1] 20.09062\n\n\n\n\n\nnp.mean(mod.predict())\n\n20.090625000000024\n\n\n\n\n\nThe main marginaleffects functions all include a by argument, which allows us to marginalize within sub-groups of the data. For example,\n\n\nR\nPython\n\n\n\n\navg_comparisons(mod, by = \"am\")\n\n\n\n    \n\n      \n\nTerm\n                Contrast\n                am\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nam\n                  mean(1) - mean(0)\n                  0\n                  -1.3830\n                  2.5250\n                  -0.548\n                  0.58388\n                  0.8\n                  -6.3319\n                   3.56589\n                \n\nam\n                  mean(1) - mean(0)\n                  1\n                   1.9029\n                  2.3086\n                   0.824\n                  0.40980\n                  1.3\n                  -2.6219\n                   6.42773\n                \n\nhp\n                  mean(+1)         \n                  0\n                  -0.0343\n                  0.0159\n                  -2.160\n                  0.03079\n                  5.0\n                  -0.0654\n                  -0.00317\n                \n\nhp\n                  mean(+1)         \n                  1\n                  -0.0436\n                  0.0213\n                  -2.050\n                  0.04039\n                  4.6\n                  -0.0854\n                  -0.00191\n                \n\nwt\n                  mean(+1)         \n                  0\n                  -2.4799\n                  1.2316\n                  -2.014\n                  0.04406\n                  4.5\n                  -4.8939\n                  -0.06595\n                \n\nwt\n                  mean(+1)         \n                  1\n                  -6.0718\n                  1.9762\n                  -3.072\n                  0.00212\n                  8.9\n                  -9.9451\n                  -2.19846\n                \n\n\n\n\n\n\n\n\n\ncmp = avg_comparisons(mod, by = \"am\")\nprint(cmp)\n\nshape: (6, 10)\n┌─────┬──────┬──────────────────────────┬──────────┬───┬─────────┬───────┬─────────┬──────────┐\n│ am  ┆ Term ┆ Contrast                 ┆ Estimate ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%    ┆ 97.5%    │\n│ --- ┆ ---  ┆ ---                      ┆ ---      ┆   ┆ ---     ┆ ---   ┆ ---     ┆ ---      │\n│ str ┆ str  ┆ str                      ┆ str      ┆   ┆ str     ┆ str   ┆ str     ┆ str      │\n╞═════╪══════╪══════════════════════════╪══════════╪═══╪═════════╪═══════╪═════════╪══════════╡\n│ 0   ┆ am   ┆ mean(True) - mean(False) ┆ -1.38    ┆ … ┆ 0.584   ┆ 0.776 ┆ -6.33   ┆ 3.57     │\n│ 1   ┆ am   ┆ mean(True) - mean(False) ┆ 1.9      ┆ … ┆ 0.41    ┆ 1.29  ┆ -2.62   ┆ 6.43     │\n│ 0   ┆ hp   ┆ +1                       ┆ -0.0343  ┆ … ┆ 0.0308  ┆ 5.02  ┆ -0.0654 ┆ -0.00317 │\n│ 1   ┆ hp   ┆ +1                       ┆ -0.0436  ┆ … ┆ 0.0404  ┆ 4.63  ┆ -0.0854 ┆ -0.00191 │\n│ 0   ┆ wt   ┆ +1                       ┆ -2.48    ┆ … ┆ 0.0441  ┆ 4.5   ┆ -4.89   ┆ -0.066   │\n│ 1   ┆ wt   ┆ +1                       ┆ -6.07    ┆ … ┆ 0.00212 ┆ 8.88  ┆ -9.95   ┆ -2.2     │\n└─────┴──────┴──────────────────────────┴──────────┴───┴─────────┴───────┴─────────┴──────────┘\n\nColumns: am, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nMarginal Means are a special case of predictions, which are marginalized (or averaged) across a balanced grid of categorical predictors. To illustrate, we estimate a new model with categorical predictors:\n\n\nR\nPython\n\n\n\n\ndat &lt;- mtcars\ndat$am &lt;- as.logical(dat$am)\ndat$cyl &lt;- as.factor(dat$cyl)\nmod_cat &lt;- lm(mpg ~ am + cyl + hp, data = dat)\n\n\n\n\ndat = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\") \\\n  .with_columns(pl.col(\"am\").cast(pl.Boolean),\n                pl.col(\"cyl\").cast(pl.Utf8))\nmod_cat = smf.ols('mpg ~ am + cyl + hp', data=dat.to_pandas()).fit()\n\n\n\n\nWe can compute marginal means manually using the functions already described:\n\n\nR\nPython\n\n\n\n\navg_predictions(\n  mod_cat,\n  newdata = \"balanced\",\n  by = \"am\")\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n TRUE\n                  22.5\n                  0.834\n                  26.9\n                  \n                  \n528.6\n                  20.8\n                  24.1\n                \n\nFALSE\n                  18.3\n                  0.785\n                  23.3\n                  \n                  \n397.4\n                  16.8\n                  19.9\n                \n\n\n\n\n\n\n\n\n\npredictions(\n  mod_cat,\n  newdata = datagrid(grid_type = \"balanced\"),\n  by = \"am\")\nprint(p)\n\n\n\n\nThe Marginal Means vignette offers more detail.",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/get_started.html#uncertainty",
    "href": "vignettes/get_started.html#uncertainty",
    "title": "Get started",
    "section": "",
    "text": "The marginaleffects package reports uncertainty estimates for all the quantities it computes: predictions, comparisons, slopes, etc. By default, standard errors are computed using the delta method and classical standard errors. These standard errors are fast to compute, and have appealing properties in some, but not all cases. marginaleffects supports several alternatives, including: Huber-White Heteroskedasticity Robust, Cluster-Robust, Bootstrap, and Simulation-based uncertainty estimates.\nThe Standard Errors vignette offers more detail. For now, it suffices to show two examples. First, we use the vcov argument to report “HC3” (heteroskedasticity-consistent) standard errors.\n\n\nR\nPython\n\n\n\n\navg_predictions(mod, by = \"am\", vcov = \"HC3\")\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n1\n                  24.4\n                  0.782\n                  31.2\n                  \n                  \n707.3\n                  22.9\n                  25.9\n                \n\n0\n                  17.1\n                  0.614\n                  27.9\n                  \n                  \n568.5\n                  15.9\n                  18.3\n                \n\n\n\n\n\n\n\n\nNot supported yet.\n\n\n\nSecond, we use the inferences() function to compute bootstrap intervals using 500 resamples:\n\n\nR\nPython\n\n\n\n\navg_predictions(mod, by = \"am\") |&gt;\n  inferences(method = \"boot\", R = 500)\n\n\n\n    \n\n      \n\nam\n                Estimate\n                Std. Error\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: am, estimate, std.error, conf.low, conf.high \n\n\n\n\n1\n                  24.4\n                  4.854\n                  21.3\n                  26.5\n                \n\n0\n                  17.1\n                  0.607\n                  16.3\n                  19.1\n                \n\n\n\n\n\n\n\n\nNot supported yet.",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/get_started.html#tests",
    "href": "vignettes/get_started.html#tests",
    "title": "Get started",
    "section": "",
    "text": "The hypotheses() function and the hypothesis argument can be used to conduct linear and non-linear hypothesis tests on model coefficients, or on any of the quantities computed by the functions introduced above.\nConsider this model:\n\n\nR\nPython\n\n\n\n\nmod &lt;- lm(mpg ~ qsec * drat, data = mtcars)\ncoef(mod)\n\n(Intercept)        qsec        drat   qsec:drat \n 12.3371987  -1.0241183  -3.4371461   0.5973153 \n\n\n\n\n\nmod = smf.ols('mpg ~ qsec * drat', data=mtcars).fit()\nprint(mod.params)\n\nIntercept    12.337199\nqsec         -1.024118\ndrat         -3.437146\nqsec:drat     0.597315\ndtype: float64\n\n\n\n\n\nCan we reject the null hypothesis that the drat coefficient is 2 times the size of the qsec coefficient?\n\nhypotheses(mod, \"drat = 2 * qsec\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-1.39\n                  10.8\n                  -0.129\n                  0.897\n                  0.2\n                  -22.5\n                  19.7\n                \n\n\n\n\n\nWe can ask the same question but refer to parameters by position, with indices b1, b2, b3, etc.:\n\n\nR\nPython\n\n\n\n\nhypotheses(mod, \"b3 = 2 * b2\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n-1.39\n                  10.8\n                  -0.129\n                  0.897\n                  0.2\n                  -22.5\n                  19.7\n                \n\n\n\n\n\n\n\n\nh = hypotheses(mod, \"b3 = 2 * b2\")\nprint(h)\n\nshape: (1, 8)\n┌─────────┬──────────┬───────────┬────────┬─────────┬───────┬───────┬───────┐\n│ Term    ┆ Estimate ┆ Std.Error ┆ z      ┆ P(&gt;|z|) ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---     ┆ ---      ┆ ---       ┆ ---    ┆ ---     ┆ ---   ┆ ---   ┆ ---   │\n│ str     ┆ str      ┆ str       ┆ str    ┆ str     ┆ str   ┆ str   ┆ str   │\n╞═════════╪══════════╪═══════════╪════════╪═════════╪═══════╪═══════╪═══════╡\n│ b3=2*b2 ┆ -1.39    ┆ 10.8      ┆ -0.129 ┆ 0.897   ┆ 0.156 ┆ -22.5 ┆ 19.7  │\n└─────────┴──────────┴───────────┴────────┴─────────┴───────┴───────┴───────┘\n\nColumns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nThe main functions in marginaleffects all have a hypothesis argument, which means that we can do complex model testing. For example, consider two slope estimates:\n\n\nR\nPython\n\n\n\n\nslopes(\n  mod,\n  variables = \"drat\",\n  newdata = datagrid(qsec = range))\n\n\n\n    \n\n      \n\nqsec\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, qsec, predicted_lo, predicted_hi, predicted, drat, mpg \n\n\n\n\n14.5\n                   5.22\n                  3.79\n                  1.38\n                  0.1682\n                  2.6\n                  -2.206\n                  12.7\n                \n\n22.9\n                  10.24\n                  5.15\n                  1.99\n                  0.0469\n                  4.4\n                   0.139\n                  20.3\n                \n\n\n\n\n\n\n\n\n\ns = slopes(\n  mod,\n  variables = \"drat\",\n  newdata = datagrid(qsec = [mtcars[\"qsec\"].min(), mtcars[\"qsec\"].max()]))\nprint(s)\n\nshape: (2, 10)\n┌──────┬──────┬──────────┬──────────┬───┬─────────┬──────┬───────┬───────┐\n│ qsec ┆ Term ┆ Contrast ┆ Estimate ┆ … ┆ P(&gt;|z|) ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---     ┆ ---  ┆ ---   ┆ ---   │\n│ str  ┆ str  ┆ str      ┆ str      ┆   ┆ str     ┆ str  ┆ str   ┆ str   │\n╞══════╪══════╪══════════╪══════════╪═══╪═════════╪══════╪═══════╪═══════╡\n│ 14.5 ┆ drat ┆ dY/dX    ┆ 5.22     ┆ … ┆ 0.168   ┆ 2.57 ┆ -2.2  ┆ 12.7  │\n│ 22.9 ┆ drat ┆ dY/dX    ┆ 10.2     ┆ … ┆ 0.0469  ┆ 4.42 ┆ 0.143 ┆ 20.3  │\n└──────┴──────┴──────────┴──────────┴───┴─────────┴──────┴───────┴───────┘\n\nColumns: qsec, rowid, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, predicted, predicted_lo, predicted_hi, rownames, mpg, cyl, disp, hp, drat, wt, vs, am, gear, carb\n\n\n\n\n\nAre these two slopes significantly different from one another? To test this, we can use the hypothesis argument:\n\n\nR\nPython\n\n\n\n\nslopes(\n  mod,\n  hypothesis = \"b1 = b2\",\n  variables = \"drat\",\n  newdata = datagrid(qsec = range))\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n-5.02\n                  8.51\n                  -0.589\n                  0.556\n                  0.8\n                  -21.7\n                  11.7\n                \n\n\n\n\n\n\n\n\ns = slopes(\n  mod,\n  hypothesis = \"b1 = b2\",\n  variables = \"drat\",\n  newdata = datagrid(qsec = [mtcars[\"qsec\"].min(), mtcars[\"qsec\"].max()]))\nprint(s)\n\nshape: (1, 8)\n┌───────┬──────────┬───────────┬───────┬─────────┬───────┬───────┬───────┐\n│ Term  ┆ Estimate ┆ Std.Error ┆ z     ┆ P(&gt;|z|) ┆ S     ┆ 2.5%  ┆ 97.5% │\n│ ---   ┆ ---      ┆ ---       ┆ ---   ┆ ---     ┆ ---   ┆ ---   ┆ ---   │\n│ str   ┆ str      ┆ str       ┆ str   ┆ str     ┆ str   ┆ str   ┆ str   │\n╞═══════╪══════════╪═══════════╪═══════╪═════════╪═══════╪═══════╪═══════╡\n│ b1=b2 ┆ -5.02    ┆ 8.51      ┆ -0.59 ┆ 0.555   ┆ 0.848 ┆ -21.7 ┆ 11.7  │\n└───────┴──────────┴───────────┴───────┴─────────┴───────┴───────┴───────┘\n\nColumns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nAlternatively, we can also refer to values with term names (when they are unique):\n\n\nR\nPython\n\n\n\n\navg_slopes(mod)\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\ndrat\n                  7.22\n                  1.365\n                  5.29\n                  \n                  \n23.0\n                  4.548\n                  9.90\n                \n\nqsec\n                  1.12\n                  0.433\n                  2.60\n                  0.00945\n                  6.7 \n                  0.275\n                  1.97\n                \n\n\n\n\n\navg_slopes(mod, hypothesis = \"drat = qsec\")\n\n\n\n    \n\n      \n\nEstimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n              \n\nType:  response \n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n6.1\n                  1.45\n                  4.2\n                  \n                  \n15.2\n                  3.25\n                  8.95\n                \n\n\n\n\n\n\n\n\ns = avg_slopes(mod)\nprint(s)\n\nshape: (2, 9)\n┌──────┬─────────────┬──────────┬───────────┬───┬──────────┬──────┬───────┬───────┐\n│ Term ┆ Contrast    ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---         ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---   ┆ ---   │\n│ str  ┆ str         ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str   ┆ str   │\n╞══════╪═════════════╪══════════╪═══════════╪═══╪══════════╪══════╪═══════╪═══════╡\n│ drat ┆ mean(dY/dX) ┆ 7.22     ┆ 1.37      ┆ … ┆ 1.21e-07 ┆ 23   ┆ 4.55  ┆ 9.9   │\n│ qsec ┆ mean(dY/dX) ┆ 1.12     ┆ 0.432     ┆ … ┆ 0.00927  ┆ 6.75 ┆ 0.277 ┆ 1.97  │\n└──────┴─────────────┴──────────┴───────────┴───┴──────────┴──────┴───────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\ns = avg_slopes(mod, hypothesis = \"drat = qsec\")\nprint(s)\n\nshape: (1, 8)\n┌───────────┬──────────┬───────────┬─────┬──────────┬──────┬──────┬───────┐\n│ Term      ┆ Estimate ┆ Std.Error ┆ z   ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---       ┆ ---      ┆ ---       ┆ --- ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str       ┆ str      ┆ str       ┆ str ┆ str      ┆ str  ┆ str  ┆ str   │\n╞═══════════╪══════════╪═══════════╪═════╪══════════╪══════╪══════╪═══════╡\n│ drat=qsec ┆ 6.1      ┆ 1.45      ┆ 4.2 ┆ 2.66e-05 ┆ 15.2 ┆ 3.25 ┆ 8.95  │\n└───────────┴──────────┴───────────┴─────┴──────────┴──────┴──────┴───────┘\n\nColumns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nNow, imagine that for theoretical (or substantive or clinical) reasons, we only care about slopes larger than 2. We can use the equivalence argument to conduct an equivalence test:\n\n\nR\nPython\n\n\n\n\navg_slopes(mod, equivalence = c(-2, 2))\n\n\n\n    \n\n      \n\nTerm\n                Estimate\n                Std. Error\n                z\n                Pr(&gt;|z|)\n                S\n                2.5 %\n                97.5 %\n                p (NonSup)\n                p (NonInf)\n                p (Equiv)\n              \n\nType:  response \n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\n\n\n\ndrat\n                  7.22\n                  1.365\n                  5.29\n                  \n                  \n23.0\n                  4.548\n                  9.90\n                  0.9999\n                  \n                  \n0.9999\n                \n\nqsec\n                  1.12\n                  0.433\n                  2.60\n                  0.00945\n                  6.7 \n                  0.275\n                  1.97\n                  0.0216\n                  \n                  \n0.0216\n                \n\n\n\n\n\n\n\n\n\ns = avg_slopes(mod, equivalence = [-2., 2.])\nprint(s)\n\nshape: (2, 9)\n┌──────┬─────────────┬──────────┬───────────┬───┬──────────┬──────┬───────┬───────┐\n│ Term ┆ Contrast    ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%  ┆ 97.5% │\n│ ---  ┆ ---         ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---   ┆ ---   │\n│ str  ┆ str         ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str   ┆ str   │\n╞══════╪═════════════╪══════════╪═══════════╪═══╪══════════╪══════╪═══════╪═══════╡\n│ drat ┆ mean(dY/dX) ┆ 7.22     ┆ 1.37      ┆ … ┆ 1.21e-07 ┆ 23   ┆ 4.55  ┆ 9.9   │\n│ qsec ┆ mean(dY/dX) ┆ 1.12     ┆ 0.432     ┆ … ┆ 0.00927  ┆ 6.75 ┆ 0.277 ┆ 1.97  │\n└──────┴─────────────┴──────────┴───────────┴───┴──────────┴──────┴───────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, statistic_noninf, statistic_nonsup, p_value_noninf, p_value_nonsup, p_value_equiv\n\n\n\n\n\nSee the Hypothesis Tests and Custom Contrasts vignette for background, details, and for instructions on how to conduct hypothesis tests in more complex situations.",
    "crumbs": [
      "Get started"
    ]
  },
  {
    "objectID": "vignettes/slopes.html",
    "href": "vignettes/slopes.html",
    "title": "Slopes",
    "section": "",
    "text": "Slopes are defined as:\n\nPartial derivatives of the regression equation with respect to a regressor of interest. a.k.a. Marginal effects, trends, velocity.\n\nIn some disciplines, like economics and political science, slopes are called “marginal effects,” where marginal refers to the idea of a “small change,” in the calculus sense. In other disciplines, they are called “trends” or “velocity.” In this vignette, we use these terms interchageably.\nA slope measures the association between a change in a regressor \\(x\\), and a change in the response \\(y\\), estimated at a specific values of the regressor \\(x\\). Slopes are extremely useful, because they are intuitive and easy to interpret. They are often the main quantity of interest in an empirical analysis.\nIn scientific practice, slopes fall in the same toolbox as the “Contrast.” Both try to answer a counterfactual question: What would happen to \\(y\\) if \\(x\\) were different? They allow us to model the “effect” of a change in the explanator \\(x\\) on the response \\(y\\).1\nTo illustrate the concept, consider this quadratic function:\n\\[y = -x^2\\]\nFrom the definition above, we know that the marginal effect is the partial derivative of \\(y\\) with respect to \\(x\\):\n\\[\\frac{\\partial y}{\\partial x} = -2x\\]\nTo get intuition about how to interpret this quantity, consider the response of \\(y\\) to \\(x\\). It looks like this:\n\n\n\n\n\n\n\n\nWhen \\(x\\) increases, \\(y\\) starts to increase. But then, as \\(x\\) increases further, \\(y\\) creeps back down in negative territory.\nA marginal effect is the slope of this response function at a certain value of \\(x\\). The next plot adds three tangent lines, highlighting the slopes of the response function for three values of \\(x\\). The slopes of these tangents tell us three things:\n\nWhen \\(x&lt;0\\), the slope is positive: an increase in \\(x\\) is associated with an increase in \\(y\\): The marginal effect is positive.\nWhen \\(x=0\\), the slope is null: a (small) change in \\(x\\) is associated with no change in \\(y\\). The marginal effect is null.\nWhen \\(x&gt;0\\), the slope is negative: an increase in \\(x\\) is associated with a decrease in \\(y\\). The marginal effect is negative.\n\n\n\n\n\n\n\n\n\nAbove, we considered how marginal effects can be computed analytically in a simple quadratic equation context. We can now use the slopes function to replicate our analysis of the quadratic function in a regression application.\nSay you estimate a linear regression model with a quadratic term:\n\\[Y = \\beta_0 + \\beta_1 X^2 + \\varepsilon\\]\nand obtain estimates of \\(\\beta_0=1\\) and \\(\\beta_1=2\\). Taking the partial derivative with respect to \\(X\\) and plugging in our estimates gives us the marginal effect of \\(X\\) on \\(Y\\):\n\\[\\partial Y / \\partial X = \\beta_0 + 2 \\cdot \\beta_1 X\\] \\[\\partial Y / \\partial X = 1 + 4X\\]\nThis result suggests that the effect of a change in \\(X\\) on \\(Y\\) depends on the level of \\(X\\). When \\(X\\) is large and positive, an increase in \\(X\\) is associated to a large increase in \\(Y\\). When \\(X\\) is small and positive, an increase in \\(X\\) is associated to a small increase in \\(Y\\). When \\(X\\) is a large negative value, an increase in \\(X\\) is associated with a decrease in \\(Y\\).\nmarginaleffects arrives at the same conclusion in simulated data:\n\nlibrary(tidyverse)\nN &lt;- 1e5\nquad &lt;- data.frame(x = rnorm(N))\nquad$y &lt;- 1 + 1 * quad$x + 2 * quad$x^2 + rnorm(N)\nmod_quad &lt;- lm(y ~ x + I(x^2), quad)\n\nslopes(mod_quad, newdata = datagrid(x = -2:2))  |&gt;\n    mutate(truth = 1 + 4 * x) |&gt;\n    select(estimate, truth)\n#&gt; \n#&gt;  Estimate\n#&gt;     -6.99\n#&gt;     -3.00\n#&gt;      1.00\n#&gt;      5.00\n#&gt;      9.00\n#&gt; \n#&gt; Columns: estimate, truth\n\nWe can plot conditional adjusted predictions with plot_predictions function:\n\nplot_predictions(mod_quad, condition = \"x\")\n\n\n\n\n\n\n\nWe can plot conditional marginal effects with the plot_slopes function (see section below):\n\nplot_slopes(mod_quad, variables = \"x\", condition = \"x\")\n\n\n\n\n\n\n\nAgain, the conclusion is the same. When \\(x&lt;0\\), an increase in \\(x\\) is associated with an decrease in \\(y\\). When \\(x&gt;1/4\\), the marginal effect is positive, which suggests that an increase in \\(x\\) is associated with an increase in \\(y\\).\nSlopes are unit-level measures of association between changes in a regressor and changes in the response. Except in the simplest linear models, the value of the marginal effect will be different from individual to individual, because it will depend on the values of the other covariates for each individual.\nBy default, the slopes() function thus produces distinct estimates of the marginal effect for each row of the data used to fit the model:\n\nmfx &lt;- slopes(mod_quad)\n\ndim(mfx)\n#&gt; [1] 100000     14\n\nhead(mfx)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;     2.854    0.00382  748   &lt;0.001 Inf  2.847  2.862\n#&gt;     1.460    0.00322  454   &lt;0.001 Inf  1.454  1.467\n#&gt;    -1.768    0.00442 -400   &lt;0.001 Inf -1.777 -1.760\n#&gt;    -0.983    0.00386 -255   &lt;0.001 Inf -0.991 -0.976\n#&gt;    -3.663    0.00610 -600   &lt;0.001 Inf -3.675 -3.651\n#&gt;    -3.750    0.00619 -606   &lt;0.001 Inf -3.762 -3.738\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, y, x\n\nmfx\n#&gt; \n#&gt;  Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 %  97.5 %\n#&gt;    2.8544    0.00382  747.5   &lt;0.001 Inf  2.847  2.8619\n#&gt;    1.4605    0.00322  453.6   &lt;0.001 Inf  1.454  1.4668\n#&gt;   -1.7683    0.00442 -400.0   &lt;0.001 Inf -1.777 -1.7596\n#&gt;   -0.9833    0.00386 -254.9   &lt;0.001 Inf -0.991 -0.9757\n#&gt;   -3.6630    0.00610 -600.2   &lt;0.001 Inf -3.675 -3.6510\n#&gt; --- 99990 rows omitted. See ?avg_slopes and ?print.marginaleffects --- \n#&gt;    0.7578    0.00318  238.3   &lt;0.001   Inf  0.752  0.7640\n#&gt;    0.0395    0.00334   11.8   &lt;0.001 104.9  0.033  0.0461\n#&gt;   -7.6770    0.01024 -749.8   &lt;0.001   Inf -7.697 -7.6569\n#&gt;    1.6701    0.00327  510.9   &lt;0.001   Inf  1.664  1.6765\n#&gt;    5.2971    0.00582  910.4   &lt;0.001   Inf  5.286  5.3085\n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, y, x",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#average-marginal-effect-ame",
    "href": "vignettes/slopes.html#average-marginal-effect-ame",
    "title": "Slopes",
    "section": "Average Marginal Effect (AME)",
    "text": "Average Marginal Effect (AME)\nA dataset with one marginal effect estimate per unit of observation is a bit unwieldy and difficult to interpret. Many analysts like to report the “Average Marginal Effect”, that is, the average of all the observation-specific marginal effects. These are easy to compute based on the full data.frame shown above, but the avg_slopes() function is convenient:\n\navg_slopes(mod)\n#&gt; \n#&gt;               Term                       Contrast Estimate Std. Error      z Pr(&gt;|z|)    S    2.5 %  97.5 %\n#&gt;  bill_length_mm    mean(dY/dX)                      0.0279    0.00595  4.685   &lt;0.001 18.4  0.01621  0.0395\n#&gt;  flipper_length_mm mean(dY/dX)                      0.0105    0.00237  4.425   &lt;0.001 16.7  0.00585  0.0151\n#&gt;  species           mean(Chinstrap) - mean(Adelie)  -0.4128    0.05600 -7.371   &lt;0.001 42.4 -0.52255 -0.3030\n#&gt;  species           mean(Gentoo) - mean(Adelie)      0.0609    0.10734  0.568     0.57  0.8 -0.14946  0.2713\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that since marginal effects are derivatives, they are only properly defined for continuous numeric variables. When the model also includes categorical regressors, the summary function will try to display relevant (regression-adjusted) contrasts between different categories, as shown above.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#group-average-marginal-effect-g-ame",
    "href": "vignettes/slopes.html#group-average-marginal-effect-g-ame",
    "title": "Slopes",
    "section": "Group-Average Marginal Effect (G-AME)",
    "text": "Group-Average Marginal Effect (G-AME)\nWe can also use the by argument the average marginal effects within different subgroups of the observed data, based on values of the regressors. For example, to compute the average marginal effects of Bill Length for each Species, we do:\n\nmfx &lt;- avg_slopes(\n  mod,\n  by = \"species\",\n  variables = \"bill_length_mm\")\nmfx\n#&gt; \n#&gt;    species Estimate Std. Error     z Pr(&gt;|z|)    S    2.5 % 97.5 %\n#&gt;  Adelie     0.04392    0.00904 4.860   &lt;0.001 19.7  0.02620 0.0616\n#&gt;  Chinstrap  0.03704    0.00970 3.818   &lt;0.001 12.9  0.01803 0.0561\n#&gt;  Gentoo     0.00307    0.00313 0.981    0.327  1.6 -0.00306 0.0092\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThis is equivalent to manually taking the mean of the observation-level marginal effect for each species sub-group:\n\naggregate(\n  mfx$estimate,\n  by = list(mfx$species, mfx$term),\n  FUN = mean)\n#&gt;     Group.1        Group.2          x\n#&gt; 1    Adelie bill_length_mm 0.04391550\n#&gt; 2 Chinstrap bill_length_mm 0.03704402\n#&gt; 3    Gentoo bill_length_mm 0.00306904\n\nNote that marginaleffects follows Stata and the margins package in computing standard errors using the group-wise averaged Jacobian.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#marginal-effect-at-user-specified-values",
    "href": "vignettes/slopes.html#marginal-effect-at-user-specified-values",
    "title": "Slopes",
    "section": "Marginal Effect at User-Specified Values",
    "text": "Marginal Effect at User-Specified Values\nSometimes, we are not interested in all the unit-specific marginal effects, but would rather look at the estimated marginal effects for certain “typical” individuals, or for user-specified values of the regressors. The datagrid function helps us build a data grid full of “typical” rows. For example, to generate artificial Adelies and Gentoos with 180mm flippers:\n\ndatagrid(flipper_length_mm = 180,\n         species = c(\"Adelie\", \"Gentoo\"),\n         model = mod)\n#&gt;   bill_length_mm flipper_length_mm species rowid\n#&gt; 1       43.92193               180  Adelie     1\n#&gt; 2       43.92193               180  Gentoo     2\n\nThe same command can be used (omitting the model argument) to marginaleffects’s newdata argument to compute marginal effects for those (fictional) individuals:\n\nslopes(\n  mod,\n  newdata = datagrid(\n    flipper_length_mm = 180,\n    species = c(\"Adelie\", \"Gentoo\")))\n#&gt; \n#&gt;               Term           Contrast flipper_length_mm species Estimate Std. Error      z Pr(&gt;|z|)    S    2.5 %   97.5 %\n#&gt;  bill_length_mm    dY/dX                            180  Adelie   0.0578    0.03496  1.652   0.0986  3.3 -0.01078 1.26e-01\n#&gt;  bill_length_mm    dY/dX                            180  Gentoo   0.0804    0.04311  1.864   0.0623  4.0 -0.00413 1.65e-01\n#&gt;  flipper_length_mm dY/dX                            180  Adelie   0.0233    0.00555  4.191   &lt;0.001 15.1  0.01238 3.41e-02\n#&gt;  flipper_length_mm dY/dX                            180  Gentoo   0.0324    0.00880  3.677   &lt;0.001 12.1  0.01512 4.96e-02\n#&gt;  species           Chinstrap - Adelie               180  Adelie  -0.2106    0.10748 -1.959   0.0501  4.3 -0.42121 9.48e-05\n#&gt;  species           Chinstrap - Adelie               180  Gentoo  -0.2106    0.10748 -1.959   0.0501  4.3 -0.42121 9.48e-05\n#&gt;  species           Gentoo - Adelie                  180  Adelie   0.1556    0.30082  0.517   0.6051  0.7 -0.43403 7.45e-01\n#&gt;  species           Gentoo - Adelie                  180  Gentoo   0.1556    0.30082  0.517   0.6051  0.7 -0.43403 7.45e-01\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, flipper_length_mm, species, predicted_lo, predicted_hi, predicted, bill_length_mm, large_penguin\n\nWhen variables are omitted from the datagrid call, they will automatically be set at their mean or mode (depending on variable type).",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#marginal-effect-at-the-mean-mem",
    "href": "vignettes/slopes.html#marginal-effect-at-the-mean-mem",
    "title": "Slopes",
    "section": "Marginal Effect at the Mean (MEM)",
    "text": "Marginal Effect at the Mean (MEM)\nThe “Marginal Effect at the Mean” is a marginal effect calculated for a hypothetical observation where each regressor is set at its mean or mode. By default, the datagrid function that we used in the previous section sets all regressors to their means or modes. To calculate the MEM, we can set the newdata argument, which determines the values of predictors at which we want to compute marginal effects:\n\nslopes(mod, newdata = \"mean\")\n#&gt; \n#&gt;               Term           Contrast Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %  97.5 %\n#&gt;  bill_length_mm    dY/dX                0.0519    0.01447   3.585   &lt;0.001 11.5  0.02351  0.0803\n#&gt;  flipper_length_mm dY/dX                0.0193    0.00558   3.463   &lt;0.001 10.9  0.00838  0.0303\n#&gt;  species           Chinstrap - Adelie  -0.8088    0.07663 -10.554   &lt;0.001 84.1 -0.95897 -0.6586\n#&gt;  species           Gentoo - Adelie      0.0818    0.11540   0.709    0.478  1.1 -0.14435  0.3080\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, bill_length_mm, flipper_length_mm, species, large_penguin",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#counterfactual-marginal-effects",
    "href": "vignettes/slopes.html#counterfactual-marginal-effects",
    "title": "Slopes",
    "section": "Counterfactual Marginal Effects",
    "text": "Counterfactual Marginal Effects\nThe datagrid function allowed us look at completely fictional individuals. Setting the grid_type argument of this function to \"counterfactual\" lets us compute the marginal effects for the actual observations in our dataset, but with a few manipulated values. For example, this code will create a data.frame twice as long as the original dat, where each observation is repeated with different values of the flipper_length_mm variable:\n\nnd &lt;- datagrid(flipper_length_mm = c(160, 180),\n               model = mod,\n               grid_type = \"counterfactual\")\n\nWe see that the rows 1, 2, and 3 of the original dataset have been replicated twice, with different values of the flipper_length_mm variable:\n\nnd[nd$rowid %in% 1:3,]\n#&gt;     rowidcf large_penguin bill_length_mm species flipper_length_mm\n#&gt; 1         1             0           39.1  Adelie               160\n#&gt; 2         2             0           39.5  Adelie               160\n#&gt; 3         3             0           40.3  Adelie               160\n#&gt; 343       1             0           39.1  Adelie               180\n#&gt; 344       2             0           39.5  Adelie               180\n#&gt; 345       3             0           40.3  Adelie               180\n\nWe can use the observation-level marginal effects to compute average (or median, or anything else) marginal effects over the counterfactual individuals:\n\nlibrary(dplyr)\n\nslopes(mod, newdata = nd) |&gt;\n    group_by(term) |&gt;\n    summarize(estimate = median(estimate))\n#&gt; # A tibble: 3 × 2\n#&gt;   term               estimate\n#&gt;   &lt;chr&gt;                 &lt;dbl&gt;\n#&gt; 1 bill_length_mm    0.00940  \n#&gt; 2 flipper_length_mm 0.00385  \n#&gt; 3 species           0.0000315",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#conditional-marginal-effects-plot",
    "href": "vignettes/slopes.html#conditional-marginal-effects-plot",
    "title": "Slopes",
    "section": "Conditional Marginal Effects (Plot)",
    "text": "Conditional Marginal Effects (Plot)\nThe plot_slopes function can be used to draw “Conditional Marginal Effects.” This is useful when a model includes interaction terms and we want to plot how the marginal effect of a variable changes as the value of a “condition” (or “moderator”) variable changes:\n\nmod &lt;- lm(mpg ~ hp * wt + drat, data = mtcars)\n\nplot_slopes(mod, variables = \"hp\", condition = \"wt\")\n\n\n\n\n\n\n\nThe marginal effects in the plot above were computed with values of all regressors – except the variables and the condition – held at their means or modes, depending on variable type.\nSince plot_slopes() produces a ggplot2 object, it is easy to customize. For example:\n\nplot_slopes(mod, variables = \"hp\", condition = \"wt\") +\n    geom_rug(aes(x = wt), data = mtcars) +\n    theme_classic()",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#slopes-vs-predictions-a-visual-interpretation",
    "href": "vignettes/slopes.html#slopes-vs-predictions-a-visual-interpretation",
    "title": "Slopes",
    "section": "Slopes vs Predictions: A Visual Interpretation",
    "text": "Slopes vs Predictions: A Visual Interpretation\nOften, analysts will plot predicted values of the outcome with a best fit line:\n\nlibrary(ggplot2)\n\nmod &lt;- lm(mpg ~ hp * qsec, data = mtcars)\n\nplot_predictions(mod, condition = \"hp\", vcov = TRUE) +\n  geom_point(data = mtcars, aes(hp, mpg)) \n\n\n\n\n\n\n\nThe slope of this line is calculated using the same technique we all learned in grade school: dividing rise over run.\n\np &lt;- plot_predictions(mod, condition = \"hp\", vcov = TRUE, draw = FALSE)\nplot_predictions(mod, condition = \"hp\", vcov = TRUE) +\n  geom_segment(aes(x = p$hp[10], xend = p$hp[10], y = p$estimate[10], yend = p$estimate[20])) +\n  geom_segment(aes(x = p$hp[10], xend = p$hp[20], y = p$estimate[20], yend = p$estimate[20])) +\n  annotate(\"text\", label = \"Rise\", y = 10, x = 140) +\n  annotate(\"text\", label = \"Run\", y = 2, x = 200)\n\n\n\n\n\n\n\nInstead of computing this slope manually, we can just call:\n\navg_slopes(mod, variables = \"hp\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 %\n#&gt;    -0.112     0.0126 -8.92   &lt;0.001 61.0 -0.137 -0.0874\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNow, consider the fact that our model includes an interaction between hp and qsec. This means that the slope will actually differ based on the value of the moderator variable qsec:\n\nplot_predictions(mod, condition = list(\"hp\", \"qsec\" = \"quartile\"))\n\n\n\n\n\n\n\nWe can estimate the slopes of these three fit lines easily:\n\nslopes(\n  mod,\n  variables = \"hp\",\n  newdata = datagrid(qsec = quantile(mtcars$qsec, probs = c(.25, .5, .75))))\n#&gt; \n#&gt;  qsec Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 %\n#&gt;  16.9  -0.0934     0.0111 -8.43   &lt;0.001 54.7 -0.115 -0.0717\n#&gt;  17.7  -0.1093     0.0123 -8.92   &lt;0.001 60.9 -0.133 -0.0853\n#&gt;  18.9  -0.1325     0.0154 -8.61   &lt;0.001 56.9 -0.163 -0.1023\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, qsec, predicted_lo, predicted_hi, predicted, hp, mpg\n\nAs we see in the graph, all three slopes are negative, but the Q3 slope is steepest.\nWe could then push this one step further, and measure the slope of mpg with respect to hp, for all observed values of qsec. This is achieved with the plot_slopes() function:\n\nplot_slopes(mod, variables = \"hp\", condition = \"qsec\") +\n  geom_hline(yintercept = 0, linetype = 3)\n\n\n\n\n\n\n\nThis plot shows that the marginal effect of hp on mpg is always negative (the slope is always below zero), and that this effect becomes even more negative as qsec increases.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/slopes.html#footnotes",
    "href": "vignettes/slopes.html#footnotes",
    "title": "Slopes",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe term “effect” is tricky. To be clear, this vignette does not use the word “effect” to imply “causality”.↩︎",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Slopes"
    ]
  },
  {
    "objectID": "vignettes/extensions.html",
    "href": "vignettes/extensions.html",
    "title": "Extensions",
    "section": "",
    "text": "This vignette shows how to add support for new models and add new functionality for supported models.\n\nIt is very easy to add support for new models in marginaleffects. All we need is to set a global option and define 4 very simple functions.\nIf you add support for a class of models produced by a CRAN package, please consider submitting your code for inclusion in the package: https://github.com/vincentarelbundock/marginaleffects\nIf you add support for a class of models produced by a package hosted elsewhere than CRAN, you can submit it for inclusion in the unsupported user-submitted library of extensions: Currently\n\n\ncountreg package. Thanks to Olivier Beaumais.\n\ncensreg package. Thanks to Oleg Komashko.\n\nThe rest of this section illustrates how to add support for a very simple lm_manual model.\n\nTo begin, we define a function which fits a model. Normally, this function will be supplied by a modeling package published on CRAN. Here, we create a function called lm_manual(), which estimates a linear regression model using simple linear algebra operates:\n\nlm_manual &lt;- function(f, data, ...) {\n    # design matrix\n    X &lt;- model.matrix(f, data = data)\n    # response matrix\n    Y &lt;- data[[as.character(f[2])]]\n    # coefficients\n    b &lt;- solve(crossprod(X)) %*% crossprod(X, Y)\n    Yhat &lt;- X %*% b\n    # variance-covariance matrix\n    e &lt;- Y - Yhat\n    df &lt;- nrow(X) - ncol(X)\n    s2 &lt;- sum(e^2) / df\n    V &lt;- s2 * solve(crossprod(X))\n    # model object\n    out &lt;- list(\n        d = data,\n        f = f,\n        X = X,\n        Y = Y,\n        V = V,\n        b = b)\n    # class name: lm_manual\n    class(out) &lt;- c(\"lm_manual\", \"list\")\n    return(out)\n}\n\nImportant: The custom fit function must assign a new class name to the object it returns. In the example above, the model is assigned to be of class lm_manual (see the penultimate line of code in the function).\nOur new function replicates the results of lm():\n\nmodel &lt;- lm_manual(mpg ~ hp + drat, data = mtcars)\nmodel$b\n#&gt;                    [,1]\n#&gt; (Intercept) 10.78986122\n#&gt; hp          -0.05178665\n#&gt; drat         4.69815776\n\nmodel_lm &lt;- lm(mpg ~ hp + drat, data = mtcars)\ncoef(model_lm)\n#&gt; (Intercept)          hp        drat \n#&gt; 10.78986122 -0.05178665  4.69815776\n\n\nTo extend support in marginaleffects, the first step is to tell the package that our new class is supported. We do this by defining a global option:\n\nlibrary(marginaleffects)\n\noptions(\"marginaleffects_model_classes\" = \"lm_manual\")\n\nThen, we define 4 methods:\n\n\nget_coef()\n\nMandatory arguments: model, ...\n\nReturns: named vector of parameters (coefficients).\n\n\n\nset_coef()\n\nMandatory arguments: model, coefs (named vector of coefficients), ...\n\nReturns: A new model object in which the original coefficients were replaced by the new vector.\nExample\n\n\n\nget_vcov()\n\nMandatory arguments: model, ....\nOptional arguments: vcov\n\nReturns: A named square variance-covariance matrix.\n\n\n\nget_predict()\n\nMandatory arguments: model, newdata (data frame), ...\n\nOption arguments: type and other model-specific arguments.\nReturns: A data frame with two columns: a unique rowid and a column of estimate values.\n\n\n\nNote that each of these methods will be named with the suffix .lm_manual to indicate that they should be used whenever marginaleffects needs to process an object of class lm_manual.\n\nget_coef.lm_manual &lt;- function(model, ...) {\n    b &lt;- model$b\n    b &lt;- setNames(as.vector(b), row.names(b))\n    return(b)\n}\n\nset_coef.lm_manual &lt;- function(model, coefs, ...) {\n    out &lt;- model\n    out$b &lt;- coefs\n    return(out)\n}\n\nget_vcov.lm_manual &lt;- function(model, ...) {\n    return(model$V)\n}\n\nget_predict.lm_manual &lt;- function(model, newdata, ...) {\n    newX &lt;- model.matrix(model$f, data = newdata)\n    Yhat &lt;- newX %*% model$b\n    out &lt;- data.frame(\n        rowid = seq_len(nrow(Yhat)),\n        estimate = as.vector(Yhat))\n    return(out)\n}\n\nThe methods we just defined work as expected:\n\nget_coef(model)\n#&gt; (Intercept)          hp        drat \n#&gt; 10.78986122 -0.05178665  4.69815776\n\nget_vcov(model)\n#&gt;             (Intercept)            hp         drat\n#&gt; (Intercept) 25.78356135 -3.054007e-02 -5.836030687\n#&gt; hp          -0.03054007  8.635615e-05  0.004969385\n#&gt; drat        -5.83603069  4.969385e-03  1.419990359\n\nget_predict(model, newdata = head(mtcars))\n#&gt;   rowid estimate\n#&gt; 1     1 23.41614\n#&gt; 2     2 23.41614\n#&gt; 3     3 24.06161\n#&gt; 4     4 19.56366\n#&gt; 5     5 16.52639\n#&gt; 6     6 18.31918\n\nNow we can use the avg_slopes function:\n\navg_slopes(model, newdata = mtcars, variables = c(\"hp\", \"drat\"))\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 %  97.5 %\n#&gt;  drat   4.6982    1.19162  3.94   &lt;0.001 13.6  2.36  7.0337\n#&gt;  hp    -0.0518    0.00929 -5.57   &lt;0.001 25.2 -0.07 -0.0336\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\npredictions(model, newdata = mtcars) |&gt; head()\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  mpg cyl disp  hp drat   wt qsec vs am gear carb\n#&gt;      23.4      0.671 34.9   &lt;0.001 883.6  22.1   24.7 21.0   6  160 110 3.90 2.62 16.5  0  1    4    4\n#&gt;      23.4      0.671 34.9   &lt;0.001 883.6  22.1   24.7 21.0   6  160 110 3.90 2.88 17.0  0  1    4    4\n#&gt;      24.1      0.720 33.4   &lt;0.001 810.2  22.6   25.5 22.8   4  108  93 3.85 2.32 18.6  1  1    4    1\n#&gt;      19.6      0.999 19.6   &lt;0.001 281.4  17.6   21.5 21.4   6  258 110 3.08 3.21 19.4  1  0    3    1\n#&gt;      16.5      0.735 22.5   &lt;0.001 369.1  15.1   18.0 18.7   8  360 175 3.15 3.44 17.0  0  0    3    2\n#&gt;      18.3      1.343 13.6   &lt;0.001 138.3  15.7   21.0 18.1   6  225 105 2.76 3.46 20.2  1  0    3    1\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nNote that, for custom model, we typically have to supply values for the newdata and variables arguments explicitly.\n\nIf you wrote a working extension, please consider contributing back to the community by submitting your code for inclusion in the main package. To do this, all you need to do is follow the steps above, and then:\n\nAdd the package to the permanent list of supported models, to avoid calling options() in every session: R/sanitize_model.R\n\nAdd the package to the vignette of supported models by editing: data-raw/supported_models.csv\n\nAdd a bullet point to the news file: NEWS.md\n\n\nLet’s say you want to estimate a model using the mclogit::mblogit function. That package is already supported by marginaleffects, but you want to use a type (scale) of predictions that is not currently supported: a “centered link scale.”\nTo achieve this, we would need to override the get_predict.mblogit() method. However, it can be unsafe to reassign methods supplied by a package that we loaded with library. To be safe, we assign a new model class to our object (“customclass”) which will inherit from mblogit. Then, we define a get_predict.customclass method to make our new kinds of predictions.\nLoad libraries, estimate a model:\n\nlibrary(mclogit)\nlibrary(data.table)\n\nmodel &lt;- mblogit(\n    factor(gear) ~ am + mpg,\n    data = mtcars,\n    trace = FALSE)\n\nTell marginaleffects that we are adding support for a new class model models, and assign a new inherited class name to a duplicate of the model object:\n\noptions(\"marginaleffects_model_classes\" = \"customclass\")\n\nmodel_custom &lt;- model\n\nclass(model_custom) &lt;- c(\"customclass\", class(model))\n\nDefine a new get_predict.customclass method. We use the default predict() function to obtain predictions. Since this is a multinomial model, predict() returns a matrix of predictions with one column per level of the response variable.\nOur new get_predict.customclass method takes this matrix of predictions, modifies it, and reshapes it to return a data frame with three columns: rowid, group, and estimate:\n\nget_predict.customclass &lt;- function(model, newdata, ...) {\n    out &lt;- predict(model, newdata = newdata, type = \"link\")\n    out &lt;- cbind(0, out)\n    colnames(out)[1] &lt;- dimnames(model$D)[[1]][[1]]\n    out &lt;- out - rowMeans(out)\n    out &lt;- as.data.frame(out)\n    out$rowid &lt;- seq_len(nrow(out))\n    out &lt;- data.table(out)\n    out &lt;- melt(\n        out,\n        id.vars = \"rowid\",\n        value.name = \"estimate\",\n        variable.name = \"group\")\n}\n\nFinally, we can call any slopes function and obtain results. Notice that our object of class customclass now produces different results than the default mblogit object:\n\navg_predictions(model)\n#&gt; \n#&gt;  Group Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      3    0.469     0.0444 10.56  &lt; 0.001 84.2 0.382  0.556\n#&gt;      4    0.375     0.0670  5.60  &lt; 0.001 25.5 0.244  0.506\n#&gt;      5    0.156     0.0501  3.12  0.00183  9.1 0.058  0.255\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\navg_predictions(model_custom)\n#&gt; \n#&gt;  Group Estimate Std. Error         z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      3    -1.42       2525 -0.000561    1.000 0.0 -4950   4947\n#&gt;      4     6.36       1779  0.003578    0.997 0.0 -3480   3493\n#&gt;      5    -4.95       3074 -0.001609    0.999 0.0 -6030   6020\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Extensions"
    ]
  },
  {
    "objectID": "vignettes/extensions.html#support-a-new-model-type",
    "href": "vignettes/extensions.html#support-a-new-model-type",
    "title": "Extensions",
    "section": "",
    "text": "It is very easy to add support for new models in marginaleffects. All we need is to set a global option and define 4 very simple functions.\nIf you add support for a class of models produced by a CRAN package, please consider submitting your code for inclusion in the package: https://github.com/vincentarelbundock/marginaleffects\nIf you add support for a class of models produced by a package hosted elsewhere than CRAN, you can submit it for inclusion in the unsupported user-submitted library of extensions: Currently\n\n\ncountreg package. Thanks to Olivier Beaumais.\n\ncensreg package. Thanks to Oleg Komashko.\n\nThe rest of this section illustrates how to add support for a very simple lm_manual model.\n\nTo begin, we define a function which fits a model. Normally, this function will be supplied by a modeling package published on CRAN. Here, we create a function called lm_manual(), which estimates a linear regression model using simple linear algebra operates:\n\nlm_manual &lt;- function(f, data, ...) {\n    # design matrix\n    X &lt;- model.matrix(f, data = data)\n    # response matrix\n    Y &lt;- data[[as.character(f[2])]]\n    # coefficients\n    b &lt;- solve(crossprod(X)) %*% crossprod(X, Y)\n    Yhat &lt;- X %*% b\n    # variance-covariance matrix\n    e &lt;- Y - Yhat\n    df &lt;- nrow(X) - ncol(X)\n    s2 &lt;- sum(e^2) / df\n    V &lt;- s2 * solve(crossprod(X))\n    # model object\n    out &lt;- list(\n        d = data,\n        f = f,\n        X = X,\n        Y = Y,\n        V = V,\n        b = b)\n    # class name: lm_manual\n    class(out) &lt;- c(\"lm_manual\", \"list\")\n    return(out)\n}\n\nImportant: The custom fit function must assign a new class name to the object it returns. In the example above, the model is assigned to be of class lm_manual (see the penultimate line of code in the function).\nOur new function replicates the results of lm():\n\nmodel &lt;- lm_manual(mpg ~ hp + drat, data = mtcars)\nmodel$b\n#&gt;                    [,1]\n#&gt; (Intercept) 10.78986122\n#&gt; hp          -0.05178665\n#&gt; drat         4.69815776\n\nmodel_lm &lt;- lm(mpg ~ hp + drat, data = mtcars)\ncoef(model_lm)\n#&gt; (Intercept)          hp        drat \n#&gt; 10.78986122 -0.05178665  4.69815776\n\n\nTo extend support in marginaleffects, the first step is to tell the package that our new class is supported. We do this by defining a global option:\n\nlibrary(marginaleffects)\n\noptions(\"marginaleffects_model_classes\" = \"lm_manual\")\n\nThen, we define 4 methods:\n\n\nget_coef()\n\nMandatory arguments: model, ...\n\nReturns: named vector of parameters (coefficients).\n\n\n\nset_coef()\n\nMandatory arguments: model, coefs (named vector of coefficients), ...\n\nReturns: A new model object in which the original coefficients were replaced by the new vector.\nExample\n\n\n\nget_vcov()\n\nMandatory arguments: model, ....\nOptional arguments: vcov\n\nReturns: A named square variance-covariance matrix.\n\n\n\nget_predict()\n\nMandatory arguments: model, newdata (data frame), ...\n\nOption arguments: type and other model-specific arguments.\nReturns: A data frame with two columns: a unique rowid and a column of estimate values.\n\n\n\nNote that each of these methods will be named with the suffix .lm_manual to indicate that they should be used whenever marginaleffects needs to process an object of class lm_manual.\n\nget_coef.lm_manual &lt;- function(model, ...) {\n    b &lt;- model$b\n    b &lt;- setNames(as.vector(b), row.names(b))\n    return(b)\n}\n\nset_coef.lm_manual &lt;- function(model, coefs, ...) {\n    out &lt;- model\n    out$b &lt;- coefs\n    return(out)\n}\n\nget_vcov.lm_manual &lt;- function(model, ...) {\n    return(model$V)\n}\n\nget_predict.lm_manual &lt;- function(model, newdata, ...) {\n    newX &lt;- model.matrix(model$f, data = newdata)\n    Yhat &lt;- newX %*% model$b\n    out &lt;- data.frame(\n        rowid = seq_len(nrow(Yhat)),\n        estimate = as.vector(Yhat))\n    return(out)\n}\n\nThe methods we just defined work as expected:\n\nget_coef(model)\n#&gt; (Intercept)          hp        drat \n#&gt; 10.78986122 -0.05178665  4.69815776\n\nget_vcov(model)\n#&gt;             (Intercept)            hp         drat\n#&gt; (Intercept) 25.78356135 -3.054007e-02 -5.836030687\n#&gt; hp          -0.03054007  8.635615e-05  0.004969385\n#&gt; drat        -5.83603069  4.969385e-03  1.419990359\n\nget_predict(model, newdata = head(mtcars))\n#&gt;   rowid estimate\n#&gt; 1     1 23.41614\n#&gt; 2     2 23.41614\n#&gt; 3     3 24.06161\n#&gt; 4     4 19.56366\n#&gt; 5     5 16.52639\n#&gt; 6     6 18.31918\n\nNow we can use the avg_slopes function:\n\navg_slopes(model, newdata = mtcars, variables = c(\"hp\", \"drat\"))\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 %  97.5 %\n#&gt;  drat   4.6982    1.19162  3.94   &lt;0.001 13.6  2.36  7.0337\n#&gt;  hp    -0.0518    0.00929 -5.57   &lt;0.001 25.2 -0.07 -0.0336\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\npredictions(model, newdata = mtcars) |&gt; head()\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  mpg cyl disp  hp drat   wt qsec vs am gear carb\n#&gt;      23.4      0.671 34.9   &lt;0.001 883.6  22.1   24.7 21.0   6  160 110 3.90 2.62 16.5  0  1    4    4\n#&gt;      23.4      0.671 34.9   &lt;0.001 883.6  22.1   24.7 21.0   6  160 110 3.90 2.88 17.0  0  1    4    4\n#&gt;      24.1      0.720 33.4   &lt;0.001 810.2  22.6   25.5 22.8   4  108  93 3.85 2.32 18.6  1  1    4    1\n#&gt;      19.6      0.999 19.6   &lt;0.001 281.4  17.6   21.5 21.4   6  258 110 3.08 3.21 19.4  1  0    3    1\n#&gt;      16.5      0.735 22.5   &lt;0.001 369.1  15.1   18.0 18.7   8  360 175 3.15 3.44 17.0  0  0    3    2\n#&gt;      18.3      1.343 13.6   &lt;0.001 138.3  15.7   21.0 18.1   6  225 105 2.76 3.46 20.2  1  0    3    1\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nNote that, for custom model, we typically have to supply values for the newdata and variables arguments explicitly.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Extensions"
    ]
  },
  {
    "objectID": "vignettes/extensions.html#merge-your-extension-into-the-main-package",
    "href": "vignettes/extensions.html#merge-your-extension-into-the-main-package",
    "title": "Extensions",
    "section": "",
    "text": "If you wrote a working extension, please consider contributing back to the community by submitting your code for inclusion in the main package. To do this, all you need to do is follow the steps above, and then:\n\nAdd the package to the permanent list of supported models, to avoid calling options() in every session: R/sanitize_model.R\n\nAdd the package to the vignette of supported models by editing: data-raw/supported_models.csv\n\nAdd a bullet point to the news file: NEWS.md",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Extensions"
    ]
  },
  {
    "objectID": "vignettes/extensions.html#modify-or-extend-supported-models",
    "href": "vignettes/extensions.html#modify-or-extend-supported-models",
    "title": "Extensions",
    "section": "",
    "text": "Let’s say you want to estimate a model using the mclogit::mblogit function. That package is already supported by marginaleffects, but you want to use a type (scale) of predictions that is not currently supported: a “centered link scale.”\nTo achieve this, we would need to override the get_predict.mblogit() method. However, it can be unsafe to reassign methods supplied by a package that we loaded with library. To be safe, we assign a new model class to our object (“customclass”) which will inherit from mblogit. Then, we define a get_predict.customclass method to make our new kinds of predictions.\nLoad libraries, estimate a model:\n\nlibrary(mclogit)\nlibrary(data.table)\n\nmodel &lt;- mblogit(\n    factor(gear) ~ am + mpg,\n    data = mtcars,\n    trace = FALSE)\n\nTell marginaleffects that we are adding support for a new class model models, and assign a new inherited class name to a duplicate of the model object:\n\noptions(\"marginaleffects_model_classes\" = \"customclass\")\n\nmodel_custom &lt;- model\n\nclass(model_custom) &lt;- c(\"customclass\", class(model))\n\nDefine a new get_predict.customclass method. We use the default predict() function to obtain predictions. Since this is a multinomial model, predict() returns a matrix of predictions with one column per level of the response variable.\nOur new get_predict.customclass method takes this matrix of predictions, modifies it, and reshapes it to return a data frame with three columns: rowid, group, and estimate:\n\nget_predict.customclass &lt;- function(model, newdata, ...) {\n    out &lt;- predict(model, newdata = newdata, type = \"link\")\n    out &lt;- cbind(0, out)\n    colnames(out)[1] &lt;- dimnames(model$D)[[1]][[1]]\n    out &lt;- out - rowMeans(out)\n    out &lt;- as.data.frame(out)\n    out$rowid &lt;- seq_len(nrow(out))\n    out &lt;- data.table(out)\n    out &lt;- melt(\n        out,\n        id.vars = \"rowid\",\n        value.name = \"estimate\",\n        variable.name = \"group\")\n}\n\nFinally, we can call any slopes function and obtain results. Notice that our object of class customclass now produces different results than the default mblogit object:\n\navg_predictions(model)\n#&gt; \n#&gt;  Group Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      3    0.469     0.0444 10.56  &lt; 0.001 84.2 0.382  0.556\n#&gt;      4    0.375     0.0670  5.60  &lt; 0.001 25.5 0.244  0.506\n#&gt;      5    0.156     0.0501  3.12  0.00183  9.1 0.058  0.255\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\navg_predictions(model_custom)\n#&gt; \n#&gt;  Group Estimate Std. Error         z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      3    -1.42       2525 -0.000561    1.000 0.0 -4950   4947\n#&gt;      4     6.36       1779  0.003578    0.997 0.0 -3480   3493\n#&gt;      5    -4.95       3074 -0.001609    0.999 0.0 -6030   6020\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Extensions"
    ]
  },
  {
    "objectID": "vignettes/supported_models.html",
    "href": "vignettes/supported_models.html",
    "title": "Supported Models",
    "section": "",
    "text": "Supported Models\nmarginaleffects effects supports 102 model types directly, and dozens more via the tidymodels and mlr3 frameworks. This table shows the list of directly supported model types. There are three main alternative software packages to compute such slopes (1) Stata’s margins command, (2) R’s margins::margins() function, and (3) R’s emmeans::emtrends() function. The test suite hosted on Github compares the numerical equivalence of results produced by marginaleffects::slopes() to those produced by all 3 alternative software packages:\n\n✓: a green check means that the results of at least one model are equal to a reasonable tolerance.\n✖: a red cross means that the results are not identical; extra caution is warranted.\nU: a grey U means that computing slopes for a model type is unsupported by alternative packages, but supported by marginaleffects.\nAn empty cell means means that no comparison has been made yet.\n\nI am eager to add support for new models. Feel free to file a request or submit code on Github.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical equivalence\n\n\n\n\nSupported by marginaleffects\n\n\nStata\n\n\nmargins\n\n\nemtrends\n\n\n\nPackage\nFunction\ndY/dX\nSE\ndY/dX\nSE\ndY/dX\nSE\n\n\n\n\nAER\nivreg\n✓\n✓\n✓\n✓\nU\nU\n\n\n\ntobit\n✓\n✓\nU\nU\n✓\n✓\n\n\nDCchoice\noohbchoice\n\n\n\n\n\n\n\n\nMASS\nglm.nb\n✓\n✓\n✓\n✓\n✓\n✓\n\n\n\nglmmPQL\n\n\nU\nU\n✓\n✓\n\n\n\npolr\n✓\n✓\n✖\n✖\n✓\n✓\n\n\n\nrlm\n\n\n✓\n✓\n✓\n✓\n\n\nMCMCglmm\nMCMCglmm\nU\nU\nU\nU\nU\nU\n\n\nREndo\ncopulaCorrection\n\n\n\n\n\n\n\n\n\nhetErrorsIV\n\n\n\n\n\n\n\n\n\nhigherMomentsIV\n\n\n\n\n\n\n\n\n\nlatentIV\n\n\n\n\n\n\n\n\n\nmultilevelIV\n\n\n\n\n\n\n\n\nRchoice\nhetprob\n\n\n\n\n\n\n\n\n\nivpml\n\n\n\n\n\n\n\n\nafex\nafex_aov\n\n\nU\nU\n✓\n✓\n\n\naod\nbetabin\n\n\nU\nU\nU\nU\n\n\nbetareg\nbetareg\n✓\n✓\n✓\n✓\n✓\n✓\n\n\nbife\nbife\n\n\nU\nU\nU\nU\n\n\nbiglm\nbigglm\n\n\nU\nU\nU\nU\n\n\n\nbiglm\n\n\nU\nU\nU\nU\n\n\nblme\nbglmer\n\n\n\n\n\n\n\n\n\nblmer\n\n\n\n\n\n\n\n\nbrglm2\nbracl\n\n\nU\nU\nU\nU\n\n\n\nbrglmFit\n\n\n✓\n✓\n✓\n✓\n\n\n\nbrmultinom\n\n\nU\nU\nU\nU\n\n\n\nbrnb\n\n\n✓\n✓\nU\nU\n\n\nbrms\nbrm\n\n\nU\nU\n✓\n✓\n\n\ncrch\ncrch\n\n\nU\nU\nU\nU\n\n\n\nhxlr\n\n\nU\nU\nU\nU\n\n\nestimatr\niv_robust\n✓\n✓\nU\nU\nU\nU\n\n\n\nlm_lin\n\n\n\n\n\n\n\n\n\nlm_robust\n✓\n✓\n✓\nU\n✓\n✓\n\n\nfixest\nfeglm\n\n\nU\nU\nU\nU\n\n\n\nfenegbin\n\n\nU\nU\nU\nU\n\n\n\nfeols\n✓\n✓\nU\nU\nU\nU\n\n\n\nfepois\n✓\n✓\nU\nU\nU\nU\n\n\nflexsurv\nflexsurvreg\n\n\n\n\n\n\n\n\n\nflexsurvspline\n\n\n\n\n\n\n\n\ngam\ngam\n\n\nU\nU\n✓\n✓\n\n\ngamlss\ngamlss\n\n\nU\nU\n✓\n✓\n\n\ngeepack\ngeeglm\n\n\nU\nU\n✓\n✓\n\n\nglmmTMB\nglmmTMB\n\n\nU\nU\n✓\n✓\n\n\nglmtoolbox\nglmgee\n\n\n\n\n\n\n\n\nglmx\nglmx\n\n\n✓\nU\nU\nU\n\n\nivreg\nivreg\n✓\n✓\n✓\n✓\nU\nU\n\n\nlme4\nglmer\n✓\n✓\n✓\n✓\n✓\n✓\n\n\n\nglmer.nb\n\n\n✓\n✓\n✓\n✓\n\n\n\nlmer\n✓\n✓\n✓\n✓\n✓\n✓\n\n\nlmerTest\nlmer\n\n\n✓\n✓\n✓\n✓\n\n\nlogistf\nflac\n\n\n\n\n\n\n\n\n\nflic\n\n\n\n\n\n\n\n\n\nlogistf\n\n\n\n\n\n\n\n\nmclogit\nmblogit\n\n\nU\nU\nU\nU\n\n\n\nmclogit\n\n\nU\nU\nU\nU\n\n\nmgcv\nbam\n\n\nU\nU\n✓\n✖\n\n\n\ngam\n\n\nU\nU\n✓\n✓\n\n\nmhurdle\nmhurdle\n\n\n✓\n✓\nU\nU\n\n\nmlogit\nmlogit\n\n\nU\nU\nU\nU\n\n\nmlr3\nLearner\n\n\n\n\n\n\n\n\nmvgam\nmvgam\n\n\n\n\n\n\n\n\nnlme\ngls\n\n\nU\nU\n✓\n✓\n\n\n\nlme\n\n\n\n\n\n\n\n\nnnet\nmultinom\n✓\n✓\nU\nU\nU\nU\n\n\nordbetareg\nordbetareg\n\n\nU\nU\n\n\n\n\nordinal\nclm\n✓\n✓\nU\nU\nU\nU\n\n\nphylolm\nphyloglm\n\n\n\n\n\n\n\n\n\nphylolm\n\n\n\n\n\n\n\n\nplm\nplm\n✓\n✓\n✓\n✓\nU\nU\n\n\npscl\nhurdle\n\n\n✓\nU\n✓\n✖\n\n\n\nhurdle\n\n\n✓\nU\n✓\n✖\n\n\n\nzeroinfl\n✓\n✓\n✓\nU\n✓\n✓\n\n\nquantreg\nrq\n✓\n✓\nU\nU\n✓\n✓\n\n\nrms\nGls\n\n\n\n\n\n\n\n\n\nlrm\n\n\n\n\n\n\n\n\n\nols\n\n\n\n\n\n\n\n\n\norm\n\n\n\n\n\n\n\n\nrobust\nlmRob\n\n\nU\nU\nU\nU\n\n\nrobustbase\nglmrob\n\n\n✓\n✓\nU\nU\n\n\n\nlmrob\n\n\n✓\n✓\nU\nU\n\n\nrobustlmm\nrlmer\n\n\nU\nU\n\n\n\n\nrstanarm\nstan_glm\n\n\n✖\nU\n✓\n✓\n\n\nrstpm2\naft\n\n\n\n\n\n\n\n\n\ngsm\n\n\n\n\n\n\n\n\n\npstpm2\n\n\n\n\n\n\n\n\n\nstpm2\n\n\n\n\n\n\n\n\nsampleSelection\nheckit\n\n\nU\nU\nU\nU\n\n\n\nselection\n\n\nU\nU\nU\nU\n\n\nscam\nscam\n\n\nU\nU\nU\nU\n\n\nspeedglm\nspeedglm\n✓\n✓\n✓\n✓\nU\nU\n\n\n\nspeedlm\n✓\n✓\n✓\n✓\nU\nU\n\n\nstats\nglm\n✓\n✓\n✓\n✓\n✓\n✓\n\n\n\nlm\n✓\n✓\n✓\n✓\n✓\n✓\n\n\n\nloess\n\n\n✓\n\nU\nU\n\n\n\nnls\n\n\n\n\n\n\n\n\nsurvey\nsvyglm\n\n\n✓\n✓\n✓\n✓\n\n\n\nsvyolr\n\n\n\n\n\n\n\n\nsurvival\nclogit\n\n\n\n\n\n\n\n\n\ncoxph\n✓\n✓\nU\nU\n✓\n✓\n\n\n\nsurvreg\n\n\n\n\n\n\n\n\ntobit1\ntobit1\n\n\n✓\n✓\nU\nU\n\n\ntruncreg\ntruncreg\n✓\n✓\n✓\n✓\nU\nU",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Supported Models"
    ]
  },
  {
    "objectID": "vignettes/performance.html",
    "href": "vignettes/performance.html",
    "title": "Performance",
    "section": "",
    "text": "Some options:\n\nCompute marginal effects and contrasts at the mean (or other representative value) instead of all observed rows of the original dataset: Use the newdata argument and the datagrid() function.\nCompute marginal effects for a subset of variables, paying special attention to exclude factor variables which can be particularly costly to process: Use the variables argument.\nDo not compute standard errors: Use the vcov = FALSE argument.\nUse parallel processing to speed up the computation of standard errors. See next section.\n\nThis simulation illustrates how computation time varies for a model with 25 regressors and 100,000 observations:\n\nlibrary(marginaleffects)\n\n## simulate data and fit a large model\nN &lt;- 1e5\ndat &lt;- data.frame(matrix(rnorm(N * 26), ncol = 26))\nmod &lt;- lm(X1 ~ ., dat)\n\nresults &lt;- bench::mark(\n    # marginal effects at the mean; no standard error\n    slopes(mod, vcov = FALSE, newdata = \"mean\"),\n    # marginal effects at the mean\n    slopes(mod, newdata = \"mean\"),\n    # 1 variable; no standard error\n    slopes(mod, vcov = FALSE, variables = \"X3\"),\n    # 1 variable\n    slopes(mod, variables = \"X3\"),\n    # 26 variables; no standard error\n    slopes(mod, vcov = FALSE),\n    # 26 variables\n    slopes(mod),\n    iterations = 1, check = FALSE)\n\nresults[, c(1, 3, 5)]\n# expression                                        median mem_alloc\n# \"slopes(mod, vcov = FALSE, newdata = \\\"mean\\\")\" 194.98ms  306.19MB\n# \"slopes(mod, newdata = \\\"mean\\\")\"               345.38ms  311.45MB\n# \"slopes(mod, vcov = FALSE, variables = \\\"X3\\\")\" 197.51ms   649.6MB\n# \"slopes(mod, variables = \\\"X3\\\")\"               742.05ms    1.27GB\n# \"slopes(mod, vcov = FALSE)\"                        4.09s   13.87GB\n# \"slopes(mod)\"                                     15.33s   26.83GB\n\nThe benchmarks above were conducted using the development version of marginaleffects on 2023-12-09.\n\nAs noted above, the most costly operation in marginaleffects, because that involves calling predict() at least twice for every coefficient in the model. This operation can be conducted in parallel to speed things up.\nHowever, when the dataset is very large, there can be considerable cost to passing it between different cores or forked processes. Unfortunately, this means that the range of cases where parallelization is beneficial is pretty small, and that the gains will generally not be proportional to the number of cores used.\nThe class of models where parallelization is likely to yield the most gains is where:\n\nThe model includes many parameters (see get_coef(model))\nThe data is not very large.\n\nIn this example, we use the future package to specify a parallization plan and compute standard errors in parallel. The key parts of that example are: (a) set a global option to tell marginaleffects that we want to compute standard errors in parallel, and (b) use future to specify the parallelization plan and number of workers.\n\nlibrary(mgcv)\nlibrary(tictoc)\nlibrary(future)\nlibrary(nycflights13)\nlibrary(marginaleffects)\ndata(\"flights\")\npackageVersion(\"marginaleffects\")\n#&gt; [1] '0.22.0'\n\ncores &lt;- 8\nplan(multicore, workers = cores, number_of_workers = 8)\n\nflights &lt;- flights |&gt;\n    transform(date = as.Date(paste(year, month, day, sep = \"/\"))) |&gt;\n    transform(date.num = as.numeric(date - min(date))) |&gt;\n    transform(wday = as.POSIXlt(date)$wday) |&gt;\n    transform(time = as.POSIXct(paste(hour, minute, sep = \":\"), format = \"%H:%M\")) |&gt;\n    transform(time.dt = difftime(time, as.POSIXct('00:00', format = '%H:%M'), units = 'min')) |&gt;\n    transform(time.num = as.numeric(time.dt)) |&gt;\n    transform(dep_delay = ifelse(dep_delay &lt; 0, 0, dep_delay)) |&gt;\n    transform(dep_delay = ifelse(is.na(dep_delay), 0, dep_delay)) |&gt;\n    transform(carrier = factor(carrier)) |&gt;\n    transform(dest = factor(dest)) |&gt;\n    transform(origin = factor(origin))\n\nmodel &lt;- bam(dep_delay ~ s(date.num, bs = \"cr\") +\n                  s(wday, bs = \"cc\", k = 3) +\n                  s(time.num, bs = \"cr\") +\n                  s(carrier, bs = \"re\") +\n                  origin +\n                  s(distance, bs = \"cr\") + \n                  s(dest, bs = \"re\"),\n              data = flights,\n              family = poisson,\n              discrete = TRUE,\n              nthreads = cores)\n\nNote that this is a good use-case, because the model in question has a lot of parameters:\n\nlength(coef(model))\n#&gt; [1] 153\n\nNo standard errors is very fast:\n\ntic()\np1 &lt;- predictions(model, vcov = FALSE)\ntoc()\n#&gt; 0.251 sec elapsed\n\nWith parallelization:\n\noptions(\"marginaleffects_parallel\" = TRUE)\n\ntic()\np1 &lt;- predictions(model)\ntoc()\n#&gt; 7.551 sec elapsed\n\nWithout parallelization:\n\noptions(\"marginaleffects_parallel\" = FALSE)\n\ntic()\np2 &lt;- predictions(model)\ntoc()\n#&gt; 24.659 sec elapsed\n\nNow we make sure the results are equivalent:\n\ncor(p1$estimate, p2$estimate)\n#&gt; [1] 1\n\ncor(p1$std.error, p2$std.error)\n#&gt; [1] 1\n\nhead(p1)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      2.48     0.0224 110.5   &lt;0.001 Inf  2.43   2.52\n#&gt;      2.22     0.0176 125.8   &lt;0.001 Inf  2.18   2.25\n#&gt;      2.16     0.0147 147.2   &lt;0.001 Inf  2.13   2.19\n#&gt;      2.52     0.0272  92.7   &lt;0.001 Inf  2.47   2.57\n#&gt;      2.37     0.0126 187.6   &lt;0.001 Inf  2.35   2.40\n#&gt;      3.10     0.0170 182.1   &lt;0.001 Inf  3.07   3.14\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, dep_delay, date.num, wday, time.num, carrier, origin, distance, dest\n\nhead(p2)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      2.48     0.0224 110.5   &lt;0.001 Inf  2.43   2.52\n#&gt;      2.22     0.0176 125.8   &lt;0.001 Inf  2.18   2.25\n#&gt;      2.16     0.0147 147.2   &lt;0.001 Inf  2.13   2.19\n#&gt;      2.52     0.0272  92.7   &lt;0.001 Inf  2.47   2.57\n#&gt;      2.37     0.0126 187.6   &lt;0.001 Inf  2.35   2.40\n#&gt;      3.10     0.0170 182.1   &lt;0.001 Inf  3.07   3.14\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, dep_delay, date.num, wday, time.num, carrier, origin, distance, dest\n\nThe gains are interesting,\n\nThe slopes function is relatively fast. This simulation was conducted using the development version of the package on 2023-12-09:\n\nlibrary(margins)\n\nN &lt;- 1e3\ndat &lt;- data.frame(\n    y = sample(0:1, N, replace = TRUE),\n    x1 = rnorm(N),\n    x2 = rnorm(N),\n    x3 = rnorm(N),\n    x4 = factor(sample(letters[1:5], N, replace = TRUE)))\nmod &lt;- glm(y ~ x1 + x2 + x3 + x4, data = dat, family = binomial)\n\nmarginaleffects can be 3 times faster and use 3 times less memory than margins when unit-level standard errors are not computed:\n\nresults &lt;- bench::mark(\n    slopes(mod, vcov = FALSE),\n    margins(mod, unit_ses = FALSE),\n    check = FALSE, relative = TRUE)\nresults[, c(1, 3, 5)]\n\n# expression                     median mem_alloc\n# &lt;bch:expr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;\n# slopes(mod, vcov = FALSE)        1         1   \n# margins(mod, unit_ses = FALSE)   3.21      2.83\n\nmarginaleffects can be up to 1000x times faster and use 32x less memory than margins when unit-level standard errors are computed:\n\nresults &lt;- bench::mark(\n    slopes(mod, vcov = TRUE),\n    margins(mod, unit_ses = TRUE),\n    check = FALSE, relative = TRUE, iterations = 1)\nresults[, c(1, 3, 5)]\n# expression                    median mem_alloc\n#  &lt;bch:expr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;\n#  slopes(mod, vcov = TRUE)          1        1  \n#  margins(mod, unit_ses = TRUE)  1161.      32.9\n\nModels estimated on larger datasets (&gt; 1000 observations) can be impossible to process using the margins package, because of memory and time constraints. In contrast, marginaleffects can work well on much larger datasets.\nNote that, in some specific cases, marginaleffects will be considerably slower than packages like emmeans or modmarg. This is because these packages make extensive use of hard-coded analytical derivatives, or reimplement their own fast prediction functions.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Performance"
    ]
  },
  {
    "objectID": "vignettes/performance.html#what-to-do-when-marginaleffects-is-slow",
    "href": "vignettes/performance.html#what-to-do-when-marginaleffects-is-slow",
    "title": "Performance",
    "section": "",
    "text": "Some options:\n\nCompute marginal effects and contrasts at the mean (or other representative value) instead of all observed rows of the original dataset: Use the newdata argument and the datagrid() function.\nCompute marginal effects for a subset of variables, paying special attention to exclude factor variables which can be particularly costly to process: Use the variables argument.\nDo not compute standard errors: Use the vcov = FALSE argument.\nUse parallel processing to speed up the computation of standard errors. See next section.\n\nThis simulation illustrates how computation time varies for a model with 25 regressors and 100,000 observations:\n\nlibrary(marginaleffects)\n\n## simulate data and fit a large model\nN &lt;- 1e5\ndat &lt;- data.frame(matrix(rnorm(N * 26), ncol = 26))\nmod &lt;- lm(X1 ~ ., dat)\n\nresults &lt;- bench::mark(\n    # marginal effects at the mean; no standard error\n    slopes(mod, vcov = FALSE, newdata = \"mean\"),\n    # marginal effects at the mean\n    slopes(mod, newdata = \"mean\"),\n    # 1 variable; no standard error\n    slopes(mod, vcov = FALSE, variables = \"X3\"),\n    # 1 variable\n    slopes(mod, variables = \"X3\"),\n    # 26 variables; no standard error\n    slopes(mod, vcov = FALSE),\n    # 26 variables\n    slopes(mod),\n    iterations = 1, check = FALSE)\n\nresults[, c(1, 3, 5)]\n# expression                                        median mem_alloc\n# \"slopes(mod, vcov = FALSE, newdata = \\\"mean\\\")\" 194.98ms  306.19MB\n# \"slopes(mod, newdata = \\\"mean\\\")\"               345.38ms  311.45MB\n# \"slopes(mod, vcov = FALSE, variables = \\\"X3\\\")\" 197.51ms   649.6MB\n# \"slopes(mod, variables = \\\"X3\\\")\"               742.05ms    1.27GB\n# \"slopes(mod, vcov = FALSE)\"                        4.09s   13.87GB\n# \"slopes(mod)\"                                     15.33s   26.83GB\n\nThe benchmarks above were conducted using the development version of marginaleffects on 2023-12-09.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Performance"
    ]
  },
  {
    "objectID": "vignettes/performance.html#parallel-computation",
    "href": "vignettes/performance.html#parallel-computation",
    "title": "Performance",
    "section": "",
    "text": "As noted above, the most costly operation in marginaleffects, because that involves calling predict() at least twice for every coefficient in the model. This operation can be conducted in parallel to speed things up.\nHowever, when the dataset is very large, there can be considerable cost to passing it between different cores or forked processes. Unfortunately, this means that the range of cases where parallelization is beneficial is pretty small, and that the gains will generally not be proportional to the number of cores used.\nThe class of models where parallelization is likely to yield the most gains is where:\n\nThe model includes many parameters (see get_coef(model))\nThe data is not very large.\n\nIn this example, we use the future package to specify a parallization plan and compute standard errors in parallel. The key parts of that example are: (a) set a global option to tell marginaleffects that we want to compute standard errors in parallel, and (b) use future to specify the parallelization plan and number of workers.\n\nlibrary(mgcv)\nlibrary(tictoc)\nlibrary(future)\nlibrary(nycflights13)\nlibrary(marginaleffects)\ndata(\"flights\")\npackageVersion(\"marginaleffects\")\n#&gt; [1] '0.22.0'\n\ncores &lt;- 8\nplan(multicore, workers = cores, number_of_workers = 8)\n\nflights &lt;- flights |&gt;\n    transform(date = as.Date(paste(year, month, day, sep = \"/\"))) |&gt;\n    transform(date.num = as.numeric(date - min(date))) |&gt;\n    transform(wday = as.POSIXlt(date)$wday) |&gt;\n    transform(time = as.POSIXct(paste(hour, minute, sep = \":\"), format = \"%H:%M\")) |&gt;\n    transform(time.dt = difftime(time, as.POSIXct('00:00', format = '%H:%M'), units = 'min')) |&gt;\n    transform(time.num = as.numeric(time.dt)) |&gt;\n    transform(dep_delay = ifelse(dep_delay &lt; 0, 0, dep_delay)) |&gt;\n    transform(dep_delay = ifelse(is.na(dep_delay), 0, dep_delay)) |&gt;\n    transform(carrier = factor(carrier)) |&gt;\n    transform(dest = factor(dest)) |&gt;\n    transform(origin = factor(origin))\n\nmodel &lt;- bam(dep_delay ~ s(date.num, bs = \"cr\") +\n                  s(wday, bs = \"cc\", k = 3) +\n                  s(time.num, bs = \"cr\") +\n                  s(carrier, bs = \"re\") +\n                  origin +\n                  s(distance, bs = \"cr\") + \n                  s(dest, bs = \"re\"),\n              data = flights,\n              family = poisson,\n              discrete = TRUE,\n              nthreads = cores)\n\nNote that this is a good use-case, because the model in question has a lot of parameters:\n\nlength(coef(model))\n#&gt; [1] 153\n\nNo standard errors is very fast:\n\ntic()\np1 &lt;- predictions(model, vcov = FALSE)\ntoc()\n#&gt; 0.251 sec elapsed\n\nWith parallelization:\n\noptions(\"marginaleffects_parallel\" = TRUE)\n\ntic()\np1 &lt;- predictions(model)\ntoc()\n#&gt; 7.551 sec elapsed\n\nWithout parallelization:\n\noptions(\"marginaleffects_parallel\" = FALSE)\n\ntic()\np2 &lt;- predictions(model)\ntoc()\n#&gt; 24.659 sec elapsed\n\nNow we make sure the results are equivalent:\n\ncor(p1$estimate, p2$estimate)\n#&gt; [1] 1\n\ncor(p1$std.error, p2$std.error)\n#&gt; [1] 1\n\nhead(p1)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      2.48     0.0224 110.5   &lt;0.001 Inf  2.43   2.52\n#&gt;      2.22     0.0176 125.8   &lt;0.001 Inf  2.18   2.25\n#&gt;      2.16     0.0147 147.2   &lt;0.001 Inf  2.13   2.19\n#&gt;      2.52     0.0272  92.7   &lt;0.001 Inf  2.47   2.57\n#&gt;      2.37     0.0126 187.6   &lt;0.001 Inf  2.35   2.40\n#&gt;      3.10     0.0170 182.1   &lt;0.001 Inf  3.07   3.14\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, dep_delay, date.num, wday, time.num, carrier, origin, distance, dest\n\nhead(p2)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      2.48     0.0224 110.5   &lt;0.001 Inf  2.43   2.52\n#&gt;      2.22     0.0176 125.8   &lt;0.001 Inf  2.18   2.25\n#&gt;      2.16     0.0147 147.2   &lt;0.001 Inf  2.13   2.19\n#&gt;      2.52     0.0272  92.7   &lt;0.001 Inf  2.47   2.57\n#&gt;      2.37     0.0126 187.6   &lt;0.001 Inf  2.35   2.40\n#&gt;      3.10     0.0170 182.1   &lt;0.001 Inf  3.07   3.14\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, dep_delay, date.num, wday, time.num, carrier, origin, distance, dest\n\nThe gains are interesting,",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Performance"
    ]
  },
  {
    "objectID": "vignettes/performance.html#speed-comparison",
    "href": "vignettes/performance.html#speed-comparison",
    "title": "Performance",
    "section": "",
    "text": "The slopes function is relatively fast. This simulation was conducted using the development version of the package on 2023-12-09:\n\nlibrary(margins)\n\nN &lt;- 1e3\ndat &lt;- data.frame(\n    y = sample(0:1, N, replace = TRUE),\n    x1 = rnorm(N),\n    x2 = rnorm(N),\n    x3 = rnorm(N),\n    x4 = factor(sample(letters[1:5], N, replace = TRUE)))\nmod &lt;- glm(y ~ x1 + x2 + x3 + x4, data = dat, family = binomial)\n\nmarginaleffects can be 3 times faster and use 3 times less memory than margins when unit-level standard errors are not computed:\n\nresults &lt;- bench::mark(\n    slopes(mod, vcov = FALSE),\n    margins(mod, unit_ses = FALSE),\n    check = FALSE, relative = TRUE)\nresults[, c(1, 3, 5)]\n\n# expression                     median mem_alloc\n# &lt;bch:expr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;\n# slopes(mod, vcov = FALSE)        1         1   \n# margins(mod, unit_ses = FALSE)   3.21      2.83\n\nmarginaleffects can be up to 1000x times faster and use 32x less memory than margins when unit-level standard errors are computed:\n\nresults &lt;- bench::mark(\n    slopes(mod, vcov = TRUE),\n    margins(mod, unit_ses = TRUE),\n    check = FALSE, relative = TRUE, iterations = 1)\nresults[, c(1, 3, 5)]\n# expression                    median mem_alloc\n#  &lt;bch:expr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;\n#  slopes(mod, vcov = TRUE)          1        1  \n#  margins(mod, unit_ses = TRUE)  1161.      32.9\n\nModels estimated on larger datasets (&gt; 1000 observations) can be impossible to process using the margins package, because of memory and time constraints. In contrast, marginaleffects can work well on much larger datasets.\nNote that, in some specific cases, marginaleffects will be considerably slower than packages like emmeans or modmarg. This is because these packages make extensive use of hard-coded analytical derivatives, or reimplement their own fast prediction functions.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Performance"
    ]
  },
  {
    "objectID": "vignettes/plot.html",
    "href": "vignettes/plot.html",
    "title": "Plots",
    "section": "",
    "text": "The marginaleffects package includes three flexible functions to plot estimates and display interactions.\n\nplot_predictions()\nplot_comparisons()\nplot_slopes()\n\nThose functions can be used to plot two kinds of quantities:\n\nConditional estimates:\n\nEstimates computed on a substantively meaningful grid of predictor values.\nThis is analogous to using the newdata argument with the datagrid() function in a predictions(), comparisons(), or slopes() call.\n\n\nMarginal estimates:\n\nEstimates computed on the original data, but averaged by subgroup.\nThis is analogous to using the newdata argument with the datagrid() function in a predictions(), comparisons(), or slopes() call.\n\n\n\nTo begin, let’s download data and fit a model:\n\n\nR\nPython\n\n\n\n\n## libraries\nlibrary(ggplot2)\nlibrary(patchwork) # combine plots with the + and / signs\nlibrary(marginaleffects)\n\n## visual theme\ntheme_set(theme_minimal())\nokabeito &lt;- c('#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999', '#000000')\noptions(ggplot2.discrete.fill = okabeito)\noptions(ggplot2.discrete.colour = okabeito)\noptions(width = 1000)\n\n## download data\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nmod &lt;- lm(body_mass_g ~ flipper_length_mm * species * bill_length_mm + island, data = dat)\n\n\n\n\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\nfrom plotnine import *\nimport polars as pl\n\n# visual theme\ntheme_set(theme_minimal())\n\ndat = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\nmod = smf.ols(\n  \"body_mass_g ~ flipper_length_mm * species * bill_length_mm + island\", \n  data = dat.to_pandas()).fit()\n\n\n\n\n\n\nWe call a prediction “conditional” when it is made on a grid of user-specified values. For example, we predict penguins’ body mass for different values of flipper length and species:\n\n\nR\nPython\n\n\n\n\npre &lt;- predictions(mod, newdata = datagrid(flipper_length_mm = c(172, 231), species = unique))\npre\n#&gt; \n#&gt;  flipper_length_mm   species Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;                172 Adelie        3859        204 18.9   &lt;0.001 263.0  3460   4259\n#&gt;                172 Gentoo        2545        369  6.9   &lt;0.001  37.5  1822   3268\n#&gt;                172 Chinstrap     3146        234 13.5   &lt;0.001 134.6  2688   3604\n#&gt;                231 Adelie        4764        362 13.2   &lt;0.001 128.9  4054   5474\n#&gt;                231 Gentoo        5597        155 36.0   &lt;0.001 940.9  5292   5901\n#&gt;                231 Chinstrap     4086        469  8.7   &lt;0.001  58.1  3166   5006\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, bill_length_mm, island, flipper_length_mm, species, body_mass_g\n\n\n\n\npre = predictions(\n  mod,\n  newdata = datagrid(\n    flipper_length_mm = [172, 231], \n    species = dat[\"species\"].unique(),\n    model = mod)\n)\npre\n\n\n\nshape: (6, 17)\n\n\n\nflipper_length_mm\nspecies\nrowid\nestimate\nstd_error\nstatistic\np_value\ns_value\nconf_low\nconf_high\nrownames\nisland\nbill_length_mm\nbill_depth_mm\nbody_mass_g\nsex\nyear\n\n\ni64\nstr\ni32\nf64\nf64\nf64\nf64\nf64\nf64\nf64\ni64\nstr\nf64\nf64\nf64\nstr\ni64\n\n\n\n\n172\n\"Adelie\"\n0\n3859.49144\n203.924857\n18.926047\n0.0\ninf\n3459.806065\n4259.176816\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n172\n\"Gentoo\"\n1\n2544.81111\n368.939151\n6.897645\n5.2871e-12\n37.460659\n1821.703662\n3267.918559\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n172\n\"Chinstrap\"\n2\n3145.853248\n233.843835\n13.452795\n0.0\ninf\n2687.527753\n3604.178742\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n231\n\"Adelie\"\n3\n4763.826651\n362.09348\n13.156345\n0.0\ninf\n4054.136472\n5473.51683\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n231\n\"Gentoo\"\n4\n5596.718663\n155.418883\n36.010545\n0.0\ninf\n5292.103251\n5901.334076\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n231\n\"Chinstrap\"\n5\n4085.954268\n469.429937\n8.704077\n0.0\ninf\n3165.888497\n5006.020038\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n\n\n\n\n\n\n\nThe condition argument of the plot_predictions() function can be used to build meaningful grids of predictor values somewhat more easily:\n\n\nR\nPython\n\n\n\n\nplot_predictions(mod, condition = c(\"flipper_length_mm\", \"species\"))\n\n\n\n\n\n\n\n\n\n\nplot_predictions(mod, condition = [\"flipper_length_mm\", \"species\"])\n#&gt; &lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\nNote that the values at each end of the x-axis correspond to the numerical results produced above. For example, the predicted outcome for a Gentoo with 231mm flippers is 5597.\nWe can include a 3rd conditioning variable, specify what values we want to consider, supply R functions to compute summaries, and use one of several string shortcuts for common reference values (“threenum”, “minmax”, “quartile”, etc.):\n\n\nR\nPython\n\n\n\n\nplot_predictions(\n    mod,\n    condition = list(\n        \"flipper_length_mm\" = 180:220,\n        \"bill_length_mm\" = \"threenum\",\n        \"species\" = unique))\n\n\n\n\n\n\n\n\n\n\nplot_predictions(\n    mod,\n    condition = {\n        \"flipper_length_mm\": list(range(180, 221)),\n        \"bill_length_mm\": \"threenum\",\n        \"species\": dat[\"species\"].unique(),\n        }\n)\n\n\n\n\nSee ?plot_predictions for more information.\n\nWe call a prediction “marginal” when it is the result of a two step process: (1) make predictions for each observed unit in the original dataset, and (2) average predictions across one or more categorical predictors. For example:\n\npredictions(mod, by = \"species\")\n#&gt; \n#&gt;    species Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;  Adelie        3701       27.2 136.1   &lt;0.001 Inf  3647   3754\n#&gt;  Gentoo        5076       30.1 168.5   &lt;0.001 Inf  5017   5135\n#&gt;  Chinstrap     3733       40.5  92.2   &lt;0.001 Inf  3654   3812\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nWe can plot those predictions by using the analogous command:\n\nplot_predictions(mod, by = \"species\")\n\n\n\n\n\n\n\nWe can also make predictions at the intersections of different variables:\n\npredictions(mod, by = c(\"species\", \"island\"))\n#&gt; \n#&gt;    species    island Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;  Adelie    Torgersen     3706       46.8  79.2   &lt;0.001 Inf  3615   3798\n#&gt;  Adelie    Biscoe        3710       50.4  73.7   &lt;0.001 Inf  3611   3808\n#&gt;  Adelie    Dream         3688       44.6  82.6   &lt;0.001 Inf  3601   3776\n#&gt;  Gentoo    Biscoe        5076       30.1 168.5   &lt;0.001 Inf  5017   5135\n#&gt;  Chinstrap Dream         3733       40.5  92.2   &lt;0.001 Inf  3654   3812\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: species, island, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nNote that certain species only live on certain islands. Visually:\n\nplot_predictions(mod, by = c(\"species\", \"island\"))\n\n\n\n\n\n\n\n\n\nThe syntax for conditional comparisons is the same as the syntax for conditional predictions, except that we now need to specify the variable(s) of interest using an additional argument:\n\ncomparisons(mod,\n  variables = \"flipper_length_mm\",\n  newdata = datagrid(flipper_length_mm = c(172, 231), species = unique))\n#&gt; \n#&gt;               Term flipper_length_mm   species Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 % bill_length_mm island\n#&gt;  flipper_length_mm               172 Adelie        15.3       9.25 1.66   0.0976  3.4 -2.81   33.5           43.9 Biscoe\n#&gt;  flipper_length_mm               172 Gentoo        51.7       8.70 5.95   &lt;0.001 28.5 34.68   68.8           43.9 Biscoe\n#&gt;  flipper_length_mm               172 Chinstrap     15.9      11.37 1.40   0.1609  2.6 -6.34   38.2           43.9 Biscoe\n#&gt;  flipper_length_mm               231 Adelie        15.3       9.25 1.66   0.0976  3.4 -2.81   33.5           43.9 Biscoe\n#&gt;  flipper_length_mm               231 Gentoo        51.7       8.70 5.95   &lt;0.001 28.5 34.68   68.8           43.9 Biscoe\n#&gt;  flipper_length_mm               231 Chinstrap     15.9      11.37 1.40   0.1609  2.6 -6.34   38.2           43.9 Biscoe\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: +1\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, flipper_length_mm, species, predicted_lo, predicted_hi, predicted, bill_length_mm, island, body_mass_g\n\nplot_comparisons(mod,\n  variables = \"flipper_length_mm\",\n  condition = c(\"bill_length_mm\", \"species\"))\n\n\n\n\n\n\n\nWe can specify custom comparisons, as we would using the variables argument of the comparisons() function. For example, see what happens to the predicted outcome when flipper_length_mm increases by 1 standard deviation or by 10mm:\n\nplot_comparisons(mod,\n  variables = list(\"flipper_length_mm\" = \"sd\"),\n  condition = c(\"bill_length_mm\", \"species\")) +\n\nplot_comparisons(mod,\n  variables = list(\"flipper_length_mm\" = 10),\n  condition = c(\"bill_length_mm\", \"species\"))\n\n\n\n\n\n\n\nNotice that the vertical scale is different in the plots above, reflecting the fact that we are plotting the effect of a change of 1 standard deviation on the left vs 10 units on the right.\nLike the comparisons() function, plot_comparisons() is a very powerful tool because it allows us to compute and display custom comparisons such as differences, ratios, odds, lift, and arbitrary functions of predicted outcomes. For example, if we want to plot the ratio of predicted body mass for different species of penguins, we could do:\n\nplot_comparisons(mod,\n  variables = \"species\",\n  condition = \"bill_length_mm\",\n  comparison = \"ratio\")\n\n\n\n\n\n\n\nThe left panel shows that the ratio of Chinstrap body mass to Adelie body mass is approximately constant, at slightly above 0.8. The right panel shows that the ratio of Gentoo to Adelie body mass is depends on their bill length. For birds with short bills, Gentoos seem to have smaller body mass than Adelies. For birds with long bills, Gentoos seem heavier than Adelies, although the null ratio (1) is not outside the confidence interval.\n\nAs above, we can also display marginal comparisons, by subgroups:\n\nplot_comparisons(mod,\n  variables = \"flipper_length_mm\",\n  by = \"species\") +\n\nplot_comparisons(mod,\n  variables = \"flipper_length_mm\",\n  by = c(\"species\", \"island\"))\n\n\n\n\n\n\n\nMultiple contrasts at once:\n\nplot_comparisons(mod,\n  variables = c(\"flipper_length_mm\", \"bill_length_mm\"),\n  by = c(\"species\", \"island\"))\n\n\n\n\n\n\n\n\nIf you have read the sections above, the behavior of the plot_slopes() function should not surprise. Here we give two examples in which we compute display the elasticity of body mass with respect to bill length:\n\n## conditional\nplot_slopes(mod,\n  variables = \"bill_length_mm\",\n  slope = \"eyex\",\n  condition = c(\"species\", \"island\"))\n\n\n\n\n\n\n\n## marginal\nplot_slopes(mod,\n  variables = \"bill_length_mm\",\n  slope = \"eyex\",\n  by = c(\"species\", \"island\"))\n\n\n\n\n\n\n\nAnd here is an example of a marginal effects (aka “slopes” or “partial derivatives”) plot for a model with multiplicative interactions between continuous variables:\n\nmod2 &lt;- lm(mpg ~ wt * qsec * factor(gear), data = mtcars)\n\nplot_slopes(mod2, variables = \"qsec\", condition = c(\"wt\", \"gear\"))\n\n\n\n\n\n\n\n\nAs with all the other functions in the package, the plot_*() functions have a conf_level argument and a vcov argument which can be used to control the size of confidence intervals and the types of standard errors used:\n\nplot_slopes(mod,\n  variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +\n  ylim(c(-150, 200)) +\n\n## clustered standard errors\nplot_slopes(mod,\n  vcov = ~island,\n  variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +\n  ylim(c(-150, 200)) +\n\n## alpha level\nplot_slopes(mod,\n  conf_level = .8,\n  variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +\n  ylim(c(-150, 200))\n\n\n\n\n\n\n\n\nA very useful feature of the plotting functions in this package is that they produce normal ggplot2 objects. So we can customize them to our heart’s content, using ggplot2 itself, or one of the many packages designed to augment its functionalities:\n\nlibrary(ggrepel)\n\nmt &lt;- mtcars\nmt$label &lt;- row.names(mt)\n\nmod &lt;- lm(mpg ~ hp * factor(cyl), data = mt)\n\nplot_predictions(mod, condition = c(\"hp\", \"cyl\"), points = .5, rug = TRUE, vcov = FALSE) +\n    geom_text_repel(aes(x = hp, y = mpg, label = label),\n                    data = subset(mt, hp &gt; 250),\n                    nudge_y = 2) +\n    theme_classic()\n\n\n\n\n\n\n\nAll the plotting functions work with all the model supported by the marginaleffects package, so we can plot the output of a logistic regression model. This plot shows the probability of survival aboard the Titanic, for different ages and different ticket classes:\n\nlibrary(ggdist)\nlibrary(ggplot2)\n\ndat &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\"\ndat &lt;- read.csv(dat)\n\nmod &lt;- glm(Survived ~ Age * SexCode * PClass, data = dat, family = binomial)\n\nplot_predictions(mod, condition = c(\"Age\", \"PClass\")) +\n    geom_dots(\n        alpha = .8,\n        scale = .3,\n        pch = 18,\n        data = dat, aes(\n        x = Age,\n        y = Survived,\n        side = ifelse(Survived == 1, \"bottom\", \"top\")))\n\n\n\n\n\n\n\nThanks to Andrew Heiss who inspired this plot.\nDesigning effective data visualizations requires a lot of customization to the specific context and data. The plotting functions in marginaleffects offer a powerful way to iterate quickly between plots and models, but they obviously cannot support all the features that users may want. Thankfully, it is very easy to use the slopes functions to generate datasets that can then be used in ggplot2 or any other data visualization tool. Just use the draw argument:\n\np &lt;- plot_predictions(mod, condition = c(\"Age\", \"PClass\"), draw = FALSE)\nhead(p)\n#&gt;   rowid  estimate    p.value  s.value  conf.low conf.high SexCode     Age PClass Survived\n#&gt; 1     1 0.8169481 0.01398979 6.159481 0.5751384 0.9363604       0 0.17000    1st        1\n#&gt; 2     2 0.8460749 0.01719013 5.862276 0.5750040 0.9571390       0 0.17000    2nd        1\n#&gt; 3     3 0.3743476 0.30356431 1.719926 0.1836114 0.6141637       0 0.17000    3rd        1\n#&gt; 4     4 0.8049295 0.01596447 5.968992 0.5657542 0.9289214       0 1.61551    1st        1\n#&gt; 5     5 0.8170027 0.02633314 5.246977 0.5438874 0.9435524       0 1.61551    2nd        1\n#&gt; 6     6 0.3573635 0.21423192 2.222755 0.1805140 0.5840004       0 1.61551    3rd        1\n\nThis allows us to feed the data easily to other functions, such as those in the useful ggdist and distributional packages:\n\nlibrary(ggdist)\nlibrary(distributional)\nplot_slopes(mod, variables = \"SexCode\", condition = c(\"Age\", \"PClass\"), type = \"link\", draw = FALSE) |&gt;\n  ggplot() +\n  stat_lineribbon(aes(\n    x = Age,\n    ydist = dist_normal(mu = estimate, sigma = std.error),\n    fill = PClass),\n    alpha = 1 / 4)\n\n\n\n\n\n\n\n\nWe can compare the model predictors with fits and smoothers using the geom_smooth() function from the ggplot2 package:\n\ndat &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\"\ndat &lt;- read.csv(dat)\nmod &lt;- glm(Survived ~ Age * PClass, data = dat, family = binomial)\n\nplot_predictions(mod, condition = c(\"Age\", \"PClass\")) +\n    geom_smooth(data = dat, aes(Age, Survived), method = \"lm\", se = FALSE, color = \"black\") +\n    geom_smooth(data = dat, aes(Age, Survived), se = FALSE, color = \"black\")\n\n\n\n\n\n\n\n\nIn some models, marginaleffects functions generate different estimates for different groups, such as categorical outcomes. For example,\n\nlibrary(MASS)\nmod &lt;- polr(factor(gear) ~ mpg + hp, data = mtcars)\n\npredictions(mod)\n#&gt; \n#&gt;  Group Estimate Std. Error    z Pr(&gt;|z|)    S   2.5 % 97.5 %\n#&gt;      3   0.5316     0.1127 4.72   &lt;0.001 18.7  0.3107  0.753\n#&gt;      3   0.5316     0.1127 4.72   &lt;0.001 18.7  0.3107  0.753\n#&gt;      3   0.4492     0.1200 3.74   &lt;0.001 12.4  0.2140  0.684\n#&gt;      3   0.4944     0.1111 4.45   &lt;0.001 16.8  0.2765  0.712\n#&gt;      3   0.4213     0.1142 3.69   &lt;0.001 12.1  0.1973  0.645\n#&gt; --- 86 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n#&gt;      5   0.6894     0.1957 3.52   &lt;0.001 11.2  0.3059  1.073\n#&gt;      5   0.1650     0.1290 1.28   0.2009  2.3 -0.0878  0.418\n#&gt;      5   0.1245     0.0698 1.78   0.0744  3.7 -0.0123  0.261\n#&gt;      5   0.3779     0.3243 1.17   0.2439  2.0 -0.2578  1.014\n#&gt;      5   0.0667     0.0458 1.46   0.1455  2.8 -0.0231  0.157\n#&gt; Type:  probs \n#&gt; Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, gear, mpg, hp\n\nIn the resulting data frame, the group column identifies levels of the categorical response.\nWe can plot those estimates in the same way as before, by specifying group as one of the conditional variable, or by adding that column to a facet_wrap() call:\n\npkgload::load_all()\nplot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\", vcov = FALSE)\n\n\n\n\n\n\n\nplot_predictions(mod, condition = \"mpg\", type = \"probs\", vcov = FALSE) +\n  facet_wrap(~ group)\n\n\n\n\n\n\n\n\nSome users may feel inclined to call plot() on a object produced by marginaleffects object. Doing so will generate an informative error like this one:\n\nmod &lt;- lm(mpg ~ hp * wt * factor(cyl), data = mtcars)\np &lt;- predictions(mod)\nplot(p)\n#&gt; Error: Please use the `plot_predictions()` function.\n\nThe reason for this error is that the user query is underspecified. marginaleffects allows users to compute so many quantities of interest that it is not clear what the user wants when they simply call plot(). Adding several new arguments would compete with the main plotting functions, and risk sowing confusion. The marginaleffects developers thus decided to support one main path to plotting: plot_predictions(), plot_comparisons(), and plot_slopes().\nThat said, it may be useful to remind users that all marginaleffects output are standard “tidy” data frames. Although they get pretty-printed to the console, all the listed columns are accessible via standard R operators. For example:\n\np &lt;- avg_predictions(mod, by = \"cyl\")\np\n#&gt; \n#&gt;  cyl Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;    6     19.7      0.871 22.7   &lt;0.001 375.1  18.0   21.5\n#&gt;    4     26.7      0.695 38.4   &lt;0.001   Inf  25.3   28.0\n#&gt;    8     15.1      0.616 24.5   &lt;0.001 438.2  13.9   16.3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\np$estimate\n#&gt; [1] 19.74286 26.66364 15.10000\n\np$std.error\n#&gt; [1] 0.8713835 0.6951236 0.6161612\n\np$conf.low\n#&gt; [1] 18.03498 25.30122 13.89235\n\nThis allows us to plot all results very easily with standard plotting functions:\n\nplot_predictions(mod, by = \"cyl\")\n\n\n\n\n\n\n\nplot(p$cyl, p$estimate)\n\n\n\n\n\n\n\nggplot(p, aes(x = cyl, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  geom_pointrange()",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#predictions",
    "href": "vignettes/plot.html#predictions",
    "title": "Plots",
    "section": "",
    "text": "We call a prediction “conditional” when it is made on a grid of user-specified values. For example, we predict penguins’ body mass for different values of flipper length and species:\n\n\nR\nPython\n\n\n\n\npre &lt;- predictions(mod, newdata = datagrid(flipper_length_mm = c(172, 231), species = unique))\npre\n#&gt; \n#&gt;  flipper_length_mm   species Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;                172 Adelie        3859        204 18.9   &lt;0.001 263.0  3460   4259\n#&gt;                172 Gentoo        2545        369  6.9   &lt;0.001  37.5  1822   3268\n#&gt;                172 Chinstrap     3146        234 13.5   &lt;0.001 134.6  2688   3604\n#&gt;                231 Adelie        4764        362 13.2   &lt;0.001 128.9  4054   5474\n#&gt;                231 Gentoo        5597        155 36.0   &lt;0.001 940.9  5292   5901\n#&gt;                231 Chinstrap     4086        469  8.7   &lt;0.001  58.1  3166   5006\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, bill_length_mm, island, flipper_length_mm, species, body_mass_g\n\n\n\n\npre = predictions(\n  mod,\n  newdata = datagrid(\n    flipper_length_mm = [172, 231], \n    species = dat[\"species\"].unique(),\n    model = mod)\n)\npre\n\n\n\nshape: (6, 17)\n\n\n\nflipper_length_mm\nspecies\nrowid\nestimate\nstd_error\nstatistic\np_value\ns_value\nconf_low\nconf_high\nrownames\nisland\nbill_length_mm\nbill_depth_mm\nbody_mass_g\nsex\nyear\n\n\ni64\nstr\ni32\nf64\nf64\nf64\nf64\nf64\nf64\nf64\ni64\nstr\nf64\nf64\nf64\nstr\ni64\n\n\n\n\n172\n\"Adelie\"\n0\n3859.49144\n203.924857\n18.926047\n0.0\ninf\n3459.806065\n4259.176816\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n172\n\"Gentoo\"\n1\n2544.81111\n368.939151\n6.897645\n5.2871e-12\n37.460659\n1821.703662\n3267.918559\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n172\n\"Chinstrap\"\n2\n3145.853248\n233.843835\n13.452795\n0.0\ninf\n2687.527753\n3604.178742\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n231\n\"Adelie\"\n3\n4763.826651\n362.09348\n13.156345\n0.0\ninf\n4054.136472\n5473.51683\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n231\n\"Gentoo\"\n4\n5596.718663\n155.418883\n36.010545\n0.0\ninf\n5292.103251\n5901.334076\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n231\n\"Chinstrap\"\n5\n4085.954268\n469.429937\n8.704077\n0.0\ninf\n3165.888497\n5006.020038\n334\n\"Biscoe\"\n43.92193\n17.15117\n4201.754386\n\"male\"\n2009\n\n\n\n\n\n\n\n\n\nThe condition argument of the plot_predictions() function can be used to build meaningful grids of predictor values somewhat more easily:\n\n\nR\nPython\n\n\n\n\nplot_predictions(mod, condition = c(\"flipper_length_mm\", \"species\"))\n\n\n\n\n\n\n\n\n\n\nplot_predictions(mod, condition = [\"flipper_length_mm\", \"species\"])\n#&gt; &lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\n\n\nNote that the values at each end of the x-axis correspond to the numerical results produced above. For example, the predicted outcome for a Gentoo with 231mm flippers is 5597.\nWe can include a 3rd conditioning variable, specify what values we want to consider, supply R functions to compute summaries, and use one of several string shortcuts for common reference values (“threenum”, “minmax”, “quartile”, etc.):\n\n\nR\nPython\n\n\n\n\nplot_predictions(\n    mod,\n    condition = list(\n        \"flipper_length_mm\" = 180:220,\n        \"bill_length_mm\" = \"threenum\",\n        \"species\" = unique))\n\n\n\n\n\n\n\n\n\n\nplot_predictions(\n    mod,\n    condition = {\n        \"flipper_length_mm\": list(range(180, 221)),\n        \"bill_length_mm\": \"threenum\",\n        \"species\": dat[\"species\"].unique(),\n        }\n)\n\n\n\n\nSee ?plot_predictions for more information.\n\nWe call a prediction “marginal” when it is the result of a two step process: (1) make predictions for each observed unit in the original dataset, and (2) average predictions across one or more categorical predictors. For example:\n\npredictions(mod, by = \"species\")\n#&gt; \n#&gt;    species Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;  Adelie        3701       27.2 136.1   &lt;0.001 Inf  3647   3754\n#&gt;  Gentoo        5076       30.1 168.5   &lt;0.001 Inf  5017   5135\n#&gt;  Chinstrap     3733       40.5  92.2   &lt;0.001 Inf  3654   3812\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nWe can plot those predictions by using the analogous command:\n\nplot_predictions(mod, by = \"species\")\n\n\n\n\n\n\n\nWe can also make predictions at the intersections of different variables:\n\npredictions(mod, by = c(\"species\", \"island\"))\n#&gt; \n#&gt;    species    island Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;  Adelie    Torgersen     3706       46.8  79.2   &lt;0.001 Inf  3615   3798\n#&gt;  Adelie    Biscoe        3710       50.4  73.7   &lt;0.001 Inf  3611   3808\n#&gt;  Adelie    Dream         3688       44.6  82.6   &lt;0.001 Inf  3601   3776\n#&gt;  Gentoo    Biscoe        5076       30.1 168.5   &lt;0.001 Inf  5017   5135\n#&gt;  Chinstrap Dream         3733       40.5  92.2   &lt;0.001 Inf  3654   3812\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: species, island, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nNote that certain species only live on certain islands. Visually:\n\nplot_predictions(mod, by = c(\"species\", \"island\"))",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#comparisons",
    "href": "vignettes/plot.html#comparisons",
    "title": "Plots",
    "section": "",
    "text": "The syntax for conditional comparisons is the same as the syntax for conditional predictions, except that we now need to specify the variable(s) of interest using an additional argument:\n\ncomparisons(mod,\n  variables = \"flipper_length_mm\",\n  newdata = datagrid(flipper_length_mm = c(172, 231), species = unique))\n#&gt; \n#&gt;               Term flipper_length_mm   species Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 % bill_length_mm island\n#&gt;  flipper_length_mm               172 Adelie        15.3       9.25 1.66   0.0976  3.4 -2.81   33.5           43.9 Biscoe\n#&gt;  flipper_length_mm               172 Gentoo        51.7       8.70 5.95   &lt;0.001 28.5 34.68   68.8           43.9 Biscoe\n#&gt;  flipper_length_mm               172 Chinstrap     15.9      11.37 1.40   0.1609  2.6 -6.34   38.2           43.9 Biscoe\n#&gt;  flipper_length_mm               231 Adelie        15.3       9.25 1.66   0.0976  3.4 -2.81   33.5           43.9 Biscoe\n#&gt;  flipper_length_mm               231 Gentoo        51.7       8.70 5.95   &lt;0.001 28.5 34.68   68.8           43.9 Biscoe\n#&gt;  flipper_length_mm               231 Chinstrap     15.9      11.37 1.40   0.1609  2.6 -6.34   38.2           43.9 Biscoe\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: +1\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, flipper_length_mm, species, predicted_lo, predicted_hi, predicted, bill_length_mm, island, body_mass_g\n\nplot_comparisons(mod,\n  variables = \"flipper_length_mm\",\n  condition = c(\"bill_length_mm\", \"species\"))\n\n\n\n\n\n\n\nWe can specify custom comparisons, as we would using the variables argument of the comparisons() function. For example, see what happens to the predicted outcome when flipper_length_mm increases by 1 standard deviation or by 10mm:\n\nplot_comparisons(mod,\n  variables = list(\"flipper_length_mm\" = \"sd\"),\n  condition = c(\"bill_length_mm\", \"species\")) +\n\nplot_comparisons(mod,\n  variables = list(\"flipper_length_mm\" = 10),\n  condition = c(\"bill_length_mm\", \"species\"))\n\n\n\n\n\n\n\nNotice that the vertical scale is different in the plots above, reflecting the fact that we are plotting the effect of a change of 1 standard deviation on the left vs 10 units on the right.\nLike the comparisons() function, plot_comparisons() is a very powerful tool because it allows us to compute and display custom comparisons such as differences, ratios, odds, lift, and arbitrary functions of predicted outcomes. For example, if we want to plot the ratio of predicted body mass for different species of penguins, we could do:\n\nplot_comparisons(mod,\n  variables = \"species\",\n  condition = \"bill_length_mm\",\n  comparison = \"ratio\")\n\n\n\n\n\n\n\nThe left panel shows that the ratio of Chinstrap body mass to Adelie body mass is approximately constant, at slightly above 0.8. The right panel shows that the ratio of Gentoo to Adelie body mass is depends on their bill length. For birds with short bills, Gentoos seem to have smaller body mass than Adelies. For birds with long bills, Gentoos seem heavier than Adelies, although the null ratio (1) is not outside the confidence interval.\n\nAs above, we can also display marginal comparisons, by subgroups:\n\nplot_comparisons(mod,\n  variables = \"flipper_length_mm\",\n  by = \"species\") +\n\nplot_comparisons(mod,\n  variables = \"flipper_length_mm\",\n  by = c(\"species\", \"island\"))\n\n\n\n\n\n\n\nMultiple contrasts at once:\n\nplot_comparisons(mod,\n  variables = c(\"flipper_length_mm\", \"bill_length_mm\"),\n  by = c(\"species\", \"island\"))",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#slopes",
    "href": "vignettes/plot.html#slopes",
    "title": "Plots",
    "section": "",
    "text": "If you have read the sections above, the behavior of the plot_slopes() function should not surprise. Here we give two examples in which we compute display the elasticity of body mass with respect to bill length:\n\n## conditional\nplot_slopes(mod,\n  variables = \"bill_length_mm\",\n  slope = \"eyex\",\n  condition = c(\"species\", \"island\"))\n\n\n\n\n\n\n\n## marginal\nplot_slopes(mod,\n  variables = \"bill_length_mm\",\n  slope = \"eyex\",\n  by = c(\"species\", \"island\"))\n\n\n\n\n\n\n\nAnd here is an example of a marginal effects (aka “slopes” or “partial derivatives”) plot for a model with multiplicative interactions between continuous variables:\n\nmod2 &lt;- lm(mpg ~ wt * qsec * factor(gear), data = mtcars)\n\nplot_slopes(mod2, variables = \"qsec\", condition = c(\"wt\", \"gear\"))",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#uncertainty-estimates",
    "href": "vignettes/plot.html#uncertainty-estimates",
    "title": "Plots",
    "section": "",
    "text": "As with all the other functions in the package, the plot_*() functions have a conf_level argument and a vcov argument which can be used to control the size of confidence intervals and the types of standard errors used:\n\nplot_slopes(mod,\n  variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +\n  ylim(c(-150, 200)) +\n\n## clustered standard errors\nplot_slopes(mod,\n  vcov = ~island,\n  variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +\n  ylim(c(-150, 200)) +\n\n## alpha level\nplot_slopes(mod,\n  conf_level = .8,\n  variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +\n  ylim(c(-150, 200))",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#customization",
    "href": "vignettes/plot.html#customization",
    "title": "Plots",
    "section": "",
    "text": "A very useful feature of the plotting functions in this package is that they produce normal ggplot2 objects. So we can customize them to our heart’s content, using ggplot2 itself, or one of the many packages designed to augment its functionalities:\n\nlibrary(ggrepel)\n\nmt &lt;- mtcars\nmt$label &lt;- row.names(mt)\n\nmod &lt;- lm(mpg ~ hp * factor(cyl), data = mt)\n\nplot_predictions(mod, condition = c(\"hp\", \"cyl\"), points = .5, rug = TRUE, vcov = FALSE) +\n    geom_text_repel(aes(x = hp, y = mpg, label = label),\n                    data = subset(mt, hp &gt; 250),\n                    nudge_y = 2) +\n    theme_classic()\n\n\n\n\n\n\n\nAll the plotting functions work with all the model supported by the marginaleffects package, so we can plot the output of a logistic regression model. This plot shows the probability of survival aboard the Titanic, for different ages and different ticket classes:\n\nlibrary(ggdist)\nlibrary(ggplot2)\n\ndat &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\"\ndat &lt;- read.csv(dat)\n\nmod &lt;- glm(Survived ~ Age * SexCode * PClass, data = dat, family = binomial)\n\nplot_predictions(mod, condition = c(\"Age\", \"PClass\")) +\n    geom_dots(\n        alpha = .8,\n        scale = .3,\n        pch = 18,\n        data = dat, aes(\n        x = Age,\n        y = Survived,\n        side = ifelse(Survived == 1, \"bottom\", \"top\")))\n\n\n\n\n\n\n\nThanks to Andrew Heiss who inspired this plot.\nDesigning effective data visualizations requires a lot of customization to the specific context and data. The plotting functions in marginaleffects offer a powerful way to iterate quickly between plots and models, but they obviously cannot support all the features that users may want. Thankfully, it is very easy to use the slopes functions to generate datasets that can then be used in ggplot2 or any other data visualization tool. Just use the draw argument:\n\np &lt;- plot_predictions(mod, condition = c(\"Age\", \"PClass\"), draw = FALSE)\nhead(p)\n#&gt;   rowid  estimate    p.value  s.value  conf.low conf.high SexCode     Age PClass Survived\n#&gt; 1     1 0.8169481 0.01398979 6.159481 0.5751384 0.9363604       0 0.17000    1st        1\n#&gt; 2     2 0.8460749 0.01719013 5.862276 0.5750040 0.9571390       0 0.17000    2nd        1\n#&gt; 3     3 0.3743476 0.30356431 1.719926 0.1836114 0.6141637       0 0.17000    3rd        1\n#&gt; 4     4 0.8049295 0.01596447 5.968992 0.5657542 0.9289214       0 1.61551    1st        1\n#&gt; 5     5 0.8170027 0.02633314 5.246977 0.5438874 0.9435524       0 1.61551    2nd        1\n#&gt; 6     6 0.3573635 0.21423192 2.222755 0.1805140 0.5840004       0 1.61551    3rd        1\n\nThis allows us to feed the data easily to other functions, such as those in the useful ggdist and distributional packages:\n\nlibrary(ggdist)\nlibrary(distributional)\nplot_slopes(mod, variables = \"SexCode\", condition = c(\"Age\", \"PClass\"), type = \"link\", draw = FALSE) |&gt;\n  ggplot() +\n  stat_lineribbon(aes(\n    x = Age,\n    ydist = dist_normal(mu = estimate, sigma = std.error),\n    fill = PClass),\n    alpha = 1 / 4)",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#fits-and-smooths",
    "href": "vignettes/plot.html#fits-and-smooths",
    "title": "Plots",
    "section": "",
    "text": "We can compare the model predictors with fits and smoothers using the geom_smooth() function from the ggplot2 package:\n\ndat &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\"\ndat &lt;- read.csv(dat)\nmod &lt;- glm(Survived ~ Age * PClass, data = dat, family = binomial)\n\nplot_predictions(mod, condition = c(\"Age\", \"PClass\")) +\n    geom_smooth(data = dat, aes(Age, Survived), method = \"lm\", se = FALSE, color = \"black\") +\n    geom_smooth(data = dat, aes(Age, Survived), se = FALSE, color = \"black\")",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#groups-and-categorical-outcomes",
    "href": "vignettes/plot.html#groups-and-categorical-outcomes",
    "title": "Plots",
    "section": "",
    "text": "In some models, marginaleffects functions generate different estimates for different groups, such as categorical outcomes. For example,\n\nlibrary(MASS)\nmod &lt;- polr(factor(gear) ~ mpg + hp, data = mtcars)\n\npredictions(mod)\n#&gt; \n#&gt;  Group Estimate Std. Error    z Pr(&gt;|z|)    S   2.5 % 97.5 %\n#&gt;      3   0.5316     0.1127 4.72   &lt;0.001 18.7  0.3107  0.753\n#&gt;      3   0.5316     0.1127 4.72   &lt;0.001 18.7  0.3107  0.753\n#&gt;      3   0.4492     0.1200 3.74   &lt;0.001 12.4  0.2140  0.684\n#&gt;      3   0.4944     0.1111 4.45   &lt;0.001 16.8  0.2765  0.712\n#&gt;      3   0.4213     0.1142 3.69   &lt;0.001 12.1  0.1973  0.645\n#&gt; --- 86 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n#&gt;      5   0.6894     0.1957 3.52   &lt;0.001 11.2  0.3059  1.073\n#&gt;      5   0.1650     0.1290 1.28   0.2009  2.3 -0.0878  0.418\n#&gt;      5   0.1245     0.0698 1.78   0.0744  3.7 -0.0123  0.261\n#&gt;      5   0.3779     0.3243 1.17   0.2439  2.0 -0.2578  1.014\n#&gt;      5   0.0667     0.0458 1.46   0.1455  2.8 -0.0231  0.157\n#&gt; Type:  probs \n#&gt; Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, gear, mpg, hp\n\nIn the resulting data frame, the group column identifies levels of the categorical response.\nWe can plot those estimates in the same way as before, by specifying group as one of the conditional variable, or by adding that column to a facet_wrap() call:\n\npkgload::load_all()\nplot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\", vcov = FALSE)\n\n\n\n\n\n\n\nplot_predictions(mod, condition = \"mpg\", type = \"probs\", vcov = FALSE) +\n  facet_wrap(~ group)",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/plot.html#plot-and-marginaleffects-objects",
    "href": "vignettes/plot.html#plot-and-marginaleffects-objects",
    "title": "Plots",
    "section": "",
    "text": "Some users may feel inclined to call plot() on a object produced by marginaleffects object. Doing so will generate an informative error like this one:\n\nmod &lt;- lm(mpg ~ hp * wt * factor(cyl), data = mtcars)\np &lt;- predictions(mod)\nplot(p)\n#&gt; Error: Please use the `plot_predictions()` function.\n\nThe reason for this error is that the user query is underspecified. marginaleffects allows users to compute so many quantities of interest that it is not clear what the user wants when they simply call plot(). Adding several new arguments would compete with the main plotting functions, and risk sowing confusion. The marginaleffects developers thus decided to support one main path to plotting: plot_predictions(), plot_comparisons(), and plot_slopes().\nThat said, it may be useful to remind users that all marginaleffects output are standard “tidy” data frames. Although they get pretty-printed to the console, all the listed columns are accessible via standard R operators. For example:\n\np &lt;- avg_predictions(mod, by = \"cyl\")\np\n#&gt; \n#&gt;  cyl Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;    6     19.7      0.871 22.7   &lt;0.001 375.1  18.0   21.5\n#&gt;    4     26.7      0.695 38.4   &lt;0.001   Inf  25.3   28.0\n#&gt;    8     15.1      0.616 24.5   &lt;0.001 438.2  13.9   16.3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\np$estimate\n#&gt; [1] 19.74286 26.66364 15.10000\n\np$std.error\n#&gt; [1] 0.8713835 0.6951236 0.6161612\n\np$conf.low\n#&gt; [1] 18.03498 25.30122 13.89235\n\nThis allows us to plot all results very easily with standard plotting functions:\n\nplot_predictions(mod, by = \"cyl\")\n\n\n\n\n\n\n\nplot(p$cyl, p$estimate)\n\n\n\n\n\n\n\nggplot(p, aes(x = cyl, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  geom_pointrange()",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Plots"
    ]
  },
  {
    "objectID": "vignettes/gcomputation.html",
    "href": "vignettes/gcomputation.html",
    "title": "G-Computation",
    "section": "",
    "text": "This vignette has 3 goals:\n\nGive a concise introduction to the idea of “Parametric g-Formula”\nHighlight the equivalence between one form of g-estimation and the “Average Contrasts” computed by marginaleffects\n\nShow how to obtain estimates, standard errors, and confidence intervals via the Parametric g-Formula, using a single line of marginaleffects code. This is convenient because, typically, analysts have to construct counterfactual datasets manually and must bootstrap their estimates.\n\nThe “Parametric g-Formula” is often used for causal inference in observational data.\nThe explanations and illustrations that follow draw heavily on Chapter 13 of this excellent book (free copy available online):\n\nHernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman & Hall/CRC.\n\n\nThe parametric g-formula is a method of standardization which can be used to address confounding problems in causal inference with observational data. It relies on the same identification assumptions as Inverse Probability Weighting (IPW), but uses different modeling assumptions. Whereas IPW models the treatment equation, standardization models the mean outcome equation. As Hernán and Robins note:\n\n“Both IP weighting and standardization are estimators of the g-formula, a general method for causal inference first described in 1986. … We say that standardization is a”plug-in g-formula estimator” because it simply replaces the conditional mean outcome in the g-formula by its estimates. When, like in Chapter 13, those estimates come from parametric models, we refer to the method as the parametric g-formula.”\n\n\nImagine a causal model like this:\n\n\n\n\n\ngraph LR;\n    W --&gt; X;\n    W --&gt; Y;\n    X --&gt; Y;\n\n\n\n\n\n\nWe want to estimate the effect of a binary treatment \\(X\\) on outcome \\(Y\\), but there is a confounding variable \\(W\\). We can use standardization with the parametric g-formula to handle this. Roughly speaking, the procedure is as follows:\n\nUse the observed data to fit a regression model with \\(Y\\) as outcome, \\(X\\) as treatment, and \\(W\\) as control variable (with perhaps some polynomials and/or interactions if there are multiple control variables).\nCreate a new dataset exactly identical to the original data, but where \\(X=1\\) in every row.\nCreate a new dataset exactly identical to the original data, but where \\(X=0\\) in every row.\nUse the model from Step 1 to compute adjusted predictions in the two counterfactual datasets from Steps 2 and 3.\nThe quantity of interest is the difference between the means of adjusted predictions in the two counterfactual datasets.\n\nThis is equivalent to computing an “Average Contrast”, in which the value of \\(X\\) moves from 0 to 1. Thanks to this equivalence, we can apply the parametric g-formula method using a single line of code in marginaleffects, and obtain delta method standard errors automatically.\n\nLet’s illustrate this method by replicating an example from Chapter 13 of Hernán and Robins. The data come from the National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study (NHEFS). The outcome is wt82_71, a measure of weight gain. The treatment is qsmk, a binary measure of smoking cessation. There are many confounders.\nStep 1 is to fit a regression model of the outcome on the treatment and control variables:\n\n\nR\nPython\n\n\n\n\nlibrary(boot)\nlibrary(marginaleffects)\n\nf &lt;- wt82_71 ~ qsmk + sex + race + age + I(age * age) + factor(education) +\n     smokeintensity + I(smokeintensity * smokeintensity) + smokeyrs +\n     I(smokeyrs * smokeyrs) + factor(exercise) + factor(active) + wt71 +\n     I(wt71 * wt71) + I(qsmk * smokeintensity)\n\nurl &lt;- \"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\"\nnhefs &lt;- read.csv(url)\nnhefs &lt;- na.omit(nhefs[, all.vars(f)])\n\nfit &lt;- glm(f, data = nhefs)\n\n\n\n\nimport polars as pl\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nf = \"wt82_71 ~ qsmk + sex + race + age + pow(age,2) + C(education) + \\\n    smokeintensity + pow(smokeintensity,2) + smokeyrs + \\\n    pow(smokeyrs,2) + C(exercise) + C(active) + wt71 + \\\n    pow(wt71,2) + qsmk*smokeintensity\"\n\nnhefs = pl.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\")\n\nvariables = [\"wt82_71\", \"qsmk\", \"sex\", \"race\", \"age\", \"education\", \"smokeintensity\", \"smokeyrs\", \"exercise\", \"active\", \"wt71\"]\nnhefs = nhefs.filter(\n    ~pl.any_horizontal(pl.col(variables).is_null())\n)\n\nfit = smf.glm(f, data=nhefs.to_pandas()).fit()\n\n\n\n\nSteps 2 and 3 require us to replicate the full dataset by setting the qsmk treatment to counterfactual values. We can do this automatically by calling comparisons().\n\nThese simple commands do everything we need to apply the parametric g-formula:\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit, variables = list(qsmk = 0:1))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.52       0.44 7.99   &lt;0.001 49.4  2.65   4.38\n\nTerm: qsmk\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n\ncmp = avg_comparisons(fit, variables = {'qsmk' : [0,1]})\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n│ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n│ qsmk ┆ mean(True) - mean(False) ┆ 3.52     ┆ 0.44      ┆ … ┆ 1.33e-15 ┆ 49.4 ┆ 2.65 ┆ 4.38  │\n└──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nThe rest of the vignette walks through the process in a bit more detail and compares to replication code from Hernán and Robins.\n\nWe can compute average predictions in the original data, and average predictions in the two counterfactual datasets like this:\n\n\nR\nPython\n\n\n\n\n## average predicted outcome in the original data\np &lt;- predictions(fit)\nmean(p$estimate)\n\n[1] 2.6383\n\n## average predicted outcome in the two counterfactual datasets\np &lt;- predictions(fit, newdata = datagrid(qsmk = 0:1, grid_type = \"counterfactual\"))\naggregate(estimate ~ qsmk, data = p, FUN = mean)\n\n  qsmk estimate\n1    0 1.756213\n2    1 5.273587\n\n\n\n\n\n## average predicted outcome in the original data\np = predictions(fit)\nprint(p['estimate'].mean())\n\n2.6382997865627953\n\n## average predicted outcome in the two counterfactual datasets\np = predictions(fit, newdata = datagrid(qsmk = [0,1], grid_type = \"counterfactual\"))\nagg = p.group_by('qsmk').agg(pl.col('estimate').mean())\nprint(agg)\n\nshape: (2, 2)\n┌──────┬──────────┐\n│ qsmk ┆ estimate │\n│ ---  ┆ ---      │\n│ i64  ┆ f64      │\n╞══════╪══════════╡\n│ 1    ┆ 5.273587 │\n│ 0    ┆ 1.756213 │\n└──────┴──────────┘\n\n\n\n\n\n\n\nR\nPython\n\n\n\nIn the R code that accompanies their book, Hernán and Robins compute the same quantities manually, as follows:\n\n## create a dataset with 3 copies of each subject\nnhefs$interv &lt;- -1 # 1st copy: equal to original one\n\ninterv0 &lt;- nhefs # 2nd copy: treatment set to 0, outcome to missing\ninterv0$interv &lt;- 0\ninterv0$qsmk &lt;- 0\ninterv0$wt82_71 &lt;- NA\n\ninterv1 &lt;- nhefs # 3rd copy: treatment set to 1, outcome to missing\ninterv1$interv &lt;- 1\ninterv1$qsmk &lt;- 1\ninterv1$wt82_71 &lt;- NA\n\nonesample &lt;- rbind(nhefs, interv0, interv1) # combining datasets\n\n## linear model to estimate mean outcome conditional on treatment and confounders\n## parameters are estimated using original observations only (nhefs)\n## parameter estimates are used to predict mean outcome for observations with \n## treatment set to 0 (interv=0) and to 1 (interv=1)\n\nstd &lt;- glm(f, data = onesample)\nonesample$predicted_meanY &lt;- predict(std, onesample)\n\n## estimate mean outcome in each of the groups interv=0, and interv=1\n## this mean outcome is a weighted average of the mean outcomes in each combination \n## of values of treatment and confounders, that is, the standardized outcome\nmean(onesample[which(onesample$interv == -1), ]$predicted_meanY)\n\n[1] 2.6383\n\nmean(onesample[which(onesample$interv == 0), ]$predicted_meanY)\n\n[1] 1.756213\n\nmean(onesample[which(onesample$interv == 1), ]$predicted_meanY)\n\n[1] 5.273587\n\n\n\n\nThe R code manually computing these quantities that accompanies Hernán and Robins’ book can be translated into Python as follows :\n\n# create a dataset with 3 copies of each subject\nnhefs = nhefs.with_columns(\n    pl.lit(-1).alias('interv') # 1st copy: equal to original one\n)\n\ninterv0 = nhefs # 2nd copy: treatment set to 0, outcome to missing\ninterv0 = interv0.with_columns(\n    pl.lit(0).alias('interv'),\n    pl.lit(0).alias('qsmk').cast(pl.Int64),\n    pl.lit(None).alias('wt82_71')\n)\n\ninterv1 = nhefs # 3rd copy: treatment set to 1, outcome to missing\ninterv1 = interv1.with_columns(\n    pl.lit(1).alias('interv'),\n    pl.lit(1).alias('qsmk').cast(pl.Int64),\n    pl.lit(None).alias('wt82_71')\n)\n\n## linear model to estimate mean outcome conditional on treatment and confounders\n## parameters are estimated using original observations only (nhefs)\n\nstd = smf.glm(f, data = nhefs.to_pandas()).fit()\n\nonesample = pl.concat([nhefs, interv0, interv1], how='vertical') # combining datasets\n\n## parameter estimates are used to predict mean outcome for observations with \n## treatment set to 0 (interv=0) and to 1 (interv=1)\nonesample = onesample.with_columns(\n    pl.Series(name = 'predicted_meanY', values = std.predict(onesample.to_pandas()))\n)\n\n## estimate mean outcome in each of the groups interv=0, and interv=1\n## this mean outcome is a weighted average of the mean outcomes in each combination \n## of values of treatment and confounders, that is, the standardized outcome\nonesample.filter(pl.col('interv') == -1)['predicted_meanY'].mean()\n\n2.638299786562795\n\nonesample.filter(pl.col('interv') == 0)['predicted_meanY'].mean()\n\n1.7562131154657705\n\nonesample.filter(pl.col('interv') == 1)['predicted_meanY'].mean()\n\n5.27358731635129\n\n\n\n\n\nIt may be useful to note that the datagrid() function provided by marginaleffects can create counterfactual datasets automatically. This is equivalent to the onesample dataset:\n\n\nR\nPython\n\n\n\n\nnd &lt;- datagrid(\n    model = fit,\n    qsmk = c(0, 1),\n    grid_type = \"counterfactual\")\n\n\n\n\nnd = datagrid(\n    model = fit,\n    qsmk = [0,1],\n    grid_type = \"counterfactual\")\n\n\n\n\n\nNow we want to compute the treatment effect with the parametric g-formula, which is the difference in average predicted outcomes in the two counterfactual datasets. This is equivalent to taking the average contrast with the comparisons() function. There are three important things to note in the command that follows:\n\nThe variables argument is used to indicate that we want to estimate a “contrast” between adjusted predictions when qsmk is equal to 1 or 0.\n\ncomparisons() automatically produces estimates of uncertainty.\n\n\n\nR\nPython\n\n\n\n\navg_comparisons(std, variables = list(qsmk = 0:1))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.52       0.44 7.99   &lt;0.001 49.4  2.65   4.38\n\nTerm: qsmk\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n\ncmp = avg_comparisons(std, variables = {\"qsmk\" : [0,1]})\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n│ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n│ qsmk ┆ mean(True) - mean(False) ┆ 3.52     ┆ 0.44      ┆ … ┆ 1.33e-15 ┆ 49.4 ┆ 2.65 ┆ 4.38  │\n└──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nUnder the hood, comparisons() did exactly what we described in the g-formula steps above:\nWe can obtain the same result by manually computing the quantities, using the replication code from Hernán and Robins:\n\n\nR\nPython\n\n\n\n\nmean(onesample[which(onesample$interv == 1), ]$predicted_meanY) -\nmean(onesample[which(onesample$interv == 0), ]$predicted_meanY)\n\n[1] 3.517374\n\n\n\n\n\nonesample.filter(pl.col('interv')==1)[\"predicted_meanY\"].mean() -\\\nonesample.filter(pl.col('interv')==0)[\"predicted_meanY\"].mean()\n\n3.5173742008855196\n\n\n\n\n\nAlthough manual computation is simple, it does not provide uncertainty estimates. In contrast, comparisons() has already computed the standard error and confidence interval using the delta method.\nInstead of the delta method, most analysts will rely on bootstrapping. For example, the replication code from Hernán and Robins does this:\n\n## function to calculate difference in means\nstandardization &lt;- function(data, indices) {\n    # create a dataset with 3 copies of each subject\n    d &lt;- data[indices, ] # 1st copy: equal to original one`\n    d$interv &lt;- -1\n    d0 &lt;- d # 2nd copy: treatment set to 0, outcome to missing\n    d0$interv &lt;- 0\n    d0$qsmk &lt;- 0\n    d0$wt82_71 &lt;- NA\n    d1 &lt;- d # 3rd copy: treatment set to 1, outcome to missing\n    d1$interv &lt;- 1\n    d1$qsmk &lt;- 1\n    d1$wt82_71 &lt;- NA\n    d.onesample &lt;- rbind(d, d0, d1) # combining datasets\n\n    # linear model to estimate mean outcome conditional on treatment and confounders\n    # parameters are estimated using original observations only (interv= -1)\n    # parameter estimates are used to predict mean outcome for observations with set\n    # treatment (interv=0 and interv=1)\n    fit &lt;- glm(f, data = d.onesample)\n\n    d.onesample$predicted_meanY &lt;- predict(fit, d.onesample)\n\n    # estimate mean outcome in each of the groups interv=-1, interv=0, and interv=1\n    return(mean(d.onesample$predicted_meanY[d.onesample$interv == 1]) -\n           mean(d.onesample$predicted_meanY[d.onesample$interv == 0]))\n}\n\n## bootstrap\nresults &lt;- boot(data = nhefs, statistic = standardization, R = 1000)\n\n## generating confidence intervals\nse &lt;- sd(results$t[, 1])\nmeant0 &lt;- results$t0\nll &lt;- meant0 - qnorm(0.975) * se\nul &lt;- meant0 + qnorm(0.975) * se\n\nbootstrap &lt;- data.frame(\n    \" \" = \"Treatment - No Treatment\",\n    estimate = meant0,\n    std.error = se,\n    conf.low = ll,\n    conf.high = ul,\n    check.names = FALSE)\nbootstrap\n\n                           estimate std.error conf.low conf.high\n1 Treatment - No Treatment 3.517374 0.4735009  2.58933  4.445419\n\n\nThe results are close to those that we obtained with comparisons(), but the confidence interval differs slightly because of the difference between bootstrapping and the delta method.\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit, variables = list(qsmk = 0:1))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.52       0.44 7.99   &lt;0.001 49.4  2.65   4.38\n\nTerm: qsmk\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n\ncmp = avg_comparisons(std, variables = {\"qsmk\" : [0,1]})\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n│ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n│ qsmk ┆ mean(True) - mean(False) ┆ 3.52     ┆ 0.44      ┆ … ┆ 1.33e-15 ┆ 49.4 ┆ 2.65 ┆ 4.38  │\n└──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high",
    "crumbs": [
      "Get started",
      "Case studies",
      "G-Computation"
    ]
  },
  {
    "objectID": "vignettes/gcomputation.html#what-is-the-parametric-g-formula",
    "href": "vignettes/gcomputation.html#what-is-the-parametric-g-formula",
    "title": "G-Computation",
    "section": "",
    "text": "The parametric g-formula is a method of standardization which can be used to address confounding problems in causal inference with observational data. It relies on the same identification assumptions as Inverse Probability Weighting (IPW), but uses different modeling assumptions. Whereas IPW models the treatment equation, standardization models the mean outcome equation. As Hernán and Robins note:\n\n“Both IP weighting and standardization are estimators of the g-formula, a general method for causal inference first described in 1986. … We say that standardization is a”plug-in g-formula estimator” because it simply replaces the conditional mean outcome in the g-formula by its estimates. When, like in Chapter 13, those estimates come from parametric models, we refer to the method as the parametric g-formula.”",
    "crumbs": [
      "Get started",
      "Case studies",
      "G-Computation"
    ]
  },
  {
    "objectID": "vignettes/gcomputation.html#how-does-it-work",
    "href": "vignettes/gcomputation.html#how-does-it-work",
    "title": "G-Computation",
    "section": "",
    "text": "Imagine a causal model like this:\n\n\n\n\n\ngraph LR;\n    W --&gt; X;\n    W --&gt; Y;\n    X --&gt; Y;\n\n\n\n\n\n\nWe want to estimate the effect of a binary treatment \\(X\\) on outcome \\(Y\\), but there is a confounding variable \\(W\\). We can use standardization with the parametric g-formula to handle this. Roughly speaking, the procedure is as follows:\n\nUse the observed data to fit a regression model with \\(Y\\) as outcome, \\(X\\) as treatment, and \\(W\\) as control variable (with perhaps some polynomials and/or interactions if there are multiple control variables).\nCreate a new dataset exactly identical to the original data, but where \\(X=1\\) in every row.\nCreate a new dataset exactly identical to the original data, but where \\(X=0\\) in every row.\nUse the model from Step 1 to compute adjusted predictions in the two counterfactual datasets from Steps 2 and 3.\nThe quantity of interest is the difference between the means of adjusted predictions in the two counterfactual datasets.\n\nThis is equivalent to computing an “Average Contrast”, in which the value of \\(X\\) moves from 0 to 1. Thanks to this equivalence, we can apply the parametric g-formula method using a single line of code in marginaleffects, and obtain delta method standard errors automatically.",
    "crumbs": [
      "Get started",
      "Case studies",
      "G-Computation"
    ]
  },
  {
    "objectID": "vignettes/gcomputation.html#example-with-real-world-data",
    "href": "vignettes/gcomputation.html#example-with-real-world-data",
    "title": "G-Computation",
    "section": "",
    "text": "Let’s illustrate this method by replicating an example from Chapter 13 of Hernán and Robins. The data come from the National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study (NHEFS). The outcome is wt82_71, a measure of weight gain. The treatment is qsmk, a binary measure of smoking cessation. There are many confounders.\nStep 1 is to fit a regression model of the outcome on the treatment and control variables:\n\n\nR\nPython\n\n\n\n\nlibrary(boot)\nlibrary(marginaleffects)\n\nf &lt;- wt82_71 ~ qsmk + sex + race + age + I(age * age) + factor(education) +\n     smokeintensity + I(smokeintensity * smokeintensity) + smokeyrs +\n     I(smokeyrs * smokeyrs) + factor(exercise) + factor(active) + wt71 +\n     I(wt71 * wt71) + I(qsmk * smokeintensity)\n\nurl &lt;- \"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\"\nnhefs &lt;- read.csv(url)\nnhefs &lt;- na.omit(nhefs[, all.vars(f)])\n\nfit &lt;- glm(f, data = nhefs)\n\n\n\n\nimport polars as pl\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nf = \"wt82_71 ~ qsmk + sex + race + age + pow(age,2) + C(education) + \\\n    smokeintensity + pow(smokeintensity,2) + smokeyrs + \\\n    pow(smokeyrs,2) + C(exercise) + C(active) + wt71 + \\\n    pow(wt71,2) + qsmk*smokeintensity\"\n\nnhefs = pl.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\")\n\nvariables = [\"wt82_71\", \"qsmk\", \"sex\", \"race\", \"age\", \"education\", \"smokeintensity\", \"smokeyrs\", \"exercise\", \"active\", \"wt71\"]\nnhefs = nhefs.filter(\n    ~pl.any_horizontal(pl.col(variables).is_null())\n)\n\nfit = smf.glm(f, data=nhefs.to_pandas()).fit()\n\n\n\n\nSteps 2 and 3 require us to replicate the full dataset by setting the qsmk treatment to counterfactual values. We can do this automatically by calling comparisons().\n\nThese simple commands do everything we need to apply the parametric g-formula:\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit, variables = list(qsmk = 0:1))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.52       0.44 7.99   &lt;0.001 49.4  2.65   4.38\n\nTerm: qsmk\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n\ncmp = avg_comparisons(fit, variables = {'qsmk' : [0,1]})\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n│ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n│ qsmk ┆ mean(True) - mean(False) ┆ 3.52     ┆ 0.44      ┆ … ┆ 1.33e-15 ┆ 49.4 ┆ 2.65 ┆ 4.38  │\n└──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nThe rest of the vignette walks through the process in a bit more detail and compares to replication code from Hernán and Robins.\n\nWe can compute average predictions in the original data, and average predictions in the two counterfactual datasets like this:\n\n\nR\nPython\n\n\n\n\n## average predicted outcome in the original data\np &lt;- predictions(fit)\nmean(p$estimate)\n\n[1] 2.6383\n\n## average predicted outcome in the two counterfactual datasets\np &lt;- predictions(fit, newdata = datagrid(qsmk = 0:1, grid_type = \"counterfactual\"))\naggregate(estimate ~ qsmk, data = p, FUN = mean)\n\n  qsmk estimate\n1    0 1.756213\n2    1 5.273587\n\n\n\n\n\n## average predicted outcome in the original data\np = predictions(fit)\nprint(p['estimate'].mean())\n\n2.6382997865627953\n\n## average predicted outcome in the two counterfactual datasets\np = predictions(fit, newdata = datagrid(qsmk = [0,1], grid_type = \"counterfactual\"))\nagg = p.group_by('qsmk').agg(pl.col('estimate').mean())\nprint(agg)\n\nshape: (2, 2)\n┌──────┬──────────┐\n│ qsmk ┆ estimate │\n│ ---  ┆ ---      │\n│ i64  ┆ f64      │\n╞══════╪══════════╡\n│ 1    ┆ 5.273587 │\n│ 0    ┆ 1.756213 │\n└──────┴──────────┘\n\n\n\n\n\n\n\nR\nPython\n\n\n\nIn the R code that accompanies their book, Hernán and Robins compute the same quantities manually, as follows:\n\n## create a dataset with 3 copies of each subject\nnhefs$interv &lt;- -1 # 1st copy: equal to original one\n\ninterv0 &lt;- nhefs # 2nd copy: treatment set to 0, outcome to missing\ninterv0$interv &lt;- 0\ninterv0$qsmk &lt;- 0\ninterv0$wt82_71 &lt;- NA\n\ninterv1 &lt;- nhefs # 3rd copy: treatment set to 1, outcome to missing\ninterv1$interv &lt;- 1\ninterv1$qsmk &lt;- 1\ninterv1$wt82_71 &lt;- NA\n\nonesample &lt;- rbind(nhefs, interv0, interv1) # combining datasets\n\n## linear model to estimate mean outcome conditional on treatment and confounders\n## parameters are estimated using original observations only (nhefs)\n## parameter estimates are used to predict mean outcome for observations with \n## treatment set to 0 (interv=0) and to 1 (interv=1)\n\nstd &lt;- glm(f, data = onesample)\nonesample$predicted_meanY &lt;- predict(std, onesample)\n\n## estimate mean outcome in each of the groups interv=0, and interv=1\n## this mean outcome is a weighted average of the mean outcomes in each combination \n## of values of treatment and confounders, that is, the standardized outcome\nmean(onesample[which(onesample$interv == -1), ]$predicted_meanY)\n\n[1] 2.6383\n\nmean(onesample[which(onesample$interv == 0), ]$predicted_meanY)\n\n[1] 1.756213\n\nmean(onesample[which(onesample$interv == 1), ]$predicted_meanY)\n\n[1] 5.273587\n\n\n\n\nThe R code manually computing these quantities that accompanies Hernán and Robins’ book can be translated into Python as follows :\n\n# create a dataset with 3 copies of each subject\nnhefs = nhefs.with_columns(\n    pl.lit(-1).alias('interv') # 1st copy: equal to original one\n)\n\ninterv0 = nhefs # 2nd copy: treatment set to 0, outcome to missing\ninterv0 = interv0.with_columns(\n    pl.lit(0).alias('interv'),\n    pl.lit(0).alias('qsmk').cast(pl.Int64),\n    pl.lit(None).alias('wt82_71')\n)\n\ninterv1 = nhefs # 3rd copy: treatment set to 1, outcome to missing\ninterv1 = interv1.with_columns(\n    pl.lit(1).alias('interv'),\n    pl.lit(1).alias('qsmk').cast(pl.Int64),\n    pl.lit(None).alias('wt82_71')\n)\n\n## linear model to estimate mean outcome conditional on treatment and confounders\n## parameters are estimated using original observations only (nhefs)\n\nstd = smf.glm(f, data = nhefs.to_pandas()).fit()\n\nonesample = pl.concat([nhefs, interv0, interv1], how='vertical') # combining datasets\n\n## parameter estimates are used to predict mean outcome for observations with \n## treatment set to 0 (interv=0) and to 1 (interv=1)\nonesample = onesample.with_columns(\n    pl.Series(name = 'predicted_meanY', values = std.predict(onesample.to_pandas()))\n)\n\n## estimate mean outcome in each of the groups interv=0, and interv=1\n## this mean outcome is a weighted average of the mean outcomes in each combination \n## of values of treatment and confounders, that is, the standardized outcome\nonesample.filter(pl.col('interv') == -1)['predicted_meanY'].mean()\n\n2.638299786562795\n\nonesample.filter(pl.col('interv') == 0)['predicted_meanY'].mean()\n\n1.7562131154657705\n\nonesample.filter(pl.col('interv') == 1)['predicted_meanY'].mean()\n\n5.27358731635129\n\n\n\n\n\nIt may be useful to note that the datagrid() function provided by marginaleffects can create counterfactual datasets automatically. This is equivalent to the onesample dataset:\n\n\nR\nPython\n\n\n\n\nnd &lt;- datagrid(\n    model = fit,\n    qsmk = c(0, 1),\n    grid_type = \"counterfactual\")\n\n\n\n\nnd = datagrid(\n    model = fit,\n    qsmk = [0,1],\n    grid_type = \"counterfactual\")\n\n\n\n\n\nNow we want to compute the treatment effect with the parametric g-formula, which is the difference in average predicted outcomes in the two counterfactual datasets. This is equivalent to taking the average contrast with the comparisons() function. There are three important things to note in the command that follows:\n\nThe variables argument is used to indicate that we want to estimate a “contrast” between adjusted predictions when qsmk is equal to 1 or 0.\n\ncomparisons() automatically produces estimates of uncertainty.\n\n\n\nR\nPython\n\n\n\n\navg_comparisons(std, variables = list(qsmk = 0:1))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.52       0.44 7.99   &lt;0.001 49.4  2.65   4.38\n\nTerm: qsmk\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n\ncmp = avg_comparisons(std, variables = {\"qsmk\" : [0,1]})\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n│ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n│ qsmk ┆ mean(True) - mean(False) ┆ 3.52     ┆ 0.44      ┆ … ┆ 1.33e-15 ┆ 49.4 ┆ 2.65 ┆ 4.38  │\n└──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\nUnder the hood, comparisons() did exactly what we described in the g-formula steps above:\nWe can obtain the same result by manually computing the quantities, using the replication code from Hernán and Robins:\n\n\nR\nPython\n\n\n\n\nmean(onesample[which(onesample$interv == 1), ]$predicted_meanY) -\nmean(onesample[which(onesample$interv == 0), ]$predicted_meanY)\n\n[1] 3.517374\n\n\n\n\n\nonesample.filter(pl.col('interv')==1)[\"predicted_meanY\"].mean() -\\\nonesample.filter(pl.col('interv')==0)[\"predicted_meanY\"].mean()\n\n3.5173742008855196\n\n\n\n\n\nAlthough manual computation is simple, it does not provide uncertainty estimates. In contrast, comparisons() has already computed the standard error and confidence interval using the delta method.\nInstead of the delta method, most analysts will rely on bootstrapping. For example, the replication code from Hernán and Robins does this:\n\n## function to calculate difference in means\nstandardization &lt;- function(data, indices) {\n    # create a dataset with 3 copies of each subject\n    d &lt;- data[indices, ] # 1st copy: equal to original one`\n    d$interv &lt;- -1\n    d0 &lt;- d # 2nd copy: treatment set to 0, outcome to missing\n    d0$interv &lt;- 0\n    d0$qsmk &lt;- 0\n    d0$wt82_71 &lt;- NA\n    d1 &lt;- d # 3rd copy: treatment set to 1, outcome to missing\n    d1$interv &lt;- 1\n    d1$qsmk &lt;- 1\n    d1$wt82_71 &lt;- NA\n    d.onesample &lt;- rbind(d, d0, d1) # combining datasets\n\n    # linear model to estimate mean outcome conditional on treatment and confounders\n    # parameters are estimated using original observations only (interv= -1)\n    # parameter estimates are used to predict mean outcome for observations with set\n    # treatment (interv=0 and interv=1)\n    fit &lt;- glm(f, data = d.onesample)\n\n    d.onesample$predicted_meanY &lt;- predict(fit, d.onesample)\n\n    # estimate mean outcome in each of the groups interv=-1, interv=0, and interv=1\n    return(mean(d.onesample$predicted_meanY[d.onesample$interv == 1]) -\n           mean(d.onesample$predicted_meanY[d.onesample$interv == 0]))\n}\n\n## bootstrap\nresults &lt;- boot(data = nhefs, statistic = standardization, R = 1000)\n\n## generating confidence intervals\nse &lt;- sd(results$t[, 1])\nmeant0 &lt;- results$t0\nll &lt;- meant0 - qnorm(0.975) * se\nul &lt;- meant0 + qnorm(0.975) * se\n\nbootstrap &lt;- data.frame(\n    \" \" = \"Treatment - No Treatment\",\n    estimate = meant0,\n    std.error = se,\n    conf.low = ll,\n    conf.high = ul,\n    check.names = FALSE)\nbootstrap\n\n                           estimate std.error conf.low conf.high\n1 Treatment - No Treatment 3.517374 0.4735009  2.58933  4.445419\n\n\nThe results are close to those that we obtained with comparisons(), but the confidence interval differs slightly because of the difference between bootstrapping and the delta method.\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit, variables = list(qsmk = 0:1))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.52       0.44 7.99   &lt;0.001 49.4  2.65   4.38\n\nTerm: qsmk\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\n\ncmp = avg_comparisons(std, variables = {\"qsmk\" : [0,1]})\nprint(cmp)\n\nshape: (1, 9)\n┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n│ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n│ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n│ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n│ qsmk ┆ mean(True) - mean(False) ┆ 3.52     ┆ 0.44      ┆ … ┆ 1.33e-15 ┆ 49.4 ┆ 2.65 ┆ 4.38  │\n└──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n\nColumns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high",
    "crumbs": [
      "Get started",
      "Case studies",
      "G-Computation"
    ]
  },
  {
    "objectID": "vignettes/elasticity.html",
    "href": "vignettes/elasticity.html",
    "title": "Elasticity",
    "section": "",
    "text": "Elasticity\nIn some contexts, it is useful to interpret the results of a regression model in terms of elasticity or semi-elasticity. One strategy to achieve that is to estimate a log-log or a semilog model, where the left and/or right-hand side variables are logged. Another approach is to note that \\(\\frac{\\partial ln(x)}{\\partial x}=\\frac{1}{x}\\), and to post-process the marginal effects to transform them into elasticities or semi-elasticities.\nFor example, say we estimate a linear model of this form:\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon\\]\nLet \\(\\hat{y}\\) be the adjusted prediction made by the model for some combination of covariates \\(x_1\\) and \\(x_2\\). The slope with respect to \\(x_1\\) (or “marginal effect”) is:\n\\[\\frac{\\partial \\hat{y}}{\\partial x_1}\\]\nWe can estimate the “eyex”, “eydx”, and “dyex” (semi-)elasticities with respect to \\(x_1\\) as follows:\n\\[\\eta_1=\\frac{\\partial \\hat{y}}{\\partial x_1}\\cdot \\frac{x_1}{\\hat{y}}\\] \\[\\eta_2=\\frac{\\partial \\hat{y}}{\\partial x_1}\\cdot \\frac{1}{\\hat{y}}\\] \\[\\eta_3=\\frac{\\partial \\hat{y}}{\\partial x_1}\\cdot x_1\\]\nwith interpretations roughly as follows:\n\nA percentage point increase in \\(x_1\\) is associated to a \\(\\eta_1\\) percentage points increase in \\(y\\).\nA unit increase in \\(x_1\\) is associated to a \\(\\eta_2\\) percentage points increase in \\(y\\).\nA percentage point increase in \\(x_1\\) is associated to a \\(\\eta_3\\) units increase in \\(y\\).\n\nFor further intuition, consider the ratio of change in \\(y\\) to change in \\(x\\): \\(\\frac{\\Delta y}{\\Delta x}\\). We can turn this ratio into a ratio between relative changes by dividing both the numerator and the denominator: \\(\\frac{\\frac{\\Delta y}{y}}{\\frac{\\Delta x}{x}}\\). This is of course linked to the expression for the \\(\\eta_1\\) elasticity above.\nWith the marginaleffects package, these quantities are easy to compute:\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + wt, data = mtcars)\n\navg_slopes(mod)\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;    hp  -0.0318    0.00903 -3.52   &lt;0.001 11.2 -0.0495 -0.0141\n#&gt;    wt  -3.8778    0.63273 -6.13   &lt;0.001 30.1 -5.1180 -2.6377\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\navg_slopes(mod, slope = \"eyex\")\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    hp   -0.285     0.0855 -3.34   &lt;0.001 10.2 -0.453 -0.118\n#&gt;    wt   -0.746     0.1418 -5.26   &lt;0.001 22.7 -1.024 -0.468\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(eY/eX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\navg_slopes(mod, slope = \"eydx\")\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S    2.5 %    97.5 %\n#&gt;    hp -0.00173   0.000502 -3.46   &lt;0.001 10.8 -0.00272 -0.000751\n#&gt;    wt -0.21165   0.037849 -5.59   &lt;0.001 25.4 -0.28583 -0.137464\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(eY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\navg_slopes(mod, slope = \"dyex\")\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    hp    -4.66       1.32 -3.52   &lt;0.001 11.2  -7.26  -2.06\n#&gt;    wt   -12.48       2.04 -6.13   &lt;0.001 30.1 -16.47  -8.49\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/eX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Case studies",
      "Elasticity"
    ]
  },
  {
    "objectID": "vignettes/heterogeneity.html",
    "href": "vignettes/heterogeneity.html",
    "title": "Heterogeneity",
    "section": "",
    "text": "Heterogeneity\nauthor: “Vincent Arel-Bundock”\nThis short vignette illustrates how to use recursive partitioning to explore treatment effect heterogeneity. This exercise inspired by Scholbeck et al. 2022 and their concept of “cATE”.\nAs pointed out in other vignettes, most of the quantities estimated by the marginaleffects package are “conditional”, in the sense that they vary based on the values of all the predictors in our model. For instance, consider a Poisson regression that models the number of hourly bike rentals in Washington, DC:\n\nlibrary(marginaleffects)\nlibrary(partykit)\ndata(bikes, package = \"fmeffects\")\n\nmod &lt;- glm(\n    count ~ season * weekday + weather * temp,\n    data = bikes, family = quasipoisson)\n\nWe can use the comparisons() function to estimate how the predicted outcome changes for a 5 celsius increase in temperature:\n\ncmp &lt;- comparisons(mod, variables = list(temp = 5))\ncmp\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n      423       55.3 7.65   &lt;0.001 45.5   315    531\n      384       51.8 7.40   &lt;0.001 42.7   282    485\n      320       40.1 8.00   &lt;0.001 49.5   242    399\n      360       43.4 8.29   &lt;0.001 52.9   275    445\n      370       45.7 8.10   &lt;0.001 50.7   281    460\n--- 721 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n      418       48.3 8.66   &lt;0.001 57.6   323    513\n      426       50.0 8.51   &lt;0.001 55.7   328    524\n      366       44.0 8.33   &lt;0.001 53.5   280    453\n      304       40.6 7.50   &lt;0.001 43.9   225    384\n      343       40.5 8.47   &lt;0.001 55.2   264    422\nTerm: temp\nType:  response \nComparison: +5\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, count, season, weekday, weather, temp \n\n\nThe output printed above includes 727 rows: 1 for each of the rows in the original bikes dataset. Indeed, since the “effect” of a 5 unit increase depends on the values of covariates, different unit of observation will typically be associated with different contrasts.\nIn such cases, a common strategy is to compute an average difference, as described in the G-Computation vignette:\n\navg_comparisons(mod, variables = list(temp = 5))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n      689       64.1 10.7   &lt;0.001 87.1   564    815\n\nTerm: temp\nType:  response \nComparison: mean(+5)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nAlternatively, one may be interested in exploring heterogeneity in effect sizes in different subsets of the data. A convenient way to achieve this is to use the ctree function of the partykit package. This function allows us to use recursive partitioning (conditional inference trees) to find subspaces with reasonably homogenous estimates, and to report useful graphical and textual summaries.\nImagine that we are particularly interested in how the effect of temperature on bike rentals varies based on day of the week and season:\n\ntree &lt;- ctree(\n    estimate ~ weekday + season,\n    data = cmp,\n    control = ctree_control(maxdepth = 2)\n)\n\nNow we can use the plot() function to draw the distributions of estimates for the effect of an increase of 5C on bike rentals, by week day and season:\n\nplot(tree)\n\n\n\n\n\n\n\nTo obtain conditional average estimates for each subspace, we first use the predict() function in order to place each observation in the dataset in its corresponding “bucket” or “node”. Then, we use the by argument to indicate that comparisons() should compute average estimates for each of the nodes in the tree:\n\ndat &lt;- transform(bikes, nodeid = predict(tree, type = \"node\"))\ncomparisons(mod,\n    variables = list(temp = 5),\n    newdata = dat,\n    by = \"nodeid\")\n\n\n nodeid Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n      3      352       37.2  9.46   &lt;0.001 68.1   279    425\n      4      433       42.9 10.08   &lt;0.001 76.9   348    517\n      6      757       70.4 10.74   &lt;0.001 87.0   619    895\n      7      841       80.9 10.40   &lt;0.001 81.8   683   1000\n\nTerm: temp\nType:  response \nComparison: mean(+5)\nColumns: term, contrast, nodeid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nThe four nodeid values correspond to the terminal nodes in this tree:\n\nprint(tree)\n\n\nModel formula:\nestimate ~ weekday + season\n\nFitted party:\n[1] root\n|   [2] season in winter\n|   |   [3] weekday in Monday, Tuesday, Sunday: 351.902 (n = 80, err = 248952.3)\n|   |   [4] weekday in Wednesday, Thursday, Friday, Saturday: 432.617 (n = 101, err = 461053.1)\n|   [5] season in spring, summer, fall\n|   |   [6] season in spring, fall: 756.522 (n = 362, err = 7548395.3)\n|   |   [7] season in summer: 841.324 (n = 188, err = 2116175.9)\n\nNumber of inner nodes:    3\nNumber of terminal nodes: 4",
    "crumbs": [
      "Get started",
      "Case studies",
      "Heterogeneity"
    ]
  },
  {
    "objectID": "vignettes/brms.html",
    "href": "vignettes/brms.html",
    "title": "Bayes",
    "section": "",
    "text": "The marginaleffects package offers convenience functions to compute and display predictions, contrasts, and marginal effects from bayesian models estimated by the brms package. To compute these quantities, marginaleffects relies on workhorse functions from the brms package to draw from the posterior distribution. The type of draws used is controlled by using the type argument of the predictions or slopes functions:\n\n\ntype = \"response\": Compute posterior draws of the expected value using the brms::posterior_epred function.\n\ntype = \"link\": Compute posterior draws of the linear predictor using the brms::posterior_linpred function.\n\ntype = \"prediction\": Compute posterior draws of the posterior predictive distribution using the brms::posterior_predict function.\n\nThe predictions and slopes functions can also pass additional arguments to the brms prediction functions via the ... ellipsis. For example, if mod is a mixed-effects model, then this command will compute 10 draws from the posterior predictive distribution, while ignoring all group-level effects:\n\npredictions(mod, type = \"prediction\", ndraws = 10, re_formula = NA)\n\nSee the brms documentation for a list of available arguments:\n\n?brms::posterior_epred\n?brms::posterior_linpred\n?brms::posterior_predict\n\n\nLoad libraries and download data on passengers of the Titanic from the Rdatasets archive:\n\nlibrary(marginaleffects)\nlibrary(brms)\nlibrary(ggplot2)\nlibrary(ggdist)\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/carData/TitanicSurvival.csv\")\ndat$survived &lt;- ifelse(dat$survived == \"yes\", 1, 0)\ndat$woman &lt;- ifelse(dat$sex == \"female\", 1, 0)\n\nFit a logit model with a multiplicative interaction:\n\nmod &lt;- brm(survived ~ woman * age + passengerClass,\n           family = bernoulli(link = \"logit\"),\n           data = dat)\n\n\nWe can compute adjusted predicted values of the outcome variable (i.e., probability of survival aboard the Titanic) using the predictions function. By default, this function calculates predictions for each row of the dataset:\n\npredictions(mod)\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;    0.9367 0.9070 0.9590\n#&gt;    0.8493 0.7453 0.9187\n#&gt;    0.9433 0.8949 0.9704\n#&gt;    0.5131 0.4302 0.6000\n#&gt;    0.9375 0.9080 0.9601\n#&gt; --- 1036 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n#&gt;    0.0376 0.0235 0.0581\n#&gt;    0.5859 0.5017 0.6663\n#&gt;    0.1043 0.0801 0.1337\n#&gt;    0.1017 0.0779 0.1307\n#&gt;    0.0916 0.0691 0.1189\n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, survived, woman, age, passengerClass\n\nTo visualize the relationship between the outcome and one of the regressors, we can plot conditional adjusted predictions with the plot_predictions function:\n\nplot_predictions(mod, condition = \"age\")\n\n\n\n\n\n\n\nCompute adjusted predictions for some user-specified values of the regressors, using the newdata argument and the datagrid function:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(woman = 0:1,\n                                       passengerClass = c(\"1st\", \"2nd\", \"3rd\")))\npred\n#&gt; \n#&gt;  woman passengerClass Estimate  2.5 % 97.5 %\n#&gt;      0            1st   0.5149 0.4319  0.602\n#&gt;      0            2nd   0.2013 0.1536  0.261\n#&gt;      0            3rd   0.0875 0.0656  0.114\n#&gt;      1            1st   0.9364 0.9066  0.959\n#&gt;      1            2nd   0.7783 0.7090  0.835\n#&gt;      1            3rd   0.5701 0.4938  0.644\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, age, woman, passengerClass, survived\n\nThe posterior_draws function samples from the posterior distribution of the model, and produces a data frame with drawid and draw columns.\n\npred &lt;- posterior_draws(pred)\nhead(pred)\n#&gt;   drawid       draw rowid   estimate   conf.low conf.high      age woman passengerClass survived\n#&gt; 1      1 0.46566713     1 0.51492993 0.43192231 0.6018749 29.88113     0            1st        1\n#&gt; 2      1 0.16658900     2 0.20128833 0.15362308 0.2613351 29.88113     0            2nd        1\n#&gt; 3      1 0.08750961     3 0.08750369 0.06555724 0.1141134 29.88113     0            3rd        1\n#&gt; 4      1 0.93735755     4 0.93641346 0.90660921 0.9587589 29.88113     1            1st        1\n#&gt; 5      1 0.77437334     5 0.77829290 0.70896643 0.8346419 29.88113     1            2nd        1\n#&gt; 6      1 0.62216334     6 0.57010265 0.49377997 0.6441967 29.88113     1            3rd        1\n\nThis “long” format makes it easy to plots results:\n\nggplot(pred, aes(x = draw, fill = factor(woman))) +\n    geom_density() +\n    facet_grid(~ passengerClass, labeller = label_both) +\n    labs(x = \"Predicted probability of survival\", y = \"\", fill = \"Woman\")\n\n\n\n\n\n\n\n\nUse slopes() to compute marginal effects (slopes of the regression equation) for each row of the dataset, and use ) to compute “Average Marginal Effects”, that is, the average of all observation-level marginal effects:\n\nmfx &lt;- slopes(mod)\nmfx\n#&gt; \n#&gt;   Term Contrast  Estimate     2.5 %    97.5 %\n#&gt;  age      dY/dX -0.000237 -0.001335  0.000880\n#&gt;  age      dY/dX -0.007257 -0.008973 -0.005265\n#&gt;  age      dY/dX -0.000214 -0.000831  0.001242\n#&gt;  age      dY/dX -0.014258 -0.018487 -0.010306\n#&gt;  age      dY/dX -0.000234 -0.001242  0.000923\n#&gt; --- 4174 rows omitted. See ?avg_slopes and ?print.marginaleffects --- \n#&gt;  woman    1 - 0  0.516022  0.401674  0.630788\n#&gt;  woman    1 - 0  0.395843  0.307400  0.486515\n#&gt;  woman    1 - 0  0.468892  0.401425  0.536243\n#&gt;  woman    1 - 0  0.471069  0.403598  0.538028\n#&gt;  woman    1 - 0  0.478699  0.410060  0.547549\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx, survived, woman, age, passengerClass\n\nCompute marginal effects with some regressors fixed at user-specified values, and other regressors held at their means:\n\nslopes(\n    mod,\n    newdata = datagrid(\n        woman = 1,\n        passengerClass = \"1st\"))\n#&gt; \n#&gt;            Term  Contrast woman passengerClass  Estimate    2.5 %    97.5 %\n#&gt;  age            dY/dX         1            1st -0.000238 -0.00136  0.000871\n#&gt;  passengerClass 2nd - 1st     1            1st -0.157442 -0.22327 -0.102890\n#&gt;  passengerClass 3rd - 1st     1            1st -0.365376 -0.43832 -0.294769\n#&gt;  woman          1 - 0         1            1st  0.420368  0.34697  0.490373\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, conf.low, conf.high, woman, passengerClass, predicted_lo, predicted_hi, predicted, tmp_idx, age, survived\n\nCompute and plot conditional marginal effects:\n\nplot_slopes(mod, variables = \"woman\", condition = \"age\")\n\n\n\n\n\n\n\nThe posterior_draws produces a dataset with drawid and draw columns:\n\ndraws &lt;- posterior_draws(mfx)\n\ndim(draws)\n#&gt; [1] 16736000       16\n\nhead(draws)\n#&gt;   drawid          draw rowid term contrast      estimate      conf.low     conf.high predicted_lo predicted_hi predicted tmp_idx survived woman     age passengerClass\n#&gt; 1      1 -0.0001793450     1  age    dY/dX -0.0002373819 -0.0013354352  0.0008803236    0.9366624    0.9366585 0.9366604       1        1     1 29.0000            1st\n#&gt; 2      1 -0.0082459626     2  age    dY/dX -0.0072572604 -0.0089728266 -0.0052650726    0.8493348    0.8492752 0.8493050       2        1     0  0.9167            1st\n#&gt; 3      1 -0.0001667655     3  age    dY/dX -0.0002137451 -0.0008314784  0.0012415040    0.9433319    0.9433267 0.9433293       3        0     1  2.0000            1st\n#&gt; 4      1 -0.0160434697     4  age    dY/dX -0.0142578648 -0.0184866253 -0.0103056297    0.5131552    0.5130514 0.5131011       4        0     0 30.0000            1st\n#&gt; 5      1 -0.0001774318     5  age    dY/dX -0.0002336788 -0.0012419718  0.0009233460    0.9374947    0.9374927 0.9374937       5        0     1 25.0000            1st\n#&gt; 6      1 -0.0108173828     6  age    dY/dX -0.0112764204 -0.0143192681 -0.0085783113    0.2730949    0.2730116 0.2730542       6        1     0 48.0000            1st\n\nWe can use this dataset to plot our results. For example, to plot the posterior density of the marginal effect of age when the woman variable is equal to 0 or 1:\n\nmfx &lt;- slopes(mod,\n    variables = \"age\",\n    newdata = datagrid(woman = 0:1)) |&gt;\n    posterior_draws()\n\nggplot(mfx, aes(x = draw, fill = factor(woman))) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Marginal Effect of Age on Survival\",\n         y = \"Posterior density\",\n         fill = \"Woman\")\n\n\n\n\n\n\n\n\nThis section replicates some of the analyses of a random effects model published in Andrew Heiss’ blog post: “A guide to correctly calculating posterior predictions and average marginal effects with multilevel Bayesian models.” The objective is mainly to illustrate the use of marginaleffects. Please refer to the original post for a detailed discussion of the quantities computed below.\nLoad libraries and download data:\n\nlibrary(brms)\nlibrary(ggdist)\nlibrary(patchwork)\nlibrary(marginaleffects)\n\nvdem_2015 &lt;- read.csv(\"https://github.com/vincentarelbundock/marginaleffects/raw/main/data-raw/vdem_2015.csv\")\n\nhead(vdem_2015)\n#&gt;   country_name country_text_id year                           region media_index party_autonomy_ord polyarchy civil_liberties party_autonomy\n#&gt; 1       Mexico             MEX 2015  Latin America and the Caribbean       0.837                  3     0.631           0.704           TRUE\n#&gt; 2     Suriname             SUR 2015  Latin America and the Caribbean       0.883                  4     0.777           0.887           TRUE\n#&gt; 3       Sweden             SWE 2015 Western Europe and North America       0.956                  4     0.915           0.968           TRUE\n#&gt; 4  Switzerland             CHE 2015 Western Europe and North America       0.939                  4     0.901           0.960           TRUE\n#&gt; 5        Ghana             GHA 2015               Sub-Saharan Africa       0.858                  4     0.724           0.921           TRUE\n#&gt; 6 South Africa             ZAF 2015               Sub-Saharan Africa       0.898                  4     0.752           0.869           TRUE\n\nFit a basic model:\n\nmod &lt;- brm(\n  bf(media_index ~ party_autonomy + civil_liberties + (1 | region),\n     phi ~ (1 | region)),\n  data = vdem_2015,\n  family = Beta(),\n  control = list(adapt_delta = 0.9))\n\n\nTo compute posterior predictions for specific values of the regressors, we use the newdata argument and the datagrid function. We also use the type argument to compute two types of predictions: accounting for residual (observation-level) residual variance (prediction) or ignoring it (response).\n\nnd = datagrid(model = mod,\n              party_autonomy = c(TRUE, FALSE),\n              civil_liberties = .5,\n              region = \"Middle East and North Africa\")\np1 &lt;- predictions(mod, type = \"response\", newdata = nd) |&gt;\n    posterior_draws() |&gt;\n    transform(type = \"Response\")\np2 &lt;- predictions(mod, type = \"prediction\", newdata = nd) |&gt;\n    posterior_draws() |&gt;\n    transform(type = \"Prediction\")\npred &lt;- rbind(p1, p2)\n\nExtract posterior draws and plot them:\n\nggplot(pred, aes(x = draw, fill = party_autonomy)) +\n    stat_halfeye(alpha = .5) +\n    facet_wrap(~ type) +\n    labs(x = \"Media index (predicted)\", \n         y = \"Posterior density\",\n         fill = \"Party autonomy\")\n\n\n\n\n\n\n\n\nAs noted in the Marginal Effects vignette, there should be one distinct marginal effect for each combination of regressor values. Here, we consider only one combination of regressor values, where region is “Middle East and North Africa”, and civil_liberties is 0.5. Then, we calculate the mean of the posterior distribution of marginal effects:\n\nmfx &lt;- slopes(mod,\n                       newdata = datagrid(civil_liberties = .5,\n                                          region = \"Middle East and North Africa\"))\nmfx\n#&gt; \n#&gt;      Contrast civil_liberties                       region Estimate 2.5 % 97.5 %\n#&gt;  dY/dX                    0.5 Middle East and North Africa    0.816 0.621  1.007\n#&gt;  TRUE - FALSE             0.5 Middle East and North Africa    0.252 0.166  0.336\n#&gt; \n#&gt; Term: civil_liberties\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, conf.low, conf.high, civil_liberties, region, predicted_lo, predicted_hi, predicted, tmp_idx, party_autonomy, media_index\n\nUse the posterior_draws() to extract draws from the posterior distribution of marginal effects, and plot them:\n\nmfx &lt;- posterior_draws(mfx)\n\nggplot(mfx, aes(x = draw, y = term)) +\n  stat_halfeye() +\n  labs(x = \"Marginal effect\", y = \"\")\n\n\n\n\n\n\n\nPlot marginal effects, conditional on a regressor:\n\nplot_slopes(mod,\n         variables = \"civil_liberties\",\n         condition = \"party_autonomy\")\n\n\n\n\n\n\n\n\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(party_autonomy = FALSE,\n                                       region = \"Middle East and North Africa\",\n                                       civil_liberties = seq(0, 1, by = 0.05))) |&gt;\n        posterior_draws()\n\nggplot(pred, aes(x = civil_liberties, y = draw)) +\n    stat_lineribbon() +\n    scale_fill_brewer(palette = \"Reds\") +\n    labs(x = \"Civil liberties\",\n         y = \"Media index (predicted)\",\n         fill = \"\")\n\n\n\n\n\n\n\nThe slope of this line for different values of civil liberties can be obtained with:\n\nmfx &lt;- slopes(mod,\n    newdata = datagrid(\n        civil_liberties = c(.2, .5, .8),\n        party_autonomy = FALSE,\n        region = \"Middle East and North Africa\"),\n    variables = \"civil_liberties\")\nmfx\n#&gt; \n#&gt;             Term civil_liberties party_autonomy                       region Estimate 2.5 % 97.5 %\n#&gt;  civil_liberties             0.2          FALSE Middle East and North Africa    0.490 0.361  0.639\n#&gt;  civil_liberties             0.5          FALSE Middle East and North Africa    0.807 0.612  0.993\n#&gt;  civil_liberties             0.8          FALSE Middle East and North Africa    0.807 0.675  0.934\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, conf.low, conf.high, civil_liberties, party_autonomy, region, predicted_lo, predicted_hi, predicted, tmp_idx, media_index\n\nAnd plotted:\n\nmfx &lt;- posterior_draws(mfx)\n\nggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Marginal effect of Civil Liberties on Media Index\",\n         y = \"Posterior density\",\n         fill = \"Civil liberties\")\n\n\n\n\n\n\n\nThe slopes function can use the ellipsis (...) to push any argument forward to the posterior_predict function. This can alter the types of predictions returned. For example, the re_formula=NA argument of the posterior_predict.brmsfit method will compute marginaleffects without including any group-level effects:\n\nmfx &lt;- slopes(\n    mod,\n    newdata = datagrid(\n        civil_liberties = c(.2, .5, .8),\n        party_autonomy = FALSE,\n        region = \"Middle East and North Africa\"),\n    variables = \"civil_liberties\",\n    re_formula = NA) |&gt;\n    posterior_draws()\n\nggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Marginal effect of Civil Liberties on Media Index\",\n         y = \"Posterior density\",\n         fill = \"Civil liberties\")\n\n\n\n\n\n\n\n\n\npred &lt;- predictions(\n    mod,\n    re_formula = NA,\n    newdata = datagrid(party_autonomy = c(TRUE, FALSE))) |&gt;\n    posterior_draws()\n\nmfx &lt;- slopes(\n    mod,\n    re_formula = NA,\n    variables = \"party_autonomy\") |&gt;\n    posterior_draws()\n\nplot1 &lt;- ggplot(pred, aes(x = draw, fill = party_autonomy)) +\n         stat_halfeye(slab_alpha = .5) +\n         labs(x = \"Media index (Predicted)\",\n              y = \"Posterior density\",\n              fill = \"Party autonomy\")\n\nplot2 &lt;- ggplot(mfx, aes(x = draw)) +\n         stat_halfeye(slab_alpha = .5)  +\n         labs(x = \"Contrast: Party autonomy TRUE - FALSE\",\n              y = \"\",\n              fill = \"Party autonomy\")\n\n## combine plots using the `patchwork` package\nplot1 + plot2\n\n\n\n\n\n\n\n\nPredicted media index by region and level of civil liberties:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(region = vdem_2015$region,\n                                       party_autonomy = FALSE, \n                                       civil_liberties = seq(0, 1, length.out = 100))) |&gt; \n        posterior_draws()\n\nggplot(pred, aes(x = civil_liberties, y = draw)) +\n    stat_lineribbon() +\n    scale_fill_brewer(palette = \"Reds\") +\n    facet_wrap(~ region) +\n    labs(x = \"Civil liberties\",\n         y = \"Media index (predicted)\",\n         fill = \"\")\n\n\n\n\n\n\n\nPredicted media index by region and level of civil liberties:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(region = vdem_2015$region,\n                                       civil_liberties = c(.2, .8),\n                                      party_autonomy = FALSE)) |&gt;\n        posterior_draws()\n\nggplot(pred, aes(x = draw, fill = factor(civil_liberties))) +\n    stat_halfeye(slab_alpha = .5) +\n    facet_wrap(~ region) +\n    labs(x = \"Media index (predicted)\",\n         y = \"Posterior density\",\n         fill = \"Civil liberties\")\n\n\n\n\n\n\n\nPredicted media index by region and party autonomy:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(region = vdem_2015$region,\n                                       party_autonomy = c(TRUE, FALSE),\n                                       civil_liberties = .5)) |&gt;\n        posterior_draws()\n\nggplot(pred, aes(x = draw, y = region , fill = party_autonomy)) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Media index (predicted)\",\n         y = \"\",\n         fill = \"Party autonomy\")\n\n\n\n\n\n\n\nTRUE/FALSE contrasts (marginal effects) of party autonomy by region:\n\nmfx &lt;- slopes(\n    mod,\n    variables = \"party_autonomy\",\n    newdata = datagrid(\n        region = vdem_2015$region,\n        civil_liberties = .5)) |&gt;\n    posterior_draws()\n\nggplot(mfx, aes(x = draw, y = region , fill = party_autonomy)) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Media index (predicted)\",\n         y = \"\",\n         fill = \"Party autonomy\")\n\n\n\n\n\n\n\n\nWe can also obtain predictions or marginal effects for a hypothetical group instead of one of the observed regions. To achieve this, we create a dataset with NA in the region column. Then we call the marginaleffects or predictions functions with the allow_new_levels argument. This argument is pushed through via the ellipsis (...) to the posterior_epred function of the brms package:\n\ndat &lt;- data.frame(civil_liberties = .5,\n                  party_autonomy = FALSE,\n                  region = \"New Region\")\n\nmfx &lt;- slopes(\n    mod,\n    variables = \"party_autonomy\",\n    allow_new_levels = TRUE,\n    newdata = dat)\n\ndraws &lt;- posterior_draws(mfx)\n\nggplot(draws, aes(x = draw)) +\n     stat_halfeye() +\n     labs(x = \"Marginal effect of party autonomy in a generic world region\", y = \"\")\n\n\n\n\n\n\n\n\nConsider a logistic regression model with random effects:\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/plm/EmplUK.csv\")\ndat$x &lt;- as.numeric(dat$output &gt; median(dat$output))\ndat$y &lt;- as.numeric(dat$emp &gt; median(dat$emp))\nmod &lt;- brm(y ~ x + (1 | firm), data = dat, backend = \"cmdstanr\", family = \"bernoulli\")\n\nWe can compute adjusted predictions for a given value of x and for each firm (random effects) as follows:\n\np &lt;- predictions(mod, newdata = datagrid(x = 0, firm = unique))\nhead(p)\n#&gt; \n#&gt;  x firm Estimate    2.5 % 97.5 %\n#&gt;  0    1  1.0e+00 9.01e-01 1.0000\n#&gt;  0    2  1.0e+00 8.95e-01 1.0000\n#&gt;  0    3  1.0e+00 9.12e-01 1.0000\n#&gt;  0    4  1.0e+00 7.97e-01 1.0000\n#&gt;  0    5  1.0e+00 9.09e-01 1.0000\n#&gt;  0    6  4.9e-08 8.42e-21 0.0019\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, x, firm, y\n\nWe can average/marginalize/integrate across random effects with the avg_predictions() function or the by argument:\n\navg_predictions(mod, newdata = datagrid(x = 0, firm = unique))\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.454  0.44  0.468\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, conf.low, conf.high\n\npredictions(mod, newdata = datagrid(x = 0:1, firm = unique), by = \"x\")\n#&gt; \n#&gt;  x Estimate 2.5 % 97.5 %\n#&gt;  0    0.454 0.440  0.468\n#&gt;  1    0.557 0.546  0.570\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: x, estimate, conf.low, conf.high\n\nWe can also draw from the (assumed gaussian) population distribution of random effects, by asking predictions() to make predictions for new “levels” of the random effects. If we then take an average of predictions using avg_predictions() or the by argument, we will have “integrated out the random effects”, as described in the brmsmargins package vignette. In the code below, we make predictions for 100 firm identifiers which were not in the original dataset. We also ask predictions() to push forward the allow_new_levels and sample_new_levels arguments to the brms::posterior_epred function:\n\npredictions(\n    mod,\n    newdata = datagrid(x = 0:1, firm = -1:-100),\n    allow_new_levels = TRUE,\n    sample_new_levels = \"gaussian\",\n    by = \"x\")\n#&gt; \n#&gt;  x Estimate 2.5 % 97.5 %\n#&gt;  0    0.451 0.339  0.566\n#&gt;  1    0.550 0.440  0.666\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: x, estimate, conf.low, conf.high\n\nWe can “integrate out” random effects in the other slopes functions too. For instance,\n\navg_comparisons(\n    mod,\n    newdata = datagrid(firm = -1:-100),\n    allow_new_levels = TRUE,\n    sample_new_levels = \"gaussian\")\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;    0.0971 0.0465   0.16\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nThis is nearly equivalent the brmsmargins command output (with slight variations due to different random seeds):\n\nlibrary(brmsmargins)\nbm &lt;- brmsmargins(\n  k = 100,\n  object = mod,\n  at = data.frame(x = c(0, 1)),\n  CI = .95,\n  CIType = \"ETI\",\n  contrasts = cbind(\"AME x\" = c(-1, 1)),\n  effects = \"integrateoutRE\")\nbm$ContrastSummary |&gt; data.frame()\n#&gt;            M        Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 0.09883675 0.09683602 0.04765318 0.1607502          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\nSee the alternative software vignette for more information on brmsmargins.\n\nFit a model with categorical outcome (heating system choice in California houses) and logit link:\n\ndat &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Heating.csv\"\ndat &lt;- read.csv(dat)\nmod &lt;- brm(depvar ~ ic.gc + oc.gc,\n           data = dat,\n           family = categorical(link = \"logit\"))\n\n\nCompute predicted probabilities for each level of the outcome variable:\n\npred &lt;- predictions(mod)\n\nhead(pred)\n#&gt; \n#&gt;  Group Estimate  2.5 % 97.5 %\n#&gt;     ec   0.0663 0.0447 0.0930\n#&gt;     ec   0.0768 0.0590 0.0974\n#&gt;     ec   0.1030 0.0618 0.1585\n#&gt;     ec   0.0634 0.0459 0.0838\n#&gt;     ec   0.0745 0.0574 0.0947\n#&gt;     ec   0.0709 0.0455 0.1036\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, group, estimate, conf.low, conf.high, depvar, ic.gc, oc.gc\n\nExtract posterior draws and plot them:\n\ndraws &lt;- posterior_draws(pred)\n\nggplot(draws, aes(x = draw, fill = group)) +\n    geom_density(alpha = .2, color = \"white\") +\n    labs(x = \"Predicted probability\",\n         y = \"Density\",\n         fill = \"Heating system\")\n\n\n\n\n\n\n\nUse the plot_predictions function to plot conditional adjusted predictions for each level of the outcome variable gear, conditional on the value of the mpg regressor:\n\nplot_predictions(mod, condition = \"oc.gc\") +\n    facet_wrap(~ group) +\n    labs(y = \"Predicted probability\")\n\n\n\n\n\n\n\n\n\navg_slopes(mod)\n#&gt; \n#&gt;  Group  Term  Estimate     2.5 %   97.5 %\n#&gt;     ec ic.gc -1.77e-04 -3.96e-04 2.37e-05\n#&gt;     ec oc.gc  4.88e-04 -4.04e-04 1.45e-03\n#&gt;     er ic.gc  1.65e-05 -2.26e-04 2.51e-04\n#&gt;     er oc.gc -1.02e-03 -2.07e-03 2.98e-05\n#&gt;     gc ic.gc  1.38e-05 -3.72e-04 4.00e-04\n#&gt;     gc oc.gc  1.04e-03 -7.39e-04 2.78e-03\n#&gt;     gr ic.gc  4.24e-05 -2.37e-04 3.29e-04\n#&gt;     gr oc.gc  9.46e-05 -1.19e-03 1.34e-03\n#&gt;     hp ic.gc  1.07e-04 -7.73e-05 2.97e-04\n#&gt;     hp oc.gc -5.85e-04 -1.45e-03 2.30e-04\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\nThis section replicates some analyses from yet another amazing blog post by Andrew Heiss.\nTo begin, we estimate a hurdle model in brms with random effects, using data from the gapminder package: 704G\n\nlibrary(gapminder)\nlibrary(brms)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggdist)\nlibrary(cmdstanr)\nlibrary(patchwork)\nlibrary(marginaleffects)\n\nset.seed(1024)\n\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\ngapminder &lt;- gapminder::gapminder |&gt; \n  filter(continent != \"Oceania\") |&gt; \n  # Make a bunch of GDP values 0\n  mutate(prob_zero = ifelse(lifeExp &lt; 50, 0.3, 0.02),\n         will_be_zero = rbinom(n(), 1, prob = prob_zero),\n         gdpPercap = ifelse(will_be_zero, 0, gdpPercap)) |&gt; \n  select(-prob_zero, -will_be_zero) |&gt; \n  # Make a logged version of GDP per capita\n  mutate(log_gdpPercap = log1p(gdpPercap)) |&gt; \n  mutate(is_zero = gdpPercap == 0)\n\nmod &lt;- brm(\n  bf(gdpPercap ~ lifeExp + year + (1 + lifeExp + year | continent),\n     hu ~ lifeExp),\n  data = gapminder,\n  backend = \"cmdstanr\",\n  family = hurdle_lognormal(),\n  cores = 2,\n  chains = CHAINS, iter = ITER, warmup = WARMUP, seed = BAYES_SEED,\n  silent = 2)\n\n\nAdjusted predictions for every observation in the original data:\n\npredictions(mod) |&gt; head()\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;       143   103    219\n#&gt;       168   125    256\n#&gt;       202   153    304\n#&gt;       251   197    373\n#&gt;       312   250    454\n#&gt;       398   325    567\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent\n\nAdjusted predictions for the hu parameter:\n\npredictions(mod, dpar = \"hu\") |&gt; head()\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.574 0.475  0.652\n#&gt;     0.537 0.442  0.611\n#&gt;     0.496 0.407  0.566\n#&gt;     0.446 0.366  0.511\n#&gt;     0.396 0.325  0.454\n#&gt;     0.341 0.282  0.391\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent\n\nPredictions on a different scale:\n\npredictions(mod, type = \"link\", dpar = \"hu\") |&gt; head()\n#&gt; \n#&gt;  Estimate  2.5 %  97.5 %\n#&gt;    0.2980 -0.101  0.6259\n#&gt;    0.1463 -0.235  0.4527\n#&gt;   -0.0178 -0.377  0.2673\n#&gt;   -0.2189 -0.551  0.0424\n#&gt;   -0.4234 -0.730 -0.1857\n#&gt;   -0.6573 -0.933 -0.4443\n#&gt; \n#&gt; Type:  link \n#&gt; Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent\n\nPlot adjusted predictions as a function of lifeExp:\n\nplot_predictions(\n    mod,\n    condition = \"lifeExp\") +\n    labs(y = \"mu\") +\nplot_predictions(\n    mod,\n    dpar = \"hu\",\n    condition = \"lifeExp\") +\n    labs(y = \"hu\")\n\n\n\n\n\n\n\nPredictions with more than one condition and the re_formula argument from brms:\n\nplot_predictions(\n    mod,\n    re_formula = NULL,\n    condition = c(\"lifeExp\", \"continent\"))\n\n\n\n\n\n\n\n\nThe posterior_draws() function extract raw samples from the posterior from objects produced by marginaleffects. This allows us to use richer geoms and summaries, such as those in the ggdist package:\n\npredictions(\n    mod,\n    re_formula = NULL,\n    newdata = datagrid(model = mod,\n                       continent = gapminder$continent,\n                       year = c(1952, 2007),\n                       lifeExp = seq(30, 80, 1))) |&gt;\n    posterior_draws() |&gt;\n    ggplot(aes(lifeExp, draw, fill = continent, color = continent)) +\n    stat_lineribbon(alpha = .25) +\n    facet_grid(year ~ continent)\n\n\n\n\n\n\n\n\nWhat happens to gdpPercap when lifeExp increases by one?\n\navg_comparisons(mod)\n#&gt; \n#&gt;     Term Estimate 2.5 % 97.5 %\n#&gt;  lifeExp    759.7 535.8  862.8\n#&gt;  year       -63.5 -83.9  -40.9\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nWhat happens to gdpPercap when lifeExp increases by one standard deviation?\n\navg_comparisons(mod, variables = list(lifeExp = \"sd\"))\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      4050  3718   4741\n#&gt; \n#&gt; Term: lifeExp\n#&gt; Type:  response \n#&gt; Comparison: mean(x + sd/2) - mean(x - sd/2)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nWhat happens to gdpPercap when lifeExp increases from 50 to 60 and year simultaneously increases its min to its max?\n\navg_comparisons(\n    mod,\n    variables = list(lifeExp = c(50, 60), year = \"minmax\"),\n    cross = TRUE)\n#&gt; \n#&gt;           C: lifeExp               C: year Estimate 2.5 % 97.5 %\n#&gt;  mean(60) - mean(50) mean(Max) - mean(Min)      835   523   1404\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast_lifeExp, contrast_year, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nPlot draws from the posterior distribution of average contrasts (not the same thing as draws from the posterior distribution of contrasts):\n\navg_comparisons(mod) |&gt;\n    posterior_draws() |&gt;\n    ggplot(aes(estimate, term)) +\n    stat_dotsinterval() +\n    labs(x = \"Posterior distribution of average contrasts\", y = \"\")\n\n\n\n\n\n\n\n\nAverage Marginal Effect of lifeExp on different scales and for different parameters:\n\navg_slopes(mod)\n#&gt; \n#&gt;     Term Estimate 2.5 % 97.5 %\n#&gt;  lifeExp    718.5 515.4  811.4\n#&gt;  year       -63.8 -84.4  -41.1\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\navg_slopes(mod, type = \"link\")\n#&gt; \n#&gt;     Term Estimate   2.5 %   97.5 %\n#&gt;  lifeExp  0.08249  0.0742  0.08856\n#&gt;  year    -0.00937 -0.0120 -0.00632\n#&gt; \n#&gt; Type:  link \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\navg_slopes(mod, dpar = \"hu\")\n#&gt; \n#&gt;     Term Estimate    2.5 %   97.5 %\n#&gt;  lifeExp -0.00817 -0.00937 -0.00669\n#&gt;  year     0.00000  0.00000  0.00000\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\navg_slopes(mod, dpar = \"hu\", type = \"link\")\n#&gt; \n#&gt;     Term Estimate  2.5 %  97.5 %\n#&gt;  lifeExp  -0.0993 -0.113 -0.0838\n#&gt;  year      0.0000  0.000  0.0000\n#&gt; \n#&gt; Type:  link \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nPlot Conditional Marginal Effects\n\nplot_slopes(\n    mod,\n    variables = \"lifeExp\",\n    condition = \"lifeExp\") +\n    labs(y = \"mu\") +\n\nplot_slopes(\n    mod,\n    dpar = \"hu\",\n    variables = \"lifeExp\",\n    condition = \"lifeExp\") +\n    labs(y = \"hu\")\n\n\n\n\n\n\n\nOr we can call slopes() or comparisons() with posterior_draws() function to have even more control:\n\ncomparisons(\n    mod,\n    type = \"link\",\n    variables = \"lifeExp\",\n    newdata = datagrid(lifeExp = c(40, 70), continent = gapminder$continent)) |&gt;\n    posterior_draws() |&gt;\n    ggplot(aes(draw, continent, fill = continent)) +\n    stat_dotsinterval() +\n    facet_grid(lifeExp ~ .) +\n    labs(x = \"Effect of a 1 unit change in Life Expectancy\")\n\n\n\n\n\n\n\n\nFor bayesian models like those produced by the brms or rstanarm packages, the marginaleffects package functions report the median of the posterior distribution as their main estimates.\nThe default credible intervals are equal-tailed intervals (quantiles), and the default function to identify the center of the distribution is the median. Users can customize the type of intervals reported by setting global options. Note that both the reported estimate and the intervals change slightly:\n\nlibrary(insight)\nlibrary(marginaleffects)\n\nmod &lt;- insight::download_model(\"brms_1\")\n\noptions(marginaleffects_posterior_interval = \"hdi\")\noptions(marginaleffects_posterior_center = mean)\navg_comparisons(mod)\n#&gt; \n#&gt;  Term Estimate 2.5 % 97.5 %\n#&gt;   cyl    -1.50 -2.38 -0.677\n#&gt;   wt     -3.21 -4.70 -1.570\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\noptions(marginaleffects_posterior_interval = \"eti\")\noptions(marginaleffects_posterior_center = stats::median)\navg_comparisons(mod)\n#&gt; \n#&gt;  Term Estimate 2.5 % 97.5 %\n#&gt;   cyl    -1.49 -2.36 -0.636\n#&gt;   wt     -3.20 -4.79 -1.645\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\nRecent versions of the posterior, brms, and ggdist packages make it easy to draw, summarize and plot random variables. The posterior_draws() can produce objects of class rvar which make it easy to use those features by returning a data frame with a column of type rvar:\n\nlibrary(brms)\nlibrary(ggdist)\nlibrary(ggplot2)\nlibrary(marginaleffects)\nmod &lt;- brm(am ~ mpg + hp, data = mtcars, family = bernoulli)\n\n\navg_comparisons(mod) |&gt;\n  posterior_draws(shape = \"rvar\") |&gt;\n  ggplot(aes(y = term, xdist = rvar)) + \n  stat_slabinterval()\n\n\n\n\n\n\n\n\nWe begin by estimating a model:\n\nmod &lt;- brm(am ~ mpg + hp, data = mtcars, family = bernoulli(),\n           seed = 1024, silent = 2, chains = 4, iter = 1000)\n\nNotice that we can compute average contrasts in two different ways, using the avg_comparisons() function or the comparison argument:\n\navg_comparisons(mod)\n#&gt; \n#&gt;  Term Estimate   2.5 %  97.5 %\n#&gt;   hp   0.00601 0.00289 0.00895\n#&gt;   mpg  0.13942 0.08464 0.18139\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\ncomparisons(mod, comparison = \"differenceavg\")\n#&gt; \n#&gt;  Term Estimate   2.5 %  97.5 %\n#&gt;   hp   0.00601 0.00289 0.00895\n#&gt;   mpg  0.13942 0.08464 0.18139\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nNow, we use the hypothesis argument to compare the first to the second rows of the comparisons() output:\n\ncomparisons(\n    mod,\n    comparison = \"differenceavg\",\n    hypothesis = \"b2 - b1 = 0.2\")\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;   -0.0665 -0.119 -0.027\n#&gt; \n#&gt; Term: b2-b1=0.2\n#&gt; Type:  response \n#&gt; Columns: term, estimate, conf.low, conf.high\n\nThe hypothesis() function of the brms package can also perform non-linear hypothesis testing, and it generates some convenient statistics and summaries. This function accepts a D-by-P matrix of draws from the posterior distribution, where D is the number of draws and N is the number of parameters. We can obtain such a matrix using the posterior_draws(x, shape = \"DxP\"), and we can simply add a couple calls to our chain of operations:\n\navg_comparisons(mod, comparison = \"differenceavg\") |&gt;\n    posterior_draws(shape = \"DxP\") |&gt;\n    brms::hypothesis(\"b2 - b1 &gt; .2\")\n#&gt; Hypothesis Tests for class :\n#&gt;         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n#&gt; 1 (b2-b1)-(.2) &gt; 0    -0.07      0.02    -0.11    -0.03          0         0     \n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\n\nSome brms models allow users to model distributional parameters:\n\ndata(iris)\nlibrary(brms)\nmod &lt;- brm(bf(\n    Sepal.Length ~ Sepal.Width * Petal.Length,\n    sigma ~ Sepal.Width * Petal.Length), \n    family = gaussian(), data = iris,\n    backend = \"cmdstanr\")\n\nWe can use marginaleffects to compute quantities based on posterior draws of those parameters by specifying the dpar argument, which will be passed internally to brms’s prediction functions. For example:\n\navg_predictions(mod)\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      5.84  5.78   5.89\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, conf.low, conf.high\n\navg_predictions(mod, dpar = \"sigma\")\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.329 0.293  0.372\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, conf.low, conf.high\n\navg_slopes(mod, dpar = \"sigma\")\n#&gt; \n#&gt;          Term Estimate  2.5 % 97.5 %\n#&gt;  Petal.Length   0.0448  0.017 0.0764\n#&gt;  Sepal.Width   -0.0131 -0.130 0.1010\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#logistic-regression-with-multiplicative-interactions",
    "href": "vignettes/brms.html#logistic-regression-with-multiplicative-interactions",
    "title": "Bayes",
    "section": "",
    "text": "Load libraries and download data on passengers of the Titanic from the Rdatasets archive:\n\nlibrary(marginaleffects)\nlibrary(brms)\nlibrary(ggplot2)\nlibrary(ggdist)\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/carData/TitanicSurvival.csv\")\ndat$survived &lt;- ifelse(dat$survived == \"yes\", 1, 0)\ndat$woman &lt;- ifelse(dat$sex == \"female\", 1, 0)\n\nFit a logit model with a multiplicative interaction:\n\nmod &lt;- brm(survived ~ woman * age + passengerClass,\n           family = bernoulli(link = \"logit\"),\n           data = dat)\n\n\nWe can compute adjusted predicted values of the outcome variable (i.e., probability of survival aboard the Titanic) using the predictions function. By default, this function calculates predictions for each row of the dataset:\n\npredictions(mod)\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;    0.9367 0.9070 0.9590\n#&gt;    0.8493 0.7453 0.9187\n#&gt;    0.9433 0.8949 0.9704\n#&gt;    0.5131 0.4302 0.6000\n#&gt;    0.9375 0.9080 0.9601\n#&gt; --- 1036 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n#&gt;    0.0376 0.0235 0.0581\n#&gt;    0.5859 0.5017 0.6663\n#&gt;    0.1043 0.0801 0.1337\n#&gt;    0.1017 0.0779 0.1307\n#&gt;    0.0916 0.0691 0.1189\n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, survived, woman, age, passengerClass\n\nTo visualize the relationship between the outcome and one of the regressors, we can plot conditional adjusted predictions with the plot_predictions function:\n\nplot_predictions(mod, condition = \"age\")\n\n\n\n\n\n\n\nCompute adjusted predictions for some user-specified values of the regressors, using the newdata argument and the datagrid function:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(woman = 0:1,\n                                       passengerClass = c(\"1st\", \"2nd\", \"3rd\")))\npred\n#&gt; \n#&gt;  woman passengerClass Estimate  2.5 % 97.5 %\n#&gt;      0            1st   0.5149 0.4319  0.602\n#&gt;      0            2nd   0.2013 0.1536  0.261\n#&gt;      0            3rd   0.0875 0.0656  0.114\n#&gt;      1            1st   0.9364 0.9066  0.959\n#&gt;      1            2nd   0.7783 0.7090  0.835\n#&gt;      1            3rd   0.5701 0.4938  0.644\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, age, woman, passengerClass, survived\n\nThe posterior_draws function samples from the posterior distribution of the model, and produces a data frame with drawid and draw columns.\n\npred &lt;- posterior_draws(pred)\nhead(pred)\n#&gt;   drawid       draw rowid   estimate   conf.low conf.high      age woman passengerClass survived\n#&gt; 1      1 0.46566713     1 0.51492993 0.43192231 0.6018749 29.88113     0            1st        1\n#&gt; 2      1 0.16658900     2 0.20128833 0.15362308 0.2613351 29.88113     0            2nd        1\n#&gt; 3      1 0.08750961     3 0.08750369 0.06555724 0.1141134 29.88113     0            3rd        1\n#&gt; 4      1 0.93735755     4 0.93641346 0.90660921 0.9587589 29.88113     1            1st        1\n#&gt; 5      1 0.77437334     5 0.77829290 0.70896643 0.8346419 29.88113     1            2nd        1\n#&gt; 6      1 0.62216334     6 0.57010265 0.49377997 0.6441967 29.88113     1            3rd        1\n\nThis “long” format makes it easy to plots results:\n\nggplot(pred, aes(x = draw, fill = factor(woman))) +\n    geom_density() +\n    facet_grid(~ passengerClass, labeller = label_both) +\n    labs(x = \"Predicted probability of survival\", y = \"\", fill = \"Woman\")\n\n\n\n\n\n\n\n\nUse slopes() to compute marginal effects (slopes of the regression equation) for each row of the dataset, and use ) to compute “Average Marginal Effects”, that is, the average of all observation-level marginal effects:\n\nmfx &lt;- slopes(mod)\nmfx\n#&gt; \n#&gt;   Term Contrast  Estimate     2.5 %    97.5 %\n#&gt;  age      dY/dX -0.000237 -0.001335  0.000880\n#&gt;  age      dY/dX -0.007257 -0.008973 -0.005265\n#&gt;  age      dY/dX -0.000214 -0.000831  0.001242\n#&gt;  age      dY/dX -0.014258 -0.018487 -0.010306\n#&gt;  age      dY/dX -0.000234 -0.001242  0.000923\n#&gt; --- 4174 rows omitted. See ?avg_slopes and ?print.marginaleffects --- \n#&gt;  woman    1 - 0  0.516022  0.401674  0.630788\n#&gt;  woman    1 - 0  0.395843  0.307400  0.486515\n#&gt;  woman    1 - 0  0.468892  0.401425  0.536243\n#&gt;  woman    1 - 0  0.471069  0.403598  0.538028\n#&gt;  woman    1 - 0  0.478699  0.410060  0.547549\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx, survived, woman, age, passengerClass\n\nCompute marginal effects with some regressors fixed at user-specified values, and other regressors held at their means:\n\nslopes(\n    mod,\n    newdata = datagrid(\n        woman = 1,\n        passengerClass = \"1st\"))\n#&gt; \n#&gt;            Term  Contrast woman passengerClass  Estimate    2.5 %    97.5 %\n#&gt;  age            dY/dX         1            1st -0.000238 -0.00136  0.000871\n#&gt;  passengerClass 2nd - 1st     1            1st -0.157442 -0.22327 -0.102890\n#&gt;  passengerClass 3rd - 1st     1            1st -0.365376 -0.43832 -0.294769\n#&gt;  woman          1 - 0         1            1st  0.420368  0.34697  0.490373\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, conf.low, conf.high, woman, passengerClass, predicted_lo, predicted_hi, predicted, tmp_idx, age, survived\n\nCompute and plot conditional marginal effects:\n\nplot_slopes(mod, variables = \"woman\", condition = \"age\")\n\n\n\n\n\n\n\nThe posterior_draws produces a dataset with drawid and draw columns:\n\ndraws &lt;- posterior_draws(mfx)\n\ndim(draws)\n#&gt; [1] 16736000       16\n\nhead(draws)\n#&gt;   drawid          draw rowid term contrast      estimate      conf.low     conf.high predicted_lo predicted_hi predicted tmp_idx survived woman     age passengerClass\n#&gt; 1      1 -0.0001793450     1  age    dY/dX -0.0002373819 -0.0013354352  0.0008803236    0.9366624    0.9366585 0.9366604       1        1     1 29.0000            1st\n#&gt; 2      1 -0.0082459626     2  age    dY/dX -0.0072572604 -0.0089728266 -0.0052650726    0.8493348    0.8492752 0.8493050       2        1     0  0.9167            1st\n#&gt; 3      1 -0.0001667655     3  age    dY/dX -0.0002137451 -0.0008314784  0.0012415040    0.9433319    0.9433267 0.9433293       3        0     1  2.0000            1st\n#&gt; 4      1 -0.0160434697     4  age    dY/dX -0.0142578648 -0.0184866253 -0.0103056297    0.5131552    0.5130514 0.5131011       4        0     0 30.0000            1st\n#&gt; 5      1 -0.0001774318     5  age    dY/dX -0.0002336788 -0.0012419718  0.0009233460    0.9374947    0.9374927 0.9374937       5        0     1 25.0000            1st\n#&gt; 6      1 -0.0108173828     6  age    dY/dX -0.0112764204 -0.0143192681 -0.0085783113    0.2730949    0.2730116 0.2730542       6        1     0 48.0000            1st\n\nWe can use this dataset to plot our results. For example, to plot the posterior density of the marginal effect of age when the woman variable is equal to 0 or 1:\n\nmfx &lt;- slopes(mod,\n    variables = \"age\",\n    newdata = datagrid(woman = 0:1)) |&gt;\n    posterior_draws()\n\nggplot(mfx, aes(x = draw, fill = factor(woman))) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Marginal Effect of Age on Survival\",\n         y = \"Posterior density\",\n         fill = \"Woman\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#random-effects-model",
    "href": "vignettes/brms.html#random-effects-model",
    "title": "Bayes",
    "section": "",
    "text": "This section replicates some of the analyses of a random effects model published in Andrew Heiss’ blog post: “A guide to correctly calculating posterior predictions and average marginal effects with multilevel Bayesian models.” The objective is mainly to illustrate the use of marginaleffects. Please refer to the original post for a detailed discussion of the quantities computed below.\nLoad libraries and download data:\n\nlibrary(brms)\nlibrary(ggdist)\nlibrary(patchwork)\nlibrary(marginaleffects)\n\nvdem_2015 &lt;- read.csv(\"https://github.com/vincentarelbundock/marginaleffects/raw/main/data-raw/vdem_2015.csv\")\n\nhead(vdem_2015)\n#&gt;   country_name country_text_id year                           region media_index party_autonomy_ord polyarchy civil_liberties party_autonomy\n#&gt; 1       Mexico             MEX 2015  Latin America and the Caribbean       0.837                  3     0.631           0.704           TRUE\n#&gt; 2     Suriname             SUR 2015  Latin America and the Caribbean       0.883                  4     0.777           0.887           TRUE\n#&gt; 3       Sweden             SWE 2015 Western Europe and North America       0.956                  4     0.915           0.968           TRUE\n#&gt; 4  Switzerland             CHE 2015 Western Europe and North America       0.939                  4     0.901           0.960           TRUE\n#&gt; 5        Ghana             GHA 2015               Sub-Saharan Africa       0.858                  4     0.724           0.921           TRUE\n#&gt; 6 South Africa             ZAF 2015               Sub-Saharan Africa       0.898                  4     0.752           0.869           TRUE\n\nFit a basic model:\n\nmod &lt;- brm(\n  bf(media_index ~ party_autonomy + civil_liberties + (1 | region),\n     phi ~ (1 | region)),\n  data = vdem_2015,\n  family = Beta(),\n  control = list(adapt_delta = 0.9))\n\n\nTo compute posterior predictions for specific values of the regressors, we use the newdata argument and the datagrid function. We also use the type argument to compute two types of predictions: accounting for residual (observation-level) residual variance (prediction) or ignoring it (response).\n\nnd = datagrid(model = mod,\n              party_autonomy = c(TRUE, FALSE),\n              civil_liberties = .5,\n              region = \"Middle East and North Africa\")\np1 &lt;- predictions(mod, type = \"response\", newdata = nd) |&gt;\n    posterior_draws() |&gt;\n    transform(type = \"Response\")\np2 &lt;- predictions(mod, type = \"prediction\", newdata = nd) |&gt;\n    posterior_draws() |&gt;\n    transform(type = \"Prediction\")\npred &lt;- rbind(p1, p2)\n\nExtract posterior draws and plot them:\n\nggplot(pred, aes(x = draw, fill = party_autonomy)) +\n    stat_halfeye(alpha = .5) +\n    facet_wrap(~ type) +\n    labs(x = \"Media index (predicted)\", \n         y = \"Posterior density\",\n         fill = \"Party autonomy\")\n\n\n\n\n\n\n\n\nAs noted in the Marginal Effects vignette, there should be one distinct marginal effect for each combination of regressor values. Here, we consider only one combination of regressor values, where region is “Middle East and North Africa”, and civil_liberties is 0.5. Then, we calculate the mean of the posterior distribution of marginal effects:\n\nmfx &lt;- slopes(mod,\n                       newdata = datagrid(civil_liberties = .5,\n                                          region = \"Middle East and North Africa\"))\nmfx\n#&gt; \n#&gt;      Contrast civil_liberties                       region Estimate 2.5 % 97.5 %\n#&gt;  dY/dX                    0.5 Middle East and North Africa    0.816 0.621  1.007\n#&gt;  TRUE - FALSE             0.5 Middle East and North Africa    0.252 0.166  0.336\n#&gt; \n#&gt; Term: civil_liberties\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, conf.low, conf.high, civil_liberties, region, predicted_lo, predicted_hi, predicted, tmp_idx, party_autonomy, media_index\n\nUse the posterior_draws() to extract draws from the posterior distribution of marginal effects, and plot them:\n\nmfx &lt;- posterior_draws(mfx)\n\nggplot(mfx, aes(x = draw, y = term)) +\n  stat_halfeye() +\n  labs(x = \"Marginal effect\", y = \"\")\n\n\n\n\n\n\n\nPlot marginal effects, conditional on a regressor:\n\nplot_slopes(mod,\n         variables = \"civil_liberties\",\n         condition = \"party_autonomy\")\n\n\n\n\n\n\n\n\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(party_autonomy = FALSE,\n                                       region = \"Middle East and North Africa\",\n                                       civil_liberties = seq(0, 1, by = 0.05))) |&gt;\n        posterior_draws()\n\nggplot(pred, aes(x = civil_liberties, y = draw)) +\n    stat_lineribbon() +\n    scale_fill_brewer(palette = \"Reds\") +\n    labs(x = \"Civil liberties\",\n         y = \"Media index (predicted)\",\n         fill = \"\")\n\n\n\n\n\n\n\nThe slope of this line for different values of civil liberties can be obtained with:\n\nmfx &lt;- slopes(mod,\n    newdata = datagrid(\n        civil_liberties = c(.2, .5, .8),\n        party_autonomy = FALSE,\n        region = \"Middle East and North Africa\"),\n    variables = \"civil_liberties\")\nmfx\n#&gt; \n#&gt;             Term civil_liberties party_autonomy                       region Estimate 2.5 % 97.5 %\n#&gt;  civil_liberties             0.2          FALSE Middle East and North Africa    0.490 0.361  0.639\n#&gt;  civil_liberties             0.5          FALSE Middle East and North Africa    0.807 0.612  0.993\n#&gt;  civil_liberties             0.8          FALSE Middle East and North Africa    0.807 0.675  0.934\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, conf.low, conf.high, civil_liberties, party_autonomy, region, predicted_lo, predicted_hi, predicted, tmp_idx, media_index\n\nAnd plotted:\n\nmfx &lt;- posterior_draws(mfx)\n\nggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Marginal effect of Civil Liberties on Media Index\",\n         y = \"Posterior density\",\n         fill = \"Civil liberties\")\n\n\n\n\n\n\n\nThe slopes function can use the ellipsis (...) to push any argument forward to the posterior_predict function. This can alter the types of predictions returned. For example, the re_formula=NA argument of the posterior_predict.brmsfit method will compute marginaleffects without including any group-level effects:\n\nmfx &lt;- slopes(\n    mod,\n    newdata = datagrid(\n        civil_liberties = c(.2, .5, .8),\n        party_autonomy = FALSE,\n        region = \"Middle East and North Africa\"),\n    variables = \"civil_liberties\",\n    re_formula = NA) |&gt;\n    posterior_draws()\n\nggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Marginal effect of Civil Liberties on Media Index\",\n         y = \"Posterior density\",\n         fill = \"Civil liberties\")\n\n\n\n\n\n\n\n\n\npred &lt;- predictions(\n    mod,\n    re_formula = NA,\n    newdata = datagrid(party_autonomy = c(TRUE, FALSE))) |&gt;\n    posterior_draws()\n\nmfx &lt;- slopes(\n    mod,\n    re_formula = NA,\n    variables = \"party_autonomy\") |&gt;\n    posterior_draws()\n\nplot1 &lt;- ggplot(pred, aes(x = draw, fill = party_autonomy)) +\n         stat_halfeye(slab_alpha = .5) +\n         labs(x = \"Media index (Predicted)\",\n              y = \"Posterior density\",\n              fill = \"Party autonomy\")\n\nplot2 &lt;- ggplot(mfx, aes(x = draw)) +\n         stat_halfeye(slab_alpha = .5)  +\n         labs(x = \"Contrast: Party autonomy TRUE - FALSE\",\n              y = \"\",\n              fill = \"Party autonomy\")\n\n## combine plots using the `patchwork` package\nplot1 + plot2\n\n\n\n\n\n\n\n\nPredicted media index by region and level of civil liberties:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(region = vdem_2015$region,\n                                       party_autonomy = FALSE, \n                                       civil_liberties = seq(0, 1, length.out = 100))) |&gt; \n        posterior_draws()\n\nggplot(pred, aes(x = civil_liberties, y = draw)) +\n    stat_lineribbon() +\n    scale_fill_brewer(palette = \"Reds\") +\n    facet_wrap(~ region) +\n    labs(x = \"Civil liberties\",\n         y = \"Media index (predicted)\",\n         fill = \"\")\n\n\n\n\n\n\n\nPredicted media index by region and level of civil liberties:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(region = vdem_2015$region,\n                                       civil_liberties = c(.2, .8),\n                                      party_autonomy = FALSE)) |&gt;\n        posterior_draws()\n\nggplot(pred, aes(x = draw, fill = factor(civil_liberties))) +\n    stat_halfeye(slab_alpha = .5) +\n    facet_wrap(~ region) +\n    labs(x = \"Media index (predicted)\",\n         y = \"Posterior density\",\n         fill = \"Civil liberties\")\n\n\n\n\n\n\n\nPredicted media index by region and party autonomy:\n\npred &lt;- predictions(mod,\n                    newdata = datagrid(region = vdem_2015$region,\n                                       party_autonomy = c(TRUE, FALSE),\n                                       civil_liberties = .5)) |&gt;\n        posterior_draws()\n\nggplot(pred, aes(x = draw, y = region , fill = party_autonomy)) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Media index (predicted)\",\n         y = \"\",\n         fill = \"Party autonomy\")\n\n\n\n\n\n\n\nTRUE/FALSE contrasts (marginal effects) of party autonomy by region:\n\nmfx &lt;- slopes(\n    mod,\n    variables = \"party_autonomy\",\n    newdata = datagrid(\n        region = vdem_2015$region,\n        civil_liberties = .5)) |&gt;\n    posterior_draws()\n\nggplot(mfx, aes(x = draw, y = region , fill = party_autonomy)) +\n    stat_halfeye(slab_alpha = .5) +\n    labs(x = \"Media index (predicted)\",\n         y = \"\",\n         fill = \"Party autonomy\")\n\n\n\n\n\n\n\n\nWe can also obtain predictions or marginal effects for a hypothetical group instead of one of the observed regions. To achieve this, we create a dataset with NA in the region column. Then we call the marginaleffects or predictions functions with the allow_new_levels argument. This argument is pushed through via the ellipsis (...) to the posterior_epred function of the brms package:\n\ndat &lt;- data.frame(civil_liberties = .5,\n                  party_autonomy = FALSE,\n                  region = \"New Region\")\n\nmfx &lt;- slopes(\n    mod,\n    variables = \"party_autonomy\",\n    allow_new_levels = TRUE,\n    newdata = dat)\n\ndraws &lt;- posterior_draws(mfx)\n\nggplot(draws, aes(x = draw)) +\n     stat_halfeye() +\n     labs(x = \"Marginal effect of party autonomy in a generic world region\", y = \"\")\n\n\n\n\n\n\n\n\nConsider a logistic regression model with random effects:\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/plm/EmplUK.csv\")\ndat$x &lt;- as.numeric(dat$output &gt; median(dat$output))\ndat$y &lt;- as.numeric(dat$emp &gt; median(dat$emp))\nmod &lt;- brm(y ~ x + (1 | firm), data = dat, backend = \"cmdstanr\", family = \"bernoulli\")\n\nWe can compute adjusted predictions for a given value of x and for each firm (random effects) as follows:\n\np &lt;- predictions(mod, newdata = datagrid(x = 0, firm = unique))\nhead(p)\n#&gt; \n#&gt;  x firm Estimate    2.5 % 97.5 %\n#&gt;  0    1  1.0e+00 9.01e-01 1.0000\n#&gt;  0    2  1.0e+00 8.95e-01 1.0000\n#&gt;  0    3  1.0e+00 9.12e-01 1.0000\n#&gt;  0    4  1.0e+00 7.97e-01 1.0000\n#&gt;  0    5  1.0e+00 9.09e-01 1.0000\n#&gt;  0    6  4.9e-08 8.42e-21 0.0019\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, x, firm, y\n\nWe can average/marginalize/integrate across random effects with the avg_predictions() function or the by argument:\n\navg_predictions(mod, newdata = datagrid(x = 0, firm = unique))\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.454  0.44  0.468\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, conf.low, conf.high\n\npredictions(mod, newdata = datagrid(x = 0:1, firm = unique), by = \"x\")\n#&gt; \n#&gt;  x Estimate 2.5 % 97.5 %\n#&gt;  0    0.454 0.440  0.468\n#&gt;  1    0.557 0.546  0.570\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: x, estimate, conf.low, conf.high\n\nWe can also draw from the (assumed gaussian) population distribution of random effects, by asking predictions() to make predictions for new “levels” of the random effects. If we then take an average of predictions using avg_predictions() or the by argument, we will have “integrated out the random effects”, as described in the brmsmargins package vignette. In the code below, we make predictions for 100 firm identifiers which were not in the original dataset. We also ask predictions() to push forward the allow_new_levels and sample_new_levels arguments to the brms::posterior_epred function:\n\npredictions(\n    mod,\n    newdata = datagrid(x = 0:1, firm = -1:-100),\n    allow_new_levels = TRUE,\n    sample_new_levels = \"gaussian\",\n    by = \"x\")\n#&gt; \n#&gt;  x Estimate 2.5 % 97.5 %\n#&gt;  0    0.451 0.339  0.566\n#&gt;  1    0.550 0.440  0.666\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: x, estimate, conf.low, conf.high\n\nWe can “integrate out” random effects in the other slopes functions too. For instance,\n\navg_comparisons(\n    mod,\n    newdata = datagrid(firm = -1:-100),\n    allow_new_levels = TRUE,\n    sample_new_levels = \"gaussian\")\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;    0.0971 0.0465   0.16\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nThis is nearly equivalent the brmsmargins command output (with slight variations due to different random seeds):\n\nlibrary(brmsmargins)\nbm &lt;- brmsmargins(\n  k = 100,\n  object = mod,\n  at = data.frame(x = c(0, 1)),\n  CI = .95,\n  CIType = \"ETI\",\n  contrasts = cbind(\"AME x\" = c(-1, 1)),\n  effects = \"integrateoutRE\")\nbm$ContrastSummary |&gt; data.frame()\n#&gt;            M        Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 0.09883675 0.09683602 0.04765318 0.1607502          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\nSee the alternative software vignette for more information on brmsmargins.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#multinomial-logit",
    "href": "vignettes/brms.html#multinomial-logit",
    "title": "Bayes",
    "section": "",
    "text": "Fit a model with categorical outcome (heating system choice in California houses) and logit link:\n\ndat &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Heating.csv\"\ndat &lt;- read.csv(dat)\nmod &lt;- brm(depvar ~ ic.gc + oc.gc,\n           data = dat,\n           family = categorical(link = \"logit\"))\n\n\nCompute predicted probabilities for each level of the outcome variable:\n\npred &lt;- predictions(mod)\n\nhead(pred)\n#&gt; \n#&gt;  Group Estimate  2.5 % 97.5 %\n#&gt;     ec   0.0663 0.0447 0.0930\n#&gt;     ec   0.0768 0.0590 0.0974\n#&gt;     ec   0.1030 0.0618 0.1585\n#&gt;     ec   0.0634 0.0459 0.0838\n#&gt;     ec   0.0745 0.0574 0.0947\n#&gt;     ec   0.0709 0.0455 0.1036\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, group, estimate, conf.low, conf.high, depvar, ic.gc, oc.gc\n\nExtract posterior draws and plot them:\n\ndraws &lt;- posterior_draws(pred)\n\nggplot(draws, aes(x = draw, fill = group)) +\n    geom_density(alpha = .2, color = \"white\") +\n    labs(x = \"Predicted probability\",\n         y = \"Density\",\n         fill = \"Heating system\")\n\n\n\n\n\n\n\nUse the plot_predictions function to plot conditional adjusted predictions for each level of the outcome variable gear, conditional on the value of the mpg regressor:\n\nplot_predictions(mod, condition = \"oc.gc\") +\n    facet_wrap(~ group) +\n    labs(y = \"Predicted probability\")\n\n\n\n\n\n\n\n\n\navg_slopes(mod)\n#&gt; \n#&gt;  Group  Term  Estimate     2.5 %   97.5 %\n#&gt;     ec ic.gc -1.77e-04 -3.96e-04 2.37e-05\n#&gt;     ec oc.gc  4.88e-04 -4.04e-04 1.45e-03\n#&gt;     er ic.gc  1.65e-05 -2.26e-04 2.51e-04\n#&gt;     er oc.gc -1.02e-03 -2.07e-03 2.98e-05\n#&gt;     gc ic.gc  1.38e-05 -3.72e-04 4.00e-04\n#&gt;     gc oc.gc  1.04e-03 -7.39e-04 2.78e-03\n#&gt;     gr ic.gc  4.24e-05 -2.37e-04 3.29e-04\n#&gt;     gr oc.gc  9.46e-05 -1.19e-03 1.34e-03\n#&gt;     hp ic.gc  1.07e-04 -7.73e-05 2.97e-04\n#&gt;     hp oc.gc -5.85e-04 -1.45e-03 2.30e-04\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, group, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#hurdle-models",
    "href": "vignettes/brms.html#hurdle-models",
    "title": "Bayes",
    "section": "",
    "text": "This section replicates some analyses from yet another amazing blog post by Andrew Heiss.\nTo begin, we estimate a hurdle model in brms with random effects, using data from the gapminder package: 704G\n\nlibrary(gapminder)\nlibrary(brms)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggdist)\nlibrary(cmdstanr)\nlibrary(patchwork)\nlibrary(marginaleffects)\n\nset.seed(1024)\n\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\ngapminder &lt;- gapminder::gapminder |&gt; \n  filter(continent != \"Oceania\") |&gt; \n  # Make a bunch of GDP values 0\n  mutate(prob_zero = ifelse(lifeExp &lt; 50, 0.3, 0.02),\n         will_be_zero = rbinom(n(), 1, prob = prob_zero),\n         gdpPercap = ifelse(will_be_zero, 0, gdpPercap)) |&gt; \n  select(-prob_zero, -will_be_zero) |&gt; \n  # Make a logged version of GDP per capita\n  mutate(log_gdpPercap = log1p(gdpPercap)) |&gt; \n  mutate(is_zero = gdpPercap == 0)\n\nmod &lt;- brm(\n  bf(gdpPercap ~ lifeExp + year + (1 + lifeExp + year | continent),\n     hu ~ lifeExp),\n  data = gapminder,\n  backend = \"cmdstanr\",\n  family = hurdle_lognormal(),\n  cores = 2,\n  chains = CHAINS, iter = ITER, warmup = WARMUP, seed = BAYES_SEED,\n  silent = 2)\n\n\nAdjusted predictions for every observation in the original data:\n\npredictions(mod) |&gt; head()\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;       143   103    219\n#&gt;       168   125    256\n#&gt;       202   153    304\n#&gt;       251   197    373\n#&gt;       312   250    454\n#&gt;       398   325    567\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent\n\nAdjusted predictions for the hu parameter:\n\npredictions(mod, dpar = \"hu\") |&gt; head()\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.574 0.475  0.652\n#&gt;     0.537 0.442  0.611\n#&gt;     0.496 0.407  0.566\n#&gt;     0.446 0.366  0.511\n#&gt;     0.396 0.325  0.454\n#&gt;     0.341 0.282  0.391\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent\n\nPredictions on a different scale:\n\npredictions(mod, type = \"link\", dpar = \"hu\") |&gt; head()\n#&gt; \n#&gt;  Estimate  2.5 %  97.5 %\n#&gt;    0.2980 -0.101  0.6259\n#&gt;    0.1463 -0.235  0.4527\n#&gt;   -0.0178 -0.377  0.2673\n#&gt;   -0.2189 -0.551  0.0424\n#&gt;   -0.4234 -0.730 -0.1857\n#&gt;   -0.6573 -0.933 -0.4443\n#&gt; \n#&gt; Type:  link \n#&gt; Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent\n\nPlot adjusted predictions as a function of lifeExp:\n\nplot_predictions(\n    mod,\n    condition = \"lifeExp\") +\n    labs(y = \"mu\") +\nplot_predictions(\n    mod,\n    dpar = \"hu\",\n    condition = \"lifeExp\") +\n    labs(y = \"hu\")\n\n\n\n\n\n\n\nPredictions with more than one condition and the re_formula argument from brms:\n\nplot_predictions(\n    mod,\n    re_formula = NULL,\n    condition = c(\"lifeExp\", \"continent\"))\n\n\n\n\n\n\n\n\nThe posterior_draws() function extract raw samples from the posterior from objects produced by marginaleffects. This allows us to use richer geoms and summaries, such as those in the ggdist package:\n\npredictions(\n    mod,\n    re_formula = NULL,\n    newdata = datagrid(model = mod,\n                       continent = gapminder$continent,\n                       year = c(1952, 2007),\n                       lifeExp = seq(30, 80, 1))) |&gt;\n    posterior_draws() |&gt;\n    ggplot(aes(lifeExp, draw, fill = continent, color = continent)) +\n    stat_lineribbon(alpha = .25) +\n    facet_grid(year ~ continent)\n\n\n\n\n\n\n\n\nWhat happens to gdpPercap when lifeExp increases by one?\n\navg_comparisons(mod)\n#&gt; \n#&gt;     Term Estimate 2.5 % 97.5 %\n#&gt;  lifeExp    759.7 535.8  862.8\n#&gt;  year       -63.5 -83.9  -40.9\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nWhat happens to gdpPercap when lifeExp increases by one standard deviation?\n\navg_comparisons(mod, variables = list(lifeExp = \"sd\"))\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      4050  3718   4741\n#&gt; \n#&gt; Term: lifeExp\n#&gt; Type:  response \n#&gt; Comparison: mean(x + sd/2) - mean(x - sd/2)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nWhat happens to gdpPercap when lifeExp increases from 50 to 60 and year simultaneously increases its min to its max?\n\navg_comparisons(\n    mod,\n    variables = list(lifeExp = c(50, 60), year = \"minmax\"),\n    cross = TRUE)\n#&gt; \n#&gt;           C: lifeExp               C: year Estimate 2.5 % 97.5 %\n#&gt;  mean(60) - mean(50) mean(Max) - mean(Min)      835   523   1404\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast_lifeExp, contrast_year, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nPlot draws from the posterior distribution of average contrasts (not the same thing as draws from the posterior distribution of contrasts):\n\navg_comparisons(mod) |&gt;\n    posterior_draws() |&gt;\n    ggplot(aes(estimate, term)) +\n    stat_dotsinterval() +\n    labs(x = \"Posterior distribution of average contrasts\", y = \"\")\n\n\n\n\n\n\n\n\nAverage Marginal Effect of lifeExp on different scales and for different parameters:\n\navg_slopes(mod)\n#&gt; \n#&gt;     Term Estimate 2.5 % 97.5 %\n#&gt;  lifeExp    718.5 515.4  811.4\n#&gt;  year       -63.8 -84.4  -41.1\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\navg_slopes(mod, type = \"link\")\n#&gt; \n#&gt;     Term Estimate   2.5 %   97.5 %\n#&gt;  lifeExp  0.08249  0.0742  0.08856\n#&gt;  year    -0.00937 -0.0120 -0.00632\n#&gt; \n#&gt; Type:  link \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\navg_slopes(mod, dpar = \"hu\")\n#&gt; \n#&gt;     Term Estimate    2.5 %   97.5 %\n#&gt;  lifeExp -0.00817 -0.00937 -0.00669\n#&gt;  year     0.00000  0.00000  0.00000\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\navg_slopes(mod, dpar = \"hu\", type = \"link\")\n#&gt; \n#&gt;     Term Estimate  2.5 %  97.5 %\n#&gt;  lifeExp  -0.0993 -0.113 -0.0838\n#&gt;  year      0.0000  0.000  0.0000\n#&gt; \n#&gt; Type:  link \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nPlot Conditional Marginal Effects\n\nplot_slopes(\n    mod,\n    variables = \"lifeExp\",\n    condition = \"lifeExp\") +\n    labs(y = \"mu\") +\n\nplot_slopes(\n    mod,\n    dpar = \"hu\",\n    variables = \"lifeExp\",\n    condition = \"lifeExp\") +\n    labs(y = \"hu\")\n\n\n\n\n\n\n\nOr we can call slopes() or comparisons() with posterior_draws() function to have even more control:\n\ncomparisons(\n    mod,\n    type = \"link\",\n    variables = \"lifeExp\",\n    newdata = datagrid(lifeExp = c(40, 70), continent = gapminder$continent)) |&gt;\n    posterior_draws() |&gt;\n    ggplot(aes(draw, continent, fill = continent)) +\n    stat_dotsinterval() +\n    facet_grid(lifeExp ~ .) +\n    labs(x = \"Effect of a 1 unit change in Life Expectancy\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#bayesian-estimates-and-credible-intervals",
    "href": "vignettes/brms.html#bayesian-estimates-and-credible-intervals",
    "title": "Bayes",
    "section": "",
    "text": "For bayesian models like those produced by the brms or rstanarm packages, the marginaleffects package functions report the median of the posterior distribution as their main estimates.\nThe default credible intervals are equal-tailed intervals (quantiles), and the default function to identify the center of the distribution is the median. Users can customize the type of intervals reported by setting global options. Note that both the reported estimate and the intervals change slightly:\n\nlibrary(insight)\nlibrary(marginaleffects)\n\nmod &lt;- insight::download_model(\"brms_1\")\n\noptions(marginaleffects_posterior_interval = \"hdi\")\noptions(marginaleffects_posterior_center = mean)\navg_comparisons(mod)\n#&gt; \n#&gt;  Term Estimate 2.5 % 97.5 %\n#&gt;   cyl    -1.50 -2.38 -0.677\n#&gt;   wt     -3.21 -4.70 -1.570\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\noptions(marginaleffects_posterior_interval = \"eti\")\noptions(marginaleffects_posterior_center = stats::median)\navg_comparisons(mod)\n#&gt; \n#&gt;  Term Estimate 2.5 % 97.5 %\n#&gt;   cyl    -1.49 -2.36 -0.636\n#&gt;   wt     -3.20 -4.79 -1.645\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#random-variables-posterior-and-ggdist",
    "href": "vignettes/brms.html#random-variables-posterior-and-ggdist",
    "title": "Bayes",
    "section": "",
    "text": "Recent versions of the posterior, brms, and ggdist packages make it easy to draw, summarize and plot random variables. The posterior_draws() can produce objects of class rvar which make it easy to use those features by returning a data frame with a column of type rvar:\n\nlibrary(brms)\nlibrary(ggdist)\nlibrary(ggplot2)\nlibrary(marginaleffects)\nmod &lt;- brm(am ~ mpg + hp, data = mtcars, family = bernoulli)\n\n\navg_comparisons(mod) |&gt;\n  posterior_draws(shape = \"rvar\") |&gt;\n  ggplot(aes(y = term, xdist = rvar)) + \n  stat_slabinterval()",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#non-linear-hypothesis-testing",
    "href": "vignettes/brms.html#non-linear-hypothesis-testing",
    "title": "Bayes",
    "section": "",
    "text": "We begin by estimating a model:\n\nmod &lt;- brm(am ~ mpg + hp, data = mtcars, family = bernoulli(),\n           seed = 1024, silent = 2, chains = 4, iter = 1000)\n\nNotice that we can compute average contrasts in two different ways, using the avg_comparisons() function or the comparison argument:\n\navg_comparisons(mod)\n#&gt; \n#&gt;  Term Estimate   2.5 %  97.5 %\n#&gt;   hp   0.00601 0.00289 0.00895\n#&gt;   mpg  0.13942 0.08464 0.18139\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\ncomparisons(mod, comparison = \"differenceavg\")\n#&gt; \n#&gt;  Term Estimate   2.5 %  97.5 %\n#&gt;   hp   0.00601 0.00289 0.00895\n#&gt;   mpg  0.13942 0.08464 0.18139\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nNow, we use the hypothesis argument to compare the first to the second rows of the comparisons() output:\n\ncomparisons(\n    mod,\n    comparison = \"differenceavg\",\n    hypothesis = \"b2 - b1 = 0.2\")\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;   -0.0665 -0.119 -0.027\n#&gt; \n#&gt; Term: b2-b1=0.2\n#&gt; Type:  response \n#&gt; Columns: term, estimate, conf.low, conf.high\n\nThe hypothesis() function of the brms package can also perform non-linear hypothesis testing, and it generates some convenient statistics and summaries. This function accepts a D-by-P matrix of draws from the posterior distribution, where D is the number of draws and N is the number of parameters. We can obtain such a matrix using the posterior_draws(x, shape = \"DxP\"), and we can simply add a couple calls to our chain of operations:\n\navg_comparisons(mod, comparison = \"differenceavg\") |&gt;\n    posterior_draws(shape = \"DxP\") |&gt;\n    brms::hypothesis(\"b2 - b1 &gt; .2\")\n#&gt; Hypothesis Tests for class :\n#&gt;         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n#&gt; 1 (b2-b1)-(.2) &gt; 0    -0.07      0.02    -0.11    -0.03          0         0     \n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/brms.html#distributional-parameters",
    "href": "vignettes/brms.html#distributional-parameters",
    "title": "Bayes",
    "section": "",
    "text": "Some brms models allow users to model distributional parameters:\n\ndata(iris)\nlibrary(brms)\nmod &lt;- brm(bf(\n    Sepal.Length ~ Sepal.Width * Petal.Length,\n    sigma ~ Sepal.Width * Petal.Length), \n    family = gaussian(), data = iris,\n    backend = \"cmdstanr\")\n\nWe can use marginaleffects to compute quantities based on posterior draws of those parameters by specifying the dpar argument, which will be passed internally to brms’s prediction functions. For example:\n\navg_predictions(mod)\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      5.84  5.78   5.89\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, conf.low, conf.high\n\navg_predictions(mod, dpar = \"sigma\")\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.329 0.293  0.372\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: estimate, conf.low, conf.high\n\navg_slopes(mod, dpar = \"sigma\")\n#&gt; \n#&gt;          Term Estimate  2.5 % 97.5 %\n#&gt;  Petal.Length   0.0448  0.017 0.0764\n#&gt;  Sepal.Width   -0.0131 -0.130 0.1010\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bayes"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#comparison-type",
    "href": "vignettes/comparisons.html#comparison-type",
    "title": "Comparisons",
    "section": "Comparison type",
    "text": "Comparison type\nThe default comparison type in comparisons() is the “difference”, which means that the comparisons() function will typically produce quantities which are often interpreted as a measure of “effect” in applications: risk differences, average treatment effects, G-computation estimates, etc. But comparisons() is not limited to differences, Indeed, it allows analysts to call on many built-in functions for comparison, and also to supply their own.\nDifferences\nBy default, the comparisons() function will compare the predicted values by differencing (subtraction). For example, consider a hypothetical Titanic passenger with these characteristics:\n\npassenger &lt;- data.frame(\n    PClass = \"3rd\",\n    Age = 20,\n    SexCode = 0\n)\n\nWhat would happen to the predicted probability of survival if we were to increase the SexCode from 0 to 1? Or increase Age by 1 unit? Or change PClass from “3rd” to “1st”? To answer these questions, we could proceed manually by computing two predictions and then subtracting one from the other:\n\npassenger_0 &lt;- passenger\npassenger_1 &lt;- transform(passenger, SexCode = 1)\n\nprediction_0 = predict(mod, newdata = passenger_0, type = \"response\")\nprediction_1 = predict(mod, newdata = passenger_1, type = \"response\")\n\nprediction_1 - prediction_0\n#&gt;         1 \n#&gt; 0.2716978\n\nThe result above shows that modifying the SexCode variable of this hypothetical passenger from 0 to 1 increases the predicted probability of survival by about 27 percentage points.\nInstead of computing this estimate by hand, we could call comparisons() to get analogous results for all predictors in the model at once:\n\ncomparisons(mod, newdata = passenger)\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %    97.5 % PClass Age SexCode\n#&gt;  Age     +1        -0.00735     0.0033 -2.23   0.0258  5.3 -0.0138 -0.000887    3rd  20       0\n#&gt;  PClass  2nd - 1st -0.36282     0.0976 -3.72   &lt;0.001 12.3 -0.5541 -0.171567    3rd  20       0\n#&gt;  PClass  3rd - 1st -0.42376     0.0871 -4.87   &lt;0.001 19.7 -0.5945 -0.253040    3rd  20       0\n#&gt;  SexCode 1 - 0      0.27170     0.0588  4.62   &lt;0.001 18.0  0.1565  0.386927    3rd  20       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nRatios\nInstead of taking simple differences between adjusted predictions, it can sometimes be useful to compute ratios or other functions of predictions. For example, the adjrr function the Stata software package can compute “adjusted risk ratios”, which are ratios of adjusted predictions. To do this in R, we could use the same predictions we computed above:\n\nprediction_1 / prediction_0\n#&gt;        1 \n#&gt; 2.511484\n\nThis shows that the predicted probability of survival would be about 2.5% larger if our hypothetical passenger were a woman than a man.\nThe same result can be obtained by setting the comparison argument:\n\ncomparisons(mod, comparison = \"ratio\", newdata = passenger)\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 % PClass Age SexCode\n#&gt;  Age     +1           0.959     0.0157 61.20   &lt;0.001  Inf 0.928  0.990    3rd  20       0\n#&gt;  PClass  2nd / 1st    0.399     0.1035  3.85   &lt;0.001 13.1 0.196  0.602    3rd  20       0\n#&gt;  PClass  3rd / 1st    0.298     0.0640  4.65   &lt;0.001 18.2 0.172  0.423    3rd  20       0\n#&gt;  SexCode 1 / 0        2.511     0.5048  4.97   &lt;0.001 20.5 1.522  3.501    3rd  20       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nBuilt-in functions\nBeyond differences and ratios, comparisons() supports many other built-in functions to compare predictions, such as log odds ratios, lift, etc. See ?comparisons for a complete list.\nThese built-in functions allow us convenient access to complex transformations. For example, this code computes the log odds ratio associated with a change in predictors:\n\ncomparisons(mod, \n    comparison = \"lnor\", \n    newdata = passenger)\n#&gt; \n#&gt;     Term                  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 % PClass Age SexCode\n#&gt;  Age     +1                         -0.0507     0.0202 -2.51   0.0121  6.4 -0.0902 -0.0111    3rd  20       0\n#&gt;  PClass  ln(odds(2nd) / odds(1st))  -1.5690     0.4491 -3.49   &lt;0.001 11.0 -2.4491 -0.6888    3rd  20       0\n#&gt;  PClass  ln(odds(3rd) / odds(1st))  -1.9381     0.3977 -4.87   &lt;0.001 19.8 -2.7177 -1.1586    3rd  20       0\n#&gt;  SexCode ln(odds(1) / odds(0))       1.3232     0.2883  4.59   &lt;0.001 17.8  0.7582  1.8882    3rd  20       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nCustom functions\nAnalysts who need more flexibility can define their own comparison functions. For example, these two calls are equivalent:\n\ncomparisons(mod, \n    comparison = function(hi, lo) hi / lo, \n    newdata = passenger)\n#&gt; \n#&gt;     Term Contrast Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;  Age     +1          0.959     0.0157 61.20   &lt;0.001  Inf 0.928  0.990\n#&gt;  PClass  2nd, 1st    0.399     0.1035  3.85   &lt;0.001 13.1 0.196  0.602\n#&gt;  PClass  3rd, 1st    0.298     0.0640  4.65   &lt;0.001 18.2 0.172  0.423\n#&gt;  SexCode 1, 0        2.511     0.5048  4.97   &lt;0.001 20.5 1.522  3.501\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, \n    comparison = function(hi, lo) hi / lo, \n    newdata = passenger)\n#&gt; \n#&gt;     Term Contrast Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;  Age     +1          0.959     0.0157 61.20   &lt;0.001  Inf 0.928  0.990\n#&gt;  PClass  2nd, 1st    0.399     0.1035  3.85   &lt;0.001 13.1 0.196  0.602\n#&gt;  PClass  3rd, 1st    0.298     0.0640  4.65   &lt;0.001 18.2 0.172  0.423\n#&gt;  SexCode 1, 0        2.511     0.5048  4.97   &lt;0.001 20.5 1.522  3.501\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nThis mechanism is powerful, because it lets users create fully customized contrasts. Here is a non-sensical example:\n\ncomparisons(mod,\n    comparison = function(hi, lo) sqrt(hi) / log(lo + 10), \n    newdata = passenger)\n#&gt; \n#&gt;     Term Contrast Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;  Age     +1          0.179     0.0145 12.36   &lt;0.001 114.2 0.151  0.207\n#&gt;  PClass  2nd, 1st    0.208     0.0230  9.04   &lt;0.001  62.4 0.163  0.253\n#&gt;  PClass  3rd, 1st    0.180     0.0150 11.97   &lt;0.001 107.3 0.150  0.209\n#&gt;  SexCode 1, 0        0.290     0.0162 17.85   &lt;0.001 234.4 0.258  0.321\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#predictor-types",
    "href": "vignettes/comparisons.html#predictor-types",
    "title": "Comparisons",
    "section": "Predictor types",
    "text": "Predictor types\nThe types of comparisons that one might care about depend on the kinds of predictors in our model: numeric, binary, or categorical.\nNumeric\nWe can also compute contrasts for differences in numeric variables. For example, we can see what happens to the adjusted predictions when we increment the Age variable by 1 unit (default) or by 5 units:\n\ncomparisons(mod, variables = \"Age\", newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %    97.5 % PClass SexCode\n#&gt;  -0.00735     0.0033 -2.23   0.0258 5.3 -0.0138 -0.000887    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: +1\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, variables = list(Age = 5), newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %   97.5 % PClass SexCode\n#&gt;   -0.0344     0.0146 -2.35   0.0188 5.7 -0.0631 -0.00569    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: +5\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nCompare adjusted predictions for a change in the regressor between two arbitrary values:\n\ncomparisons(mod, variables = list(Age = c(5, 60)), newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 % PClass SexCode\n#&gt;    -0.291      0.106 -2.75  0.00595 7.4 -0.498 -0.0836    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: 60 - 5\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nCompare adjusted predictions when the regressor changes across the interquartile range, across one or two standard deviations about its mean, or from across its full range:\n\ncomparisons(mod, variables = list(Age = \"iqr\"), newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 % PClass SexCode\n#&gt;   -0.0952     0.0319 -2.98  0.00284 8.5 -0.158 -0.0327    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: Q3 - Q1\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, variables = list(Age = \"sd\"), newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 % PClass SexCode\n#&gt;   -0.0739     0.0241 -3.07  0.00217 8.8 -0.121 -0.0267    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: (x + sd/2) - (x - sd/2)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, variables = list(Age = \"2sd\"), newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 % PClass SexCode\n#&gt;    -0.151     0.0519 -2.92  0.00355 8.1 -0.253 -0.0496    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: (x + sd) - (x - sd)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, variables = list(Age = \"minmax\"), newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 % 97.5 % PClass SexCode\n#&gt;    -0.358       0.13 -2.75  0.00601 7.4 -0.614 -0.103    3rd       0\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: Max - Min\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nBinary or Logical\nFor logical or binary variables, the default comparison correponds to a change from 0 to 1, or from FALSE to TRUE:\n\ndat2 &lt;- transform(dat, SexCode = as.logical(SexCode))\nmod2 &lt;- glm(Survived ~ PClass * SexCode * Age, data = dat2, family = binomial)\n\ncomparisons(mod, variables = \"SexCode\", newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 % PClass Age\n#&gt;     0.272     0.0588 4.62   &lt;0.001 18.0 0.156  0.387    3rd  20\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: 1 - 0\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod2, variables = \"SexCode\", newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 % PClass Age\n#&gt;     0.272     0.0588 4.62   &lt;0.001 18.0 0.156  0.387    3rd  20\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: TRUE - FALSE\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nFactor or Character\nThe comparisons() function automatically computes contrasts for each level of a categorical variable (factor or character), relative to the baseline category, while holding all other values at their observed values. We can obtain different contrasts by using the variables argument:\n\ncomparisons(mod, variables = list(PClass = \"sequential\"), newdata = passenger)\n#&gt; \n#&gt;   Contrast Estimate Std. Error      z Pr(&gt;|z|)    S  2.5 %  97.5 % Age SexCode\n#&gt;  2nd - 1st  -0.3628     0.0976 -3.718   &lt;0.001 12.3 -0.554 -0.1716  20       0\n#&gt;  3rd - 2nd  -0.0609     0.0611 -0.997    0.319  1.6 -0.181  0.0589  20       0\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, variables = list(PClass = \"pairwise\"), newdata = passenger)\n#&gt; \n#&gt;   Contrast Estimate Std. Error      z Pr(&gt;|z|)    S  2.5 %  97.5 % Age SexCode\n#&gt;  2nd - 1st  -0.3628     0.0976 -3.718   &lt;0.001 12.3 -0.554 -0.1716  20       0\n#&gt;  3rd - 1st  -0.4238     0.0871 -4.865   &lt;0.001 19.7 -0.594 -0.2530  20       0\n#&gt;  3rd - 2nd  -0.0609     0.0611 -0.997    0.319  1.6 -0.181  0.0589  20       0\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, variables = list(PClass = \"reference\"), newdata = passenger)\n#&gt; \n#&gt;   Contrast Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 % Age SexCode\n#&gt;  2nd - 1st   -0.363     0.0976 -3.72   &lt;0.001 12.3 -0.554 -0.172  20       0\n#&gt;  3rd - 1st   -0.424     0.0871 -4.87   &lt;0.001 19.7 -0.594 -0.253  20       0\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nWe can also specify a particular contrast of interest in variables:\n\ncomparisons(mod, \n    variables = list(PClass = c(\"3rd\", \"1st\")),\n    newdata = passenger)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 % Age SexCode\n#&gt;     0.424     0.0871 4.87   &lt;0.001 19.7 0.253  0.594  20       0\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Comparison: 1st - 3rd\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nCross-contrasts\nIn other contexts, we are interested in a “cross-contrast” or “cross-comparisons”, that is, we would like to know what happens when two (or more) predictors change at the same time. To assess this, we can specify the regressors of interest in the variables argument, and set the cross=TRUE.\n\ncmp &lt;- comparisons(mod, \n    variables = list(SexCode = 0:1, Age = 5),\n    cross = TRUE,\n    newdata = passenger)\ncmp\n#&gt; \n#&gt;  C: Age C: SexCode Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 % PClass Age SexCode\n#&gt;      +5      1 - 0    0.271     0.0584 4.64   &lt;0.001 18.1 0.156  0.385    3rd  20       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast_Age, contrast_SexCode, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, Survived, SexCode\n\nThis tells us that changing our hypothetical passenger from SexCode=0 to 1, and from Age=20 to 25 simultaneously is associated with a change of 0.27 in the predicted probability of survival (on a 0 to 1 scale).",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#outcome-type",
    "href": "vignettes/comparisons.html#outcome-type",
    "title": "Comparisons",
    "section": "Outcome type",
    "text": "Outcome type\nWe can compute contrasts on different response scales. In GLM model, for example, we tend to estimate contrasts and comparisons on the “response” scale, becasue the results are expressed on the natural unit of measurement of the dependent variable. However, we an also compute the quantity on the “link” scale, by changing the type argument:\n\ncomparisons(mod, type = \"response\", newdata = passenger)\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %    97.5 % PClass Age SexCode\n#&gt;  Age     +1        -0.00735     0.0033 -2.23   0.0258  5.3 -0.0138 -0.000887    3rd  20       0\n#&gt;  PClass  2nd - 1st -0.36282     0.0976 -3.72   &lt;0.001 12.3 -0.5541 -0.171567    3rd  20       0\n#&gt;  PClass  3rd - 1st -0.42376     0.0871 -4.87   &lt;0.001 19.7 -0.5945 -0.253040    3rd  20       0\n#&gt;  SexCode 1 - 0      0.27170     0.0588  4.62   &lt;0.001 18.0  0.1565  0.386927    3rd  20       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\ncomparisons(mod, type = \"link\", newdata = passenger)\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 % PClass Age SexCode\n#&gt;  Age     +1         -0.0507     0.0202 -2.51   0.0121  6.4 -0.0902 -0.0111    3rd  20       0\n#&gt;  PClass  2nd - 1st  -1.5690     0.4491 -3.49   &lt;0.001 11.0 -2.4491 -0.6888    3rd  20       0\n#&gt;  PClass  3rd - 1st  -1.9381     0.3977 -4.87   &lt;0.001 19.8 -2.7177 -1.1586    3rd  20       0\n#&gt;  SexCode 1 - 0       1.3232     0.2883  4.59   &lt;0.001 17.8  0.7582  1.8882    3rd  20       0\n#&gt; \n#&gt; Type:  link \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived\n\nThe support type values depend on the kind of fitted model at hand. Supported types for a specific model are printed to screen when a bad type is entered:\n\ncomparisons(mod, type = \"bad type name\")\n#&gt; Error in sanitize_type(model = model, type = type, calling_function = \"comparisons\"): Assertion on 'type' failed: Must be element of set {'response','link'}, but is 'bad type name'.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#empirical-distribution",
    "href": "vignettes/comparisons.html#empirical-distribution",
    "title": "Comparisons",
    "section": "Empirical distribution",
    "text": "Empirical distribution\nBy default, the comparisons() function returns estimates for every single row of the original data frame which was used to fit the model. The Titanic dataset includes 756 complete observations (after dropping missing data), so this command will yield 756 estimates:\n\ncomparisons(mod, variables = \"Age\")\n#&gt; \n#&gt;   Estimate Std. Error      z Pr(&gt;|z|)    S    2.5 %   97.5 %\n#&gt;   0.000618    0.00169  0.365  0.71479  0.5 -0.00270  0.00393\n#&gt;   0.000823    0.00283  0.291  0.77092  0.4 -0.00472  0.00636\n#&gt;  -0.013485    0.00386 -3.493  &lt; 0.001 11.0 -0.02105 -0.00592\n#&gt;   0.000645    0.00183  0.352  0.72511  0.5 -0.00295  0.00424\n#&gt;  -0.008463    0.00117 -7.217  &lt; 0.001 40.8 -0.01076 -0.00616\n#&gt; --- 746 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n#&gt;  -0.005742    0.00207 -2.774  0.00554 7.5 -0.00980 -0.00168\n#&gt;  -0.005959    0.00223 -2.673  0.00753 7.1 -0.01033 -0.00159\n#&gt;  -0.006871    0.00292 -2.350  0.01877 5.7 -0.01260 -0.00114\n#&gt;  -0.006407    0.00257 -2.496  0.01255 6.3 -0.01144 -0.00138\n#&gt;  -0.005321    0.00177 -3.006  0.00264 8.6 -0.00879 -0.00185\n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: +1\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, Survived, PClass, SexCode, Age\n\nIf we do not specify the variables argument, comparisons() computes 4 distinct contrasts for all the variables, so we get \\(4\\\\times 756=3024\\) rows:\n\ncomparisons(mod)\n#&gt; \n#&gt;     Term Contrast  Estimate Std. Error      z Pr(&gt;|z|)    S    2.5 %   97.5 %\n#&gt;  Age        +1     0.000618    0.00169  0.365    0.715  0.5 -0.00270  0.00393\n#&gt;  Age        +1     0.000823    0.00283  0.291    0.771  0.4 -0.00472  0.00636\n#&gt;  Age        +1    -0.013485    0.00386 -3.493   &lt;0.001 11.0 -0.02105 -0.00592\n#&gt;  Age        +1     0.000645    0.00183  0.352    0.725  0.5 -0.00295  0.00424\n#&gt;  Age        +1    -0.008463    0.00117 -7.217   &lt;0.001 40.8 -0.01076 -0.00616\n#&gt; --- 3014 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n#&gt;  SexCode    1 - 0  0.317013    0.05762  5.501   &lt;0.001 24.7  0.20407  0.42995\n#&gt;  SexCode    1 - 0  0.311224    0.05657  5.502   &lt;0.001 24.7  0.20035  0.42210\n#&gt;  SexCode    1 - 0  0.285811    0.05627  5.080   &lt;0.001 21.3  0.17553  0.39609\n#&gt;  SexCode    1 - 0  0.298977    0.05557  5.380   &lt;0.001 23.7  0.19005  0.40790\n#&gt;  SexCode    1 - 0  0.327942    0.06066  5.406   &lt;0.001 23.9  0.20905  0.44684\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, Survived, PClass, SexCode, Age\n\nWe can plot the full distribution of unit-specific contrasts easily:\n\nlibrary(ggplot2)\n\ncomparisons(mod) |&gt;\n    ggplot(aes(x = estimate)) +\n    geom_histogram(bins = 30) +\n    facet_grid(. ~ term + contrast, scales = \"free\")\n\n\n\n\n\n\n\nThe plot above suggests that there is substantial heterogeneity in treatment effects across different unit characteristics.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#user-specified-values",
    "href": "vignettes/comparisons.html#user-specified-values",
    "title": "Comparisons",
    "section": "User-specified values",
    "text": "User-specified values\nIn some contexts, it is interesting to estimate a contrast for a specific individual with characteristics of interest. To achieve this, we can supply a data frame to the newdata argument.\nThis code shows the expected change in probability of survival in the counterfactual world where Mr Harry Anderson had been 20 years older:\n\nunit &lt;- subset(dat, Name == \"Anderson, Mr Harry\")\n\ncomparisons(mod, newdata = unit)\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 %   97.5 % rownames               Name PClass Age  Sex SexCode\n#&gt;  Age     +1         -0.0103    0.00239 -4.31   &lt;0.001  15.9 -0.015 -0.00562        6 Anderson, Mr Harry    1st  47 male       0\n#&gt;  PClass  2nd - 1st  -0.2538    0.04630 -5.48   &lt;0.001  24.5 -0.345 -0.16307        6 Anderson, Mr Harry    1st  47 male       0\n#&gt;  PClass  3rd - 1st  -0.2074    0.05290 -3.92   &lt;0.001  13.5 -0.311 -0.10372        6 Anderson, Mr Harry    1st  47 male       0\n#&gt;  SexCode 1 - 0       0.6959    0.05207 13.37   &lt;0.001 132.9  0.594  0.79791        6 Anderson, Mr Harry    1st  47 male       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, rownames, Name, PClass, Age, Sex, Survived, SexCode\n\nA very convenient way to create grids of units with specific predictor values is to the datagrid() function from the marginaleffects package. With this function, we can specify exactly where we want to evaluate the comparison in the predictor space. Say we are interested in:\n\nThe effect of changing passenger class on the predicted probability of survival for a 50 year old man and a 50 year old woman.\n\nWe can type:\n\ncomparisons(mod,\n  variables = \"PClass\", \n  newdata = datagrid(Age = 50, SexCode = 0:1))\n#&gt; \n#&gt;   Contrast Age SexCode Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 %\n#&gt;  2nd - 1st  50       0   -0.226     0.0473 -4.78   &lt;0.001 19.1 -0.319 -0.1333\n#&gt;  2nd - 1st  50       1   -0.156     0.1034 -1.51    0.131  2.9 -0.359  0.0465\n#&gt;  3rd - 1st  50       0   -0.184     0.0535 -3.45   &lt;0.001 10.8 -0.289 -0.0796\n#&gt;  3rd - 1st  50       1   -0.511     0.1242 -4.12   &lt;0.001 14.7 -0.755 -0.2679\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Age, SexCode, predicted_lo, predicted_hi, predicted, PClass, Survived\n\nNotice that the contrasts are different for the man and the woman. It appears that changing class has a larger effect on the expected probability of survival for men than for women.\nNote that when using datagrid() in this manner, variables that are not specified explicitly by the user are held at their mean or mode.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#representative-values",
    "href": "vignettes/comparisons.html#representative-values",
    "title": "Comparisons",
    "section": "Representative values",
    "text": "Representative values\nAn alternative which used to be very common but has now fallen into a bit of disfavor is to compute “Contrasts at the mean.” The idea is to create a “representative” or “synthetic” individual (row of the dataset) whose characteristics are completely average (or modal). Then, we compute and report the contrast for this specific hypothetical individual. For example:\n\ncomparisons(mod, newdata = \"mean\")\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S    2.5 %   97.5 % PClass SexCode  Age\n#&gt;  Age     +1        -0.00504    0.00158 -3.20  0.00139  9.5 -0.00813 -0.00195    3rd       0 30.4\n#&gt;  PClass  2nd - 1st -0.39777    0.06378 -6.24  &lt; 0.001 31.1 -0.52278 -0.27277    3rd       0 30.4\n#&gt;  PClass  3rd - 1st -0.34949    0.06333 -5.52  &lt; 0.001 24.8 -0.47361 -0.22537    3rd       0 30.4\n#&gt;  SexCode 1 - 0      0.33509    0.06340  5.29  &lt; 0.001 22.9  0.21083  0.45935    3rd       0 30.4\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, SexCode, Age, Survived\n\ncomparisons(mod, newdata = \"mean\")\n#&gt; \n#&gt;     Term  Contrast Estimate Std. Error     z Pr(&gt;|z|)    S    2.5 %   97.5 % PClass SexCode  Age\n#&gt;  Age     +1        -0.00504    0.00158 -3.20  0.00139  9.5 -0.00813 -0.00195    3rd       0 30.4\n#&gt;  PClass  2nd - 1st -0.39777    0.06378 -6.24  &lt; 0.001 31.1 -0.52278 -0.27277    3rd       0 30.4\n#&gt;  PClass  3rd - 1st -0.34949    0.06333 -5.52  &lt; 0.001 24.8 -0.47361 -0.22537    3rd       0 30.4\n#&gt;  SexCode 1 - 0      0.33509    0.06340  5.29  &lt; 0.001 22.9  0.21083  0.45935    3rd       0 30.4\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, SexCode, Age, Survived\n\nContrasts at the mean can differ substantially from average contrasts.\nThe advantage of this approach is that it is very cheap and fast computationally. The disadvantage is that the interpretation is somewhat ambiguous. Often times, there simply does not exist an individual who is perfectly average across all dimensions of the dataset. It is also not clear why the analyst should be particularly interested in the contrast for this one, synthetic, perfectly average individual.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#balanced-grids",
    "href": "vignettes/comparisons.html#balanced-grids",
    "title": "Comparisons",
    "section": "Balanced grids",
    "text": "Balanced grids\nOne type of grid which may be particularly useful in experimental setting is the “balanced grid”, which includes all unique combinations of categorical variables, while holding numeric variables a their means. For example, in the Titanic dataset there are two categorical variables, SexCode and PClass, with 2 and 3 categories respectively. A balanced grid, will thus have rows. We can create this grid with:\n\ndatagrid(model = mod, grid_type = \"balanced\")\n#&gt;   PClass SexCode      Age rowid\n#&gt; 1    1st       1 30.39799     1\n#&gt; 2    1st       0 30.39799     2\n#&gt; 3    2nd       1 30.39799     3\n#&gt; 4    2nd       0 30.39799     4\n#&gt; 5    3rd       1 30.39799     5\n#&gt; 6    3rd       0 30.39799     6\n\nWhen using datagrid() inside a comparisons() call, we do not need to specify the model argument manually:\n\ncomparisons(mod,\n    variables = \"SexCode\",\n    newdata = datagrid(grid_type = \"balanced\"))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 % PClass  Age\n#&gt;     0.483     0.0631  7.65   &lt;0.001  45.5 0.359  0.606    1st 30.4\n#&gt;     0.483     0.0631  7.65   &lt;0.001  45.5 0.359  0.606    1st 30.4\n#&gt;     0.812     0.0447 18.18   &lt;0.001 243.0 0.725  0.900    2nd 30.4\n#&gt;     0.812     0.0447 18.18   &lt;0.001 243.0 0.725  0.900    2nd 30.4\n#&gt;     0.335     0.0634  5.29   &lt;0.001  22.9 0.211  0.459    3rd 30.4\n#&gt;     0.335     0.0634  5.29   &lt;0.001  22.9 0.211  0.459    3rd 30.4\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: 1 - 0\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, SexCode, Age, Survived\n\ncomparisons(mod,\n    variables = \"SexCode\",\n    newdata = \"balanced\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 % PClass  Age\n#&gt;     0.483     0.0631  7.65   &lt;0.001  45.5 0.359  0.606    1st 30.4\n#&gt;     0.483     0.0631  7.65   &lt;0.001  45.5 0.359  0.606    1st 30.4\n#&gt;     0.812     0.0447 18.18   &lt;0.001 243.0 0.725  0.900    2nd 30.4\n#&gt;     0.812     0.0447 18.18   &lt;0.001 243.0 0.725  0.900    2nd 30.4\n#&gt;     0.335     0.0634  5.29   &lt;0.001  22.9 0.211  0.459    3rd 30.4\n#&gt;     0.335     0.0634  5.29   &lt;0.001  22.9 0.211  0.459    3rd 30.4\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: 1 - 0\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, SexCode, Age, Survived",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#subgroups",
    "href": "vignettes/comparisons.html#subgroups",
    "title": "Comparisons",
    "section": "Subgroups",
    "text": "Subgroups\nUsing the by argument we can compute the “average effect” (i.e., “contrast” or “risk difference”) of an increase of 10 years of Age in each of the passenger classes:\n\navg_comparisons(mod,\n    variables = list(Age = 10),\n    by = \"PClass\")\n#&gt; \n#&gt;  PClass Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;     1st  -0.0524     0.0129 -4.08   &lt;0.001 14.4 -0.0776 -0.02725\n#&gt;     2nd  -0.0718     0.0164 -4.39   &lt;0.001 16.4 -0.1039 -0.03976\n#&gt;     3rd  -0.0359     0.0178 -2.02   0.0433  4.5 -0.0708 -0.00108\n#&gt; \n#&gt; Term: Age\n#&gt; Type:  response \n#&gt; Comparison: mean(+10)\n#&gt; Columns: term, contrast, PClass, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#marginal-means",
    "href": "vignettes/comparisons.html#marginal-means",
    "title": "Comparisons",
    "section": "Marginal means",
    "text": "Marginal means\nIn experimental studies, it can often make sense to estimate contrasts, averaged across a balanced grid of treatment conditions:\n\navg_comparisons(mod, newdata = \"balanced\")\n#&gt; \n#&gt;     Term              Contrast Estimate Std. Error     z Pr(&gt;|z|)     S    2.5 %  97.5 %\n#&gt;  Age     mean(+1)              -0.00494    0.00119 -4.14   &lt;0.001  14.8 -0.00728 -0.0026\n#&gt;  PClass  mean(2nd) - mean(1st) -0.23312    0.03865 -6.03   &lt;0.001  29.2 -0.30887 -0.1574\n#&gt;  PClass  mean(3rd) - mean(1st) -0.42333    0.04472 -9.47   &lt;0.001  68.2 -0.51098 -0.3357\n#&gt;  SexCode mean(1) - mean(0)      0.54331    0.03332 16.30   &lt;0.001 196.1  0.47800  0.6086\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that the results are slightly different than when averaging across the empirical, because the number of actual passengers aboard the Titanic was not perfectly balanced across gender and ticket categories:\n\navg_comparisons(mod)\n#&gt; \n#&gt;     Term              Contrast Estimate Std. Error     z Pr(&gt;|z|)     S    2.5 %   97.5 %\n#&gt;  Age     mean(+1)              -0.00598    0.00109 -5.51   &lt;0.001  24.7 -0.00811 -0.00386\n#&gt;  PClass  mean(2nd) - mean(1st) -0.22484    0.04054 -5.55   &lt;0.001  25.0 -0.30429 -0.14539\n#&gt;  PClass  mean(3rd) - mean(1st) -0.39568    0.04253 -9.30   &lt;0.001  66.0 -0.47904 -0.31231\n#&gt;  SexCode mean(1) - mean(0)      0.49731    0.03017 16.48   &lt;0.001 200.3  0.43816  0.55645\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#robust-clustered-standard-errors",
    "href": "vignettes/comparisons.html#robust-clustered-standard-errors",
    "title": "Comparisons",
    "section": "Robust (clustered) standard errors",
    "text": "Robust (clustered) standard errors\nThe standard errors reported by default for most models are “classical” (or “iid”). For models supported by the sandwich or clubSandwich packages, we can call on the vcov argument to report robust standard errors (and confidence intervales, p values, etc.):\nClassical:\n\navg_comparisons(mod, variables = \"SexCode\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;     0.497     0.0302 16.5   &lt;0.001 200.3 0.438  0.556\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nHeteroskedasticity-robust:\n\navg_comparisons(mod, vcov = \"HC3\", variables = \"SexCode\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;     0.497     0.0306 16.2   &lt;0.001 194.7 0.437  0.557\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#bootstrap-and-simulation",
    "href": "vignettes/comparisons.html#bootstrap-and-simulation",
    "title": "Comparisons",
    "section": "Bootstrap and simulation",
    "text": "Bootstrap and simulation\nWe can use bootstrapping or simulations to compute uncertainty estimates, via the inferences() function. Notice that, for some quantities, the classical intervals are very different (here: symmetric) than boostrap intervals (here: asymmetric):\n\n# classical\navg_comparisons(mod, comparison = \"lnor\", variables = \"SexCode\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      2.19      0.159 13.8   &lt;0.001 141.7  1.88   2.51\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: ln(odds(1) / odds(0))\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n# bootstrap\navg_comparisons(mod, comparison = \"lnor\", variables = \"SexCode\") |&gt;\n    inferences(\"rsample\")\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      2.19  1.87   2.52\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: ln(odds(1) / odds(0))\n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#transformation",
    "href": "vignettes/comparisons.html#transformation",
    "title": "Comparisons",
    "section": "Transformation",
    "text": "Transformation\nBy default, the standard errors around contrasts are computed on the scale determined by the type argument (e.g., “link” or “response”). Some analysts may prefer to proceed differently. For example, in Stata, the adjrr computes adjusted risk ratios (ARR) in two steps:\n\nCompute the natural log of the ratio between the mean of adjusted predictions with \\(x+1\\) and the mean of adjusted predictions with \\(x\\).\nExponentiate the estimate and confidence interval bounds.\n\nStep 1 is easy to achieve with the comparison argument described above. Step 2 can be achieved with the transform argument:\n\navg_comparisons(\n    mod,\n    comparison = function(hi, lo) log(hi / lo),\n    transform = exp)\n#&gt; \n#&gt;     Term Contrast Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;  Age     +1          0.962   &lt;0.001 24.9 0.949  0.975\n#&gt;  PClass  2nd, 1st    0.267   &lt;0.001 19.6 0.157  0.456\n#&gt;  PClass  3rd, 1st    0.323   &lt;0.001 35.9 0.233  0.449\n#&gt;  SexCode 1, 0        4.506   &lt;0.001 86.6 3.421  5.934\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high\n\nNote that we can use the lnratioavg shortcut instead of defining the function ourselves.\nThe order of operations in previous command was:\n\nCompute the custom unit-level log ratios\nExponentiate them\nTake the average using the avg_comparisons()\n\n\nThere is a very subtle difference between the procedure above and this code:\n\navg_comparisons(\n    mod,\n    comparison = function(hi, lo) log(hi / lo),\n    transform = exp)\n#&gt; \n#&gt;     Term Contrast Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;  Age     +1          0.962   &lt;0.001 24.9 0.949  0.975\n#&gt;  PClass  2nd, 1st    0.267   &lt;0.001 19.6 0.157  0.456\n#&gt;  PClass  3rd, 1st    0.323   &lt;0.001 35.9 0.233  0.449\n#&gt;  SexCode 1, 0        4.506   &lt;0.001 86.6 3.421  5.934\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high\n\nSince the exp function is now passed to the transform argument of the comparisons() function, the exponentiation is now done only after unit-level contrasts have been averaged. This is what Stata appears to do under the hood, and the results are slightly different.\n\ncomparisons(\n    mod,\n    comparison = function(hi, lo) log(mean(hi) / mean(lo)),\n    transform = exp)\n#&gt; \n#&gt;     Term Contrast Estimate Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;  Age     +1          0.986   &lt;0.001  25.5 0.981  0.991\n#&gt;  PClass  2nd, 1st    0.652   &lt;0.001  27.1 0.565  0.754\n#&gt;  PClass  3rd, 1st    0.388   &lt;0.001  53.8 0.311  0.485\n#&gt;  SexCode 1, 0        3.228   &lt;0.001 134.0 2.720  3.831\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that equivalent results can be obtained using shortcut strings in the comparison argument: “ratio”, “lnratio”, “lnratioavg”.\n\ncomparisons(\n    mod,\n    comparison = \"lnratioavg\",\n    transform = exp)\n#&gt; \n#&gt;     Term                  Contrast Estimate Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;  Age     mean(+1)                     0.986   &lt;0.001  25.5 0.981  0.991\n#&gt;  PClass  ln(mean(2nd) / mean(1st))    0.652   &lt;0.001  27.1 0.565  0.754\n#&gt;  PClass  ln(mean(3rd) / mean(1st))    0.388   &lt;0.001  53.8 0.311  0.485\n#&gt;  SexCode ln(mean(1) / mean(0))        3.228   &lt;0.001 134.0 2.720  3.831\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#customization",
    "href": "vignettes/comparisons.html#customization",
    "title": "Comparisons",
    "section": "Customization",
    "text": "Customization\nThe plot customization section of the Plots vignette illustrates two more ways to customize plots. In addition to using the plot_*() function arguments, users can:\n\nModify the plot objects using ggplot2 functions or add-on packages.\nExtract the underlying plotting data with the draw=FALSE argument, and feed that data to their preferred plotting software.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#manual-computation",
    "href": "vignettes/comparisons.html#manual-computation",
    "title": "Comparisons",
    "section": "Manual computation",
    "text": "Manual computation\nNow we show how to use the base R predict() function to compute some of the same quantities as above. This exercise may be clarifying for some users.\n\ngrid_50_1_3 &lt;- data.frame(Age = 50, SexCode = 1, PClass = \"3rd\")\ngrid_50_1_1 &lt;- data.frame(Age = 50, SexCode = 1, PClass = \"1st\")\ngrid_50_0_3 &lt;- data.frame(Age = 50, SexCode = 0, PClass = \"3rd\")\ngrid_50_0_1 &lt;- data.frame(Age = 50, SexCode = 0, PClass = \"1st\")\n\n\nyhat_50_1_3 &lt;- predict(mod, newdata = grid_50_1_3, type = \"response\")\nyhat_50_1_1 &lt;- predict(mod, newdata = grid_50_1_1, type = \"response\")\nyhat_50_0_3 &lt;- predict(mod, newdata = grid_50_0_3, type = \"response\")\nyhat_50_0_1 &lt;- predict(mod, newdata = grid_50_0_1, type = \"response\")\n\n## prediction on a grid\npredictions(mod, newdata = datagrid(Age = 50, SexCode = 1, PClass = \"3rd\"))\n#&gt; \n#&gt;  Age SexCode PClass Estimate Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;   50       1    3rd    0.446    0.661 0.6 0.235  0.679\n#&gt; \n#&gt; Type:  invlink(link) \n#&gt; Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, Age, SexCode, PClass, Survived\nyhat_50_1_3\n#&gt;         1 \n#&gt; 0.4463379\n\n## contrast on a grid\ncomparisons(mod,\n  variables = list(PClass = c(\"1st\", \"3rd\")),\n  newdata = datagrid(Age = 50, SexCode = 0:1))\n#&gt; \n#&gt;  Age SexCode Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 %\n#&gt;   50       0   -0.184     0.0535 -3.45   &lt;0.001 10.8 -0.289 -0.0796\n#&gt;   50       1   -0.511     0.1242 -4.12   &lt;0.001 14.7 -0.755 -0.2679\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Comparison: 3rd - 1st\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Age, SexCode, predicted_lo, predicted_hi, predicted, PClass, Survived\n\nyhat_50_0_3 - yhat_50_0_1\n#&gt;          1 \n#&gt; -0.1844289\nyhat_50_1_3 - yhat_50_1_1\n#&gt;          1 \n#&gt; -0.5113098\n\n## difference-in-differences \ncomparisons(mod,\n  variables = list(PClass = c(\"1st\", \"3rd\")),\n  newdata = datagrid(Age = 50, SexCode = 0:1),\n  hypothesis = \"b1 = b2\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;     0.327      0.135 2.42   0.0156 6.0 0.0618  0.592\n#&gt; \n#&gt; Term: b1=b2\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\n(yhat_50_0_3 - yhat_50_0_1) - (yhat_50_1_3 - yhat_50_1_1)\n#&gt;         1 \n#&gt; 0.3268809\n\n## average of the empirical distribution of contrasts\navg_comparisons(mod, variables = list(PClass = c(\"1st\", \"3rd\")), by = \"SexCode\")\n#&gt; \n#&gt;  SexCode Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;        0   -0.334     0.0570 -5.86   &lt;0.001 27.7 -0.446 -0.222\n#&gt;        1   -0.496     0.0623 -7.95   &lt;0.001 49.0 -0.618 -0.374\n#&gt; \n#&gt; Term: PClass\n#&gt; Type:  response \n#&gt; Comparison: mean(3rd) - mean(1st)\n#&gt; Columns: term, contrast, SexCode, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\ngrid_empirical_1_3 &lt;- dat |&gt; subset(SexCode == 1) |&gt; transform(PClass = \"3rd\")\ngrid_empirical_1_1 &lt;- dat |&gt; subset(SexCode == 1) |&gt; transform(PClass = \"1st\")\ngrid_empirical_0_3 &lt;- dat |&gt; subset(SexCode == 0) |&gt; transform(PClass = \"3rd\")\ngrid_empirical_0_1 &lt;- dat |&gt; subset(SexCode == 0) |&gt; transform(PClass = \"1st\")\nyhat_empirical_0_1 &lt;- predict(mod, newdata = grid_empirical_0_1, type = \"response\")\nyhat_empirical_0_3 &lt;- predict(mod, newdata = grid_empirical_0_3, type = \"response\")\nyhat_empirical_1_1 &lt;- predict(mod, newdata = grid_empirical_1_1, type = \"response\")\nyhat_empirical_1_3 &lt;- predict(mod, newdata = grid_empirical_1_3, type = \"response\")\nmean(yhat_empirical_0_3, na.rm = TRUE) - mean(yhat_empirical_0_1, na.rm = TRUE)\n#&gt; [1] -0.3341426\nmean(yhat_empirical_1_3, na.rm = TRUE) - mean(yhat_empirical_1_1, na.rm = TRUE)\n#&gt; [1] -0.4956673",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#transformations",
    "href": "vignettes/comparisons.html#transformations",
    "title": "Comparisons",
    "section": "Transformations",
    "text": "Transformations\nSo far we have focused on simple differences between adjusted predictions. Now, we show how to use ratios, back transformations, and arbitrary functions to estimate a slew of quantities of interest. Powerful transformations and custom contrasts are made possible by using three arguments which act at different stages of the computation process:\n\ncomparison\ntransform\n\nConsider the case of a model with a single predictor \\(x\\). To compute average contrasts, we proceed as follows:\n\nCompute adjusted predictions for each row of the dataset for the observed values \\(x\\): \\(\\hat{y}_x\\)\n\nCompute adjusted predictions for each row of the dataset for the observed values \\(x + 1\\): \\(\\hat{y}_{x+1}\\)\n\n\ncomparison: Compute unit-level contrasts by taking the difference between (or some other function of) adjusted predictions: \\(\\hat{y}_{x+1} - \\hat{y}_x\\)\n\nCompute the average contrast by taking the mean of unit-level contrasts: \\(1/N \\sum_{i=1}^N \\hat{y}_{x+1} - \\hat{y}_x\\)\n\n\ntransform: Transform the average contrast or return them as-is.\n\nThe comparison argument of the comparisons() function determines how adjusted predictions are combined to create a contrast. By default, we take a simple difference between predictions with hi value of \\(x\\), and predictions with a lo value of \\(x\\): function(hi, lo) hi-lo.\nThe transform argument of the comparisons() function applies a custom transformation to the unit-level contrasts.\nThe transform argument applies a custom transformation to the final quantity, as would be returned if we evaluated the same call without transform.\nThis call adds the transform argument to exponentiate the log-odds ratios at the very end of calculations:\n\nmod &lt;- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial)\n\ncomparisons(mod, \n    comparison = \"lnor\", \n    transform = exp,\n    newdata = passenger)\n#&gt; \n#&gt;     Term                  Contrast Estimate Pr(&gt;|z|)    S  2.5 % 97.5 % PClass Age SexCode\n#&gt;  Age     +1                           0.951   0.0121  6.4 0.9137  0.989    3rd  20       0\n#&gt;  PClass  ln(odds(2nd) / odds(1st))    0.208   &lt;0.001 11.0 0.0864  0.502    3rd  20       0\n#&gt;  PClass  ln(odds(3rd) / odds(1st))    0.144   &lt;0.001 19.8 0.0660  0.314    3rd  20       0\n#&gt;  SexCode ln(odds(1) / odds(0))        3.755   &lt;0.001 17.8 2.1345  6.607    3rd  20       0\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, PClass, Age, SexCode, Survived",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#difference-in-differences",
    "href": "vignettes/comparisons.html#difference-in-differences",
    "title": "Comparisons",
    "section": "Difference-in-Differences",
    "text": "Difference-in-Differences\nOne thing we can notice in the Titanic example, is that the gap in predicted probabilities of survival between men and women is larger in 1st class than in 3rd class.\n\ncomparisons(\n  mod,\n  variables = \"SexCode\",\n  newdata = datagrid(PClass = c(\"1st\", \"3rd\")))\n#&gt; \n#&gt;  PClass Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %  Age\n#&gt;     1st    0.483     0.0631 7.65   &lt;0.001 45.5 0.359  0.606 30.4\n#&gt;     3rd    0.335     0.0634 5.29   &lt;0.001 22.9 0.211  0.459 30.4\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: 1 - 0\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, PClass, predicted_lo, predicted_hi, predicted, SexCode, Age, Survived\n\nIndeed, being a woman matters more for your chances of survival if you travel in first class. Is the difference between those contrasts (diff-in-diff) statistically significant?\nTo answer this question, we can compute a difference-in-difference using the hypothesis argument (see the Hypothesis vignette for details). For example, using b1 and b2 to refer to the contrasts in the first and second rows of the output above, we can test if the difference between the two quantities is different from 0:\n\ncomparisons(\n  mod,\n  hypothesis = \"b1 - b2 = 0\",\n  variables = \"SexCode\",\n  newdata = datagrid(PClass = c(\"1st\", \"3rd\")))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S   2.5 % 97.5 %\n#&gt;     0.148     0.0894 1.65   0.0987 3.3 -0.0276  0.323\n#&gt; \n#&gt; Term: b1-b2=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nNow, let’s say we consider more types of individuals:\n\ncomparisons(\n  mod,\n  variables = \"SexCode\",\n  newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range))\n#&gt; \n#&gt;  PClass   Age Estimate Std. Error      z Pr(&gt;|z|)     S   2.5 % 97.5 %\n#&gt;     1st  0.17   0.1081      0.122  0.883   0.3774   1.4 -0.1319  0.348\n#&gt;     1st 71.00   0.8795      0.057 15.437   &lt;0.001 176.2  0.7679  0.991\n#&gt;     3rd  0.17   0.0805      0.157  0.513   0.6081   0.7 -0.2272  0.388\n#&gt;     3rd 71.00   0.4265      0.203  2.101   0.0356   4.8  0.0287  0.824\n#&gt; \n#&gt; Term: SexCode\n#&gt; Type:  response \n#&gt; Comparison: 1 - 0\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, PClass, Age, predicted_lo, predicted_hi, predicted, SexCode, Survived\n\nWith these results, we could compute a triple difference:\n\ncomparisons(\n  mod,\n  hypothesis = \"(b1 - b3) - (b2 - b4) = 0\",\n  variables = \"SexCode\",\n  newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.425      0.359 -1.19    0.236 2.1 -1.13  0.278\n#&gt; \n#&gt; Term: (b1-b3)-(b2-b4)=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#forward-backward-centered",
    "href": "vignettes/comparisons.html#forward-backward-centered",
    "title": "Comparisons",
    "section": "Forward, Backward, Centered",
    "text": "Forward, Backward, Centered\nBy default, the comparisons() function computes a “forward” difference. For example, if we ask comparisons() to estimate the effect of a 10-unit change in predictor x on outcome y, comparisons() will compare the predicted values with x and x+10.\n\nmt &lt;- mtcars\nmt$new_hp &lt;- 49 * (mt$hp - min(mt$hp)) / (max(mt$hp) - min(mt$hp)) + 1\nmod_mt &lt;- lm(mpg ~ log(new_hp), data = mt)\n\navg_comparisons(\n  mod_mt,\n  variables = list(new_hp = 10))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      -3.8      0.435 -8.74   &lt;0.001 58.6 -4.65  -2.95\n#&gt; \n#&gt; Term: new_hp\n#&gt; Type:  response \n#&gt; Comparison: mean(+10)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nWe can supply arbitrary functions to create custom differences. These functions must accept a vector of values for the predictor of interest, and return a data frame with the same number of rows as the length, and two columns with the values to compare. For example, we can do:\n\nforward_diff &lt;- \\(x) data.frame(x, x + 10)\nbackward_diff &lt;- \\(x) data.frame(x - 10, x)\ncenter_diff &lt;- \\(x) data.frame(x - 5, x + 5)\n\navg_comparisons(\n  mod_mt,\n  variables = list(new_hp = forward_diff))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      -3.8      0.435 -8.74   &lt;0.001 58.6 -4.65  -2.95\n#&gt; \n#&gt; Term: new_hp\n#&gt; Type:  response \n#&gt; Comparison: custom\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\navg_comparisons(\n  mod_mt,\n  variables = list(new_hp = backward_diff))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;     -6.51      0.744 -8.74   &lt;0.001 58.6 -7.97  -5.05\n#&gt; \n#&gt; Term: new_hp\n#&gt; Type:  response \n#&gt; Comparison: custom\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\navg_comparisons(\n  mod_mt,\n  variables = list(new_hp = center_diff))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;     -4.06      0.464 -8.74   &lt;0.001 58.6 -4.97  -3.15\n#&gt; \n#&gt; Term: new_hp\n#&gt; Type:  response \n#&gt; Comparison: custom\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNotice that the last “centered” difference gives the same results as the default comparisons() call.",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/comparisons.html#observation-wise-categorical-marginal-effect",
    "href": "vignettes/comparisons.html#observation-wise-categorical-marginal-effect",
    "title": "Comparisons",
    "section": "Observation-Wise Categorical Marginal Effect",
    "text": "Observation-Wise Categorical Marginal Effect\nFor categorical predictors, Scholbeck et al. 2023 recommend that analysts report what they call the “observation-wise categorical marginal effects.” They describe the procedure as follows:\n\nRecall that the common definition of categorical MEs is based on first changing all observations’ value of \\(x_j\\) to each category and then computing the difference in predictions when changing it to the reference category. However, one is often interested in prediction changes if aspects of an actual observation change. We therefore propose an observation-wise categorical ME. We first select a single reference category \\(c_h\\). For each observation whose feature value \\(x_j \\neq c_h\\), we predict once with the observed value \\(x_j\\) and once where \\(x_j\\) has been replaced by \\(c_h\\).\n\nTo achieve this with marginaleffects, we proceed in three simple steps:\n\nUse the factor() function to set the reference level of the categorical variable.\nUse the newdata argument to take the subset of data where the observed \\(x_j\\) is different from the reference level we picked in 1.\nApply the avg_comparisons() with the \"revreference\" option.\n\n\nmt &lt;- transform(mtcars, cyl = factor(cyl, levels = c(6, 4, 8)))\n\nmod_mt &lt;- glm(vs ~ mpg * factor(cyl), data = mt, family = binomial)\n\navg_comparisons(mod_mt,\n  variables = list(cyl = \"revreference\"),\n  newdata = subset(mt, cyl != 6))\n#&gt; \n#&gt;           Contrast Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;  mean(6) - mean(4)   -0.323     0.2170 -1.49    0.137   2.9 -0.748  0.103\n#&gt;  mean(6) - mean(8)    0.561     0.0357 15.69   &lt;0.001 181.9  0.491  0.631\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Tutorials",
      "Comparisons"
    ]
  },
  {
    "objectID": "vignettes/bootstrap.html",
    "href": "vignettes/bootstrap.html",
    "title": "Bootstrap & Simulation",
    "section": "",
    "text": "marginaleffects offers an inferences() function to compute uncertainty estimates using the bootstrap and simulation-based inference.\nWARNING: The inferences() function is experimental. It may be renamed, the user interface may change, or the functionality may migrate to arguments in other marginaleffects functions.\nConsider a simple model:\n\nlibrary(marginaleffects)\n\nmod &lt;- lm(Sepal.Length ~ Petal.Width * Petal.Length + factor(Species), data = iris)\n\nWe will compute uncertainty estimates around the output of comparisons(), but note that the same approach works with the predictions() and slopes() functions as well.\n\nThe default strategy to compute standard errors and confidence intervals is the delta method. This is what we obtain by calling:\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\")\n#&gt; \n#&gt;     Species Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.285 -0.387    0.699 0.5 -0.669  0.449\n#&gt;  versicolor  -0.0201      0.160 -0.125    0.900 0.2 -0.334  0.293\n#&gt;  virginica    0.0216      0.169  0.128    0.898 0.2 -0.309  0.353\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nSince this is the default method, we obtain the same results if we add the inferences() call in the chain:\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"delta\")\n#&gt; \n#&gt;     Species Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.285 -0.387    0.699 0.5 -0.669  0.449\n#&gt;  versicolor  -0.0201      0.160 -0.125    0.900 0.2 -0.334  0.293\n#&gt;  virginica    0.0216      0.169  0.128    0.898 0.2 -0.309  0.353\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nmarginaleffects supports three bootstrap frameworks in R: the well-established boot package, the newer rsample package, and the so-called “bayesian bootstrap” in fwb.\n\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"boot\")\n#&gt; \n#&gt;     Species Estimate Std. Error  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.272 -0.655  0.430\n#&gt;  versicolor  -0.0201      0.163 -0.317  0.316\n#&gt;  virginica    0.0216      0.179 -0.315  0.402\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, std.error, conf.low, conf.high\n\nAll unknown arguments that we feed to inferences() are pushed forward to boot::boot():\n\nest &lt;- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"boot\", sim = \"balanced\", R = 500, conf_type = \"bca\")\nest\n#&gt; \n#&gt;     Species Estimate Std. Error  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.264 -0.573  0.428\n#&gt;  versicolor  -0.0201      0.162 -0.327  0.330\n#&gt;  virginica    0.0216      0.187 -0.338  0.412\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, std.error, conf.low, conf.high\n\nWe can extract the original boot object from an attribute:\n\nattr(est, \"inferences\")\n#&gt; \n#&gt; BALANCED BOOTSTRAP\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; (function (model, INF_FUN, ...) \n#&gt; {\n#&gt;     conf_type &lt;- attr(model, \"inferences_conf_type\")\n#&gt;     checkmate::assert_choice(conf_type, choices = c(\"perc\", \"norm\", \n#&gt;         \"basic\", \"bca\"))\n#&gt;     modcall &lt;- insight::get_call(model)\n#&gt;     modeldata &lt;- get_modeldata(model, additional_variables = FALSE)\n#&gt;     dots &lt;- list(...)\n#&gt;     dots[[\"vcov\"]] &lt;- FALSE\n#&gt;     attr(model, \"inferences_method\") &lt;- NULL\n#&gt;     out &lt;- do.call(INF_FUN, c(list(model), dots))\n#&gt;     if (is.null(dots[[\"conf_level\"]])) {\n#&gt;         conf_level &lt;- 0.95\n#&gt;     }\n#&gt;     else {\n#&gt;         conf_level &lt;- dots[[\"conf_level\"]]\n#&gt;     }\n#&gt;     bootfun &lt;- function(data, indices) {\n#&gt;         d &lt;- data[indices, , drop = FALSE]\n#&gt;         modcall[[\"data\"]] &lt;- d\n#&gt;         modboot &lt;- eval(modcall)\n#&gt;         modboot &lt;- eval(modboot)\n#&gt;         args &lt;- c(list(modboot, modeldata = d), dots)\n#&gt;         out &lt;- do.call(INF_FUN, args)$estimate\n#&gt;         return(out)\n#&gt;     }\n#&gt;     args &lt;- list(data = modeldata, statistic = bootfun)\n#&gt;     args &lt;- c(args, attr(model, \"inferences_dots\"))\n#&gt;     args &lt;- args[unique(names(args))]\n#&gt;     B &lt;- do.call(boot::boot, args)\n#&gt;     B$call &lt;- match.call()\n#&gt;     pr &lt;- utils::capture.output(print(B))\n#&gt;     pr &lt;- pr[(grep(\"^Bootstrap Statistics :\", pr) + 1):length(pr)]\n#&gt;     pr &lt;- gsub(\"std. error\", \"std.error\", pr)\n#&gt;     pr &lt;- paste(pr, collapse = \"\\n\")\n#&gt;     pr &lt;- utils::read.table(text = pr, header = TRUE)\n#&gt;     out$std.error &lt;- pr$std.error\n#&gt;     ci_list &lt;- lapply(seq_along(B$t0), boot::boot.ci, boot.out = B, \n#&gt;         conf = conf_level, type = conf_type)\n#&gt;     pos &lt;- pmatch(conf_type, names(ci_list[[1]]))\n#&gt;     if (conf_type == \"norm\") {\n#&gt;         cols &lt;- 2:3\n#&gt;     }\n#&gt;     else {\n#&gt;         cols &lt;- 4:5\n#&gt;     }\n#&gt;     ci &lt;- lapply(ci_list, function(x) x[[pos]])\n#&gt;     ci &lt;- do.call(\"rbind\", ci)[, cols]\n#&gt;     if (is.matrix(ci)) {\n#&gt;         out$conf.low &lt;- ci[, 1]\n#&gt;         out$conf.high &lt;- ci[, 2]\n#&gt;     }\n#&gt;     else {\n#&gt;         out$conf.low &lt;- ci[1]\n#&gt;         out$conf.high &lt;- ci[2]\n#&gt;     }\n#&gt;     attr(out, \"inferences\") &lt;- B\n#&gt;     attr(out, \"posterior_draws\") &lt;- t(B$t)\n#&gt;     return(out)\n#&gt; })(model = list(c(3.78396410453894, -0.157380650291409, 0.854286226046438, \n#&gt; -1.46293310566858, -1.98423971100058, 0.0322348822561755), c(0.142485542022615, \n#&gt; -0.0575144579773967, -0.171441137727629, -0.443587778227166, \n#&gt; 0.0424855420226034, 0.204781851364483, -0.346289276464121, -0.0435877782271645, \n#&gt; -0.557514457977397, -0.154490610917879, 0.356412221772836, -0.329661098476932, \n#&gt; -0.168739639490674, -0.411486725209057, 1.01463218252214, 0.678217887154265, \n#&gt; 0.551653922944047, 0.153710723535879, 0.494523716318892, 0.0673150544635498, \n#&gt; 0.184265581273301, 0.0782178871542645, -0.013221176978328, -0.0849600135899262, \n#&gt; -0.587881059226235, -0.129661098476932, -0.108500130740626, 0.156412221772836, \n#&gt; 0.242485542022603, -0.429661098476932, -0.329661098476932, 0.378217887154265, \n#&gt; 0.145509389082121, 0.542485542022603, -0.143587778227164, 0.214632182522137, \n#&gt; 0.62855886227237, -0.0687396394906731, -0.47144113772763, 0.0564122217728351, \n#&gt; 0.140106392608208, -0.359893607391792, -0.47144113772763, -0.0873391630043204, \n#&gt; -0.268654184425299, -0.146289276464121, -0.0296610984769325, \n#&gt; -0.357514457977398, 0.256412221772835, 0.042485542022603, 0.672051123873723, \n#&gt; 0.253166504128602, 0.392111084356321, -0.201202445409389, 0.262902649185532, \n#&gt; -0.449298231899122, -0.0267735353888003, -0.189170005977571, \n#&gt; 0.361082610802931, -0.408416827162209, -0.266474227638094, 0.0239580689578126, \n#&gt; 0.290265218210599, -0.227948876126278, 0.257274183782397, 0.641875642235248, \n#&gt; -0.546833495871398, 0.00161310738033736, 0.053166504128602, -0.0179162100099074, \n#&gt; -0.516829096062078, 0.398797554590611, -0.207888915643679, -0.229124216863755, \n#&gt; 0.429940082696772, 0.541875642235248, 0.382109617753214, 0.101088477215358, \n#&gt; -0.146833495871398, 0.433525772361906, -0.0289417503570838, 0.0562215507013826, \n#&gt; 0.185250250939325, -0.689118350451328, -0.746833495871398, -0.145601127857536, \n#&gt; 0.372638794242462, 0.240320925398824, -0.190821602707335, -0.201202445409389, \n#&gt; -0.5612337914376, -0.138007370005769, 0.09595344246394, -0.0891700059775712, \n#&gt; -0.280440760005283, -0.182640174486829, -0.180440760005282, 0.229940082696771, \n#&gt; 0.282853926865501, -0.090821602707335, -0.715513357931099, -0.369916919883858, \n#&gt; 0.191096047245598, -0.325369702016127, -0.319664171555401, 0.045710412096514, \n#&gt; -0.723062154511679, 0.0360139881085848, -0.107831504837638, 0.0909992989002138, \n#&gt; 0.329381355194633, 0.0469765796495076, 0.259887838759361, -0.378743045749488, \n#&gt; -0.373425544491401, 0.0415908893829795, -0.0341388006053719, \n#&gt; 0.0476531581355767, -0.143891438994049, -0.0768461652547545, \n#&gt; 0.170220307288722, -0.38686744669361, 0.0593717703005697, 0.31324660785916, \n#&gt; -0.0245080569975196, 0.209706692340851, 0.304477509269916, 0.11324660785916, \n#&gt; -0.232310109119078, 0.398084828521244, 0.31455057778297, 0.534998567468207, \n#&gt; -0.234623578153396, 0.132889979802175, -0.516115825878858, 0.598849725194466, \n#&gt; -0.33925051622203, -0.134138800605372, 0.104477509269916, 0.452085786637802, \n#&gt; 0.0607494837779699, 0.727276180430108, -0.369916919883858, -0.115464983758407, \n#&gt; -0.0350513284250356, 0.434433534906543, 0.221636330349458, 0.237505756138754, \n#&gt; -0.251251756140585, -0.26921519496235), c(-71.5659253183152, \n#&gt; 8.26761414419049, 3.15185596602052, -1.28216612276567, -2.35695868745888, \n#&gt; 0.148835738547779, -0.340443902992748, -0.0297961938363055, -0.537559267311158, \n#&gt; -0.126979856156088, 0.370203806163695, -0.322033120361453, -0.134674631629569, \n#&gt; -0.357758958050013, 1.04691458573913, 0.66457113080326, 0.548771791848065, \n#&gt; 0.159556097007252, 0.483050211435928, 0.0673874684834769, 0.185729953113401, \n#&gt; 0.0645711308032596, 0.0313884387894284, -0.122309271919019, -0.598743899936893, \n#&gt; -0.122033120361453, -0.127529199719143, 0.170203806163695, 0.262440732688842, \n#&gt; -0.422033120361452, -0.322033120361453, 0.36457113080326, 0.173020143843912, \n#&gt; 0.562440732688841, -0.129796193836305, 0.246914585739135, 0.654677659213988, \n#&gt; -0.0346746316295687, -0.445322340786012, 0.0702038061636942, \n#&gt; 0.151724725531026, -0.348275274468974, -0.445322340786012, -0.133025279076833, \n#&gt; -0.303830191286351, -0.140443902992748, -0.0220331203614529, \n#&gt; -0.337559267311159, 0.270203806163694, 0.0624407326888415, 0.594789558050432, \n#&gt; 0.176856861428742, 0.311460651399507, -0.264180100742888, 0.185507808921433, \n#&gt; -0.521608343293153, -0.106472045222184, -0.219019640205961, 0.286906008196794, \n#&gt; -0.47387163788012, -0.3024007252343, -0.0490959810493318, 0.239146562194852, \n#&gt; -0.305210441949568, 0.201762493297324, 0.569041609576475, -0.623143138571258, \n#&gt; -0.0525439803193176, -0.023143138571258, -0.070340080938264, \n#&gt; -0.598877806997992, 0.335819899257112, -0.288539348600494, -0.303948838676952, \n#&gt; 0.361362953726953, 0.469041609576474, 0.303372207541751, 0.0192597836278147, \n#&gt; -0.223143138571258, 0.3975992747657, -0.0787178364254662, 0.0142181897373602, \n#&gt; 0.12848273341445, -0.77159506324593, -0.823143138571258, -0.22391053621031, \n#&gt; 0.294158756414124, 0.169877305216899, -0.255665749252941, -0.264180100742888, \n#&gt; -0.629286999142676, -0.213793091440887, 0.0369287869030251, -0.119019640205961, \n#&gt; -0.347151397762995, -0.246179106119825, -0.247151397762994, 0.161362953726953, \n#&gt; 0.254260119676912, -0.15566574925294, -0.678723653276397, -0.360583343049196, \n#&gt; 0.211187321696559, -0.315946525934337, -0.297752937425579, 0.0746124702030289, \n#&gt; -0.71259338476017, 0.0460443645433169, -0.0982348429407217, 0.130610274230017, \n#&gt; 0.339059047319985, 0.0572649359471646, 0.274944379692862, -0.369933390179567, \n#&gt; -0.362371391203293, 0.0563808814348639, -0.0248023674311454, \n#&gt; 0.084408364095088, -0.09646181450644, -0.067803852018609, 0.193170207449538, \n#&gt; -0.37892582767912, 0.0829380473128177, 0.322062583588008, -0.00693414930528918, \n#&gt; 0.219476840052894, 0.313206742091201, 0.122062583588008, -0.215994884806213, \n#&gt; 0.401524204301707, 0.328658051932604, 0.555960734814162, -0.216011004430172, \n#&gt; 0.140847095474082, -0.515882047438503, 0.629959533464212, -0.316043243678089, \n#&gt; -0.124802367431145, 0.113206742091201, 0.465883644191938, 0.0839567563219111, \n#&gt; 0.737986218427527, -0.360583343049196, -0.0884351295431258, -0.0067254357956353, \n#&gt; 0.447183549931195, 0.230492517452624, 0.248051484819537, -0.234421787061468, \n#&gt; -0.260225733418376), 6, c(4.95751445797738, 4.9575144579774, \n#&gt; 4.87144113772763, 5.04358777822717, 4.9575144579774, 5.19521814863552, \n#&gt; 4.94628927646412, 5.04358777822716, 4.9575144579774, 5.05449061091788, \n#&gt; 5.04358777822716, 5.12966109847693, 4.96873963949067, 4.71148672520906, \n#&gt; 4.78536781747786, 5.02178211284574, 4.84834607705595, 4.94628927646412, \n#&gt; 5.20547628368111, 5.03268494553645, 5.2157344187267, 5.02178211284574, \n#&gt; 4.61322117697833, 5.18496001358993, 5.38788105922623, 5.12966109847693, \n#&gt; 5.10850013074063, 5.04358777822716, 4.9575144579774, 5.12966109847693, \n#&gt; 5.12966109847693, 5.02178211284574, 5.05449061091788, 4.9575144579774, \n#&gt; 5.04358777822716, 4.78536781747786, 4.87144113772763, 4.96873963949067, \n#&gt; 4.87144113772763, 5.04358777822716, 4.85989360739179, 4.85989360739179, \n#&gt; 4.87144113772763, 5.08733916300432, 5.3686541844253, 4.94628927646412, \n#&gt; 5.12966109847693, 4.9575144579774, 5.04358777822716, 4.9575144579774, \n#&gt; 6.32794887612628, 6.1468334958714, 6.50788891564368, 5.70120244540939, \n#&gt; 6.23709735081447, 6.14929823189912, 6.3267735353888, 5.08917000597757, \n#&gt; 6.23891738919707, 5.60841682716221, 5.2664742276381, 5.87604193104219, \n#&gt; 5.7097347817894, 6.32794887612628, 5.3427258162176, 6.05812435776475, \n#&gt; 6.1468334958714, 5.79838689261966, 6.1468334958714, 5.61791621000991, \n#&gt; 6.41682909606208, 5.70120244540939, 6.50788891564368, 6.32912421686375, \n#&gt; 5.97005991730323, 6.05812435776475, 6.41789038224679, 6.59891152278464, \n#&gt; 6.1468334958714, 5.2664742276381, 5.52894175035708, 5.44377844929862, \n#&gt; 5.61474974906067, 6.68911835045133, 6.1468334958714, 6.14560112785754, \n#&gt; 6.32736120575754, 6.05967907460118, 5.79082160270733, 5.70120244540939, \n#&gt; 6.0612337914376, 6.23800737000577, 5.70404655753606, 5.08917000597757, \n#&gt; 5.88044076000528, 5.88264017448683, 5.88044076000528, 5.97005991730323, \n#&gt; 4.8171460731345, 5.79082160270733, 7.0155133579311, 6.16991691988386, \n#&gt; 6.9089039527544, 6.62536970201613, 6.8196641715554, 7.55428958790349, \n#&gt; 5.62306215451168, 7.26398601189142, 6.80783150483764, 7.10900070109979, \n#&gt; 6.17061864480537, 6.35302342035049, 6.54011216124064, 6.07874304574949, \n#&gt; 6.1734255444914, 6.35840911061702, 6.53413880060537, 7.65234684186442, \n#&gt; 7.84389143899405, 6.07684616525475, 6.72977969271128, 5.98686744669361, \n#&gt; 7.64062822969943, 5.98675339214084, 6.72450805699752, 6.99029330765915, \n#&gt; 5.89552249073008, 5.98675339214084, 6.63231010911908, 6.80191517147876, \n#&gt; 7.08544942221703, 7.36500143253179, 6.6346235781534, 6.16711002019782, \n#&gt; 6.61611582587886, 7.10115027480553, 6.63925051622203, 6.53413880060537, \n#&gt; 5.89552249073008, 6.4479142133622, 6.63925051622203, 6.17272381956989, \n#&gt; 6.16991691988386, 6.91546498375841, 6.73505132842504, 6.26556646509346, \n#&gt; 6.07836366965054, 6.26249424386125, 6.45125175614059, 6.16921519496235\n#&gt; ), c(0, 1, 2, 3, 3, 4), list(c(-12.2474487139159, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; -14.6887734908898, 9.30429649857169, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.0778024888416311, 0.088550211682939, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.110045657365555, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.110045657365555, 0.110045657365555, 0.0992979345242469, 0.0778024888416311, \n#&gt; 0.0778024888416311, 0.088550211682939, 0.088550211682939, 0.088550211682939, \n#&gt; 0.0992979345242469, 0.0778024888416311, 0.0992979345242469, 0.0670547660003233, \n#&gt; 0.0992979345242469, 0.0992979345242469, 0.0778024888416311, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.0992979345242469, 0.0992979345242469, 0.0778024888416311, \n#&gt; 0.110045657365555, 0.0992979345242469, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.110045657365555, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.088550211682939, 0.088550211682939, 0.0992979345242469, 0.0563070431590154, \n#&gt; 0.0778024888416311, 0.088550211682939, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.0992979345242469, -0.0296747395714478, \n#&gt; -0.0404224624127557, -0.0404224624127557, -0.0189270167301399, \n#&gt; -0.0404224624127557, -0.0189270167301399, -0.0511701852540636, \n#&gt; 0.0133161517937838, -0.0189270167301399, -0.0296747395714478, \n#&gt; 0.0133161517937838, -0.0404224624127557, 0.0133161517937838, \n#&gt; -0.0296747395714478, -0.0189270167301399, -0.0296747395714478, \n#&gt; -0.0404224624127557, 0.0133161517937838, -0.0404224624127557, \n#&gt; 0.00256842895247588, -0.0726656309366794, -0.0189270167301399, \n#&gt; -0.0404224624127557, -0.008179293888832, -0.0189270167301399, \n#&gt; -0.0296747395714478, -0.0296747395714478, -0.0619179080953715, \n#&gt; -0.0404224624127557, 0.0133161517937838, 0.00256842895247588, \n#&gt; 0.0133161517937838, -0.008179293888832, -0.0511701852540636, \n#&gt; -0.0404224624127557, -0.0511701852540636, -0.0404224624127557, \n#&gt; -0.0189270167301399, -0.0189270167301399, -0.0189270167301399, \n#&gt; -0.008179293888832, -0.0296747395714478, -0.008179293888832, \n#&gt; 0.0133161517937838, -0.0189270167301399, -0.008179293888832, \n#&gt; -0.0189270167301399, -0.0189270167301399, 0.00256842895247588, \n#&gt; -0.0189270167301399, -0.147899690825835, -0.0834133537779873, \n#&gt; -0.104908799460603, -0.0726656309366794, -0.115656522301911, \n#&gt; -0.104908799460603, -0.0619179080953715, -0.0726656309366794, \n#&gt; -0.0726656309366794, -0.147899690825835, -0.0941610766192952, \n#&gt; -0.0834133537779873, -0.104908799460603, -0.0941610766192952, \n#&gt; -0.137151967984527, -0.126404245143219, -0.0726656309366794, \n#&gt; -0.115656522301911, -0.126404245143219, -0.0404224624127557, \n#&gt; -0.126404245143219, -0.0941610766192952, -0.0941610766192952, \n#&gt; -0.0726656309366794, -0.104908799460603, -0.0726656309366794, \n#&gt; -0.0726656309366794, -0.0726656309366794, -0.104908799460603, \n#&gt; -0.0511701852540636, -0.0834133537779873, -0.0941610766192952, \n#&gt; -0.115656522301911, -0.0404224624127557, -0.0296747395714478, \n#&gt; -0.126404245143219, -0.137151967984527, -0.0726656309366794, \n#&gt; -0.0726656309366794, -0.104908799460603, -0.137151967984527, \n#&gt; -0.126404245143219, -0.0834133537779873, -0.126404245143219, \n#&gt; -0.147899690825835, -0.126404245143219, -0.0834133537779873, \n#&gt; -0.0941610766192952, -0.126404245143219, -0.0726656309366794, \n#&gt; -46.0259122668959, 20.7480275407855, 5.81762435765699, 0.00153822106493907, \n#&gt; 0.0187273680177469, 0.0442240300146606, 0.0572594194454154, 0.00153822106493907, \n#&gt; 0.0187273680177469, -0.0369938303627295, 0.00153822106493907, \n#&gt; -0.0156509258878688, -0.0198046834099217, 0.0317627574485017, \n#&gt; 0.0531056619233624, 0.0786023239202762, 0.112980617825892, 0.0572594194454154, \n#&gt; 0.00569197858699198, 0.0400702724926076, -0.0328400728406765, \n#&gt; 0.0786023239202762, 0.087483955828978, 0.0827560814423291, -0.0672183667462921, \n#&gt; -0.0156509258878688, 0.0614131769674684, 0.00153822106493907, \n#&gt; 0.0187273680177469, -0.0156509258878688, -0.0156509258878688, \n#&gt; 0.0786023239202762, -0.0369938303627295, 0.0187273680177469, \n#&gt; 0.00153822106493907, 0.0531056619233624, 0.0359165149705546, \n#&gt; -0.0198046834099217, 0.0359165149705546, 0.00153822106493907, \n#&gt; 0.0744485663982231, 0.0744485663982231, 0.0359165149705546, 0.138477279822805, \n#&gt; 0.00984573610904502, 0.0572594194454154, -0.0156509258878688, \n#&gt; 0.0187273680177469, 0.00153822106493907, 0.0187273680177469, \n#&gt; -0.0861298642928878, -0.0132195189596035, -0.0819761067708348, \n#&gt; -0.00433788705090168, -0.0304086659124113, -0.0902836218149406, \n#&gt; -0.0090657614375506, 0.000389987335747224, -0.107472768767748, \n#&gt; 0.0513833113295746, -0.0339883065698684, 0.0383479218988198, \n#&gt; -0.119934041333907, -0.0861298642928878, 0.0644187007603295, \n#&gt; -0.0345624234344644, -0.0132195189596035, -0.137123188286715, \n#&gt; -0.0132195189596035, -0.064212842953431, 0.0508091944649788, \n#&gt; -0.00433788705090168, -0.0819761067708348, -0.163193967148225, \n#&gt; -0.055905327909325, -0.0345624234344644, -0.103319011245696, \n#&gt; -0.0221011508683054, -0.0132195189596035, -0.0339883065698684, \n#&gt; -0.0470236960006232, -0.068366600475484, -0.0256807915257625, \n#&gt; -0.0778223492487817, -0.0132195189596035, 0.025312532468065, \n#&gt; -0.0475978128652192, -0.0730944748621329, -0.0215270340037094, \n#&gt; -0.00433788705090168, -0.111626526289801, -0.0689407173400799, \n#&gt; -0.0428699384785703, 0.000389987335747224, -0.0387161809565173, \n#&gt; -0.0772482323841859, -0.0387161809565173, -0.055905327909325, \n#&gt; 0.0904894796218392, -0.0215270340037094, 0.114263791024965, 0.0377738050342239, \n#&gt; -0.0226752677329013, -0.0867039811574835, 0.0330459306475751, \n#&gt; -0.142999296402556, 0.0638445838957336, -0.207028009827138, -0.121082275063099, \n#&gt; 0.0970746440721574, 0.0763058564618925, 0.00339551112860831, \n#&gt; 0.0460813200783299, 0.0934950034147003, 0.230434062172567, 0.157523716839282, \n#&gt; -0.0695148342046758, -0.121656391927695, -0.117502634405642, \n#&gt; -0.0991652537236425, 0.0887671290280512, 0.110684150367508, -0.198720494783032, \n#&gt; 0.0336200475121709, 0.0117030261727143, -0.155460568968715, 0.0508091944649788, \n#&gt; 0.0336200475121709, 0.0288921731255222, -0.198146377918436, -0.134117664493854, \n#&gt; -0.147153053924609, 0.0674242245531907, -0.11635440067645, -0.240832186868158, \n#&gt; 0.0200105412168202, 0.144488327408528, -0.0695148342046758, 0.0508091944649788, \n#&gt; 0.0632704670311376, 0.144488327408528, 0.191902010744898, 0.0377738050342239, \n#&gt; 0.0543888351224356, 0.165831231883388, 0.17471286379209, 0.0549629519870317, \n#&gt; 0.0591167095090847, 0.140334569886475, -0.000758246393444546, \n#&gt; -4.08248290463863, 0.680689113282833, 1.8868601435992, 5.41384839674038, \n#&gt; 0.033392481153859, 0.0273909956668532, 0.0207108967780347, 0.0398463755754066, \n#&gt; 0.033392481153859, 0.0525279599512309, 0.0398463755754066, 0.0463002699969543, \n#&gt; 0.0460740655296833, 0.0267123822650405, 0.0204846923107638, 0.014483206823758, \n#&gt; 0.00157541798066278, 0.0207108967780347, 0.0400725800426776, \n#&gt; 0.0271647911995823, 0.0527541644185019, 0.014483206823758, 0.00757690346766855, \n#&gt; 0.0147094112910289, 0.0656619532615971, 0.0463002699969543, 0.0209371012453056, \n#&gt; 0.0398463755754066, 0.033392481153859, 0.0463002699969543, 0.0463002699969543, \n#&gt; 0.014483206823758, 0.0525279599512309, 0.033392481153859, 0.0398463755754066, \n#&gt; 0.0204846923107638, 0.0269385867323114, 0.0460740655296833, 0.0269385867323114, \n#&gt; 0.0398463755754066, 0.0142570023564871, 0.0142570023564871, 0.0269385867323114, \n#&gt; -0.00442606750634301, 0.0402987845099485, 0.0207108967780347, \n#&gt; 0.0463002699969543, 0.033392481153859, 0.0398463755754066, 0.033392481153859, \n#&gt; -0.0905195047068495, -0.116108877925769, -0.0902933002395785, \n#&gt; -0.123015181281858, -0.109654983504221, -0.0907457091741204, \n#&gt; -0.115882673458498, -0.130147689105219, -0.0842918147525728, \n#&gt; -0.14215066007923, -0.117239900262124, -0.135470561190412, -0.0849704281543855, \n#&gt; -0.0905195047068495, -0.148830758968049, -0.109881187971492, \n#&gt; -0.116108877925769, -0.0785165337328379, -0.116108877925769, \n#&gt; -0.104105906951757, -0.134791947788599, -0.123015181281858, -0.0902933002395785, \n#&gt; -0.0651563359552008, -0.103653498017216, -0.109881187971492, \n#&gt; -0.0840656102853019, -0.10920257456968, -0.116108877925769, -0.117239900262124, \n#&gt; -0.110559801373305, -0.104332111419028, -0.116787491327582, -0.0900670957723077, \n#&gt; -0.116108877925769, -0.128790462301593, -0.103201089082674, -0.097199603595668, \n#&gt; -0.116561286860311, -0.123015181281858, -0.0845180192198437, \n#&gt; -0.0969733991283971, -0.110333596906034, -0.130147689105219, \n#&gt; -0.110107392438763, -0.0974258080629389, -0.110107392438763, \n#&gt; -0.103653498017216, -0.162190956745686, -0.116561286860311, 0.03859518390109, \n#&gt; 0.0565996403621074, 0.0828676269828397, 0.10155069684567, 0.0637321481854677, \n#&gt; 0.128044887933673, 0.0432394425844703, 0.146727957796503, 0.114458485688765, \n#&gt; 0.0450490783226376, 0.0439180559862831, 0.0695074292052027, 0.0570520492966492, \n#&gt; 0.0374641615647355, -0.00680828151701418, 0.0187810917019054, \n#&gt; 0.0950968024241222, 0.121817197979396, 0.122043402446667, 0.100872083443857, \n#&gt; 0.0445966693880959, 0.0310102671431879, 0.147180366731045, 0.0563734358948365, \n#&gt; 0.0699598381397445, 0.12736627453186, 0.0499195414732889, 0.0563734358948365, \n#&gt; 0.0635059437181968, 0.139821654440414, 0.121138584577584, 0.127818683466402, \n#&gt; 0.0508243593423725, 0.107325977865405, 0.152277034348967, 0.0704122470742863, \n#&gt; 0.0254611905907239, 0.0950968024241222, 0.0499195414732889, 0.0505981548751016, \n#&gt; 0.0254611905907239, 0.00587330285881018, 0.0565996403621074, \n#&gt; 0.0575044582311911, 0.0192335006364472, 0.0123271972803578, 0.0501457459405598, \n#&gt; 0.0503719504078307, 0.0252349861234531, 0.0692812247379317, -4.08248290463863, \n#&gt; 4.44239210774059, -0.424722128220301, -3.4890454943047, 1.11564257129667, \n#&gt; 0.0809550703643557, 0.024695794624255, 0.0162883406803865, 0.00432538523132845, \n#&gt; -0.00408206871254012, 0.0162883406803865, 0.0282512961294445, \n#&gt; -0.0160450241615981, -0.0519338905087722, -0.0196005256667876, \n#&gt; 0.0570291594662397, 0.0331032485681237, 0.024695794624255, 0.0605846609714291, \n#&gt; 0.036658750073313, 0.0402142515785025, 0.0570291594662397, -0.0435264365649036, \n#&gt; 0.101325479757282, 0.0641401624766186, 0.0282512961294445, 0.0689921149152977, \n#&gt; 0.0162883406803865, 0.00432538523132845, 0.0282512961294445, \n#&gt; 0.0282512961294445, 0.0570291594662397, -0.00408206871254012, \n#&gt; 0.00432538523132845, 0.0162883406803865, -0.0196005256667876, \n#&gt; -0.00763757021772952, -0.0160450241615981, -0.00763757021772952, \n#&gt; 0.0162883406803865, 0.012732839175197, 0.012732839175197, -0.00763757021772952, \n#&gt; 0.109732933701151, 0.104880981262472, 0.024695794624255, 0.0282512961294445, \n#&gt; 0.00432538523132845, 0.0162883406803865, 0.00432538523132845, \n#&gt; 0.0688922571589244, 0.0653367556537349, 0.113188577449967, -0.0352188403774083, \n#&gt; 0.0772997111027929, 0.0245959368678818, 0.109633075944778, -0.180070756699594, \n#&gt; 0.0365588923169398, -0.0268113864335398, -0.156144845801478, \n#&gt; 0.0294478893065609, -0.0963300685561881, 0.0688922571589244, \n#&gt; -0.0830706621736404, 0.0330033908117504, 0.0653367556537349, \n#&gt; -0.0843671131071301, 0.0653367556537349, -0.0879226146123196, \n#&gt; 0.162336850179689, -0.0352188403774083, 0.113188577449967, 0.0281514383730712, \n#&gt; 0.000670025969765682, 0.0330033908117504, 0.0808552126079824, \n#&gt; 0.165892351684878, 0.0653367556537349, -0.156144845801478, -0.0998855700613776, \n#&gt; -0.132218934903362, -0.0675522052193929, 0.15748489774101, 0.0653367556537349, \n#&gt; 0.0857071650466615, 0.089262666551851, 0.0126329814188238, -0.0232558849283504, \n#&gt; -0.0352188403774083, -0.00773742797410282, 0.0569293017098664, \n#&gt; -0.0555892497703349, -0.180070756699594, -0.0112929294792922, \n#&gt; -0.0316633388722189, -0.0112929294792922, 0.000670025969765682, \n#&gt; -0.195589213653842, -0.0232558849283504, 0.126796326095687, -0.103092729303395, \n#&gt; 0.0333517330749229, -0.0636483614510311, 0.0417591870187914, \n#&gt; 0.117092421218329, -0.215611280783596, 0.020092326692375, -0.0397224505529149, \n#&gt; 0.138759281544745, -0.082722319910468, -0.0791668184052785, -0.0145000887213092, \n#&gt; -0.094685275359526, -0.00124068233876161, 0.00231481916642784, \n#&gt; -0.075611316900089, 0.149425786060314, 0.193722106351356, -0.196537322324159, \n#&gt; 0.0501666409626599, -0.106648230808584, 0.10868496727446, -0.147389049594437, \n#&gt; 0.00942582217680681, -0.0157965396547989, -0.159352005043495, \n#&gt; -0.147389049594437, -0.00253713327225124, -0.0804632693387682, \n#&gt; 0.0165368251871856, 0.0727961009272864, 0.0178332761206754, -0.184574366875101, \n#&gt; -0.145129999022737, 0.0980184627588919, 0.0585740949065285, -0.075611316900089, \n#&gt; -0.159352005043495, -0.0264630441703672, 0.0585740949065285, \n#&gt; -0.0216110917316882, -0.103092729303395, 0.074092551860776, 0.0909074597485132, \n#&gt; -0.00964813628263016, -0.115055684752453, -0.0707593644614099, \n#&gt; 0.0142777746154859, -0.123463138696321, -70.9625343450096, 56.3907660022668, \n#&gt; 3.08793638683961, -8.84664926411501, -4.44414200339705, 4.61722606476297, \n#&gt; 0.0342936864802481, -0.0102831456627637, -0.0400113570729295, \n#&gt; -0.0824223866626905, -0.0102831456627637, 0.0194450657474023, \n#&gt; -0.114316400626107, -0.209998442516358, -0.0994677798932615, \n#&gt; 0.13399533633709, 0.083202123729762, 0.0342936864802481, 0.116980913050993, \n#&gt; 0.0618560953371631, 0.0491732771575683, 0.13399533633709, -0.158924202713593, \n#&gt; 0.252596184837844, 0.1086296999779, 0.0194450657474023, 0.159391942640755, \n#&gt; -0.0102831456627637, -0.0400113570729295, 0.0194450657474023, \n#&gt; 0.0194450657474023, 0.13399533633709, -0.0824223866626905, -0.0400113570729295, \n#&gt; -0.0102831456627637, -0.0994677798932615, -0.0697395684830954, \n#&gt; -0.114316400626107, -0.0697395684830954, -0.0102831456627637, \n#&gt; 0.00673127762333315, 0.00673127762333315, -0.0697395684830954, \n#&gt; 0.299338819534107, 0.235581761551747, 0.0342936864802481, 0.0194450657474023, \n#&gt; -0.0400113570729295, -0.0102831456627637, -0.0400113570729295, \n#&gt; 0.0400912555211672, 0.0397792583812572, 0.046070371252877, -0.00407298704557909, \n#&gt; 0.0413520365991622, 0.025448929576454, 0.0457583741129669, -0.144868055440661, \n#&gt; 0.0313533129008607, 0.0101826093519207, -0.120064473472342, 0.0350609237275423, \n#&gt; -0.0580555185515465, 0.0400912555211672, -0.0276905203432057, \n#&gt; 0.0288755132076998, 0.0397792583812572, -0.0456537275673874, \n#&gt; 0.0397792583812572, -0.0502973298137991, 0.046500863262919, -0.00407298704557909, \n#&gt; 0.046070371252877, 0.0344241369293675, 0.0136401629276408, 0.0288755132076998, \n#&gt; 0.0438298362923229, 0.0403154527430766, 0.0397792583812572, -0.120064473472342, \n#&gt; -0.0605333182447075, -0.095260891504024, -0.0301373500918924, \n#&gt; 0.0433862767715832, 0.0397792583812572, 0.0469444227836587, 0.042924814817067, \n#&gt; 0.0195445462520475, 0.00183139627882739, -0.00407298704557909, \n#&gt; 0.010213579296395, 0.0363526747500114, -0.0220671642142349, -0.144868055440661, \n#&gt; 0.00773577960323411, -0.00592679245891999, 0.00773577960323411, \n#&gt; 0.0136401629276408, -0.142421225691974, 0.00183139627882739, \n#&gt; -0.153524218361304, 0.0622209129727486, -0.0408146856742592, \n#&gt; 0.0434274166806142, -0.0503829173625185, -0.12076894538546, 0.0904331761385364, \n#&gt; 0.00895501058768104, 0.0335781577969193, -0.173609465675907, \n#&gt; 0.0563912620556454, 0.0480400489825521, 0.00487346273214126, \n#&gt; 0.0656474966039946, 0.0330726583872315, 0.00739502488813094, \n#&gt; 0.048352046122462, -0.172673474256178, -0.244663250441498, 0.0839667384232578, \n#&gt; -0.0556195439442763, 0.0749037311523439, -0.0917084907179432, \n#&gt; 0.0778998227735477, -0.017970611471059, 0.0237288989132239, 0.0828244522153951, \n#&gt; 0.0778998227735477, -0.00654857436945884, 0.075558695376638, \n#&gt; -0.00868340697823551, -0.0639397870728954, -0.0232072380528166, \n#&gt; 0.0855395166411628, 0.110062071414045, -0.118634112776683, -0.0565245654195321, \n#&gt; 0.048352046122462, 0.0828244522153951, 0.0162954998337413, -0.0565245654195321, \n#&gt; 0.0389023093043347, 0.0622209129727486, -0.0871268283604801, \n#&gt; -0.0932684764174932, 0.0231486670962329, 0.0693113449678471, \n#&gt; 0.047135027507296, -0.00835861731997081, 0.0680505638898524), \n#&gt;     c(1.08164965809277, 1.09929793452425, 1.03591651497055, 1.03984637557541, \n#&gt;     1.00432538523133, 1.18478854894442), 1:6, 1e-07, 6), 144, \n#&gt;     list(\"contr.treatment\"), list(c(\"setosa\", \"versicolor\", \"virginica\"\n#&gt;     )), lm(formula = Sepal.Length ~ Petal.Width * Petal.Length + \n#&gt;         factor(Species), data = iris), Sepal.Length ~ Petal.Width * \n#&gt;         Petal.Length + factor(Species), list(c(5.1, 4.9, 4.7, \n#&gt;     4.6, 5, 5.4, 4.6, 5, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, \n#&gt;     5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5, 5, 5.2, 5.2, \n#&gt;     4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5, 5.5, 4.9, 4.4, 5.1, 5, 4.5, \n#&gt;     4.4, 5, 5.1, 4.8, 5.1, 4.6, 5.3, 5, 7, 6.4, 6.9, 5.5, 6.5, \n#&gt;     5.7, 6.3, 4.9, 6.6, 5.2, 5, 5.9, 6, 6.1, 5.6, 6.7, 5.6, 5.8, \n#&gt;     6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6, 5.7, \n#&gt;     5.5, 5.5, 5.8, 6, 5.4, 6, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, \n#&gt;     5, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, \n#&gt;     7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, \n#&gt;     7.7, 7.7, 6, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, \n#&gt;     7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6, 6.9, 6.7, \n#&gt;     6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9), c(0.2, 0.2, \n#&gt;     0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, \n#&gt;     0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, \n#&gt;     0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, \n#&gt;     0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, \n#&gt;     1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1, 1.3, 1.4, 1, 1.5, 1, \n#&gt;     1.4, 1.3, 1.4, 1.5, 1, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, \n#&gt;     1.4, 1.4, 1.7, 1.5, 1, 1.1, 1, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, \n#&gt;     1.3, 1.3, 1.2, 1.4, 1.2, 1, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, \n#&gt;     2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2, 1.9, \n#&gt;     2.1, 2, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2, 2, 1.8, 2.1, \n#&gt;     1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2, 2.2, 1.5, 1.4, 2.3, 2.4, \n#&gt;     1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2, 2.3, \n#&gt;     1.8), c(1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, \n#&gt;     1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, \n#&gt;     1, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, \n#&gt;     1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, \n#&gt;     1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4, 4.6, 4.5, 4.7, 3.3, \n#&gt;     4.6, 3.9, 3.5, 4.2, 4, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, \n#&gt;     4.8, 4, 4.9, 4.7, 4.3, 4.4, 4.8, 5, 4.5, 3.5, 3.8, 3.7, 3.9, \n#&gt;     5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4, 4.4, 4.6, 4, 3.3, 4.2, 4.2, \n#&gt;     4.2, 4.3, 3, 4.1, 6, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, \n#&gt;     6.1, 5.1, 5.3, 5.5, 5, 5.1, 5.3, 5.5, 6.7, 6.9, 5, 5.7, 4.9, \n#&gt;     6.7, 4.9, 5.7, 6, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, \n#&gt;     5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, \n#&gt;     5, 5.2, 5.4, 5.1), c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt;     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt;     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt;     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt;     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt;     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, \n#&gt;     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt;     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt;     3, 3, 3, 3, 3))), INF_FUN = function (model, newdata = NULL, \n#&gt;     variables = NULL, comparison = \"difference\", type = NULL, \n#&gt;     vcov = TRUE, by = FALSE, conf_level = 0.95, transform = NULL, \n#&gt;     cross = FALSE, wts = FALSE, hypothesis = NULL, equivalence = NULL, \n#&gt;     p_adjust = NULL, df = Inf, eps = NULL, numderiv = \"fdforward\", \n#&gt;     ...) \n#&gt; {\n#&gt;     dots &lt;- list(...)\n#&gt;     if (\"transform_post\" %in% names(dots)) {\n#&gt;         transform &lt;- dots[[\"transform_post\"]]\n#&gt;         insight::format_warning(\"The `transform_post` argument is deprecated. Use `transform` instead.\")\n#&gt;     }\n#&gt;     if (\"transform_pre\" %in% names(dots)) {\n#&gt;         comparison &lt;- dots[[\"transform_pre\"]]\n#&gt;         insight::format_warning(\"The `transform_pre` argument is deprecated. Use `comparison` instead.\")\n#&gt;     }\n#&gt;     scall &lt;- rlang::enquo(newdata)\n#&gt;     newdata &lt;- sanitize_newdata_call(scall, newdata, model, by = by)\n#&gt;     if (isTRUE(by)) {\n#&gt;         modeldata &lt;- get_modeldata(model, additional_variables = FALSE, \n#&gt;             modeldata = dots[[\"modeldata\"]], wts = wts)\n#&gt;     }\n#&gt;     else {\n#&gt;         modeldata &lt;- get_modeldata(model, additional_variables = by, \n#&gt;             modeldata = dots[[\"modeldata\"]], wts = wts)\n#&gt;     }\n#&gt;     call_attr &lt;- c(list(name = \"comparisons\", model = model, \n#&gt;         newdata = newdata, variables = variables, type = type, \n#&gt;         vcov = vcov, by = by, conf_level = conf_level, comparison = comparison, \n#&gt;         transform = transform, cross = cross, wts = wts, hypothesis = hypothesis, \n#&gt;         equivalence = equivalence, p_adjust = p_adjust, df = df), \n#&gt;         dots)\n#&gt;     if (\"modeldata\" %in% names(dots)) {\n#&gt;         call_attr[[\"modeldata\"]] &lt;- modeldata\n#&gt;     }\n#&gt;     call_attr &lt;- do.call(\"call\", call_attr)\n#&gt;     bycols &lt;- NULL\n#&gt;     sanity_dots(model, ...)\n#&gt;     sanity_df(df, newdata)\n#&gt;     conf_level &lt;- sanitize_conf_level(conf_level, ...)\n#&gt;     checkmate::assert_number(eps, lower = 1e-10, null.ok = TRUE)\n#&gt;     numderiv &lt;- sanitize_numderiv(numderiv)\n#&gt;     sanity_equivalence_p_adjust(equivalence, p_adjust)\n#&gt;     model &lt;- sanitize_model(model = model, newdata = newdata, \n#&gt;         wts = wts, vcov = vcov, by = by, calling_function = \"comparisons\", \n#&gt;         ...)\n#&gt;     cross &lt;- sanitize_cross(cross, variables, model)\n#&gt;     type &lt;- sanitize_type(model = model, type = type, calling_function = \"comparisons\")\n#&gt;     sanity_comparison(comparison)\n#&gt;     if (inherits(model, c(\"mira\", \"amest\"))) {\n#&gt;         out &lt;- process_imputation(model, call_attr)\n#&gt;         return(out)\n#&gt;     }\n#&gt;     comparison_label &lt;- transform_label &lt;- NULL\n#&gt;     if (is.function(comparison)) {\n#&gt;         comparison_label &lt;- deparse(substitute(comparison))\n#&gt;     }\n#&gt;     if (is.function(transform)) {\n#&gt;         transform_label &lt;- deparse(substitute(transform))\n#&gt;         transform &lt;- sanitize_transform(transform)\n#&gt;         names(transform) &lt;- transform_label\n#&gt;     }\n#&gt;     else {\n#&gt;         transform &lt;- sanitize_transform(transform)\n#&gt;         transform_label &lt;- names(transform)\n#&gt;     }\n#&gt;     marginalmeans &lt;- isTRUE(checkmate::check_choice(newdata, \n#&gt;         choices = \"marginalmeans\"))\n#&gt;     newdata &lt;- sanitize_newdata(model = model, newdata = newdata, \n#&gt;         modeldata = modeldata, by = by, wts = wts)\n#&gt;     sanity_by(by, newdata)\n#&gt;     newdata &lt;- dedup_newdata(model = model, newdata = newdata, \n#&gt;         wts = wts, by = by, cross = cross, comparison = comparison)\n#&gt;     if (isFALSE(wts) && \"marginaleffects_wts_internal\" %in% colnames(newdata)) {\n#&gt;         wts &lt;- \"marginaleffects_wts_internal\"\n#&gt;     }\n#&gt;     variables_list &lt;- sanitize_variables(model = model, newdata = newdata, \n#&gt;         modeldata = modeldata, variables = variables, cross = cross, \n#&gt;         by = by, comparison = comparison, eps = eps)\n#&gt;     if (inherits(model, \"lmerMod\") && (isTRUE(hush(vcov %in% \n#&gt;         c(\"satterthwaite\", \"kenward-roger\"))))) {\n#&gt;         dv &lt;- insight::find_response(model)\n#&gt;         if (!dv %in% colnames(newdata)) {\n#&gt;             newdata[[dv]] &lt;- mean(insight::get_response(model))\n#&gt;         }\n#&gt;         if (!isTRUE(hush(is.infinite(df)))) {\n#&gt;             insight::format_error(\"The `df` argument is not supported when `vcov` is \\\"satterthwaite\\\" or \\\"kenward-roger\\\".\")\n#&gt;         }\n#&gt;         df &lt;- insight::get_df(model, type = vcov, data = newdata, \n#&gt;             df_per_observation = TRUE)\n#&gt;     }\n#&gt;     vcov_false &lt;- isFALSE(vcov)\n#&gt;     vcov.type &lt;- get_vcov_label(vcov)\n#&gt;     vcov &lt;- get_vcov(model, vcov = vcov, type = type, ...)\n#&gt;     predictors &lt;- variables_list$conditional\n#&gt;     out &lt;- inferences_dispatch(INF_FUN = comparisons, model = model, \n#&gt;         newdata = newdata, vcov = vcov, variables = variables, \n#&gt;         type = type, by = by, conf_level = conf_level, cross = cross, \n#&gt;         comparison = comparison, transform = transform, wts = wts, \n#&gt;         hypothesis = hypothesis, eps = eps, ...)\n#&gt;     if (!is.null(out)) {\n#&gt;         return(out)\n#&gt;     }\n#&gt;     tmp &lt;- sanitize_hypothesis(hypothesis, ...)\n#&gt;     hypothesis &lt;- tmp$hypothesis\n#&gt;     hypothesis_null &lt;- tmp$hypothesis_null\n#&gt;     args &lt;- list(model = model, newdata = newdata, variables = predictors, \n#&gt;         cross = cross, marginalmeans = marginalmeans, modeldata = modeldata)\n#&gt;     dots[[\"modeldata\"]] &lt;- NULL\n#&gt;     args &lt;- c(args, dots)\n#&gt;     contrast_data &lt;- do.call(\"get_contrast_data\", args)\n#&gt;     args &lt;- list(model, newdata = newdata, variables = predictors, \n#&gt;         type = type, original = contrast_data[[\"original\"]], \n#&gt;         hi = contrast_data[[\"hi\"]], lo = contrast_data[[\"lo\"]], \n#&gt;         wts = contrast_data[[\"original\"]][[\"marginaleffects_wts_internal\"]], \n#&gt;         by = by, marginalmeans = marginalmeans, cross = cross, \n#&gt;         hypothesis = hypothesis, modeldata = modeldata)\n#&gt;     args &lt;- c(args, dots)\n#&gt;     mfx &lt;- do.call(\"get_contrasts\", args)\n#&gt;     hyp_by &lt;- attr(mfx, \"hypothesis_function_by\")\n#&gt;     if (!is.null(attr(mfx, \"posterior_draws\"))) {\n#&gt;         draws &lt;- attr(mfx, \"posterior_draws\")\n#&gt;         J &lt;- NULL\n#&gt;     }\n#&gt;     else if (!vcov_false && isTRUE(checkmate::check_matrix(vcov))) {\n#&gt;         idx &lt;- intersect(colnames(mfx), c(\"group\", \"term\", \"contrast\"))\n#&gt;         idx &lt;- mfx[, (idx), drop = FALSE]\n#&gt;         args &lt;- list(model, vcov = vcov, type = type, FUN = get_se_delta_contrasts, \n#&gt;             newdata = newdata, index = idx, variables = predictors, \n#&gt;             marginalmeans = marginalmeans, hypothesis = hypothesis, \n#&gt;             hi = contrast_data$hi, lo = contrast_data$lo, original = contrast_data$original, \n#&gt;             by = by, eps = eps, cross = cross, numderiv = numderiv)\n#&gt;         args &lt;- c(args, dots)\n#&gt;         se &lt;- do.call(\"get_se_delta\", args)\n#&gt;         J &lt;- attr(se, \"jacobian\")\n#&gt;         attr(se, \"jacobian\") &lt;- NULL\n#&gt;         mfx$std.error &lt;- as.numeric(se)\n#&gt;         draws &lt;- NULL\n#&gt;     }\n#&gt;     else {\n#&gt;         J &lt;- draws &lt;- NULL\n#&gt;     }\n#&gt;     if ((is.null(by) || isFALSE(by)) && \"rowid\" %in% colnames(mfx)) {\n#&gt;         if (\"rowid\" %in% colnames(newdata)) {\n#&gt;             idx &lt;- c(\"rowid\", \"rowidcf\", \"term\", \"contrast\", \n#&gt;                 \"by\", setdiff(colnames(contrast_data$original), \n#&gt;                   colnames(mfx)))\n#&gt;             idx &lt;- intersect(idx, colnames(contrast_data$original))\n#&gt;             tmp &lt;- contrast_data$original[, ..idx, drop = FALSE]\n#&gt;             bycols &lt;- intersect(colnames(tmp), colnames(mfx))\n#&gt;             idx &lt;- duplicated(tmp, by = bycols)\n#&gt;             tmp &lt;- tmp[!idx]\n#&gt;             mfx &lt;- merge(mfx, tmp, all.x = TRUE, by = bycols, \n#&gt;                 sort = FALSE)\n#&gt;         }\n#&gt;         else {\n#&gt;             idx &lt;- setdiff(colnames(contrast_data$original), \n#&gt;                 colnames(mfx))\n#&gt;             mfx &lt;- data.table(mfx, contrast_data$original[, ..idx])\n#&gt;         }\n#&gt;     }\n#&gt;     mfx &lt;- get_ci(mfx, conf_level = conf_level, df = df, draws = draws, \n#&gt;         estimate = \"estimate\", null_hypothesis = hypothesis_null, \n#&gt;         p_adjust = p_adjust, model = model)\n#&gt;     mfx &lt;- sort_columns(mfx, newdata, by)\n#&gt;     attr(mfx, \"posterior_draws\") &lt;- draws\n#&gt;     mfx &lt;- equivalence(mfx, equivalence = equivalence, df = df, \n#&gt;         ...)\n#&gt;     mfx &lt;- backtransform(mfx, transform)\n#&gt;     if (!all(is.na(mfx[[\"marginaleffects_wts_internal\"]]))) {\n#&gt;         marginaleffects_wts_internal &lt;- mfx[[\"marginaleffects_wts_internal\"]]\n#&gt;     }\n#&gt;     else {\n#&gt;         marginaleffects_wts_internal &lt;- NULL\n#&gt;     }\n#&gt;     mfx[[\"marginaleffects_wts_internal\"]] &lt;- NULL\n#&gt;     out &lt;- mfx\n#&gt;     data.table::setDF(out)\n#&gt;     out &lt;- set_marginaleffects_attributes(out, get_marginaleffects_attributes(newdata, \n#&gt;         include_regex = \"^newdata.*class|explicit|matrix|levels\"))\n#&gt;     attr(out, \"newdata\") &lt;- newdata\n#&gt;     attr(out, \"call\") &lt;- call_attr\n#&gt;     attr(out, \"type\") &lt;- type\n#&gt;     attr(out, \"model_type\") &lt;- class(model)[1]\n#&gt;     attr(out, \"model\") &lt;- model\n#&gt;     attr(out, \"variables\") &lt;- predictors\n#&gt;     attr(out, \"jacobian\") &lt;- J\n#&gt;     attr(out, \"vcov\") &lt;- vcov\n#&gt;     attr(out, \"vcov.type\") &lt;- vcov.type\n#&gt;     attr(out, \"weights\") &lt;- marginaleffects_wts_internal\n#&gt;     attr(out, \"comparison\") &lt;- comparison\n#&gt;     attr(out, \"transform\") &lt;- transform[[1]]\n#&gt;     attr(out, \"comparison_label\") &lt;- comparison_label\n#&gt;     attr(out, \"hypothesis_by\") &lt;- hyp_by\n#&gt;     attr(out, \"transform_label\") &lt;- transform_label\n#&gt;     attr(out, \"conf_level\") &lt;- conf_level\n#&gt;     attr(out, \"by\") &lt;- by\n#&gt;     if (inherits(model, \"brmsfit\")) {\n#&gt;         insight::check_if_installed(\"brms\")\n#&gt;         attr(out, \"nchains\") &lt;- brms::nchains(model)\n#&gt;     }\n#&gt;     class(out) &lt;- c(\"comparisons\", class(out))\n#&gt;     return(out)\n#&gt; }, newdata = list(c(5.1, 4.9, 4.7, 4.6, 5, 5.4, 4.6, 5, 4.4, \n#&gt; 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, \n#&gt; 4.6, 5.1, 4.8, 5, 5, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, \n#&gt; 5, 5.5, 4.9, 4.4, 5.1, 5, 4.5, 4.4, 5, 5.1, 4.8, 5.1, 4.6, 5.3, \n#&gt; 5, 7, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5, 5.9, 6, \n#&gt; 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, \n#&gt; 6.8, 6.7, 6, 5.7, 5.5, 5.5, 5.8, 6, 5.4, 6, 6.7, 6.3, 5.6, 5.5, \n#&gt; 5.5, 6.1, 5.8, 5, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, \n#&gt; 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, \n#&gt; 6.5, 7.7, 7.7, 6, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, \n#&gt; 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6, 6.9, 6.7, 6.9, \n#&gt; 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9), c(0.2, 0.2, 0.2, 0.2, \n#&gt; 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, \n#&gt; 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, \n#&gt; 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, \n#&gt; 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, \n#&gt; 1.6, 1, 1.3, 1.4, 1, 1.5, 1, 1.4, 1.3, 1.4, 1.5, 1, 1.5, 1.1, \n#&gt; 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1, 1.1, 1, 1.2, \n#&gt; 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1, 1.3, 1.2, \n#&gt; 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, \n#&gt; 2.5, 2, 1.9, 2.1, 2, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2, 2, \n#&gt; 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2, 2.2, 1.5, 1.4, 2.3, \n#&gt; 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2, 2.3, \n#&gt; 1.8), c(1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, \n#&gt; 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1, 1.7, \n#&gt; 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, \n#&gt; 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, \n#&gt; 4.7, 4.5, 4.9, 4, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4, \n#&gt; 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4, 4.9, 4.7, 4.3, 4.4, \n#&gt; 4.8, 5, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, \n#&gt; 4, 4.4, 4.6, 4, 3.3, 4.2, 4.2, 4.2, 4.3, 3, 4.1, 6, 5.1, 5.9, \n#&gt; 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5, 5.1, 5.3, \n#&gt; 5.5, 6.7, 6.9, 5, 5.7, 4.9, 6.7, 4.9, 5.7, 6, 4.8, 4.9, 5.6, \n#&gt; 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, \n#&gt; 5.1, 5.9, 5.7, 5.2, 5, 5.2, 5.4, 5.1), c(1, 1, 1, 1, 1, 1, 1, \n#&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt; 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3), 1:150), vcov = c(0.0648561358708614, \n#&gt; -0.0776075989705507, -0.0339713425276863, 0.0855221415040715, \n#&gt; 0.088949330395953, 0.0170000905579961, -0.0776075989705507, 0.144241283857235, \n#&gt; 0.0351858298835599, -0.117761642231515, -0.122089476746883, -0.0254853395735601, \n#&gt; -0.0339713425276863, 0.0351858298835599, 0.0194905399614243, \n#&gt; -0.0459657347451442, -0.0472861136127865, -0.00869677529341257, \n#&gt; 0.0855221415040715, -0.117761642231515, -0.0459657347451442, \n#&gt; 0.138337982006763, 0.15072216454488, 0.0227990421926966, 0.088949330395953, \n#&gt; -0.122089476746883, -0.0472861136127865, 0.15072216454488, 0.179060079636581, \n#&gt; 0.0216170189525216, 0.0170000905579961, -0.0254853395735601, \n#&gt; -0.00869677529341257, 0.0227990421926966, 0.0216170189525216, \n#&gt; 0.00542666426714662), variables = \"Petal.Width\", type = \"response\", \n#&gt;     by = \"Species\", conf_level = 0.95, cross = FALSE, comparison = \"difference\", \n#&gt;     transform = NULL, wts = FALSE, hypothesis = NULL, eps = NULL)\n#&gt; \n#&gt; \n#&gt; Bootstrap Statistics :\n#&gt;        original       bias    std. error\n#&gt; t1* -0.11025325 -0.001978228   0.2637472\n#&gt; t2* -0.02006005 -0.002071668   0.1624522\n#&gt; t3*  0.02158742 -0.002114815   0.1870299\n\nOr we can extract the individual draws with the posterior_draws() function:\n\nposterior_draws(est) |&gt; head()\n#&gt;   drawid         draw        term contrast    Species    estimate predicted_lo predicted_hi predicted std.error   conf.low conf.high\n#&gt; 1      1 -0.189523311 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 0.2637472 -0.5727651 0.4276856\n#&gt; 2      1 -0.202933561 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 0.1624522 -0.3265992 0.3295583\n#&gt; 3      1 -0.209125856 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 0.1870299 -0.3380324 0.4124401\n#&gt; 4      2 -0.213874597 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 0.2637472 -0.5727651 0.4276856\n#&gt; 5      2 -0.001101391 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 0.1624522 -0.3265992 0.3295583\n#&gt; 6      2  0.097148424 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 0.1870299 -0.3380324 0.4124401\n\nposterior_draws(est, shape = \"DxP\") |&gt; dim()\n#&gt; [1] 500   3\n\n\nAs before, we can pass arguments to rsample::bootstraps() through inferences(). For example, for stratified resampling:\n\nest &lt;- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"rsample\", R = 100, strata = \"Species\")\nest\n#&gt; \n#&gt;     Species Estimate  2.5 % 97.5 %\n#&gt;  setosa      -0.1103 -0.613  0.295\n#&gt;  versicolor  -0.0201 -0.304  0.314\n#&gt;  virginica    0.0216 -0.345  0.401\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high\n\nattr(est, \"inferences\")\n#&gt; # Bootstrap sampling using stratification with apparent sample \n#&gt; # A tibble: 101 × 3\n#&gt;    splits           id           estimates       \n#&gt;    &lt;list&gt;           &lt;chr&gt;        &lt;list&gt;          \n#&gt;  1 &lt;split [150/51]&gt; Bootstrap001 &lt;tibble [3 × 7]&gt;\n#&gt;  2 &lt;split [150/58]&gt; Bootstrap002 &lt;tibble [3 × 7]&gt;\n#&gt;  3 &lt;split [150/57]&gt; Bootstrap003 &lt;tibble [3 × 7]&gt;\n#&gt;  4 &lt;split [150/56]&gt; Bootstrap004 &lt;tibble [3 × 7]&gt;\n#&gt;  5 &lt;split [150/55]&gt; Bootstrap005 &lt;tibble [3 × 7]&gt;\n#&gt;  6 &lt;split [150/56]&gt; Bootstrap006 &lt;tibble [3 × 7]&gt;\n#&gt;  7 &lt;split [150/55]&gt; Bootstrap007 &lt;tibble [3 × 7]&gt;\n#&gt;  8 &lt;split [150/51]&gt; Bootstrap008 &lt;tibble [3 × 7]&gt;\n#&gt;  9 &lt;split [150/57]&gt; Bootstrap009 &lt;tibble [3 × 7]&gt;\n#&gt; 10 &lt;split [150/58]&gt; Bootstrap010 &lt;tibble [3 × 7]&gt;\n#&gt; # ℹ 91 more rows\n\nOr we can extract the individual draws with the posterior_draws() function:\n\nposterior_draws(est) |&gt; head()\n#&gt;   drawid        draw        term contrast    Species    estimate predicted_lo predicted_hi predicted   conf.low conf.high\n#&gt; 1      1  0.07310920 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 -0.6131832 0.2945774\n#&gt; 2      1 -0.10375860 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 -0.3038898 0.3135018\n#&gt; 3      1 -0.18542879 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 -0.3450145 0.4009513\n#&gt; 4      2 -0.44785351 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 -0.6131832 0.2945774\n#&gt; 5      2  0.06769106 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 -0.3038898 0.3135018\n#&gt; 6      2  0.30574810 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 -0.3450145 0.4009513\n\nposterior_draws(est, shape = \"PxD\") |&gt; dim()\n#&gt; [1]   3 100\n\n\nThe fwb package implements fractional weighted bootstrap (aka Bayesian bootstrap):\n\n“fwb implements the fractional weighted bootstrap (FWB), also known as the Bayesian bootstrap, following the treatment by Xu et al. (2020). The FWB involves generating sets of weights from a uniform Dirichlet distribution to be used in estimating statistics of interest, which yields a posterior distribution that can be interpreted in the same way the traditional (resampling-based) bootstrap distribution can be.” -Noah Greifer\n\nThe inferences() function makes it easy to apply this inference strategy to marginaleffects objects:\n\navg_comparisons(mod) |&gt; inferences(method = \"fwb\")\n#&gt; \n#&gt;          Term                        Contrast Estimate Std. Error  2.5 % 97.5 %\n#&gt;  Petal.Length mean(+1)                          0.8929      0.081  0.732   1.05\n#&gt;  Petal.Width  mean(+1)                         -0.0362      0.160 -0.357   0.27\n#&gt;  Species      mean(versicolor) - mean(setosa)  -1.4629      0.335 -2.144  -0.76\n#&gt;  Species      mean(virginica) - mean(setosa)   -1.9842      0.397 -2.804  -1.18\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted, std.error, conf.low, conf.high\n\n\nThis simulation-based strategy to compute confidence intervals was described in Krinsky & Robb (1986) and popularized by King, Tomz, Wittenberg (2000). We proceed in 3 steps:\n\nDraw R sets of simulated coefficients from a multivariate normal distribution with mean equal to the original model’s estimated coefficients and variance equal to the model’s variance-covariance matrix (classical, “HC3”, or other).\nUse the R sets of coefficients to compute R sets of estimands: predictions, comparisons, or slopes.\nTake quantiles of the resulting distribution of estimands to obtain a confidence interval and the standard deviation of simulated estimates to estimate the standard error.\n\nHere are a few examples:\n\nlibrary(ggplot2)\nlibrary(ggdist)\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"simulation\")\n#&gt; \n#&gt;     Species Estimate  2.5 % 97.5 %\n#&gt;  setosa      -0.1103 -0.677  0.469\n#&gt;  versicolor  -0.0201 -0.329  0.296\n#&gt;  virginica    0.0216 -0.316  0.343\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high\n\nSince simulation based inference generates R estimates of the quantities of interest, we can treat them similarly to draws from the posterior distribution in bayesian models. For example, we can extract draws using the posterior_draws() function, and plot their distributions using packages likeggplot2 and ggdist:\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"simulation\") |&gt;\n  posterior_draws(\"rvar\") |&gt;\n  ggplot(aes(y = Species, xdist = rvar)) +\n  stat_slabinterval()\n\n\n\n\n\n\n\n\nThe same workflow and the same inferences function can be used to estimate models with multiple imputation for missing data.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bootstrap & Simulation"
    ]
  },
  {
    "objectID": "vignettes/bootstrap.html#delta-method",
    "href": "vignettes/bootstrap.html#delta-method",
    "title": "Bootstrap & Simulation",
    "section": "",
    "text": "The default strategy to compute standard errors and confidence intervals is the delta method. This is what we obtain by calling:\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\")\n#&gt; \n#&gt;     Species Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.285 -0.387    0.699 0.5 -0.669  0.449\n#&gt;  versicolor  -0.0201      0.160 -0.125    0.900 0.2 -0.334  0.293\n#&gt;  virginica    0.0216      0.169  0.128    0.898 0.2 -0.309  0.353\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nSince this is the default method, we obtain the same results if we add the inferences() call in the chain:\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"delta\")\n#&gt; \n#&gt;     Species Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.285 -0.387    0.699 0.5 -0.669  0.449\n#&gt;  versicolor  -0.0201      0.160 -0.125    0.900 0.2 -0.334  0.293\n#&gt;  virginica    0.0216      0.169  0.128    0.898 0.2 -0.309  0.353\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bootstrap & Simulation"
    ]
  },
  {
    "objectID": "vignettes/bootstrap.html#bootstrap",
    "href": "vignettes/bootstrap.html#bootstrap",
    "title": "Bootstrap & Simulation",
    "section": "",
    "text": "marginaleffects supports three bootstrap frameworks in R: the well-established boot package, the newer rsample package, and the so-called “bayesian bootstrap” in fwb.\n\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"boot\")\n#&gt; \n#&gt;     Species Estimate Std. Error  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.272 -0.655  0.430\n#&gt;  versicolor  -0.0201      0.163 -0.317  0.316\n#&gt;  virginica    0.0216      0.179 -0.315  0.402\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, std.error, conf.low, conf.high\n\nAll unknown arguments that we feed to inferences() are pushed forward to boot::boot():\n\nest &lt;- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"boot\", sim = \"balanced\", R = 500, conf_type = \"bca\")\nest\n#&gt; \n#&gt;     Species Estimate Std. Error  2.5 % 97.5 %\n#&gt;  setosa      -0.1103      0.264 -0.573  0.428\n#&gt;  versicolor  -0.0201      0.162 -0.327  0.330\n#&gt;  virginica    0.0216      0.187 -0.338  0.412\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, std.error, conf.low, conf.high\n\nWe can extract the original boot object from an attribute:\n\nattr(est, \"inferences\")\n#&gt; \n#&gt; BALANCED BOOTSTRAP\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; (function (model, INF_FUN, ...) \n#&gt; {\n#&gt;     conf_type &lt;- attr(model, \"inferences_conf_type\")\n#&gt;     checkmate::assert_choice(conf_type, choices = c(\"perc\", \"norm\", \n#&gt;         \"basic\", \"bca\"))\n#&gt;     modcall &lt;- insight::get_call(model)\n#&gt;     modeldata &lt;- get_modeldata(model, additional_variables = FALSE)\n#&gt;     dots &lt;- list(...)\n#&gt;     dots[[\"vcov\"]] &lt;- FALSE\n#&gt;     attr(model, \"inferences_method\") &lt;- NULL\n#&gt;     out &lt;- do.call(INF_FUN, c(list(model), dots))\n#&gt;     if (is.null(dots[[\"conf_level\"]])) {\n#&gt;         conf_level &lt;- 0.95\n#&gt;     }\n#&gt;     else {\n#&gt;         conf_level &lt;- dots[[\"conf_level\"]]\n#&gt;     }\n#&gt;     bootfun &lt;- function(data, indices) {\n#&gt;         d &lt;- data[indices, , drop = FALSE]\n#&gt;         modcall[[\"data\"]] &lt;- d\n#&gt;         modboot &lt;- eval(modcall)\n#&gt;         modboot &lt;- eval(modboot)\n#&gt;         args &lt;- c(list(modboot, modeldata = d), dots)\n#&gt;         out &lt;- do.call(INF_FUN, args)$estimate\n#&gt;         return(out)\n#&gt;     }\n#&gt;     args &lt;- list(data = modeldata, statistic = bootfun)\n#&gt;     args &lt;- c(args, attr(model, \"inferences_dots\"))\n#&gt;     args &lt;- args[unique(names(args))]\n#&gt;     B &lt;- do.call(boot::boot, args)\n#&gt;     B$call &lt;- match.call()\n#&gt;     pr &lt;- utils::capture.output(print(B))\n#&gt;     pr &lt;- pr[(grep(\"^Bootstrap Statistics :\", pr) + 1):length(pr)]\n#&gt;     pr &lt;- gsub(\"std. error\", \"std.error\", pr)\n#&gt;     pr &lt;- paste(pr, collapse = \"\\n\")\n#&gt;     pr &lt;- utils::read.table(text = pr, header = TRUE)\n#&gt;     out$std.error &lt;- pr$std.error\n#&gt;     ci_list &lt;- lapply(seq_along(B$t0), boot::boot.ci, boot.out = B, \n#&gt;         conf = conf_level, type = conf_type)\n#&gt;     pos &lt;- pmatch(conf_type, names(ci_list[[1]]))\n#&gt;     if (conf_type == \"norm\") {\n#&gt;         cols &lt;- 2:3\n#&gt;     }\n#&gt;     else {\n#&gt;         cols &lt;- 4:5\n#&gt;     }\n#&gt;     ci &lt;- lapply(ci_list, function(x) x[[pos]])\n#&gt;     ci &lt;- do.call(\"rbind\", ci)[, cols]\n#&gt;     if (is.matrix(ci)) {\n#&gt;         out$conf.low &lt;- ci[, 1]\n#&gt;         out$conf.high &lt;- ci[, 2]\n#&gt;     }\n#&gt;     else {\n#&gt;         out$conf.low &lt;- ci[1]\n#&gt;         out$conf.high &lt;- ci[2]\n#&gt;     }\n#&gt;     attr(out, \"inferences\") &lt;- B\n#&gt;     attr(out, \"posterior_draws\") &lt;- t(B$t)\n#&gt;     return(out)\n#&gt; })(model = list(c(3.78396410453894, -0.157380650291409, 0.854286226046438, \n#&gt; -1.46293310566858, -1.98423971100058, 0.0322348822561755), c(0.142485542022615, \n#&gt; -0.0575144579773967, -0.171441137727629, -0.443587778227166, \n#&gt; 0.0424855420226034, 0.204781851364483, -0.346289276464121, -0.0435877782271645, \n#&gt; -0.557514457977397, -0.154490610917879, 0.356412221772836, -0.329661098476932, \n#&gt; -0.168739639490674, -0.411486725209057, 1.01463218252214, 0.678217887154265, \n#&gt; 0.551653922944047, 0.153710723535879, 0.494523716318892, 0.0673150544635498, \n#&gt; 0.184265581273301, 0.0782178871542645, -0.013221176978328, -0.0849600135899262, \n#&gt; -0.587881059226235, -0.129661098476932, -0.108500130740626, 0.156412221772836, \n#&gt; 0.242485542022603, -0.429661098476932, -0.329661098476932, 0.378217887154265, \n#&gt; 0.145509389082121, 0.542485542022603, -0.143587778227164, 0.214632182522137, \n#&gt; 0.62855886227237, -0.0687396394906731, -0.47144113772763, 0.0564122217728351, \n#&gt; 0.140106392608208, -0.359893607391792, -0.47144113772763, -0.0873391630043204, \n#&gt; -0.268654184425299, -0.146289276464121, -0.0296610984769325, \n#&gt; -0.357514457977398, 0.256412221772835, 0.042485542022603, 0.672051123873723, \n#&gt; 0.253166504128602, 0.392111084356321, -0.201202445409389, 0.262902649185532, \n#&gt; -0.449298231899122, -0.0267735353888003, -0.189170005977571, \n#&gt; 0.361082610802931, -0.408416827162209, -0.266474227638094, 0.0239580689578126, \n#&gt; 0.290265218210599, -0.227948876126278, 0.257274183782397, 0.641875642235248, \n#&gt; -0.546833495871398, 0.00161310738033736, 0.053166504128602, -0.0179162100099074, \n#&gt; -0.516829096062078, 0.398797554590611, -0.207888915643679, -0.229124216863755, \n#&gt; 0.429940082696772, 0.541875642235248, 0.382109617753214, 0.101088477215358, \n#&gt; -0.146833495871398, 0.433525772361906, -0.0289417503570838, 0.0562215507013826, \n#&gt; 0.185250250939325, -0.689118350451328, -0.746833495871398, -0.145601127857536, \n#&gt; 0.372638794242462, 0.240320925398824, -0.190821602707335, -0.201202445409389, \n#&gt; -0.5612337914376, -0.138007370005769, 0.09595344246394, -0.0891700059775712, \n#&gt; -0.280440760005283, -0.182640174486829, -0.180440760005282, 0.229940082696771, \n#&gt; 0.282853926865501, -0.090821602707335, -0.715513357931099, -0.369916919883858, \n#&gt; 0.191096047245598, -0.325369702016127, -0.319664171555401, 0.045710412096514, \n#&gt; -0.723062154511679, 0.0360139881085848, -0.107831504837638, 0.0909992989002138, \n#&gt; 0.329381355194633, 0.0469765796495076, 0.259887838759361, -0.378743045749488, \n#&gt; -0.373425544491401, 0.0415908893829795, -0.0341388006053719, \n#&gt; 0.0476531581355767, -0.143891438994049, -0.0768461652547545, \n#&gt; 0.170220307288722, -0.38686744669361, 0.0593717703005697, 0.31324660785916, \n#&gt; -0.0245080569975196, 0.209706692340851, 0.304477509269916, 0.11324660785916, \n#&gt; -0.232310109119078, 0.398084828521244, 0.31455057778297, 0.534998567468207, \n#&gt; -0.234623578153396, 0.132889979802175, -0.516115825878858, 0.598849725194466, \n#&gt; -0.33925051622203, -0.134138800605372, 0.104477509269916, 0.452085786637802, \n#&gt; 0.0607494837779699, 0.727276180430108, -0.369916919883858, -0.115464983758407, \n#&gt; -0.0350513284250356, 0.434433534906543, 0.221636330349458, 0.237505756138754, \n#&gt; -0.251251756140585, -0.26921519496235), c(-71.5659253183152, \n#&gt; 8.26761414419049, 3.15185596602052, -1.28216612276567, -2.35695868745888, \n#&gt; 0.148835738547779, -0.340443902992748, -0.0297961938363055, -0.537559267311158, \n#&gt; -0.126979856156088, 0.370203806163695, -0.322033120361453, -0.134674631629569, \n#&gt; -0.357758958050013, 1.04691458573913, 0.66457113080326, 0.548771791848065, \n#&gt; 0.159556097007252, 0.483050211435928, 0.0673874684834769, 0.185729953113401, \n#&gt; 0.0645711308032596, 0.0313884387894284, -0.122309271919019, -0.598743899936893, \n#&gt; -0.122033120361453, -0.127529199719143, 0.170203806163695, 0.262440732688842, \n#&gt; -0.422033120361452, -0.322033120361453, 0.36457113080326, 0.173020143843912, \n#&gt; 0.562440732688841, -0.129796193836305, 0.246914585739135, 0.654677659213988, \n#&gt; -0.0346746316295687, -0.445322340786012, 0.0702038061636942, \n#&gt; 0.151724725531026, -0.348275274468974, -0.445322340786012, -0.133025279076833, \n#&gt; -0.303830191286351, -0.140443902992748, -0.0220331203614529, \n#&gt; -0.337559267311159, 0.270203806163694, 0.0624407326888415, 0.594789558050432, \n#&gt; 0.176856861428742, 0.311460651399507, -0.264180100742888, 0.185507808921433, \n#&gt; -0.521608343293153, -0.106472045222184, -0.219019640205961, 0.286906008196794, \n#&gt; -0.47387163788012, -0.3024007252343, -0.0490959810493318, 0.239146562194852, \n#&gt; -0.305210441949568, 0.201762493297324, 0.569041609576475, -0.623143138571258, \n#&gt; -0.0525439803193176, -0.023143138571258, -0.070340080938264, \n#&gt; -0.598877806997992, 0.335819899257112, -0.288539348600494, -0.303948838676952, \n#&gt; 0.361362953726953, 0.469041609576474, 0.303372207541751, 0.0192597836278147, \n#&gt; -0.223143138571258, 0.3975992747657, -0.0787178364254662, 0.0142181897373602, \n#&gt; 0.12848273341445, -0.77159506324593, -0.823143138571258, -0.22391053621031, \n#&gt; 0.294158756414124, 0.169877305216899, -0.255665749252941, -0.264180100742888, \n#&gt; -0.629286999142676, -0.213793091440887, 0.0369287869030251, -0.119019640205961, \n#&gt; -0.347151397762995, -0.246179106119825, -0.247151397762994, 0.161362953726953, \n#&gt; 0.254260119676912, -0.15566574925294, -0.678723653276397, -0.360583343049196, \n#&gt; 0.211187321696559, -0.315946525934337, -0.297752937425579, 0.0746124702030289, \n#&gt; -0.71259338476017, 0.0460443645433169, -0.0982348429407217, 0.130610274230017, \n#&gt; 0.339059047319985, 0.0572649359471646, 0.274944379692862, -0.369933390179567, \n#&gt; -0.362371391203293, 0.0563808814348639, -0.0248023674311454, \n#&gt; 0.084408364095088, -0.09646181450644, -0.067803852018609, 0.193170207449538, \n#&gt; -0.37892582767912, 0.0829380473128177, 0.322062583588008, -0.00693414930528918, \n#&gt; 0.219476840052894, 0.313206742091201, 0.122062583588008, -0.215994884806213, \n#&gt; 0.401524204301707, 0.328658051932604, 0.555960734814162, -0.216011004430172, \n#&gt; 0.140847095474082, -0.515882047438503, 0.629959533464212, -0.316043243678089, \n#&gt; -0.124802367431145, 0.113206742091201, 0.465883644191938, 0.0839567563219111, \n#&gt; 0.737986218427527, -0.360583343049196, -0.0884351295431258, -0.0067254357956353, \n#&gt; 0.447183549931195, 0.230492517452624, 0.248051484819537, -0.234421787061468, \n#&gt; -0.260225733418376), 6, c(4.95751445797738, 4.9575144579774, \n#&gt; 4.87144113772763, 5.04358777822717, 4.9575144579774, 5.19521814863552, \n#&gt; 4.94628927646412, 5.04358777822716, 4.9575144579774, 5.05449061091788, \n#&gt; 5.04358777822716, 5.12966109847693, 4.96873963949067, 4.71148672520906, \n#&gt; 4.78536781747786, 5.02178211284574, 4.84834607705595, 4.94628927646412, \n#&gt; 5.20547628368111, 5.03268494553645, 5.2157344187267, 5.02178211284574, \n#&gt; 4.61322117697833, 5.18496001358993, 5.38788105922623, 5.12966109847693, \n#&gt; 5.10850013074063, 5.04358777822716, 4.9575144579774, 5.12966109847693, \n#&gt; 5.12966109847693, 5.02178211284574, 5.05449061091788, 4.9575144579774, \n#&gt; 5.04358777822716, 4.78536781747786, 4.87144113772763, 4.96873963949067, \n#&gt; 4.87144113772763, 5.04358777822716, 4.85989360739179, 4.85989360739179, \n#&gt; 4.87144113772763, 5.08733916300432, 5.3686541844253, 4.94628927646412, \n#&gt; 5.12966109847693, 4.9575144579774, 5.04358777822716, 4.9575144579774, \n#&gt; 6.32794887612628, 6.1468334958714, 6.50788891564368, 5.70120244540939, \n#&gt; 6.23709735081447, 6.14929823189912, 6.3267735353888, 5.08917000597757, \n#&gt; 6.23891738919707, 5.60841682716221, 5.2664742276381, 5.87604193104219, \n#&gt; 5.7097347817894, 6.32794887612628, 5.3427258162176, 6.05812435776475, \n#&gt; 6.1468334958714, 5.79838689261966, 6.1468334958714, 5.61791621000991, \n#&gt; 6.41682909606208, 5.70120244540939, 6.50788891564368, 6.32912421686375, \n#&gt; 5.97005991730323, 6.05812435776475, 6.41789038224679, 6.59891152278464, \n#&gt; 6.1468334958714, 5.2664742276381, 5.52894175035708, 5.44377844929862, \n#&gt; 5.61474974906067, 6.68911835045133, 6.1468334958714, 6.14560112785754, \n#&gt; 6.32736120575754, 6.05967907460118, 5.79082160270733, 5.70120244540939, \n#&gt; 6.0612337914376, 6.23800737000577, 5.70404655753606, 5.08917000597757, \n#&gt; 5.88044076000528, 5.88264017448683, 5.88044076000528, 5.97005991730323, \n#&gt; 4.8171460731345, 5.79082160270733, 7.0155133579311, 6.16991691988386, \n#&gt; 6.9089039527544, 6.62536970201613, 6.8196641715554, 7.55428958790349, \n#&gt; 5.62306215451168, 7.26398601189142, 6.80783150483764, 7.10900070109979, \n#&gt; 6.17061864480537, 6.35302342035049, 6.54011216124064, 6.07874304574949, \n#&gt; 6.1734255444914, 6.35840911061702, 6.53413880060537, 7.65234684186442, \n#&gt; 7.84389143899405, 6.07684616525475, 6.72977969271128, 5.98686744669361, \n#&gt; 7.64062822969943, 5.98675339214084, 6.72450805699752, 6.99029330765915, \n#&gt; 5.89552249073008, 5.98675339214084, 6.63231010911908, 6.80191517147876, \n#&gt; 7.08544942221703, 7.36500143253179, 6.6346235781534, 6.16711002019782, \n#&gt; 6.61611582587886, 7.10115027480553, 6.63925051622203, 6.53413880060537, \n#&gt; 5.89552249073008, 6.4479142133622, 6.63925051622203, 6.17272381956989, \n#&gt; 6.16991691988386, 6.91546498375841, 6.73505132842504, 6.26556646509346, \n#&gt; 6.07836366965054, 6.26249424386125, 6.45125175614059, 6.16921519496235\n#&gt; ), c(0, 1, 2, 3, 3, 4), list(c(-12.2474487139159, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, 0.0816496580927726, \n#&gt; -14.6887734908898, 9.30429649857169, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.0778024888416311, 0.088550211682939, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.110045657365555, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.110045657365555, 0.110045657365555, 0.0992979345242469, 0.0778024888416311, \n#&gt; 0.0778024888416311, 0.088550211682939, 0.088550211682939, 0.088550211682939, \n#&gt; 0.0992979345242469, 0.0778024888416311, 0.0992979345242469, 0.0670547660003233, \n#&gt; 0.0992979345242469, 0.0992979345242469, 0.0778024888416311, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.0992979345242469, 0.0992979345242469, 0.0778024888416311, \n#&gt; 0.110045657365555, 0.0992979345242469, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.110045657365555, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.088550211682939, 0.088550211682939, 0.0992979345242469, 0.0563070431590154, \n#&gt; 0.0778024888416311, 0.088550211682939, 0.0992979345242469, 0.0992979345242469, \n#&gt; 0.0992979345242469, 0.0992979345242469, -0.0296747395714478, \n#&gt; -0.0404224624127557, -0.0404224624127557, -0.0189270167301399, \n#&gt; -0.0404224624127557, -0.0189270167301399, -0.0511701852540636, \n#&gt; 0.0133161517937838, -0.0189270167301399, -0.0296747395714478, \n#&gt; 0.0133161517937838, -0.0404224624127557, 0.0133161517937838, \n#&gt; -0.0296747395714478, -0.0189270167301399, -0.0296747395714478, \n#&gt; -0.0404224624127557, 0.0133161517937838, -0.0404224624127557, \n#&gt; 0.00256842895247588, -0.0726656309366794, -0.0189270167301399, \n#&gt; -0.0404224624127557, -0.008179293888832, -0.0189270167301399, \n#&gt; -0.0296747395714478, -0.0296747395714478, -0.0619179080953715, \n#&gt; -0.0404224624127557, 0.0133161517937838, 0.00256842895247588, \n#&gt; 0.0133161517937838, -0.008179293888832, -0.0511701852540636, \n#&gt; -0.0404224624127557, -0.0511701852540636, -0.0404224624127557, \n#&gt; -0.0189270167301399, -0.0189270167301399, -0.0189270167301399, \n#&gt; -0.008179293888832, -0.0296747395714478, -0.008179293888832, \n#&gt; 0.0133161517937838, -0.0189270167301399, -0.008179293888832, \n#&gt; -0.0189270167301399, -0.0189270167301399, 0.00256842895247588, \n#&gt; -0.0189270167301399, -0.147899690825835, -0.0834133537779873, \n#&gt; -0.104908799460603, -0.0726656309366794, -0.115656522301911, \n#&gt; -0.104908799460603, -0.0619179080953715, -0.0726656309366794, \n#&gt; -0.0726656309366794, -0.147899690825835, -0.0941610766192952, \n#&gt; -0.0834133537779873, -0.104908799460603, -0.0941610766192952, \n#&gt; -0.137151967984527, -0.126404245143219, -0.0726656309366794, \n#&gt; -0.115656522301911, -0.126404245143219, -0.0404224624127557, \n#&gt; -0.126404245143219, -0.0941610766192952, -0.0941610766192952, \n#&gt; -0.0726656309366794, -0.104908799460603, -0.0726656309366794, \n#&gt; -0.0726656309366794, -0.0726656309366794, -0.104908799460603, \n#&gt; -0.0511701852540636, -0.0834133537779873, -0.0941610766192952, \n#&gt; -0.115656522301911, -0.0404224624127557, -0.0296747395714478, \n#&gt; -0.126404245143219, -0.137151967984527, -0.0726656309366794, \n#&gt; -0.0726656309366794, -0.104908799460603, -0.137151967984527, \n#&gt; -0.126404245143219, -0.0834133537779873, -0.126404245143219, \n#&gt; -0.147899690825835, -0.126404245143219, -0.0834133537779873, \n#&gt; -0.0941610766192952, -0.126404245143219, -0.0726656309366794, \n#&gt; -46.0259122668959, 20.7480275407855, 5.81762435765699, 0.00153822106493907, \n#&gt; 0.0187273680177469, 0.0442240300146606, 0.0572594194454154, 0.00153822106493907, \n#&gt; 0.0187273680177469, -0.0369938303627295, 0.00153822106493907, \n#&gt; -0.0156509258878688, -0.0198046834099217, 0.0317627574485017, \n#&gt; 0.0531056619233624, 0.0786023239202762, 0.112980617825892, 0.0572594194454154, \n#&gt; 0.00569197858699198, 0.0400702724926076, -0.0328400728406765, \n#&gt; 0.0786023239202762, 0.087483955828978, 0.0827560814423291, -0.0672183667462921, \n#&gt; -0.0156509258878688, 0.0614131769674684, 0.00153822106493907, \n#&gt; 0.0187273680177469, -0.0156509258878688, -0.0156509258878688, \n#&gt; 0.0786023239202762, -0.0369938303627295, 0.0187273680177469, \n#&gt; 0.00153822106493907, 0.0531056619233624, 0.0359165149705546, \n#&gt; -0.0198046834099217, 0.0359165149705546, 0.00153822106493907, \n#&gt; 0.0744485663982231, 0.0744485663982231, 0.0359165149705546, 0.138477279822805, \n#&gt; 0.00984573610904502, 0.0572594194454154, -0.0156509258878688, \n#&gt; 0.0187273680177469, 0.00153822106493907, 0.0187273680177469, \n#&gt; -0.0861298642928878, -0.0132195189596035, -0.0819761067708348, \n#&gt; -0.00433788705090168, -0.0304086659124113, -0.0902836218149406, \n#&gt; -0.0090657614375506, 0.000389987335747224, -0.107472768767748, \n#&gt; 0.0513833113295746, -0.0339883065698684, 0.0383479218988198, \n#&gt; -0.119934041333907, -0.0861298642928878, 0.0644187007603295, \n#&gt; -0.0345624234344644, -0.0132195189596035, -0.137123188286715, \n#&gt; -0.0132195189596035, -0.064212842953431, 0.0508091944649788, \n#&gt; -0.00433788705090168, -0.0819761067708348, -0.163193967148225, \n#&gt; -0.055905327909325, -0.0345624234344644, -0.103319011245696, \n#&gt; -0.0221011508683054, -0.0132195189596035, -0.0339883065698684, \n#&gt; -0.0470236960006232, -0.068366600475484, -0.0256807915257625, \n#&gt; -0.0778223492487817, -0.0132195189596035, 0.025312532468065, \n#&gt; -0.0475978128652192, -0.0730944748621329, -0.0215270340037094, \n#&gt; -0.00433788705090168, -0.111626526289801, -0.0689407173400799, \n#&gt; -0.0428699384785703, 0.000389987335747224, -0.0387161809565173, \n#&gt; -0.0772482323841859, -0.0387161809565173, -0.055905327909325, \n#&gt; 0.0904894796218392, -0.0215270340037094, 0.114263791024965, 0.0377738050342239, \n#&gt; -0.0226752677329013, -0.0867039811574835, 0.0330459306475751, \n#&gt; -0.142999296402556, 0.0638445838957336, -0.207028009827138, -0.121082275063099, \n#&gt; 0.0970746440721574, 0.0763058564618925, 0.00339551112860831, \n#&gt; 0.0460813200783299, 0.0934950034147003, 0.230434062172567, 0.157523716839282, \n#&gt; -0.0695148342046758, -0.121656391927695, -0.117502634405642, \n#&gt; -0.0991652537236425, 0.0887671290280512, 0.110684150367508, -0.198720494783032, \n#&gt; 0.0336200475121709, 0.0117030261727143, -0.155460568968715, 0.0508091944649788, \n#&gt; 0.0336200475121709, 0.0288921731255222, -0.198146377918436, -0.134117664493854, \n#&gt; -0.147153053924609, 0.0674242245531907, -0.11635440067645, -0.240832186868158, \n#&gt; 0.0200105412168202, 0.144488327408528, -0.0695148342046758, 0.0508091944649788, \n#&gt; 0.0632704670311376, 0.144488327408528, 0.191902010744898, 0.0377738050342239, \n#&gt; 0.0543888351224356, 0.165831231883388, 0.17471286379209, 0.0549629519870317, \n#&gt; 0.0591167095090847, 0.140334569886475, -0.000758246393444546, \n#&gt; -4.08248290463863, 0.680689113282833, 1.8868601435992, 5.41384839674038, \n#&gt; 0.033392481153859, 0.0273909956668532, 0.0207108967780347, 0.0398463755754066, \n#&gt; 0.033392481153859, 0.0525279599512309, 0.0398463755754066, 0.0463002699969543, \n#&gt; 0.0460740655296833, 0.0267123822650405, 0.0204846923107638, 0.014483206823758, \n#&gt; 0.00157541798066278, 0.0207108967780347, 0.0400725800426776, \n#&gt; 0.0271647911995823, 0.0527541644185019, 0.014483206823758, 0.00757690346766855, \n#&gt; 0.0147094112910289, 0.0656619532615971, 0.0463002699969543, 0.0209371012453056, \n#&gt; 0.0398463755754066, 0.033392481153859, 0.0463002699969543, 0.0463002699969543, \n#&gt; 0.014483206823758, 0.0525279599512309, 0.033392481153859, 0.0398463755754066, \n#&gt; 0.0204846923107638, 0.0269385867323114, 0.0460740655296833, 0.0269385867323114, \n#&gt; 0.0398463755754066, 0.0142570023564871, 0.0142570023564871, 0.0269385867323114, \n#&gt; -0.00442606750634301, 0.0402987845099485, 0.0207108967780347, \n#&gt; 0.0463002699969543, 0.033392481153859, 0.0398463755754066, 0.033392481153859, \n#&gt; -0.0905195047068495, -0.116108877925769, -0.0902933002395785, \n#&gt; -0.123015181281858, -0.109654983504221, -0.0907457091741204, \n#&gt; -0.115882673458498, -0.130147689105219, -0.0842918147525728, \n#&gt; -0.14215066007923, -0.117239900262124, -0.135470561190412, -0.0849704281543855, \n#&gt; -0.0905195047068495, -0.148830758968049, -0.109881187971492, \n#&gt; -0.116108877925769, -0.0785165337328379, -0.116108877925769, \n#&gt; -0.104105906951757, -0.134791947788599, -0.123015181281858, -0.0902933002395785, \n#&gt; -0.0651563359552008, -0.103653498017216, -0.109881187971492, \n#&gt; -0.0840656102853019, -0.10920257456968, -0.116108877925769, -0.117239900262124, \n#&gt; -0.110559801373305, -0.104332111419028, -0.116787491327582, -0.0900670957723077, \n#&gt; -0.116108877925769, -0.128790462301593, -0.103201089082674, -0.097199603595668, \n#&gt; -0.116561286860311, -0.123015181281858, -0.0845180192198437, \n#&gt; -0.0969733991283971, -0.110333596906034, -0.130147689105219, \n#&gt; -0.110107392438763, -0.0974258080629389, -0.110107392438763, \n#&gt; -0.103653498017216, -0.162190956745686, -0.116561286860311, 0.03859518390109, \n#&gt; 0.0565996403621074, 0.0828676269828397, 0.10155069684567, 0.0637321481854677, \n#&gt; 0.128044887933673, 0.0432394425844703, 0.146727957796503, 0.114458485688765, \n#&gt; 0.0450490783226376, 0.0439180559862831, 0.0695074292052027, 0.0570520492966492, \n#&gt; 0.0374641615647355, -0.00680828151701418, 0.0187810917019054, \n#&gt; 0.0950968024241222, 0.121817197979396, 0.122043402446667, 0.100872083443857, \n#&gt; 0.0445966693880959, 0.0310102671431879, 0.147180366731045, 0.0563734358948365, \n#&gt; 0.0699598381397445, 0.12736627453186, 0.0499195414732889, 0.0563734358948365, \n#&gt; 0.0635059437181968, 0.139821654440414, 0.121138584577584, 0.127818683466402, \n#&gt; 0.0508243593423725, 0.107325977865405, 0.152277034348967, 0.0704122470742863, \n#&gt; 0.0254611905907239, 0.0950968024241222, 0.0499195414732889, 0.0505981548751016, \n#&gt; 0.0254611905907239, 0.00587330285881018, 0.0565996403621074, \n#&gt; 0.0575044582311911, 0.0192335006364472, 0.0123271972803578, 0.0501457459405598, \n#&gt; 0.0503719504078307, 0.0252349861234531, 0.0692812247379317, -4.08248290463863, \n#&gt; 4.44239210774059, -0.424722128220301, -3.4890454943047, 1.11564257129667, \n#&gt; 0.0809550703643557, 0.024695794624255, 0.0162883406803865, 0.00432538523132845, \n#&gt; -0.00408206871254012, 0.0162883406803865, 0.0282512961294445, \n#&gt; -0.0160450241615981, -0.0519338905087722, -0.0196005256667876, \n#&gt; 0.0570291594662397, 0.0331032485681237, 0.024695794624255, 0.0605846609714291, \n#&gt; 0.036658750073313, 0.0402142515785025, 0.0570291594662397, -0.0435264365649036, \n#&gt; 0.101325479757282, 0.0641401624766186, 0.0282512961294445, 0.0689921149152977, \n#&gt; 0.0162883406803865, 0.00432538523132845, 0.0282512961294445, \n#&gt; 0.0282512961294445, 0.0570291594662397, -0.00408206871254012, \n#&gt; 0.00432538523132845, 0.0162883406803865, -0.0196005256667876, \n#&gt; -0.00763757021772952, -0.0160450241615981, -0.00763757021772952, \n#&gt; 0.0162883406803865, 0.012732839175197, 0.012732839175197, -0.00763757021772952, \n#&gt; 0.109732933701151, 0.104880981262472, 0.024695794624255, 0.0282512961294445, \n#&gt; 0.00432538523132845, 0.0162883406803865, 0.00432538523132845, \n#&gt; 0.0688922571589244, 0.0653367556537349, 0.113188577449967, -0.0352188403774083, \n#&gt; 0.0772997111027929, 0.0245959368678818, 0.109633075944778, -0.180070756699594, \n#&gt; 0.0365588923169398, -0.0268113864335398, -0.156144845801478, \n#&gt; 0.0294478893065609, -0.0963300685561881, 0.0688922571589244, \n#&gt; -0.0830706621736404, 0.0330033908117504, 0.0653367556537349, \n#&gt; -0.0843671131071301, 0.0653367556537349, -0.0879226146123196, \n#&gt; 0.162336850179689, -0.0352188403774083, 0.113188577449967, 0.0281514383730712, \n#&gt; 0.000670025969765682, 0.0330033908117504, 0.0808552126079824, \n#&gt; 0.165892351684878, 0.0653367556537349, -0.156144845801478, -0.0998855700613776, \n#&gt; -0.132218934903362, -0.0675522052193929, 0.15748489774101, 0.0653367556537349, \n#&gt; 0.0857071650466615, 0.089262666551851, 0.0126329814188238, -0.0232558849283504, \n#&gt; -0.0352188403774083, -0.00773742797410282, 0.0569293017098664, \n#&gt; -0.0555892497703349, -0.180070756699594, -0.0112929294792922, \n#&gt; -0.0316633388722189, -0.0112929294792922, 0.000670025969765682, \n#&gt; -0.195589213653842, -0.0232558849283504, 0.126796326095687, -0.103092729303395, \n#&gt; 0.0333517330749229, -0.0636483614510311, 0.0417591870187914, \n#&gt; 0.117092421218329, -0.215611280783596, 0.020092326692375, -0.0397224505529149, \n#&gt; 0.138759281544745, -0.082722319910468, -0.0791668184052785, -0.0145000887213092, \n#&gt; -0.094685275359526, -0.00124068233876161, 0.00231481916642784, \n#&gt; -0.075611316900089, 0.149425786060314, 0.193722106351356, -0.196537322324159, \n#&gt; 0.0501666409626599, -0.106648230808584, 0.10868496727446, -0.147389049594437, \n#&gt; 0.00942582217680681, -0.0157965396547989, -0.159352005043495, \n#&gt; -0.147389049594437, -0.00253713327225124, -0.0804632693387682, \n#&gt; 0.0165368251871856, 0.0727961009272864, 0.0178332761206754, -0.184574366875101, \n#&gt; -0.145129999022737, 0.0980184627588919, 0.0585740949065285, -0.075611316900089, \n#&gt; -0.159352005043495, -0.0264630441703672, 0.0585740949065285, \n#&gt; -0.0216110917316882, -0.103092729303395, 0.074092551860776, 0.0909074597485132, \n#&gt; -0.00964813628263016, -0.115055684752453, -0.0707593644614099, \n#&gt; 0.0142777746154859, -0.123463138696321, -70.9625343450096, 56.3907660022668, \n#&gt; 3.08793638683961, -8.84664926411501, -4.44414200339705, 4.61722606476297, \n#&gt; 0.0342936864802481, -0.0102831456627637, -0.0400113570729295, \n#&gt; -0.0824223866626905, -0.0102831456627637, 0.0194450657474023, \n#&gt; -0.114316400626107, -0.209998442516358, -0.0994677798932615, \n#&gt; 0.13399533633709, 0.083202123729762, 0.0342936864802481, 0.116980913050993, \n#&gt; 0.0618560953371631, 0.0491732771575683, 0.13399533633709, -0.158924202713593, \n#&gt; 0.252596184837844, 0.1086296999779, 0.0194450657474023, 0.159391942640755, \n#&gt; -0.0102831456627637, -0.0400113570729295, 0.0194450657474023, \n#&gt; 0.0194450657474023, 0.13399533633709, -0.0824223866626905, -0.0400113570729295, \n#&gt; -0.0102831456627637, -0.0994677798932615, -0.0697395684830954, \n#&gt; -0.114316400626107, -0.0697395684830954, -0.0102831456627637, \n#&gt; 0.00673127762333315, 0.00673127762333315, -0.0697395684830954, \n#&gt; 0.299338819534107, 0.235581761551747, 0.0342936864802481, 0.0194450657474023, \n#&gt; -0.0400113570729295, -0.0102831456627637, -0.0400113570729295, \n#&gt; 0.0400912555211672, 0.0397792583812572, 0.046070371252877, -0.00407298704557909, \n#&gt; 0.0413520365991622, 0.025448929576454, 0.0457583741129669, -0.144868055440661, \n#&gt; 0.0313533129008607, 0.0101826093519207, -0.120064473472342, 0.0350609237275423, \n#&gt; -0.0580555185515465, 0.0400912555211672, -0.0276905203432057, \n#&gt; 0.0288755132076998, 0.0397792583812572, -0.0456537275673874, \n#&gt; 0.0397792583812572, -0.0502973298137991, 0.046500863262919, -0.00407298704557909, \n#&gt; 0.046070371252877, 0.0344241369293675, 0.0136401629276408, 0.0288755132076998, \n#&gt; 0.0438298362923229, 0.0403154527430766, 0.0397792583812572, -0.120064473472342, \n#&gt; -0.0605333182447075, -0.095260891504024, -0.0301373500918924, \n#&gt; 0.0433862767715832, 0.0397792583812572, 0.0469444227836587, 0.042924814817067, \n#&gt; 0.0195445462520475, 0.00183139627882739, -0.00407298704557909, \n#&gt; 0.010213579296395, 0.0363526747500114, -0.0220671642142349, -0.144868055440661, \n#&gt; 0.00773577960323411, -0.00592679245891999, 0.00773577960323411, \n#&gt; 0.0136401629276408, -0.142421225691974, 0.00183139627882739, \n#&gt; -0.153524218361304, 0.0622209129727486, -0.0408146856742592, \n#&gt; 0.0434274166806142, -0.0503829173625185, -0.12076894538546, 0.0904331761385364, \n#&gt; 0.00895501058768104, 0.0335781577969193, -0.173609465675907, \n#&gt; 0.0563912620556454, 0.0480400489825521, 0.00487346273214126, \n#&gt; 0.0656474966039946, 0.0330726583872315, 0.00739502488813094, \n#&gt; 0.048352046122462, -0.172673474256178, -0.244663250441498, 0.0839667384232578, \n#&gt; -0.0556195439442763, 0.0749037311523439, -0.0917084907179432, \n#&gt; 0.0778998227735477, -0.017970611471059, 0.0237288989132239, 0.0828244522153951, \n#&gt; 0.0778998227735477, -0.00654857436945884, 0.075558695376638, \n#&gt; -0.00868340697823551, -0.0639397870728954, -0.0232072380528166, \n#&gt; 0.0855395166411628, 0.110062071414045, -0.118634112776683, -0.0565245654195321, \n#&gt; 0.048352046122462, 0.0828244522153951, 0.0162954998337413, -0.0565245654195321, \n#&gt; 0.0389023093043347, 0.0622209129727486, -0.0871268283604801, \n#&gt; -0.0932684764174932, 0.0231486670962329, 0.0693113449678471, \n#&gt; 0.047135027507296, -0.00835861731997081, 0.0680505638898524), \n#&gt;     c(1.08164965809277, 1.09929793452425, 1.03591651497055, 1.03984637557541, \n#&gt;     1.00432538523133, 1.18478854894442), 1:6, 1e-07, 6), 144, \n#&gt;     list(\"contr.treatment\"), list(c(\"setosa\", \"versicolor\", \"virginica\"\n#&gt;     )), lm(formula = Sepal.Length ~ Petal.Width * Petal.Length + \n#&gt;         factor(Species), data = iris), Sepal.Length ~ Petal.Width * \n#&gt;         Petal.Length + factor(Species), list(c(5.1, 4.9, 4.7, \n#&gt;     4.6, 5, 5.4, 4.6, 5, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, \n#&gt;     5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5, 5, 5.2, 5.2, \n#&gt;     4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5, 5.5, 4.9, 4.4, 5.1, 5, 4.5, \n#&gt;     4.4, 5, 5.1, 4.8, 5.1, 4.6, 5.3, 5, 7, 6.4, 6.9, 5.5, 6.5, \n#&gt;     5.7, 6.3, 4.9, 6.6, 5.2, 5, 5.9, 6, 6.1, 5.6, 6.7, 5.6, 5.8, \n#&gt;     6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6, 5.7, \n#&gt;     5.5, 5.5, 5.8, 6, 5.4, 6, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, \n#&gt;     5, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, \n#&gt;     7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, \n#&gt;     7.7, 7.7, 6, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, \n#&gt;     7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6, 6.9, 6.7, \n#&gt;     6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9), c(0.2, 0.2, \n#&gt;     0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, \n#&gt;     0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, \n#&gt;     0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, \n#&gt;     0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, \n#&gt;     1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1, 1.3, 1.4, 1, 1.5, 1, \n#&gt;     1.4, 1.3, 1.4, 1.5, 1, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, \n#&gt;     1.4, 1.4, 1.7, 1.5, 1, 1.1, 1, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, \n#&gt;     1.3, 1.3, 1.2, 1.4, 1.2, 1, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, \n#&gt;     2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2, 1.9, \n#&gt;     2.1, 2, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2, 2, 1.8, 2.1, \n#&gt;     1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2, 2.2, 1.5, 1.4, 2.3, 2.4, \n#&gt;     1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2, 2.3, \n#&gt;     1.8), c(1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, \n#&gt;     1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, \n#&gt;     1, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, \n#&gt;     1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, \n#&gt;     1.6, 1.4, 1.5, 1.4, 4.7, 4.5, 4.9, 4, 4.6, 4.5, 4.7, 3.3, \n#&gt;     4.6, 3.9, 3.5, 4.2, 4, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, \n#&gt;     4.8, 4, 4.9, 4.7, 4.3, 4.4, 4.8, 5, 4.5, 3.5, 3.8, 3.7, 3.9, \n#&gt;     5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4, 4.4, 4.6, 4, 3.3, 4.2, 4.2, \n#&gt;     4.2, 4.3, 3, 4.1, 6, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, \n#&gt;     6.1, 5.1, 5.3, 5.5, 5, 5.1, 5.3, 5.5, 6.7, 6.9, 5, 5.7, 4.9, \n#&gt;     6.7, 4.9, 5.7, 6, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, \n#&gt;     5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, \n#&gt;     5, 5.2, 5.4, 5.1), c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt;     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt;     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt;     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt;     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt;     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, \n#&gt;     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt;     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt;     3, 3, 3, 3, 3))), INF_FUN = function (model, newdata = NULL, \n#&gt;     variables = NULL, comparison = \"difference\", type = NULL, \n#&gt;     vcov = TRUE, by = FALSE, conf_level = 0.95, transform = NULL, \n#&gt;     cross = FALSE, wts = FALSE, hypothesis = NULL, equivalence = NULL, \n#&gt;     p_adjust = NULL, df = Inf, eps = NULL, numderiv = \"fdforward\", \n#&gt;     ...) \n#&gt; {\n#&gt;     dots &lt;- list(...)\n#&gt;     if (\"transform_post\" %in% names(dots)) {\n#&gt;         transform &lt;- dots[[\"transform_post\"]]\n#&gt;         insight::format_warning(\"The `transform_post` argument is deprecated. Use `transform` instead.\")\n#&gt;     }\n#&gt;     if (\"transform_pre\" %in% names(dots)) {\n#&gt;         comparison &lt;- dots[[\"transform_pre\"]]\n#&gt;         insight::format_warning(\"The `transform_pre` argument is deprecated. Use `comparison` instead.\")\n#&gt;     }\n#&gt;     scall &lt;- rlang::enquo(newdata)\n#&gt;     newdata &lt;- sanitize_newdata_call(scall, newdata, model, by = by)\n#&gt;     if (isTRUE(by)) {\n#&gt;         modeldata &lt;- get_modeldata(model, additional_variables = FALSE, \n#&gt;             modeldata = dots[[\"modeldata\"]], wts = wts)\n#&gt;     }\n#&gt;     else {\n#&gt;         modeldata &lt;- get_modeldata(model, additional_variables = by, \n#&gt;             modeldata = dots[[\"modeldata\"]], wts = wts)\n#&gt;     }\n#&gt;     call_attr &lt;- c(list(name = \"comparisons\", model = model, \n#&gt;         newdata = newdata, variables = variables, type = type, \n#&gt;         vcov = vcov, by = by, conf_level = conf_level, comparison = comparison, \n#&gt;         transform = transform, cross = cross, wts = wts, hypothesis = hypothesis, \n#&gt;         equivalence = equivalence, p_adjust = p_adjust, df = df), \n#&gt;         dots)\n#&gt;     if (\"modeldata\" %in% names(dots)) {\n#&gt;         call_attr[[\"modeldata\"]] &lt;- modeldata\n#&gt;     }\n#&gt;     call_attr &lt;- do.call(\"call\", call_attr)\n#&gt;     bycols &lt;- NULL\n#&gt;     sanity_dots(model, ...)\n#&gt;     sanity_df(df, newdata)\n#&gt;     conf_level &lt;- sanitize_conf_level(conf_level, ...)\n#&gt;     checkmate::assert_number(eps, lower = 1e-10, null.ok = TRUE)\n#&gt;     numderiv &lt;- sanitize_numderiv(numderiv)\n#&gt;     sanity_equivalence_p_adjust(equivalence, p_adjust)\n#&gt;     model &lt;- sanitize_model(model = model, newdata = newdata, \n#&gt;         wts = wts, vcov = vcov, by = by, calling_function = \"comparisons\", \n#&gt;         ...)\n#&gt;     cross &lt;- sanitize_cross(cross, variables, model)\n#&gt;     type &lt;- sanitize_type(model = model, type = type, calling_function = \"comparisons\")\n#&gt;     sanity_comparison(comparison)\n#&gt;     if (inherits(model, c(\"mira\", \"amest\"))) {\n#&gt;         out &lt;- process_imputation(model, call_attr)\n#&gt;         return(out)\n#&gt;     }\n#&gt;     comparison_label &lt;- transform_label &lt;- NULL\n#&gt;     if (is.function(comparison)) {\n#&gt;         comparison_label &lt;- deparse(substitute(comparison))\n#&gt;     }\n#&gt;     if (is.function(transform)) {\n#&gt;         transform_label &lt;- deparse(substitute(transform))\n#&gt;         transform &lt;- sanitize_transform(transform)\n#&gt;         names(transform) &lt;- transform_label\n#&gt;     }\n#&gt;     else {\n#&gt;         transform &lt;- sanitize_transform(transform)\n#&gt;         transform_label &lt;- names(transform)\n#&gt;     }\n#&gt;     marginalmeans &lt;- isTRUE(checkmate::check_choice(newdata, \n#&gt;         choices = \"marginalmeans\"))\n#&gt;     newdata &lt;- sanitize_newdata(model = model, newdata = newdata, \n#&gt;         modeldata = modeldata, by = by, wts = wts)\n#&gt;     sanity_by(by, newdata)\n#&gt;     newdata &lt;- dedup_newdata(model = model, newdata = newdata, \n#&gt;         wts = wts, by = by, cross = cross, comparison = comparison)\n#&gt;     if (isFALSE(wts) && \"marginaleffects_wts_internal\" %in% colnames(newdata)) {\n#&gt;         wts &lt;- \"marginaleffects_wts_internal\"\n#&gt;     }\n#&gt;     variables_list &lt;- sanitize_variables(model = model, newdata = newdata, \n#&gt;         modeldata = modeldata, variables = variables, cross = cross, \n#&gt;         by = by, comparison = comparison, eps = eps)\n#&gt;     if (inherits(model, \"lmerMod\") && (isTRUE(hush(vcov %in% \n#&gt;         c(\"satterthwaite\", \"kenward-roger\"))))) {\n#&gt;         dv &lt;- insight::find_response(model)\n#&gt;         if (!dv %in% colnames(newdata)) {\n#&gt;             newdata[[dv]] &lt;- mean(insight::get_response(model))\n#&gt;         }\n#&gt;         if (!isTRUE(hush(is.infinite(df)))) {\n#&gt;             insight::format_error(\"The `df` argument is not supported when `vcov` is \\\"satterthwaite\\\" or \\\"kenward-roger\\\".\")\n#&gt;         }\n#&gt;         df &lt;- insight::get_df(model, type = vcov, data = newdata, \n#&gt;             df_per_observation = TRUE)\n#&gt;     }\n#&gt;     vcov_false &lt;- isFALSE(vcov)\n#&gt;     vcov.type &lt;- get_vcov_label(vcov)\n#&gt;     vcov &lt;- get_vcov(model, vcov = vcov, type = type, ...)\n#&gt;     predictors &lt;- variables_list$conditional\n#&gt;     out &lt;- inferences_dispatch(INF_FUN = comparisons, model = model, \n#&gt;         newdata = newdata, vcov = vcov, variables = variables, \n#&gt;         type = type, by = by, conf_level = conf_level, cross = cross, \n#&gt;         comparison = comparison, transform = transform, wts = wts, \n#&gt;         hypothesis = hypothesis, eps = eps, ...)\n#&gt;     if (!is.null(out)) {\n#&gt;         return(out)\n#&gt;     }\n#&gt;     tmp &lt;- sanitize_hypothesis(hypothesis, ...)\n#&gt;     hypothesis &lt;- tmp$hypothesis\n#&gt;     hypothesis_null &lt;- tmp$hypothesis_null\n#&gt;     args &lt;- list(model = model, newdata = newdata, variables = predictors, \n#&gt;         cross = cross, marginalmeans = marginalmeans, modeldata = modeldata)\n#&gt;     dots[[\"modeldata\"]] &lt;- NULL\n#&gt;     args &lt;- c(args, dots)\n#&gt;     contrast_data &lt;- do.call(\"get_contrast_data\", args)\n#&gt;     args &lt;- list(model, newdata = newdata, variables = predictors, \n#&gt;         type = type, original = contrast_data[[\"original\"]], \n#&gt;         hi = contrast_data[[\"hi\"]], lo = contrast_data[[\"lo\"]], \n#&gt;         wts = contrast_data[[\"original\"]][[\"marginaleffects_wts_internal\"]], \n#&gt;         by = by, marginalmeans = marginalmeans, cross = cross, \n#&gt;         hypothesis = hypothesis, modeldata = modeldata)\n#&gt;     args &lt;- c(args, dots)\n#&gt;     mfx &lt;- do.call(\"get_contrasts\", args)\n#&gt;     hyp_by &lt;- attr(mfx, \"hypothesis_function_by\")\n#&gt;     if (!is.null(attr(mfx, \"posterior_draws\"))) {\n#&gt;         draws &lt;- attr(mfx, \"posterior_draws\")\n#&gt;         J &lt;- NULL\n#&gt;     }\n#&gt;     else if (!vcov_false && isTRUE(checkmate::check_matrix(vcov))) {\n#&gt;         idx &lt;- intersect(colnames(mfx), c(\"group\", \"term\", \"contrast\"))\n#&gt;         idx &lt;- mfx[, (idx), drop = FALSE]\n#&gt;         args &lt;- list(model, vcov = vcov, type = type, FUN = get_se_delta_contrasts, \n#&gt;             newdata = newdata, index = idx, variables = predictors, \n#&gt;             marginalmeans = marginalmeans, hypothesis = hypothesis, \n#&gt;             hi = contrast_data$hi, lo = contrast_data$lo, original = contrast_data$original, \n#&gt;             by = by, eps = eps, cross = cross, numderiv = numderiv)\n#&gt;         args &lt;- c(args, dots)\n#&gt;         se &lt;- do.call(\"get_se_delta\", args)\n#&gt;         J &lt;- attr(se, \"jacobian\")\n#&gt;         attr(se, \"jacobian\") &lt;- NULL\n#&gt;         mfx$std.error &lt;- as.numeric(se)\n#&gt;         draws &lt;- NULL\n#&gt;     }\n#&gt;     else {\n#&gt;         J &lt;- draws &lt;- NULL\n#&gt;     }\n#&gt;     if ((is.null(by) || isFALSE(by)) && \"rowid\" %in% colnames(mfx)) {\n#&gt;         if (\"rowid\" %in% colnames(newdata)) {\n#&gt;             idx &lt;- c(\"rowid\", \"rowidcf\", \"term\", \"contrast\", \n#&gt;                 \"by\", setdiff(colnames(contrast_data$original), \n#&gt;                   colnames(mfx)))\n#&gt;             idx &lt;- intersect(idx, colnames(contrast_data$original))\n#&gt;             tmp &lt;- contrast_data$original[, ..idx, drop = FALSE]\n#&gt;             bycols &lt;- intersect(colnames(tmp), colnames(mfx))\n#&gt;             idx &lt;- duplicated(tmp, by = bycols)\n#&gt;             tmp &lt;- tmp[!idx]\n#&gt;             mfx &lt;- merge(mfx, tmp, all.x = TRUE, by = bycols, \n#&gt;                 sort = FALSE)\n#&gt;         }\n#&gt;         else {\n#&gt;             idx &lt;- setdiff(colnames(contrast_data$original), \n#&gt;                 colnames(mfx))\n#&gt;             mfx &lt;- data.table(mfx, contrast_data$original[, ..idx])\n#&gt;         }\n#&gt;     }\n#&gt;     mfx &lt;- get_ci(mfx, conf_level = conf_level, df = df, draws = draws, \n#&gt;         estimate = \"estimate\", null_hypothesis = hypothesis_null, \n#&gt;         p_adjust = p_adjust, model = model)\n#&gt;     mfx &lt;- sort_columns(mfx, newdata, by)\n#&gt;     attr(mfx, \"posterior_draws\") &lt;- draws\n#&gt;     mfx &lt;- equivalence(mfx, equivalence = equivalence, df = df, \n#&gt;         ...)\n#&gt;     mfx &lt;- backtransform(mfx, transform)\n#&gt;     if (!all(is.na(mfx[[\"marginaleffects_wts_internal\"]]))) {\n#&gt;         marginaleffects_wts_internal &lt;- mfx[[\"marginaleffects_wts_internal\"]]\n#&gt;     }\n#&gt;     else {\n#&gt;         marginaleffects_wts_internal &lt;- NULL\n#&gt;     }\n#&gt;     mfx[[\"marginaleffects_wts_internal\"]] &lt;- NULL\n#&gt;     out &lt;- mfx\n#&gt;     data.table::setDF(out)\n#&gt;     out &lt;- set_marginaleffects_attributes(out, get_marginaleffects_attributes(newdata, \n#&gt;         include_regex = \"^newdata.*class|explicit|matrix|levels\"))\n#&gt;     attr(out, \"newdata\") &lt;- newdata\n#&gt;     attr(out, \"call\") &lt;- call_attr\n#&gt;     attr(out, \"type\") &lt;- type\n#&gt;     attr(out, \"model_type\") &lt;- class(model)[1]\n#&gt;     attr(out, \"model\") &lt;- model\n#&gt;     attr(out, \"variables\") &lt;- predictors\n#&gt;     attr(out, \"jacobian\") &lt;- J\n#&gt;     attr(out, \"vcov\") &lt;- vcov\n#&gt;     attr(out, \"vcov.type\") &lt;- vcov.type\n#&gt;     attr(out, \"weights\") &lt;- marginaleffects_wts_internal\n#&gt;     attr(out, \"comparison\") &lt;- comparison\n#&gt;     attr(out, \"transform\") &lt;- transform[[1]]\n#&gt;     attr(out, \"comparison_label\") &lt;- comparison_label\n#&gt;     attr(out, \"hypothesis_by\") &lt;- hyp_by\n#&gt;     attr(out, \"transform_label\") &lt;- transform_label\n#&gt;     attr(out, \"conf_level\") &lt;- conf_level\n#&gt;     attr(out, \"by\") &lt;- by\n#&gt;     if (inherits(model, \"brmsfit\")) {\n#&gt;         insight::check_if_installed(\"brms\")\n#&gt;         attr(out, \"nchains\") &lt;- brms::nchains(model)\n#&gt;     }\n#&gt;     class(out) &lt;- c(\"comparisons\", class(out))\n#&gt;     return(out)\n#&gt; }, newdata = list(c(5.1, 4.9, 4.7, 4.6, 5, 5.4, 4.6, 5, 4.4, \n#&gt; 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, \n#&gt; 4.6, 5.1, 4.8, 5, 5, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, \n#&gt; 5, 5.5, 4.9, 4.4, 5.1, 5, 4.5, 4.4, 5, 5.1, 4.8, 5.1, 4.6, 5.3, \n#&gt; 5, 7, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5, 5.9, 6, \n#&gt; 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, \n#&gt; 6.8, 6.7, 6, 5.7, 5.5, 5.5, 5.8, 6, 5.4, 6, 6.7, 6.3, 5.6, 5.5, \n#&gt; 5.5, 6.1, 5.8, 5, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, \n#&gt; 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, \n#&gt; 6.5, 7.7, 7.7, 6, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, \n#&gt; 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6, 6.9, 6.7, 6.9, \n#&gt; 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9), c(0.2, 0.2, 0.2, 0.2, \n#&gt; 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, \n#&gt; 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, \n#&gt; 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, \n#&gt; 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, \n#&gt; 1.6, 1, 1.3, 1.4, 1, 1.5, 1, 1.4, 1.3, 1.4, 1.5, 1, 1.5, 1.1, \n#&gt; 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1, 1.1, 1, 1.2, \n#&gt; 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1, 1.3, 1.2, \n#&gt; 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, \n#&gt; 2.5, 2, 1.9, 2.1, 2, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2, 2, \n#&gt; 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2, 2.2, 1.5, 1.4, 2.3, \n#&gt; 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2, 2.3, \n#&gt; 1.8), c(1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, \n#&gt; 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1, 1.7, \n#&gt; 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, \n#&gt; 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4, \n#&gt; 4.7, 4.5, 4.9, 4, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4, \n#&gt; 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4, 4.9, 4.7, 4.3, 4.4, \n#&gt; 4.8, 5, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, \n#&gt; 4, 4.4, 4.6, 4, 3.3, 4.2, 4.2, 4.2, 4.3, 3, 4.1, 6, 5.1, 5.9, \n#&gt; 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5, 5.1, 5.3, \n#&gt; 5.5, 6.7, 6.9, 5, 5.7, 4.9, 6.7, 4.9, 5.7, 6, 4.8, 4.9, 5.6, \n#&gt; 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, \n#&gt; 5.1, 5.9, 5.7, 5.2, 5, 5.2, 5.4, 5.1), c(1, 1, 1, 1, 1, 1, 1, \n#&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n#&gt; 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n#&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, \n#&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3), 1:150), vcov = c(0.0648561358708614, \n#&gt; -0.0776075989705507, -0.0339713425276863, 0.0855221415040715, \n#&gt; 0.088949330395953, 0.0170000905579961, -0.0776075989705507, 0.144241283857235, \n#&gt; 0.0351858298835599, -0.117761642231515, -0.122089476746883, -0.0254853395735601, \n#&gt; -0.0339713425276863, 0.0351858298835599, 0.0194905399614243, \n#&gt; -0.0459657347451442, -0.0472861136127865, -0.00869677529341257, \n#&gt; 0.0855221415040715, -0.117761642231515, -0.0459657347451442, \n#&gt; 0.138337982006763, 0.15072216454488, 0.0227990421926966, 0.088949330395953, \n#&gt; -0.122089476746883, -0.0472861136127865, 0.15072216454488, 0.179060079636581, \n#&gt; 0.0216170189525216, 0.0170000905579961, -0.0254853395735601, \n#&gt; -0.00869677529341257, 0.0227990421926966, 0.0216170189525216, \n#&gt; 0.00542666426714662), variables = \"Petal.Width\", type = \"response\", \n#&gt;     by = \"Species\", conf_level = 0.95, cross = FALSE, comparison = \"difference\", \n#&gt;     transform = NULL, wts = FALSE, hypothesis = NULL, eps = NULL)\n#&gt; \n#&gt; \n#&gt; Bootstrap Statistics :\n#&gt;        original       bias    std. error\n#&gt; t1* -0.11025325 -0.001978228   0.2637472\n#&gt; t2* -0.02006005 -0.002071668   0.1624522\n#&gt; t3*  0.02158742 -0.002114815   0.1870299\n\nOr we can extract the individual draws with the posterior_draws() function:\n\nposterior_draws(est) |&gt; head()\n#&gt;   drawid         draw        term contrast    Species    estimate predicted_lo predicted_hi predicted std.error   conf.low conf.high\n#&gt; 1      1 -0.189523311 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 0.2637472 -0.5727651 0.4276856\n#&gt; 2      1 -0.202933561 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 0.1624522 -0.3265992 0.3295583\n#&gt; 3      1 -0.209125856 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 0.1870299 -0.3380324 0.4124401\n#&gt; 4      2 -0.213874597 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 0.2637472 -0.5727651 0.4276856\n#&gt; 5      2 -0.001101391 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 0.1624522 -0.3265992 0.3295583\n#&gt; 6      2  0.097148424 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 0.1870299 -0.3380324 0.4124401\n\nposterior_draws(est, shape = \"DxP\") |&gt; dim()\n#&gt; [1] 500   3\n\n\nAs before, we can pass arguments to rsample::bootstraps() through inferences(). For example, for stratified resampling:\n\nest &lt;- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"rsample\", R = 100, strata = \"Species\")\nest\n#&gt; \n#&gt;     Species Estimate  2.5 % 97.5 %\n#&gt;  setosa      -0.1103 -0.613  0.295\n#&gt;  versicolor  -0.0201 -0.304  0.314\n#&gt;  virginica    0.0216 -0.345  0.401\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high\n\nattr(est, \"inferences\")\n#&gt; # Bootstrap sampling using stratification with apparent sample \n#&gt; # A tibble: 101 × 3\n#&gt;    splits           id           estimates       \n#&gt;    &lt;list&gt;           &lt;chr&gt;        &lt;list&gt;          \n#&gt;  1 &lt;split [150/51]&gt; Bootstrap001 &lt;tibble [3 × 7]&gt;\n#&gt;  2 &lt;split [150/58]&gt; Bootstrap002 &lt;tibble [3 × 7]&gt;\n#&gt;  3 &lt;split [150/57]&gt; Bootstrap003 &lt;tibble [3 × 7]&gt;\n#&gt;  4 &lt;split [150/56]&gt; Bootstrap004 &lt;tibble [3 × 7]&gt;\n#&gt;  5 &lt;split [150/55]&gt; Bootstrap005 &lt;tibble [3 × 7]&gt;\n#&gt;  6 &lt;split [150/56]&gt; Bootstrap006 &lt;tibble [3 × 7]&gt;\n#&gt;  7 &lt;split [150/55]&gt; Bootstrap007 &lt;tibble [3 × 7]&gt;\n#&gt;  8 &lt;split [150/51]&gt; Bootstrap008 &lt;tibble [3 × 7]&gt;\n#&gt;  9 &lt;split [150/57]&gt; Bootstrap009 &lt;tibble [3 × 7]&gt;\n#&gt; 10 &lt;split [150/58]&gt; Bootstrap010 &lt;tibble [3 × 7]&gt;\n#&gt; # ℹ 91 more rows\n\nOr we can extract the individual draws with the posterior_draws() function:\n\nposterior_draws(est) |&gt; head()\n#&gt;   drawid        draw        term contrast    Species    estimate predicted_lo predicted_hi predicted   conf.low conf.high\n#&gt; 1      1  0.07310920 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 -0.6131832 0.2945774\n#&gt; 2      1 -0.10375860 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 -0.3038898 0.3135018\n#&gt; 3      1 -0.18542879 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 -0.3450145 0.4009513\n#&gt; 4      2 -0.44785351 Petal.Width mean(+1)     setosa -0.11025325     4.957514     4.845263  4.957514 -0.6131832 0.2945774\n#&gt; 5      2  0.06769106 Petal.Width mean(+1) versicolor -0.02006005     6.327949     6.322072  6.327949 -0.3038898 0.3135018\n#&gt; 6      2  0.30574810 Petal.Width mean(+1)  virginica  0.02158742     7.015513     7.051542  7.015513 -0.3450145 0.4009513\n\nposterior_draws(est, shape = \"PxD\") |&gt; dim()\n#&gt; [1]   3 100\n\n\nThe fwb package implements fractional weighted bootstrap (aka Bayesian bootstrap):\n\n“fwb implements the fractional weighted bootstrap (FWB), also known as the Bayesian bootstrap, following the treatment by Xu et al. (2020). The FWB involves generating sets of weights from a uniform Dirichlet distribution to be used in estimating statistics of interest, which yields a posterior distribution that can be interpreted in the same way the traditional (resampling-based) bootstrap distribution can be.” -Noah Greifer\n\nThe inferences() function makes it easy to apply this inference strategy to marginaleffects objects:\n\navg_comparisons(mod) |&gt; inferences(method = \"fwb\")\n#&gt; \n#&gt;          Term                        Contrast Estimate Std. Error  2.5 % 97.5 %\n#&gt;  Petal.Length mean(+1)                          0.8929      0.081  0.732   1.05\n#&gt;  Petal.Width  mean(+1)                         -0.0362      0.160 -0.357   0.27\n#&gt;  Species      mean(versicolor) - mean(setosa)  -1.4629      0.335 -2.144  -0.76\n#&gt;  Species      mean(virginica) - mean(setosa)   -1.9842      0.397 -2.804  -1.18\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted, std.error, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bootstrap & Simulation"
    ]
  },
  {
    "objectID": "vignettes/bootstrap.html#simulation-based-inference",
    "href": "vignettes/bootstrap.html#simulation-based-inference",
    "title": "Bootstrap & Simulation",
    "section": "",
    "text": "This simulation-based strategy to compute confidence intervals was described in Krinsky & Robb (1986) and popularized by King, Tomz, Wittenberg (2000). We proceed in 3 steps:\n\nDraw R sets of simulated coefficients from a multivariate normal distribution with mean equal to the original model’s estimated coefficients and variance equal to the model’s variance-covariance matrix (classical, “HC3”, or other).\nUse the R sets of coefficients to compute R sets of estimands: predictions, comparisons, or slopes.\nTake quantiles of the resulting distribution of estimands to obtain a confidence interval and the standard deviation of simulated estimates to estimate the standard error.\n\nHere are a few examples:\n\nlibrary(ggplot2)\nlibrary(ggdist)\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"simulation\")\n#&gt; \n#&gt;     Species Estimate  2.5 % 97.5 %\n#&gt;  setosa      -0.1103 -0.677  0.469\n#&gt;  versicolor  -0.0201 -0.329  0.296\n#&gt;  virginica    0.0216 -0.316  0.343\n#&gt; \n#&gt; Term: Petal.Width\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, Species, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high\n\nSince simulation based inference generates R estimates of the quantities of interest, we can treat them similarly to draws from the posterior distribution in bayesian models. For example, we can extract draws using the posterior_draws() function, and plot their distributions using packages likeggplot2 and ggdist:\n\navg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |&gt;\n  inferences(method = \"simulation\") |&gt;\n  posterior_draws(\"rvar\") |&gt;\n  ggplot(aes(y = Species, xdist = rvar)) +\n  stat_slabinterval()",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bootstrap & Simulation"
    ]
  },
  {
    "objectID": "vignettes/bootstrap.html#multiple-imputation-and-missing-data",
    "href": "vignettes/bootstrap.html#multiple-imputation-and-missing-data",
    "title": "Bootstrap & Simulation",
    "section": "",
    "text": "The same workflow and the same inferences function can be used to estimate models with multiple imputation for missing data.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Bootstrap & Simulation"
    ]
  },
  {
    "objectID": "vignettes/gam.html",
    "href": "vignettes/gam.html",
    "title": "GAM",
    "section": "",
    "text": "We will estimate a GAM model using the mgcv package and the simdat dataset distributed with the itsadug package:\n\nlibrary(marginaleffects)\nlibrary(itsadug)\nlibrary(mgcv)\n\nsimdat$Subject &lt;- as.factor(simdat$Subject)\n\ndim(simdat)\n#&gt; [1] 75600     6\nhead(simdat)\n#&gt;    Group      Time Trial Condition Subject         Y\n#&gt; 1 Adults   0.00000   -10        -1     a01 0.7554469\n#&gt; 2 Adults  20.20202   -10        -1     a01 2.7834759\n#&gt; 3 Adults  40.40404   -10        -1     a01 1.9696963\n#&gt; 4 Adults  60.60606   -10        -1     a01 0.6814298\n#&gt; 5 Adults  80.80808   -10        -1     a01 1.6939195\n#&gt; 6 Adults 101.01010   -10        -1     a01 2.3651969\n\nFit a model with a random effect and group-time smooths:\n\nmodel &lt;- bam(Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\"),\n             data = simdat)\n\nsummary(model)\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\")\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)   \n#&gt; (Intercept)   2.0574     0.6903   2.980  0.00288 **\n#&gt; GroupAdults   3.1265     0.9763   3.202  0.00136 **\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;                         edf Ref.df    F p-value    \n#&gt; s(Time):GroupChildren  8.26  8.850 3649  &lt;2e-16 ***\n#&gt; s(Time):GroupAdults    8.66  8.966 6730  &lt;2e-16 ***\n#&gt; s(Subject)            33.94 34.000  569  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.609   Deviance explained =   61%\n#&gt; fREML = 2.3795e+05  Scale est. = 31.601    n = 75600\n\n\nCompute adjusted predictions for each observed combination of regressor in the dataset used to fit the model. This gives us a dataset with the same number of rows as the original data, but new columns with predicted values and uncertainty estimates:\n\npred &lt;- predictions(model)\ndim(pred)\n#&gt; [1] 75600    12\nhead(pred)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;    -1.874      0.199 -9.41   &lt;0.001 67.4 -2.2643 -1.4834\n#&gt;    -1.346      0.182 -7.41   &lt;0.001 42.8 -1.7025 -0.9901\n#&gt;    -0.819      0.167 -4.90   &lt;0.001 20.0 -1.1467 -0.4916\n#&gt;    -0.293      0.156 -1.88   0.0605  4.0 -0.5988  0.0129\n#&gt;     0.231      0.149  1.55   0.1204  3.1 -0.0606  0.5232\n#&gt;     0.753      0.146  5.17   &lt;0.001 22.0  0.4675  1.0379\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Y, Group, Time, Subject\n\nWe can easily plot adjusted predictions for different values of a regressor using the plot_predictions() function:\n\nplot_predictions(model, condition = \"Time\")\n\n\n\n\n\n\n\n\nMarginal effects are slopes of the prediction equation. They are an observation-level quantity. The slopes() function produces a dataset with the same number of rows as the original data, but with new columns for the slop and uncertainty estimates:\n\nmfx &lt;- slopes(model, variables = \"Time\")\nhead(mfx)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;    0.0261    0.00137 19.1   &lt;0.001 267.8 0.0234 0.0288\n#&gt;    0.0261    0.00136 19.2   &lt;0.001 270.3 0.0234 0.0288\n#&gt;    0.0261    0.00133 19.5   &lt;0.001 280.0 0.0235 0.0287\n#&gt;    0.0260    0.00128 20.3   &lt;0.001 301.1 0.0235 0.0285\n#&gt;    0.0259    0.00120 21.5   &lt;0.001 339.6 0.0235 0.0282\n#&gt;    0.0257    0.00109 23.5   &lt;0.001 404.2 0.0236 0.0279\n#&gt; \n#&gt; Term: Time\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, Y, Group, Time, Subject\n\nWe can plot marginal effects for different values of a regressor using the plot_slopes() function. This next plot shows the slope of the prediction equation, that is, the slope of the previous plot, at every value of the Time variable.\n\nplot_slopes(model, variables = \"Time\", condition = \"Time\")\n\n\n\n\n\n\n\nThe marginal effects in this plot can be interpreted as measuring the change in Y that is associated with a small increase in Time, for different baseline values of Time.\n\nThe predict() method of the mgcv package allows users to “exclude” some smoothing terms, using the exclude argument. You can pass the same argument to any function in the marginaleffects package:\n\npredictions(model, newdata = \"mean\", exclude = \"s(Subject)\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  Group Time Subject\n#&gt;      11.7      0.695 16.9   &lt;0.001 210.8  10.4   13.1 Adults 1000     a01\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Group, Time, Subject, Y\n\nSee the documentation in ?mgcv:::predict.bam for details.",
    "crumbs": [
      "Get started",
      "Case studies",
      "GAM"
    ]
  },
  {
    "objectID": "vignettes/gam.html#estimate-a-generalized-additive-model",
    "href": "vignettes/gam.html#estimate-a-generalized-additive-model",
    "title": "GAM",
    "section": "",
    "text": "We will estimate a GAM model using the mgcv package and the simdat dataset distributed with the itsadug package:\n\nlibrary(marginaleffects)\nlibrary(itsadug)\nlibrary(mgcv)\n\nsimdat$Subject &lt;- as.factor(simdat$Subject)\n\ndim(simdat)\n#&gt; [1] 75600     6\nhead(simdat)\n#&gt;    Group      Time Trial Condition Subject         Y\n#&gt; 1 Adults   0.00000   -10        -1     a01 0.7554469\n#&gt; 2 Adults  20.20202   -10        -1     a01 2.7834759\n#&gt; 3 Adults  40.40404   -10        -1     a01 1.9696963\n#&gt; 4 Adults  60.60606   -10        -1     a01 0.6814298\n#&gt; 5 Adults  80.80808   -10        -1     a01 1.6939195\n#&gt; 6 Adults 101.01010   -10        -1     a01 2.3651969\n\nFit a model with a random effect and group-time smooths:\n\nmodel &lt;- bam(Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\"),\n             data = simdat)\n\nsummary(model)\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\")\n#&gt; \n#&gt; Parametric coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)   \n#&gt; (Intercept)   2.0574     0.6903   2.980  0.00288 **\n#&gt; GroupAdults   3.1265     0.9763   3.202  0.00136 **\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Approximate significance of smooth terms:\n#&gt;                         edf Ref.df    F p-value    \n#&gt; s(Time):GroupChildren  8.26  8.850 3649  &lt;2e-16 ***\n#&gt; s(Time):GroupAdults    8.66  8.966 6730  &lt;2e-16 ***\n#&gt; s(Subject)            33.94 34.000  569  &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; R-sq.(adj) =  0.609   Deviance explained =   61%\n#&gt; fREML = 2.3795e+05  Scale est. = 31.601    n = 75600",
    "crumbs": [
      "Get started",
      "Case studies",
      "GAM"
    ]
  },
  {
    "objectID": "vignettes/gam.html#adjusted-predictions-predictions-and-plot_predictions",
    "href": "vignettes/gam.html#adjusted-predictions-predictions-and-plot_predictions",
    "title": "GAM",
    "section": "",
    "text": "Compute adjusted predictions for each observed combination of regressor in the dataset used to fit the model. This gives us a dataset with the same number of rows as the original data, but new columns with predicted values and uncertainty estimates:\n\npred &lt;- predictions(model)\ndim(pred)\n#&gt; [1] 75600    12\nhead(pred)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;    -1.874      0.199 -9.41   &lt;0.001 67.4 -2.2643 -1.4834\n#&gt;    -1.346      0.182 -7.41   &lt;0.001 42.8 -1.7025 -0.9901\n#&gt;    -0.819      0.167 -4.90   &lt;0.001 20.0 -1.1467 -0.4916\n#&gt;    -0.293      0.156 -1.88   0.0605  4.0 -0.5988  0.0129\n#&gt;     0.231      0.149  1.55   0.1204  3.1 -0.0606  0.5232\n#&gt;     0.753      0.146  5.17   &lt;0.001 22.0  0.4675  1.0379\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Y, Group, Time, Subject\n\nWe can easily plot adjusted predictions for different values of a regressor using the plot_predictions() function:\n\nplot_predictions(model, condition = \"Time\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "GAM"
    ]
  },
  {
    "objectID": "vignettes/gam.html#marginal-effects-slopes-and-plot_slopes",
    "href": "vignettes/gam.html#marginal-effects-slopes-and-plot_slopes",
    "title": "GAM",
    "section": "",
    "text": "Marginal effects are slopes of the prediction equation. They are an observation-level quantity. The slopes() function produces a dataset with the same number of rows as the original data, but with new columns for the slop and uncertainty estimates:\n\nmfx &lt;- slopes(model, variables = \"Time\")\nhead(mfx)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;    0.0261    0.00137 19.1   &lt;0.001 267.8 0.0234 0.0288\n#&gt;    0.0261    0.00136 19.2   &lt;0.001 270.3 0.0234 0.0288\n#&gt;    0.0261    0.00133 19.5   &lt;0.001 280.0 0.0235 0.0287\n#&gt;    0.0260    0.00128 20.3   &lt;0.001 301.1 0.0235 0.0285\n#&gt;    0.0259    0.00120 21.5   &lt;0.001 339.6 0.0235 0.0282\n#&gt;    0.0257    0.00109 23.5   &lt;0.001 404.2 0.0236 0.0279\n#&gt; \n#&gt; Term: Time\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, Y, Group, Time, Subject\n\nWe can plot marginal effects for different values of a regressor using the plot_slopes() function. This next plot shows the slope of the prediction equation, that is, the slope of the previous plot, at every value of the Time variable.\n\nplot_slopes(model, variables = \"Time\", condition = \"Time\")\n\n\n\n\n\n\n\nThe marginal effects in this plot can be interpreted as measuring the change in Y that is associated with a small increase in Time, for different baseline values of Time.",
    "crumbs": [
      "Get started",
      "Case studies",
      "GAM"
    ]
  },
  {
    "objectID": "vignettes/gam.html#excluding-terms",
    "href": "vignettes/gam.html#excluding-terms",
    "title": "GAM",
    "section": "",
    "text": "The predict() method of the mgcv package allows users to “exclude” some smoothing terms, using the exclude argument. You can pass the same argument to any function in the marginaleffects package:\n\npredictions(model, newdata = \"mean\", exclude = \"s(Subject)\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  Group Time Subject\n#&gt;      11.7      0.695 16.9   &lt;0.001 210.8  10.4   13.1 Adults 1000     a01\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Group, Time, Subject, Y\n\nSee the documentation in ?mgcv:::predict.bam for details.",
    "crumbs": [
      "Get started",
      "Case studies",
      "GAM"
    ]
  },
  {
    "objectID": "vignettes/meme.html",
    "href": "vignettes/meme.html",
    "title": "Meme gallery",
    "section": "",
    "text": "meme a\n\n\nmeme c\n\n\nmeme b\n\n\nmeme d\n\n\nmeme e",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Meme gallery"
    ]
  },
  {
    "objectID": "man/predictions.html",
    "href": "man/predictions.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Outcome predicted by a fitted model on a specified scale for a given combination of values of the predictor variables, such as their observed values, their means, or factor levels (a.k.a. \"reference grid\").\n\n\npredictions(): unit-level (conditional) estimates.\n\n\navg_predictions(): average (marginal) estimates.\n\n\nThe newdata argument and the datagrid() function can be used to control where statistics are evaluated in the predictor space: \"at observed values\", \"at the mean\", \"at representative values\", etc.\nSee the predictions vignette and package website for worked examples and case studies:\n\n\nhttps://marginaleffects.com/vignettes/predictions.html\n\n\nhttps://marginaleffects.com/\n\n\npredictions(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  vcov = TRUE,\n  conf_level = 0.95,\n  type = NULL,\n  by = FALSE,\n  byfun = NULL,\n  wts = FALSE,\n  transform = NULL,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  numderiv = \"fdforward\",\n  ...\n)\n\navg_predictions(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  vcov = TRUE,\n  conf_level = 0.95,\n  type = NULL,\n  by = TRUE,\n  byfun = NULL,\n  wts = FALSE,\n  transform = NULL,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\nGrid of predictor values at which we evaluate predictions.\n\n\nWarning: Please avoid modifying your dataset between fitting the model and calling a marginaleffects function. This can sometimes lead to unexpected results.\n\n\nNULL (default): Unit-level predictions for each observed value in the dataset (empirical distribution). The dataset is retrieved using insight::get_data(), which tries to extract data from the environment. This may produce unexpected results if the original data frame has been altered since fitting the model.\n\n\nstring:\n\n\n\"mean\": Predictions evaluated when each predictor is held at its mean or mode.\n\n\n\"median\": Predictions evaluated when each predictor is held at its median or mode.\n\n\n\"balanced\": Predictions evaluated on a balanced grid with every combination of categories and numeric variables held at their means.\n\n\n\"tukey\": Predictions evaluated at Tukey’s 5 numbers.\n\n\n\"grid\": Predictions evaluated on a grid of representative numbers (Tukey’s 5 numbers and unique values of categorical predictors).\n\n\n\n\ndatagrid() call to specify a custom grid of regressors. For example:\n\n\nnewdata = datagrid(cyl = c(4, 6)): cyl variable equal to 4 and 6 and other regressors fixed at their means or modes.\n\n\nSee the Examples section and the datagrid() documentation.\n\n\n\n\nsubset() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = subset(treatment == 1)\n\n\ndplyr::filter() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = filter(treatment == 1)\n\n\n\n\n\n\nvariables\n\n\nCounterfactual variables.\n\n\nOutput:\n\n\npredictions(): The entire dataset is replicated once for each unique combination of variables, and predictions are made.\n\n\navg_predictions(): The entire dataset is replicated, predictions are made, and they are marginalized by variables categories.\n\n\nWarning: This can be expensive in large datasets.\n\n\nWarning: Users who need \"conditional\" predictions should use the newdata argument instead of variables.\n\n\n\n\nInput:\n\n\nNULL: computes one prediction per row of newdata\n\n\nCharacter vector: the dataset is replicated once of every combination of unique values of the variables identified in variables.\n\n\nNamed list: names identify the subset of variables of interest and their values. For numeric variables, the variables argument supports functions and string shortcuts:\n\n\nA function which returns a numeric value\n\n\nNumeric vector: Contrast between the 2nd element and the 1st element of the x vector.\n\n\n\"iqr\": Contrast across the interquartile range of the regressor.\n\n\n\"sd\": Contrast across one standard deviation around the regressor mean.\n\n\n\"2sd\": Contrast across two standard deviations around the regressor mean.\n\n\n\"minmax\": Contrast between the maximum and the minimum values of the regressor.\n\n\n\"threenum\": mean and 1 standard deviation on both sides\n\n\n\"fivenum\": Tukey’s five numbers\n\n\n\n\n\n\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nbyfun\n\n\nA function such as mean() or sum() used to aggregate estimates within the subgroups defined by the by argument. NULL uses the mean() function. Must accept a numeric vector and return a single numeric value. This is sometimes used to take the sum or mean of predicted probabilities across outcome or predictor levels. See examples section.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\ntransform\n\n\nA function applied to unit-level adjusted predictions and confidence intervals just before the function returns results. For bayesian models, this function is applied to individual draws from the posterior distribution, before computing summaries.\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\np_adjust\n\n\nAdjust p-values for multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", or \"fdr\". See stats::p.adjust\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When df is Inf, the normal distribution is used. When df is finite, the t distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: slopes(model, df = insight::get_df(model))\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA data.frame with one row per observation and several columns:\n\n\nrowid: row number of the newdata data frame\n\n\ntype: prediction type, as defined by the type argument\n\n\ngroup: (optional) value of the grouped outcome (e.g., categorical outcome models)\n\n\nestimate: predicted outcome\n\n\nstd.error: standard errors computed using the delta method.\n\n\np.value: p value associated to the estimate column. The null is determined by the hypothesis argument (0 by default), and p values are computed before applying the transform argument. For models of class feglm, Gam, glm and negbin, p values are computed on the link scale by default unless the type argument is specified explicitly.\n\n\ns.value: Shannon information transforms of p values. How many consecutive \"heads\" tosses would provide the same amount of evidence (or \"surprise\") against the null hypothesis that the coin is fair? The purpose of S is to calibrate the analyst’s intuition about the strength of evidence encoded in p against a well-known physical phenomenon. See Greenland (2019) and Cole et al. (2020).\n\n\nconf.low: lower bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nconf.high: upper bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nSee ?print.marginaleffects for printing options.\n\n\n\navg_predictions(): Average predictions\n\n\nStandard errors for all quantities estimated by marginaleffects can be obtained via the delta method. This requires differentiating a function with respect to the coefficients in the model using a finite difference approach. In some models, the delta method standard errors can be sensitive to various aspects of the numeric differentiation strategy, including the step size. By default, the step size is set to 1e-8, or to 1e-4 times the smallest absolute model coefficient, whichever is largest.\nmarginaleffects can delegate numeric differentiation to the numDeriv package, which allows more flexibility. To do this, users can pass arguments to the numDeriv::jacobian function through a global option. For example:\n\n\noptions(marginaleffects_numDeriv = list(method = “simple”, method.args = list(eps = 1e-6)))\n\n\noptions(marginaleffects_numDeriv = list(method = “Richardson”, method.args = list(eps = 1e-5)))\n\n\noptions(marginaleffects_numDeriv = NULL)\n\n\nSee the \"Standard Errors and Confidence Intervals\" vignette on the marginaleffects website for more details on the computation of standard errors:\nhttps://marginaleffects.com/vignettes/uncertainty.html\nNote that the inferences() function can be used to compute uncertainty estimates using a bootstrap or simulation-based inference. See the vignette:\nhttps://marginaleffects.com/vignettes/bootstrap.html\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nBy default, credible intervals in bayesian models are built as equal-tailed intervals. This can be changed to a highest density interval by setting a global option:\noptions(“marginaleffects_posterior_interval” = “eti”)\noptions(“marginaleffects_posterior_interval” = “hdi”)\nBy default, the center of the posterior distribution in bayesian models is identified by the median. Users can use a different summary function by setting a global option:\noptions(“marginaleffects_posterior_center” = “mean”)\noptions(“marginaleffects_posterior_center” = “median”)\nWhen estimates are averaged using the by argument, the tidy() function, or the summary() function, the posterior distribution is marginalized twice over. First, we take the average across units but within each iteration of the MCMC chain, according to what the user requested in by argument or tidy()/summary() functions. Then, we identify the center of the resulting posterior using the function supplied to the “marginaleffects_posterior_center” option (the median by default).\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\nBehind the scenes, the arguments of marginaleffects functions are evaluated in this order:\n\n\nnewdata\n\n\nvariables\n\n\ncomparison and slopes\n\n\nby\n\n\nvcov\n\n\nhypothesis\n\n\ntransform\n\n\nThe slopes() and comparisons() functions can use parallelism to speed up computation. Operations are parallelized for the computation of standard errors, at the model coefficient level. There is always considerable overhead when using parallel computation, mainly involved in passing the whole dataset to the different processes. Thus, parallel computation is most likely to be useful when the model includes many parameters and the dataset is relatively small.\nWarning: In many cases, parallel processing will not be useful at all.\nTo activate parallel computation, users must load the future.apply package, call plan() function, and set a global option. For example:\n\nlibrary(future.apply)\nplan(\"multicore\", workers = 4)\noptions(marginaleffects_parallel = TRUE)\n\nslopes(model)\n\n\nTo disable parallelism in marginaleffects altogether, you can set a global option:\n\noptions(marginaleffects_parallel = FALSE)\n\n\n\nThe behavior of marginaleffects functions can be modified by setting global options.\nDisable some safety checks:\n\noptions(marginaleffects_safe = FALSE)`\n\n\nOmit some columns from the printed output:\n\noptions(marginaleffects_print_omit = c(\"p.value\", \"s.value\"))`\n\n\n\n\n\nGreenland S. 2019. \"Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values.\" The American Statistician. 73(S1): 106–114.\n\n\nCole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. \"Surprise!\" American Journal of Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136\n\n\n\nlibrary(\"marginaleffects\")\n\n\n\n# Adjusted Prediction for every row of the original dataset\nmod &lt;- lm(mpg ~ hp + factor(cyl), data = mtcars)\npred &lt;- predictions(mod)\nhead(pred)\n\n# Adjusted Predictions at User-Specified Values of the Regressors\npredictions(mod, newdata = datagrid(hp = c(100, 120), cyl = 4))\n\nm &lt;- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars)\npredictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median))\n\n# Average Adjusted Predictions (AAP)\nlibrary(dplyr)\nmod &lt;- lm(mpg ~ hp * am * vs, mtcars)\n\navg_predictions(mod)\n\npredictions(mod, by = \"am\")\n\n# Conditional Adjusted Predictions\nplot_predictions(mod, condition = \"hp\")\n\n# Counterfactual predictions with the `variables` argument\n# the `mtcars` dataset has 32 rows\n\nmod &lt;- lm(mpg ~ hp + am, data = mtcars)\np &lt;- predictions(mod)\nhead(p)\nnrow(p)\n\n# average counterfactual predictions\navg_predictions(mod, variables = \"am\")\n\n# counterfactual predictions obtained by replicating the entire for different\n# values of the predictors\np &lt;- predictions(mod, variables = list(hp = c(90, 110)))\nnrow(p)\n\n\n# hypothesis test: is the prediction in the 1st row equal to the prediction in the 2nd row\nmod &lt;- lm(mpg ~ wt + drat, data = mtcars)\n\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = \"b1 = b2\")\n\n# same hypothesis test using row indices\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = \"b1 - b2 = 0\")\n\n# same hypothesis test using numeric vector of weights\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = c(1, -1))\n\n# two custom contrasts using a matrix of weights\nlc &lt;- matrix(c(\n    1, -1,\n    2, 3),\n    ncol = 2)\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = lc)\n\n\n# `by` argument\nmod &lt;- lm(mpg ~ hp * am * vs, data = mtcars)\npredictions(mod, by = c(\"am\", \"vs\"))\n\nlibrary(nnet)\nnom &lt;- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)\n\n# first 5 raw predictions\npredictions(nom, type = \"probs\") |&gt; head()\n\n# average predictions\navg_predictions(nom, type = \"probs\", by = \"group\")\n\nby &lt;- data.frame(\n    group = c(\"3\", \"4\", \"5\"),\n    by = c(\"3,4\", \"3,4\", \"5\"))\n\npredictions(nom, type = \"probs\", by = by)\n\n# sum of predicted probabilities for combined response levels\nmod &lt;- multinom(factor(cyl) ~ mpg + am, data = mtcars, trace = FALSE)\nby &lt;- data.frame(\n    by = c(\"4,6\", \"4,6\", \"8\"),\n    group = as.character(c(4, 6, 8)))\npredictions(mod, newdata = \"mean\", byfun = sum, by = by)",
    "crumbs": [
      "Get started",
      "Functions",
      "`predictions`"
    ]
  },
  {
    "objectID": "man/predictions.html#predictions",
    "href": "man/predictions.html#predictions",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Outcome predicted by a fitted model on a specified scale for a given combination of values of the predictor variables, such as their observed values, their means, or factor levels (a.k.a. \"reference grid\").\n\n\npredictions(): unit-level (conditional) estimates.\n\n\navg_predictions(): average (marginal) estimates.\n\n\nThe newdata argument and the datagrid() function can be used to control where statistics are evaluated in the predictor space: \"at observed values\", \"at the mean\", \"at representative values\", etc.\nSee the predictions vignette and package website for worked examples and case studies:\n\n\nhttps://marginaleffects.com/vignettes/predictions.html\n\n\nhttps://marginaleffects.com/\n\n\npredictions(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  vcov = TRUE,\n  conf_level = 0.95,\n  type = NULL,\n  by = FALSE,\n  byfun = NULL,\n  wts = FALSE,\n  transform = NULL,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  numderiv = \"fdforward\",\n  ...\n)\n\navg_predictions(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  vcov = TRUE,\n  conf_level = 0.95,\n  type = NULL,\n  by = TRUE,\n  byfun = NULL,\n  wts = FALSE,\n  transform = NULL,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\nGrid of predictor values at which we evaluate predictions.\n\n\nWarning: Please avoid modifying your dataset between fitting the model and calling a marginaleffects function. This can sometimes lead to unexpected results.\n\n\nNULL (default): Unit-level predictions for each observed value in the dataset (empirical distribution). The dataset is retrieved using insight::get_data(), which tries to extract data from the environment. This may produce unexpected results if the original data frame has been altered since fitting the model.\n\n\nstring:\n\n\n\"mean\": Predictions evaluated when each predictor is held at its mean or mode.\n\n\n\"median\": Predictions evaluated when each predictor is held at its median or mode.\n\n\n\"balanced\": Predictions evaluated on a balanced grid with every combination of categories and numeric variables held at their means.\n\n\n\"tukey\": Predictions evaluated at Tukey’s 5 numbers.\n\n\n\"grid\": Predictions evaluated on a grid of representative numbers (Tukey’s 5 numbers and unique values of categorical predictors).\n\n\n\n\ndatagrid() call to specify a custom grid of regressors. For example:\n\n\nnewdata = datagrid(cyl = c(4, 6)): cyl variable equal to 4 and 6 and other regressors fixed at their means or modes.\n\n\nSee the Examples section and the datagrid() documentation.\n\n\n\n\nsubset() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = subset(treatment == 1)\n\n\ndplyr::filter() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = filter(treatment == 1)\n\n\n\n\n\n\nvariables\n\n\nCounterfactual variables.\n\n\nOutput:\n\n\npredictions(): The entire dataset is replicated once for each unique combination of variables, and predictions are made.\n\n\navg_predictions(): The entire dataset is replicated, predictions are made, and they are marginalized by variables categories.\n\n\nWarning: This can be expensive in large datasets.\n\n\nWarning: Users who need \"conditional\" predictions should use the newdata argument instead of variables.\n\n\n\n\nInput:\n\n\nNULL: computes one prediction per row of newdata\n\n\nCharacter vector: the dataset is replicated once of every combination of unique values of the variables identified in variables.\n\n\nNamed list: names identify the subset of variables of interest and their values. For numeric variables, the variables argument supports functions and string shortcuts:\n\n\nA function which returns a numeric value\n\n\nNumeric vector: Contrast between the 2nd element and the 1st element of the x vector.\n\n\n\"iqr\": Contrast across the interquartile range of the regressor.\n\n\n\"sd\": Contrast across one standard deviation around the regressor mean.\n\n\n\"2sd\": Contrast across two standard deviations around the regressor mean.\n\n\n\"minmax\": Contrast between the maximum and the minimum values of the regressor.\n\n\n\"threenum\": mean and 1 standard deviation on both sides\n\n\n\"fivenum\": Tukey’s five numbers\n\n\n\n\n\n\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nbyfun\n\n\nA function such as mean() or sum() used to aggregate estimates within the subgroups defined by the by argument. NULL uses the mean() function. Must accept a numeric vector and return a single numeric value. This is sometimes used to take the sum or mean of predicted probabilities across outcome or predictor levels. See examples section.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\ntransform\n\n\nA function applied to unit-level adjusted predictions and confidence intervals just before the function returns results. For bayesian models, this function is applied to individual draws from the posterior distribution, before computing summaries.\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\np_adjust\n\n\nAdjust p-values for multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", or \"fdr\". See stats::p.adjust\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When df is Inf, the normal distribution is used. When df is finite, the t distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: slopes(model, df = insight::get_df(model))\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA data.frame with one row per observation and several columns:\n\n\nrowid: row number of the newdata data frame\n\n\ntype: prediction type, as defined by the type argument\n\n\ngroup: (optional) value of the grouped outcome (e.g., categorical outcome models)\n\n\nestimate: predicted outcome\n\n\nstd.error: standard errors computed using the delta method.\n\n\np.value: p value associated to the estimate column. The null is determined by the hypothesis argument (0 by default), and p values are computed before applying the transform argument. For models of class feglm, Gam, glm and negbin, p values are computed on the link scale by default unless the type argument is specified explicitly.\n\n\ns.value: Shannon information transforms of p values. How many consecutive \"heads\" tosses would provide the same amount of evidence (or \"surprise\") against the null hypothesis that the coin is fair? The purpose of S is to calibrate the analyst’s intuition about the strength of evidence encoded in p against a well-known physical phenomenon. See Greenland (2019) and Cole et al. (2020).\n\n\nconf.low: lower bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nconf.high: upper bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nSee ?print.marginaleffects for printing options.\n\n\n\navg_predictions(): Average predictions\n\n\nStandard errors for all quantities estimated by marginaleffects can be obtained via the delta method. This requires differentiating a function with respect to the coefficients in the model using a finite difference approach. In some models, the delta method standard errors can be sensitive to various aspects of the numeric differentiation strategy, including the step size. By default, the step size is set to 1e-8, or to 1e-4 times the smallest absolute model coefficient, whichever is largest.\nmarginaleffects can delegate numeric differentiation to the numDeriv package, which allows more flexibility. To do this, users can pass arguments to the numDeriv::jacobian function through a global option. For example:\n\n\noptions(marginaleffects_numDeriv = list(method = “simple”, method.args = list(eps = 1e-6)))\n\n\noptions(marginaleffects_numDeriv = list(method = “Richardson”, method.args = list(eps = 1e-5)))\n\n\noptions(marginaleffects_numDeriv = NULL)\n\n\nSee the \"Standard Errors and Confidence Intervals\" vignette on the marginaleffects website for more details on the computation of standard errors:\nhttps://marginaleffects.com/vignettes/uncertainty.html\nNote that the inferences() function can be used to compute uncertainty estimates using a bootstrap or simulation-based inference. See the vignette:\nhttps://marginaleffects.com/vignettes/bootstrap.html\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nBy default, credible intervals in bayesian models are built as equal-tailed intervals. This can be changed to a highest density interval by setting a global option:\noptions(“marginaleffects_posterior_interval” = “eti”)\noptions(“marginaleffects_posterior_interval” = “hdi”)\nBy default, the center of the posterior distribution in bayesian models is identified by the median. Users can use a different summary function by setting a global option:\noptions(“marginaleffects_posterior_center” = “mean”)\noptions(“marginaleffects_posterior_center” = “median”)\nWhen estimates are averaged using the by argument, the tidy() function, or the summary() function, the posterior distribution is marginalized twice over. First, we take the average across units but within each iteration of the MCMC chain, according to what the user requested in by argument or tidy()/summary() functions. Then, we identify the center of the resulting posterior using the function supplied to the “marginaleffects_posterior_center” option (the median by default).\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\nBehind the scenes, the arguments of marginaleffects functions are evaluated in this order:\n\n\nnewdata\n\n\nvariables\n\n\ncomparison and slopes\n\n\nby\n\n\nvcov\n\n\nhypothesis\n\n\ntransform\n\n\nThe slopes() and comparisons() functions can use parallelism to speed up computation. Operations are parallelized for the computation of standard errors, at the model coefficient level. There is always considerable overhead when using parallel computation, mainly involved in passing the whole dataset to the different processes. Thus, parallel computation is most likely to be useful when the model includes many parameters and the dataset is relatively small.\nWarning: In many cases, parallel processing will not be useful at all.\nTo activate parallel computation, users must load the future.apply package, call plan() function, and set a global option. For example:\n\nlibrary(future.apply)\nplan(\"multicore\", workers = 4)\noptions(marginaleffects_parallel = TRUE)\n\nslopes(model)\n\n\nTo disable parallelism in marginaleffects altogether, you can set a global option:\n\noptions(marginaleffects_parallel = FALSE)\n\n\n\nThe behavior of marginaleffects functions can be modified by setting global options.\nDisable some safety checks:\n\noptions(marginaleffects_safe = FALSE)`\n\n\nOmit some columns from the printed output:\n\noptions(marginaleffects_print_omit = c(\"p.value\", \"s.value\"))`\n\n\n\n\n\nGreenland S. 2019. \"Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values.\" The American Statistician. 73(S1): 106–114.\n\n\nCole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. \"Surprise!\" American Journal of Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136\n\n\n\nlibrary(\"marginaleffects\")\n\n\n\n# Adjusted Prediction for every row of the original dataset\nmod &lt;- lm(mpg ~ hp + factor(cyl), data = mtcars)\npred &lt;- predictions(mod)\nhead(pred)\n\n# Adjusted Predictions at User-Specified Values of the Regressors\npredictions(mod, newdata = datagrid(hp = c(100, 120), cyl = 4))\n\nm &lt;- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars)\npredictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median))\n\n# Average Adjusted Predictions (AAP)\nlibrary(dplyr)\nmod &lt;- lm(mpg ~ hp * am * vs, mtcars)\n\navg_predictions(mod)\n\npredictions(mod, by = \"am\")\n\n# Conditional Adjusted Predictions\nplot_predictions(mod, condition = \"hp\")\n\n# Counterfactual predictions with the `variables` argument\n# the `mtcars` dataset has 32 rows\n\nmod &lt;- lm(mpg ~ hp + am, data = mtcars)\np &lt;- predictions(mod)\nhead(p)\nnrow(p)\n\n# average counterfactual predictions\navg_predictions(mod, variables = \"am\")\n\n# counterfactual predictions obtained by replicating the entire for different\n# values of the predictors\np &lt;- predictions(mod, variables = list(hp = c(90, 110)))\nnrow(p)\n\n\n# hypothesis test: is the prediction in the 1st row equal to the prediction in the 2nd row\nmod &lt;- lm(mpg ~ wt + drat, data = mtcars)\n\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = \"b1 = b2\")\n\n# same hypothesis test using row indices\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = \"b1 - b2 = 0\")\n\n# same hypothesis test using numeric vector of weights\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = c(1, -1))\n\n# two custom contrasts using a matrix of weights\nlc &lt;- matrix(c(\n    1, -1,\n    2, 3),\n    ncol = 2)\npredictions(\n    mod,\n    newdata = datagrid(wt = 2:3),\n    hypothesis = lc)\n\n\n# `by` argument\nmod &lt;- lm(mpg ~ hp * am * vs, data = mtcars)\npredictions(mod, by = c(\"am\", \"vs\"))\n\nlibrary(nnet)\nnom &lt;- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)\n\n# first 5 raw predictions\npredictions(nom, type = \"probs\") |&gt; head()\n\n# average predictions\navg_predictions(nom, type = \"probs\", by = \"group\")\n\nby &lt;- data.frame(\n    group = c(\"3\", \"4\", \"5\"),\n    by = c(\"3,4\", \"3,4\", \"5\"))\n\npredictions(nom, type = \"probs\", by = by)\n\n# sum of predicted probabilities for combined response levels\nmod &lt;- multinom(factor(cyl) ~ mpg + am, data = mtcars, trace = FALSE)\nby &lt;- data.frame(\n    by = c(\"4,6\", \"4,6\", \"8\"),\n    group = as.character(c(4, 6, 8)))\npredictions(mod, newdata = \"mean\", byfun = sum, by = by)",
    "crumbs": [
      "Get started",
      "Functions",
      "`predictions`"
    ]
  },
  {
    "objectID": "man/datagrid.html",
    "href": "man/datagrid.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Generate a data grid of user-specified values for use in the newdata argument of the predictions(), comparisons(), and slopes() functions. This is useful to define where in the predictor space we want to evaluate the quantities of interest. Ex: the predicted outcome or slope for a 37 year old college graduate.\n\ndatagrid(\n  ...,\n  model = NULL,\n  newdata = NULL,\n  by = NULL,\n  grid_type = \"mean_or_mode\",\n  response = FALSE,\n  FUN_character = NULL,\n  FUN_factor = NULL,\n  FUN_logical = NULL,\n  FUN_numeric = NULL,\n  FUN_integer = NULL,\n  FUN_binary = NULL,\n  FUN_other = NULL\n)\n\n\n\n\n\n…\n\n\nnamed arguments with vectors of values or functions for user-specified variables.\n\n\nFunctions are applied to the variable in the model dataset or newdata, and must return a vector of the appropriate type.\n\n\nCharacter vectors are automatically transformed to factors if necessary. +The output will include all combinations of these variables (see Examples below.)\n\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\ndata.frame (one and only one of the model and newdata arguments can be used.)\n\n\n\n\nby\n\n\ncharacter vector with grouping variables within which FUN_* functions are applied to create \"sub-grids\" with unspecified variables.\n\n\n\n\ngrid_type\n\n\ncharacter. Determines the functions to apply to each variable. The defaults can be overridden by defining individual variables explicitly in …, or by supplying a function to one of the FUN_* arguments.\n\n\n\"mean_or_mode\": Character, factor, logical, and binary variables are set to their modes. Numeric, integer, and other variables are set to their means.\n\n\n\"balanced\": Each unique level of character, factor, logical, and binary variables are preserved. Numeric, integer, and other variables are set to their means. Warning: When there are many variables and many levels per variable, a balanced grid can be very large. In those cases, it is better to use grid_type=“mean_or_mode” and to specify the unique levels of a subset of named variables explicitly.\n\n\n\"counterfactual\": the entire dataset is duplicated for each combination of the variable values specified in …. Variables not explicitly supplied to datagrid() are set to their observed values in the original dataset.\n\n\n\n\n\n\nresponse\n\n\nLogical should the response variable be included in the grid, even if it is not specified explicitly.\n\n\n\n\nFUN_character\n\n\nthe function to be applied to character variables.\n\n\n\n\nFUN_factor\n\n\nthe function to be applied to factor variables. This only applies if the variable in the original data is a factor. For variables converted to factor in a model-fitting formula, for example, FUN_character is used.\n\n\n\n\nFUN_logical\n\n\nthe function to be applied to logical variables.\n\n\n\n\nFUN_numeric\n\n\nthe function to be applied to numeric variables.\n\n\n\n\nFUN_integer\n\n\nthe function to be applied to integer variables.\n\n\n\n\nFUN_binary\n\n\nthe function to be applied to binary variables.\n\n\n\n\nFUN_other\n\n\nthe function to be applied to other variable types.\n\n\n\nIf datagrid is used in a predictions(), comparisons(), or slopes() call as the newdata argument, the model is automatically inserted in the model argument of datagrid() call, and users do not need to specify either the model or newdata arguments. The same behavior will occur when the value supplied to newdata= is a function call which starts with \"datagrid\". This is intended to allow users to create convenience shortcuts like:\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ am + vs + factor(cyl) + hp, mtcars)\ndatagrid_bal &lt;- function(...) datagrid(..., grid_type = \"balanced\")\npredictions(model, newdata = datagrid_bal(cyl = 4))\n\nIf users supply a model, the data used to fit that model is retrieved using the insight::get_data function.\n\nA data.frame in which each row corresponds to one combination of the named predictors supplied by the user via the … dots. Variables which are not explicitly defined are held at their mean or mode.\n\n\nlibrary(\"marginaleffects\")\n\n# The output only has 2 rows, and all the variables except `hp` are at their\n# mean or mode.\ndatagrid(newdata = mtcars, hp = c(100, 110))\n\n       mpg    cyl     disp     drat      wt     qsec vs am   gear   carb  hp\n1 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 100\n2 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 110\n  rowid\n1     1\n2     2\n\n# We get the same result by feeding a model instead of a data.frame\nmod &lt;- lm(mpg ~ hp, mtcars)\ndatagrid(model = mod, hp = c(100, 110))\n\n   hp rowid\n1 100     1\n2 110     2\n\n# Use in `marginaleffects` to compute \"Typical Marginal Effects\". When used\n# in `slopes()` or `predictions()` we do not need to specify the\n#`model` or `newdata` arguments.\nslopes(mod, newdata = datagrid(hp = c(100, 110)))\n\n\n Term  hp Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n   hp 100  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 110  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n\nType:  response \nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, predicted_lo, predicted_hi, predicted, mpg \n\n# datagrid accepts functions\ndatagrid(hp = range, cyl = unique, newdata = mtcars)\n\n       mpg     disp     drat      wt     qsec vs am   gear   carb  hp cyl rowid\n1 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125  52   6     1\n2 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125  52   4     2\n3 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125  52   8     3\n4 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 335   6     4\n5 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 335   4     5\n6 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 335   8     6\n\ncomparisons(mod, newdata = datagrid(hp = fivenum))\n\n\n Term  hp Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n   hp  52  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp  96  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 123  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 180  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 335  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n\nType:  response \nComparison: +1\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, predicted_lo, predicted_hi, predicted, mpg \n\n# The full dataset is duplicated with each observation given counterfactual\n# values of 100 and 110 for the `hp` variable. The original `mtcars` includes\n# 32 rows, so the resulting dataset includes 64 rows.\ndg &lt;- datagrid(newdata = mtcars, hp = c(100, 110), grid_type = \"counterfactual\")\nnrow(dg)\n\n[1] 64\n\n# We get the same result by feeding a model instead of a data.frame\nmod &lt;- lm(mpg ~ hp, mtcars)\ndg &lt;- datagrid(model = mod, hp = c(100, 110), grid_type = \"counterfactual\")\nnrow(dg)\n\n[1] 64",
    "crumbs": [
      "Get started",
      "Functions",
      "`datagrid`"
    ]
  },
  {
    "objectID": "man/datagrid.html#data-grids",
    "href": "man/datagrid.html#data-grids",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Generate a data grid of user-specified values for use in the newdata argument of the predictions(), comparisons(), and slopes() functions. This is useful to define where in the predictor space we want to evaluate the quantities of interest. Ex: the predicted outcome or slope for a 37 year old college graduate.\n\ndatagrid(\n  ...,\n  model = NULL,\n  newdata = NULL,\n  by = NULL,\n  grid_type = \"mean_or_mode\",\n  response = FALSE,\n  FUN_character = NULL,\n  FUN_factor = NULL,\n  FUN_logical = NULL,\n  FUN_numeric = NULL,\n  FUN_integer = NULL,\n  FUN_binary = NULL,\n  FUN_other = NULL\n)\n\n\n\n\n\n…\n\n\nnamed arguments with vectors of values or functions for user-specified variables.\n\n\nFunctions are applied to the variable in the model dataset or newdata, and must return a vector of the appropriate type.\n\n\nCharacter vectors are automatically transformed to factors if necessary. +The output will include all combinations of these variables (see Examples below.)\n\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\ndata.frame (one and only one of the model and newdata arguments can be used.)\n\n\n\n\nby\n\n\ncharacter vector with grouping variables within which FUN_* functions are applied to create \"sub-grids\" with unspecified variables.\n\n\n\n\ngrid_type\n\n\ncharacter. Determines the functions to apply to each variable. The defaults can be overridden by defining individual variables explicitly in …, or by supplying a function to one of the FUN_* arguments.\n\n\n\"mean_or_mode\": Character, factor, logical, and binary variables are set to their modes. Numeric, integer, and other variables are set to their means.\n\n\n\"balanced\": Each unique level of character, factor, logical, and binary variables are preserved. Numeric, integer, and other variables are set to their means. Warning: When there are many variables and many levels per variable, a balanced grid can be very large. In those cases, it is better to use grid_type=“mean_or_mode” and to specify the unique levels of a subset of named variables explicitly.\n\n\n\"counterfactual\": the entire dataset is duplicated for each combination of the variable values specified in …. Variables not explicitly supplied to datagrid() are set to their observed values in the original dataset.\n\n\n\n\n\n\nresponse\n\n\nLogical should the response variable be included in the grid, even if it is not specified explicitly.\n\n\n\n\nFUN_character\n\n\nthe function to be applied to character variables.\n\n\n\n\nFUN_factor\n\n\nthe function to be applied to factor variables. This only applies if the variable in the original data is a factor. For variables converted to factor in a model-fitting formula, for example, FUN_character is used.\n\n\n\n\nFUN_logical\n\n\nthe function to be applied to logical variables.\n\n\n\n\nFUN_numeric\n\n\nthe function to be applied to numeric variables.\n\n\n\n\nFUN_integer\n\n\nthe function to be applied to integer variables.\n\n\n\n\nFUN_binary\n\n\nthe function to be applied to binary variables.\n\n\n\n\nFUN_other\n\n\nthe function to be applied to other variable types.\n\n\n\nIf datagrid is used in a predictions(), comparisons(), or slopes() call as the newdata argument, the model is automatically inserted in the model argument of datagrid() call, and users do not need to specify either the model or newdata arguments. The same behavior will occur when the value supplied to newdata= is a function call which starts with \"datagrid\". This is intended to allow users to create convenience shortcuts like:\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ am + vs + factor(cyl) + hp, mtcars)\ndatagrid_bal &lt;- function(...) datagrid(..., grid_type = \"balanced\")\npredictions(model, newdata = datagrid_bal(cyl = 4))\n\nIf users supply a model, the data used to fit that model is retrieved using the insight::get_data function.\n\nA data.frame in which each row corresponds to one combination of the named predictors supplied by the user via the … dots. Variables which are not explicitly defined are held at their mean or mode.\n\n\nlibrary(\"marginaleffects\")\n\n# The output only has 2 rows, and all the variables except `hp` are at their\n# mean or mode.\ndatagrid(newdata = mtcars, hp = c(100, 110))\n\n       mpg    cyl     disp     drat      wt     qsec vs am   gear   carb  hp\n1 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 100\n2 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 110\n  rowid\n1     1\n2     2\n\n# We get the same result by feeding a model instead of a data.frame\nmod &lt;- lm(mpg ~ hp, mtcars)\ndatagrid(model = mod, hp = c(100, 110))\n\n   hp rowid\n1 100     1\n2 110     2\n\n# Use in `marginaleffects` to compute \"Typical Marginal Effects\". When used\n# in `slopes()` or `predictions()` we do not need to specify the\n#`model` or `newdata` arguments.\nslopes(mod, newdata = datagrid(hp = c(100, 110)))\n\n\n Term  hp Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n   hp 100  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 110  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n\nType:  response \nColumns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, predicted_lo, predicted_hi, predicted, mpg \n\n# datagrid accepts functions\ndatagrid(hp = range, cyl = unique, newdata = mtcars)\n\n       mpg     disp     drat      wt     qsec vs am   gear   carb  hp cyl rowid\n1 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125  52   6     1\n2 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125  52   4     2\n3 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125  52   8     3\n4 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 335   6     4\n5 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 335   4     5\n6 20.09062 230.7219 3.596563 3.21725 17.84875  0  0 3.6875 2.8125 335   8     6\n\ncomparisons(mod, newdata = datagrid(hp = fivenum))\n\n\n Term  hp Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n   hp  52  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp  96  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 123  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 180  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n   hp 335  -0.0682     0.0101 -6.74   &lt;0.001 35.9 -0.0881 -0.0484\n\nType:  response \nComparison: +1\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, predicted_lo, predicted_hi, predicted, mpg \n\n# The full dataset is duplicated with each observation given counterfactual\n# values of 100 and 110 for the `hp` variable. The original `mtcars` includes\n# 32 rows, so the resulting dataset includes 64 rows.\ndg &lt;- datagrid(newdata = mtcars, hp = c(100, 110), grid_type = \"counterfactual\")\nnrow(dg)\n\n[1] 64\n\n# We get the same result by feeding a model instead of a data.frame\nmod &lt;- lm(mpg ~ hp, mtcars)\ndg &lt;- datagrid(model = mod, hp = c(100, 110), grid_type = \"counterfactual\")\nnrow(dg)\n\n[1] 64",
    "crumbs": [
      "Get started",
      "Functions",
      "`datagrid`"
    ]
  },
  {
    "objectID": "man/posterior_draws.html",
    "href": "man/posterior_draws.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects\n\n\n\nposterior_draws(x, shape = \"long\")\n\n\n\n\n\n\n\nx\n\n\nAn object produced by a marginaleffects package function, such as predictions(), avg_slopes(), hypotheses(), etc.\n\n\n\n\nshape\n\n\nstring indicating the shape of the output format:\n\n\n\"long\": long format data frame\n\n\n\"DxP\": Matrix with draws as rows and parameters as columns\n\n\n\"PxD\": Matrix with draws as rows and parameters as columns\n\n\n\"rvar\": Random variable datatype (see posterior package documentation).\n\n\n\n\n\n\n\n\nA data.frame with drawid and draw columns.",
    "crumbs": [
      "Get started",
      "Functions",
      "`posterior_draws`"
    ]
  },
  {
    "objectID": "man/posterior_draws.html#extract-posterior-draws-or-bootstrap-resamples-from-marginaleffects-objects",
    "href": "man/posterior_draws.html#extract-posterior-draws-or-bootstrap-resamples-from-marginaleffects-objects",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects\n\n\n\nposterior_draws(x, shape = \"long\")\n\n\n\n\n\n\n\nx\n\n\nAn object produced by a marginaleffects package function, such as predictions(), avg_slopes(), hypotheses(), etc.\n\n\n\n\nshape\n\n\nstring indicating the shape of the output format:\n\n\n\"long\": long format data frame\n\n\n\"DxP\": Matrix with draws as rows and parameters as columns\n\n\n\"PxD\": Matrix with draws as rows and parameters as columns\n\n\n\"rvar\": Random variable datatype (see posterior package documentation).\n\n\n\n\n\n\n\n\nA data.frame with drawid and draw columns.",
    "crumbs": [
      "Get started",
      "Functions",
      "`posterior_draws`"
    ]
  },
  {
    "objectID": "man/plot_comparisons.html",
    "href": "man/plot_comparisons.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Plot comparisons on the y-axis against values of one or more predictors (x-axis, colors/shapes, and facets).\nThe by argument is used to plot marginal comparisons, that is, comparisons made on the original data, but averaged by subgroups. This is analogous to using the by argument in the comparisons() function.\nThe condition argument is used to plot conditional comparisons, that is, comparisons made on a user-specified grid. This is analogous to using the newdata argument and datagrid() function in a comparisons() call. All variables whose values are not specified explicitly are treated as usual by datagrid(), that is, they are held at their mean or mode (or rounded mean for integers). This includes grouping variables in mixed-effects models, so analysts who fit such models may want to specify the groups of interest using the condition argument, or supply model-specific arguments to compute population-level estimates. See details below.\nSee the \"Plots\" vignette and website for tutorials and information on how to customize plots:\n\n\nhttps://marginaleffects.com/vignettes/plot.html\n\n\nhttps://marginaleffects.com\n\n\nplot_comparisons(\n  model,\n  variables = NULL,\n  condition = NULL,\n  by = NULL,\n  newdata = NULL,\n  type = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  wts = FALSE,\n  comparison = \"difference\",\n  transform = NULL,\n  rug = FALSE,\n  gray = FALSE,\n  draw = TRUE,\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nvariables\n\n\nName of the variable whose contrast we want to plot on the y-axis.\n\n\n\n\ncondition\n\n\nConditional slopes\n\n\nCharacter vector (max length 4): Names of the predictors to display.\n\n\nNamed list (max length 4): List names correspond to predictors. List elements can be:\n\n\nNumeric vector\n\n\nFunction which returns a numeric vector or a set of unique categorical values\n\n\nShortcut strings for common reference values: \"minmax\", \"quartile\", \"threenum\"\n\n\n\n\n1: x-axis. 2: color/shape. 3: facet (wrap if no fourth variable, otherwise cols of grid). 4: facet (rows of grid).\n\n\nNumeric variables in positions 2 and 3 are summarized by Tukey’s five numbers ?stats::fivenum.\n\n\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nnewdata\n\n\nWhen newdata is NULL, the grid is determined by the condition argument. When newdata is not NULL, the argument behaves in the same way as in the comparisons() function.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\ncomparison\n\n\nHow should pairs of predictions be compared? Difference, ratio, odds ratio, or user-defined functions.\n\n\nstring: shortcuts to common contrast functions.\n\n\nSupported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, lift, liftavg, liftavgwts, expdydx, expdydxavg, expdydxavgwts\n\n\nSee the Comparisons section below for definitions of each transformation.\n\n\n\n\nfunction: accept two equal-length numeric vectors of adjusted predictions (hi and lo) and returns a vector of contrasts of the same length, or a unique numeric value.\n\n\nSee the Transformations section below for examples of valid functions.\n\n\n\n\n\n\n\n\ntransform\n\n\nstring or function. Transformation applied to unit-level estimates and confidence intervals just before the function returns results. Functions must accept a vector and return a vector of the same length. Support string shortcuts: \"exp\", \"ln\"\n\n\n\n\nrug\n\n\nTRUE displays tick marks on the axes to mark the distribution of raw data.\n\n\n\n\ngray\n\n\nFALSE grayscale or color plot\n\n\n\n\ndraw\n\n\nTRUE returns a ggplot2 plot. FALSE returns a data.frame of the underlying data.\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA ggplot2 object\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\n\nlibrary(\"marginaleffects\")\n\nmod &lt;- lm(mpg ~ hp * drat * factor(am), data = mtcars)\n\nplot_comparisons(mod, variables = \"hp\", condition = \"drat\")\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"hp\", condition = c(\"drat\", \"am\"))\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"hp\", condition = list(\"am\", \"drat\" = 3:5))\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = range))\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))",
    "crumbs": [
      "Get started",
      "Functions",
      "`plot_comparisons`"
    ]
  },
  {
    "objectID": "man/plot_comparisons.html#plot-conditional-or-marginal-comparisons",
    "href": "man/plot_comparisons.html#plot-conditional-or-marginal-comparisons",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Plot comparisons on the y-axis against values of one or more predictors (x-axis, colors/shapes, and facets).\nThe by argument is used to plot marginal comparisons, that is, comparisons made on the original data, but averaged by subgroups. This is analogous to using the by argument in the comparisons() function.\nThe condition argument is used to plot conditional comparisons, that is, comparisons made on a user-specified grid. This is analogous to using the newdata argument and datagrid() function in a comparisons() call. All variables whose values are not specified explicitly are treated as usual by datagrid(), that is, they are held at their mean or mode (or rounded mean for integers). This includes grouping variables in mixed-effects models, so analysts who fit such models may want to specify the groups of interest using the condition argument, or supply model-specific arguments to compute population-level estimates. See details below.\nSee the \"Plots\" vignette and website for tutorials and information on how to customize plots:\n\n\nhttps://marginaleffects.com/vignettes/plot.html\n\n\nhttps://marginaleffects.com\n\n\nplot_comparisons(\n  model,\n  variables = NULL,\n  condition = NULL,\n  by = NULL,\n  newdata = NULL,\n  type = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  wts = FALSE,\n  comparison = \"difference\",\n  transform = NULL,\n  rug = FALSE,\n  gray = FALSE,\n  draw = TRUE,\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nvariables\n\n\nName of the variable whose contrast we want to plot on the y-axis.\n\n\n\n\ncondition\n\n\nConditional slopes\n\n\nCharacter vector (max length 4): Names of the predictors to display.\n\n\nNamed list (max length 4): List names correspond to predictors. List elements can be:\n\n\nNumeric vector\n\n\nFunction which returns a numeric vector or a set of unique categorical values\n\n\nShortcut strings for common reference values: \"minmax\", \"quartile\", \"threenum\"\n\n\n\n\n1: x-axis. 2: color/shape. 3: facet (wrap if no fourth variable, otherwise cols of grid). 4: facet (rows of grid).\n\n\nNumeric variables in positions 2 and 3 are summarized by Tukey’s five numbers ?stats::fivenum.\n\n\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nnewdata\n\n\nWhen newdata is NULL, the grid is determined by the condition argument. When newdata is not NULL, the argument behaves in the same way as in the comparisons() function.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\ncomparison\n\n\nHow should pairs of predictions be compared? Difference, ratio, odds ratio, or user-defined functions.\n\n\nstring: shortcuts to common contrast functions.\n\n\nSupported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, lift, liftavg, liftavgwts, expdydx, expdydxavg, expdydxavgwts\n\n\nSee the Comparisons section below for definitions of each transformation.\n\n\n\n\nfunction: accept two equal-length numeric vectors of adjusted predictions (hi and lo) and returns a vector of contrasts of the same length, or a unique numeric value.\n\n\nSee the Transformations section below for examples of valid functions.\n\n\n\n\n\n\n\n\ntransform\n\n\nstring or function. Transformation applied to unit-level estimates and confidence intervals just before the function returns results. Functions must accept a vector and return a vector of the same length. Support string shortcuts: \"exp\", \"ln\"\n\n\n\n\nrug\n\n\nTRUE displays tick marks on the axes to mark the distribution of raw data.\n\n\n\n\ngray\n\n\nFALSE grayscale or color plot\n\n\n\n\ndraw\n\n\nTRUE returns a ggplot2 plot. FALSE returns a data.frame of the underlying data.\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA ggplot2 object\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\n\nlibrary(\"marginaleffects\")\n\nmod &lt;- lm(mpg ~ hp * drat * factor(am), data = mtcars)\n\nplot_comparisons(mod, variables = \"hp\", condition = \"drat\")\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"hp\", condition = c(\"drat\", \"am\"))\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"hp\", condition = list(\"am\", \"drat\" = 3:5))\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = range))\n\n\n\n\n\n\nplot_comparisons(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))",
    "crumbs": [
      "Get started",
      "Functions",
      "`plot_comparisons`"
    ]
  },
  {
    "objectID": "man/comparisons.html",
    "href": "man/comparisons.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Predict the outcome variable at different regressor values (e.g., college graduates vs. others), and compare those predictions by computing a difference, ratio, or some other function. comparisons() can return many quantities of interest, such as contrasts, differences, risk ratios, changes in log odds, lift, slopes, elasticities, etc.\n\n\ncomparisons(): unit-level (conditional) estimates.\n\n\navg_comparisons(): average (marginal) estimates.\n\n\nvariables identifies the focal regressors whose \"effect\" we are interested in. comparison determines how predictions with different regressor values are compared (difference, ratio, odds, etc.). The newdata argument and the datagrid() function control where statistics are evaluated in the predictor space: \"at observed values\", \"at the mean\", \"at representative values\", etc.\nSee the comparisons vignette and package website for worked examples and case studies:\n\n\nhttps://marginaleffects.com/vignettes/comparisons.html\n\n\nhttps://marginaleffects.com/\n\n\ncomparisons(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  comparison = \"difference\",\n  type = NULL,\n  vcov = TRUE,\n  by = FALSE,\n  conf_level = 0.95,\n  transform = NULL,\n  cross = FALSE,\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\navg_comparisons(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  type = NULL,\n  vcov = TRUE,\n  by = TRUE,\n  conf_level = 0.95,\n  comparison = \"difference\",\n  transform = NULL,\n  cross = FALSE,\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\nGrid of predictor values at which we evaluate the comparisons.\n\n\nWarning: Avoid modifying your dataset between fitting the model and calling a marginaleffects function. This can sometimes lead to unexpected results.\n\n\nNULL (default): Unit-level contrasts for each observed value in the dataset (empirical distribution). The dataset is retrieved using insight::get_data(), which tries to extract data from the environment. This may produce unexpected results if the original data frame has been altered since fitting the model.\n\n\ndata frame: Unit-level contrasts for each row of the newdata data frame.\n\n\nstring:\n\n\n\"mean\": Contrasts at the Mean. Contrasts when each predictor is held at its mean or mode.\n\n\n\"median\": Contrasts at the Median. Contrasts when each predictor is held at its median or mode.\n\n\n\"balanced\": Contrasts evaluated on a balanced grid with every combination of categories and numeric variables held at their means.\n\n\n\"tukey\": Contrasts at Tukey’s 5 numbers.\n\n\n\"grid\": Contrasts on a grid of representative numbers (Tukey’s 5 numbers and unique values of categorical predictors).\n\n\n\n\ndatagrid() call to specify a custom grid of regressors. For example:\n\n\nnewdata = datagrid(cyl = c(4, 6)): cyl variable equal to 4 and 6 and other regressors fixed at their means or modes.\n\n\nnewdata = datagrid(mpg = fivenum): mpg variable held at Tukey’s five numbers (using the fivenum function), and other regressors fixed at their means or modes.\n\n\nSee the Examples section and the datagrid documentation.\n\n\n\n\nsubset() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = subset(treatment == 1)\n\n\ndplyr::filter() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = filter(treatment == 1)\n\n\n\n\n\n\nvariables\n\n\nFocal variables\n\n\nNULL: compute comparisons for all the variables in the model object (can be slow).\n\n\nCharacter vector: subset of variables (usually faster).\n\n\nNamed list: names identify the subset of variables of interest, and values define the type of contrast to compute. Acceptable values depend on the variable type:\n\n\nFactor or character variables:\n\n\n\"reference\": Each factor level is compared to the factor reference (base) level\n\n\n\"all\": All combinations of observed levels\n\n\n\"sequential\": Each factor level is compared to the previous factor level\n\n\n\"pairwise\": Each factor level is compared to all other levels\n\n\n\"minmax\": The highest and lowest levels of a factor.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses.\n\n\nVector of length 2 with the two values to compare.\n\n\nData frame with the same number of rows as newdata, with two columns of \"lo\" and \"hi\" values to compare.\n\n\nFunction that accepts a vector and returns a data frame with two columns of \"lo\" and \"hi\" values to compare. See examples below.\n\n\n\n\nLogical variables:\n\n\nNULL: contrast between TRUE and FALSE\n\n\nData frame with the same number of rows as newdata, with two columns of \"lo\" and \"hi\" values to compare.\n\n\nFunction that accepts a vector and returns a data frame with two columns of \"lo\" and \"hi\" values to compare. See examples below.\n\n\n\n\nNumeric variables:\n\n\nNumeric of length 1: Forward contrast for a gap of x, computed between the observed value and the observed value plus x. Users can set a global option to get a \"center\" or \"backward\" contrast instead: options(marginaleffects_contrast_direction=“center”)\n\n\nNumeric vector of length 2: Contrast between the largest and the smallest elements of the x vector.\n\n\nData frame with the same number of rows as newdata, with two columns of \"lo\" and \"hi\" values to compare.\n\n\nFunction that accepts a vector and returns a data frame with two columns of \"lo\" and \"hi\" values to compare. See examples below.\n\n\n\"iqr\": Contrast across the interquartile range of the regressor.\n\n\n\"sd\": Contrast across one standard deviation around the regressor mean.\n\n\n\"2sd\": Contrast across two standard deviations around the regressor mean.\n\n\n\"minmax\": Contrast between the maximum and the minimum values of the regressor.\n\n\n\n\nExamples:\n\n\nvariables = list(gear = “pairwise”, hp = 10)\n\n\nvariables = list(gear = “sequential”, hp = c(100, 120))\n\n\nvariables = list(hp = (x) data.frame(low = x - 5, high = x + 10))\n\n\nSee the Examples section below for more.\n\n\n\n\n\n\n\n\n\n\ncomparison\n\n\nHow should pairs of predictions be compared? Difference, ratio, odds ratio, or user-defined functions.\n\n\nstring: shortcuts to common contrast functions.\n\n\nSupported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, lift, liftavg, liftavgwts, expdydx, expdydxavg, expdydxavgwts\n\n\nSee the Comparisons section below for definitions of each transformation.\n\n\n\n\nfunction: accept two equal-length numeric vectors of adjusted predictions (hi and lo) and returns a vector of contrasts of the same length, or a unique numeric value.\n\n\nSee the Transformations section below for examples of valid functions.\n\n\n\n\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\ntransform\n\n\nstring or function. Transformation applied to unit-level estimates and confidence intervals just before the function returns results. Functions must accept a vector and return a vector of the same length. Support string shortcuts: \"exp\", \"ln\"\n\n\n\n\ncross\n\n\n\n\nFALSE: Contrasts represent the change in adjusted predictions when one predictor changes and all other variables are held constant.\n\n\nTRUE: Contrasts represent the changes in adjusted predictions when all the predictors specified in the variables argument are manipulated simultaneously (a \"cross-contrast\").\n\n\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\np_adjust\n\n\nAdjust p-values for multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", or \"fdr\". See stats::p.adjust\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When df is Inf, the normal distribution is used. When df is finite, the t distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: slopes(model, df = insight::get_df(model))\n\n\n\n\neps\n\n\nNULL or numeric value which determines the step size to use when calculating numerical derivatives: (f(x+eps)-f(x))/eps. When eps is NULL, the step size is 0.0001 multiplied by the difference between the maximum and minimum values of the variable with respect to which we are taking the derivative. Changing eps may be necessary to avoid numerical problems in certain models.\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA data.frame with one row per observation (per term/group) and several columns:\n\n\nrowid: row number of the newdata data frame\n\n\ntype: prediction type, as defined by the type argument\n\n\ngroup: (optional) value of the grouped outcome (e.g., categorical outcome models)\n\n\nterm: the variable whose marginal effect is computed\n\n\ndydx: slope of the outcome with respect to the term, for a given combination of predictor values\n\n\nstd.error: standard errors computed by via the delta method.\n\n\np.value: p value associated to the estimate column. The null is determined by the hypothesis argument (0 by default), and p values are computed before applying the transform argument.\n\n\ns.value: Shannon information transforms of p values. How many consecutive \"heads\" tosses would provide the same amount of evidence (or \"surprise\") against the null hypothesis that the coin is fair? The purpose of S is to calibrate the analyst’s intuition about the strength of evidence encoded in p against a well-known physical phenomenon. See Greenland (2019) and Cole et al. (2020).\n\n\nconf.low: lower bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nconf.high: upper bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nSee ?print.marginaleffects for printing options.\n\n\n\navg_comparisons(): Average comparisons\n\n\nStandard errors for all quantities estimated by marginaleffects can be obtained via the delta method. This requires differentiating a function with respect to the coefficients in the model using a finite difference approach. In some models, the delta method standard errors can be sensitive to various aspects of the numeric differentiation strategy, including the step size. By default, the step size is set to 1e-8, or to 1e-4 times the smallest absolute model coefficient, whichever is largest.\nmarginaleffects can delegate numeric differentiation to the numDeriv package, which allows more flexibility. To do this, users can pass arguments to the numDeriv::jacobian function through a global option. For example:\n\n\noptions(marginaleffects_numDeriv = list(method = “simple”, method.args = list(eps = 1e-6)))\n\n\noptions(marginaleffects_numDeriv = list(method = “Richardson”, method.args = list(eps = 1e-5)))\n\n\noptions(marginaleffects_numDeriv = NULL)\n\n\nSee the \"Standard Errors and Confidence Intervals\" vignette on the marginaleffects website for more details on the computation of standard errors:\nhttps://marginaleffects.com/vignettes/uncertainty.html\nNote that the inferences() function can be used to compute uncertainty estimates using a bootstrap or simulation-based inference. See the vignette:\nhttps://marginaleffects.com/vignettes/bootstrap.html\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nThe following transformations can be applied by supplying one of the shortcut strings to the comparison argument. hi is a vector of adjusted predictions for the \"high\" side of the contrast. lo is a vector of adjusted predictions for the \"low\" side of the contrast. y is a vector of adjusted predictions for the original data. x is the predictor in the original data. eps is the step size to use to compute derivatives and elasticities.\n\n\n\nShortcut\n\n\nFunction\n\n\n\n\ndifference\n\n\n(hi, lo) hi - lo\n\n\n\n\ndifferenceavg\n\n\n(hi, lo) mean(hi - lo)\n\n\n\n\ndydx\n\n\n(hi, lo, eps) (hi - lo)/eps\n\n\n\n\neyex\n\n\n(hi, lo, eps, y, x) (hi - lo)/eps * (x/y)\n\n\n\n\neydx\n\n\n(hi, lo, eps, y, x) ((hi - lo)/eps)/y\n\n\n\n\ndyex\n\n\n(hi, lo, eps, x) ((hi - lo)/eps) * x\n\n\n\n\ndydxavg\n\n\n(hi, lo, eps) mean((hi - lo)/eps)\n\n\n\n\neyexavg\n\n\n(hi, lo, eps, y, x) mean((hi - lo)/eps * (x/y))\n\n\n\n\neydxavg\n\n\n(hi, lo, eps, y, x) mean(((hi - lo)/eps)/y)\n\n\n\n\ndyexavg\n\n\n(hi, lo, eps, x) mean(((hi - lo)/eps) * x)\n\n\n\n\nratio\n\n\n(hi, lo) hi/lo\n\n\n\n\nratioavg\n\n\n(hi, lo) mean(hi)/mean(lo)\n\n\n\n\nlnratio\n\n\n(hi, lo) log(hi/lo)\n\n\n\n\nlnratioavg\n\n\n(hi, lo) log(mean(hi)/mean(lo))\n\n\n\n\nlnor\n\n\n(hi, lo) log((hi/(1 - hi))/(lo/(1 - lo)))\n\n\n\n\nlnoravg\n\n\n(hi, lo) log((mean(hi)/(1 - mean(hi)))/(mean(lo)/(1 - mean(lo))))\n\n\n\n\nlift\n\n\n(hi, lo) (hi - lo)/lo\n\n\n\n\nliftavg\n\n\n(hi, lo) (mean(hi - lo))/mean(lo)\n\n\n\n\nexpdydx\n\n\n(hi, lo, eps) ((exp(hi) - exp(lo))/exp(eps))/eps\n\n\n\n\nexpdydxavg\n\n\n(hi, lo, eps) mean(((exp(hi) - exp(lo))/exp(eps))/eps)\n\n\n\n\n\n\n\nBy default, credible intervals in bayesian models are built as equal-tailed intervals. This can be changed to a highest density interval by setting a global option:\noptions(“marginaleffects_posterior_interval” = “eti”)\noptions(“marginaleffects_posterior_interval” = “hdi”)\nBy default, the center of the posterior distribution in bayesian models is identified by the median. Users can use a different summary function by setting a global option:\noptions(“marginaleffects_posterior_center” = “mean”)\noptions(“marginaleffects_posterior_center” = “median”)\nWhen estimates are averaged using the by argument, the tidy() function, or the summary() function, the posterior distribution is marginalized twice over. First, we take the average across units but within each iteration of the MCMC chain, according to what the user requested in by argument or tidy()/summary() functions. Then, we identify the center of the resulting posterior using the function supplied to the “marginaleffects_posterior_center” option (the median by default).\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\nBehind the scenes, the arguments of marginaleffects functions are evaluated in this order:\n\n\nnewdata\n\n\nvariables\n\n\ncomparison and slopes\n\n\nby\n\n\nvcov\n\n\nhypothesis\n\n\ntransform\n\n\nThe slopes() and comparisons() functions can use parallelism to speed up computation. Operations are parallelized for the computation of standard errors, at the model coefficient level. There is always considerable overhead when using parallel computation, mainly involved in passing the whole dataset to the different processes. Thus, parallel computation is most likely to be useful when the model includes many parameters and the dataset is relatively small.\nWarning: In many cases, parallel processing will not be useful at all.\nTo activate parallel computation, users must load the future.apply package, call plan() function, and set a global option. For example:\n\nlibrary(future.apply)\nplan(\"multicore\", workers = 4)\noptions(marginaleffects_parallel = TRUE)\n\nslopes(model)\n\n\nTo disable parallelism in marginaleffects altogether, you can set a global option:\n\noptions(marginaleffects_parallel = FALSE)\n\n\n\nThe behavior of marginaleffects functions can be modified by setting global options.\nDisable some safety checks:\n\noptions(marginaleffects_safe = FALSE)`\n\n\nOmit some columns from the printed output:\n\noptions(marginaleffects_print_omit = c(\"p.value\", \"s.value\"))`\n\n\n\n\n\nGreenland S. 2019. \"Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values.\" The American Statistician. 73(S1): 106–114.\n\n\nCole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. \"Surprise!\" American Journal of Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136\n\n\n\nlibrary(\"marginaleffects\")\n\n\n\nlibrary(marginaleffects)\n\n# Linear model\ntmp &lt;- mtcars\ntmp$am &lt;- as.logical(tmp$am)\nmod &lt;- lm(mpg ~ am + factor(cyl), tmp)\navg_comparisons(mod, variables = list(cyl = \"reference\"))\navg_comparisons(mod, variables = list(cyl = \"sequential\"))\navg_comparisons(mod, variables = list(cyl = \"pairwise\"))\n\n# GLM with different scale types\nmod &lt;- glm(am ~ factor(gear), data = mtcars)\navg_comparisons(mod, type = \"response\")\navg_comparisons(mod, type = \"link\")\n\n# Contrasts at the mean\ncomparisons(mod, newdata = \"mean\")\n\n# Contrasts between marginal means\ncomparisons(mod, newdata = \"marginalmeans\")\n\n# Contrasts at user-specified values\ncomparisons(mod, newdata = datagrid(am = 0, gear = tmp$gear))\ncomparisons(mod, newdata = datagrid(am = unique, gear = max))\n\nm &lt;- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars)\ncomparisons(m, variables = \"hp\", newdata = datagrid(FUN_factor = unique, FUN_numeric = median))\n\n# Numeric contrasts\nmod &lt;- lm(mpg ~ hp, data = mtcars)\navg_comparisons(mod, variables = list(hp = 1))\navg_comparisons(mod, variables = list(hp = 5))\navg_comparisons(mod, variables = list(hp = c(90, 100)))\navg_comparisons(mod, variables = list(hp = \"iqr\"))\navg_comparisons(mod, variables = list(hp = \"sd\"))\navg_comparisons(mod, variables = list(hp = \"minmax\"))\n\n# using a function to specify a custom difference in one regressor\ndat &lt;- mtcars\ndat$new_hp &lt;- 49 * (dat$hp - min(dat$hp)) / (max(dat$hp) - min(dat$hp)) + 1\nmodlog &lt;- lm(mpg ~ log(new_hp) + factor(cyl), data = dat)\nfdiff &lt;- \\(x) data.frame(x, x + 10)\navg_comparisons(modlog, variables = list(new_hp = fdiff))\n\n# Adjusted Risk Ratio: see the contrasts vignette\nmod &lt;- glm(vs ~ mpg, data = mtcars, family = binomial)\navg_comparisons(mod, comparison = \"lnratioavg\", transform = exp)\n\n# Adjusted Risk Ratio: Manual specification of the `comparison`\navg_comparisons(\n     mod,\n     comparison = function(hi, lo) log(mean(hi) / mean(lo)),\n     transform = exp)\n# cross contrasts\nmod &lt;- lm(mpg ~ factor(cyl) * factor(gear) + hp, data = mtcars)\navg_comparisons(mod, variables = c(\"cyl\", \"gear\"), cross = TRUE)\n\n# variable-specific contrasts\navg_comparisons(mod, variables = list(gear = \"sequential\", hp = 10))\n\n# hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect\nmod &lt;- lm(mpg ~ wt + drat, data = mtcars)\n\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"wt = drat\")\n\n# same hypothesis test using row indices\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"b1 - b2 = 0\")\n\n# same hypothesis test using numeric vector of weights\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = c(1, -1))\n\n# two custom contrasts using a matrix of weights\nlc &lt;- matrix(c(\n    1, -1,\n    2, 3),\n    ncol = 2)\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = lc)\n\n# Effect of a 1 group-wise standard deviation change\n# First we calculate the SD in each group of `cyl`\n# Second, we use that SD as the treatment size in the `variables` argument\nlibrary(dplyr)\nmod &lt;- lm(mpg ~ hp + factor(cyl), mtcars)\ntmp &lt;- mtcars %&gt;%\n    group_by(cyl) %&gt;%\n    mutate(hp_sd = sd(hp))\navg_comparisons(mod, \n    variables = list(hp = function(x) data.frame(x, x + tmp$hp_sd)),\n    by = \"cyl\")\n\n# `by` argument\nmod &lt;- lm(mpg ~ hp * am * vs, data = mtcars)\ncomparisons(mod, by = TRUE)\n\nmod &lt;- lm(mpg ~ hp * am * vs, data = mtcars)\navg_comparisons(mod, variables = \"hp\", by = c(\"vs\", \"am\"))\n\nlibrary(nnet)\nmod &lt;- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)\nby &lt;- data.frame(\n    group = c(\"3\", \"4\", \"5\"),\n    by = c(\"3,4\", \"3,4\", \"5\"))\ncomparisons(mod, type = \"probs\", by = by)",
    "crumbs": [
      "Get started",
      "Functions",
      "`comparisons`"
    ]
  },
  {
    "objectID": "man/comparisons.html#comparisons-between-predictions-made-with-different-regressor-values",
    "href": "man/comparisons.html#comparisons-between-predictions-made-with-different-regressor-values",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Predict the outcome variable at different regressor values (e.g., college graduates vs. others), and compare those predictions by computing a difference, ratio, or some other function. comparisons() can return many quantities of interest, such as contrasts, differences, risk ratios, changes in log odds, lift, slopes, elasticities, etc.\n\n\ncomparisons(): unit-level (conditional) estimates.\n\n\navg_comparisons(): average (marginal) estimates.\n\n\nvariables identifies the focal regressors whose \"effect\" we are interested in. comparison determines how predictions with different regressor values are compared (difference, ratio, odds, etc.). The newdata argument and the datagrid() function control where statistics are evaluated in the predictor space: \"at observed values\", \"at the mean\", \"at representative values\", etc.\nSee the comparisons vignette and package website for worked examples and case studies:\n\n\nhttps://marginaleffects.com/vignettes/comparisons.html\n\n\nhttps://marginaleffects.com/\n\n\ncomparisons(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  comparison = \"difference\",\n  type = NULL,\n  vcov = TRUE,\n  by = FALSE,\n  conf_level = 0.95,\n  transform = NULL,\n  cross = FALSE,\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\navg_comparisons(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  type = NULL,\n  vcov = TRUE,\n  by = TRUE,\n  conf_level = 0.95,\n  comparison = \"difference\",\n  transform = NULL,\n  cross = FALSE,\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\nGrid of predictor values at which we evaluate the comparisons.\n\n\nWarning: Avoid modifying your dataset between fitting the model and calling a marginaleffects function. This can sometimes lead to unexpected results.\n\n\nNULL (default): Unit-level contrasts for each observed value in the dataset (empirical distribution). The dataset is retrieved using insight::get_data(), which tries to extract data from the environment. This may produce unexpected results if the original data frame has been altered since fitting the model.\n\n\ndata frame: Unit-level contrasts for each row of the newdata data frame.\n\n\nstring:\n\n\n\"mean\": Contrasts at the Mean. Contrasts when each predictor is held at its mean or mode.\n\n\n\"median\": Contrasts at the Median. Contrasts when each predictor is held at its median or mode.\n\n\n\"balanced\": Contrasts evaluated on a balanced grid with every combination of categories and numeric variables held at their means.\n\n\n\"tukey\": Contrasts at Tukey’s 5 numbers.\n\n\n\"grid\": Contrasts on a grid of representative numbers (Tukey’s 5 numbers and unique values of categorical predictors).\n\n\n\n\ndatagrid() call to specify a custom grid of regressors. For example:\n\n\nnewdata = datagrid(cyl = c(4, 6)): cyl variable equal to 4 and 6 and other regressors fixed at their means or modes.\n\n\nnewdata = datagrid(mpg = fivenum): mpg variable held at Tukey’s five numbers (using the fivenum function), and other regressors fixed at their means or modes.\n\n\nSee the Examples section and the datagrid documentation.\n\n\n\n\nsubset() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = subset(treatment == 1)\n\n\ndplyr::filter() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = filter(treatment == 1)\n\n\n\n\n\n\nvariables\n\n\nFocal variables\n\n\nNULL: compute comparisons for all the variables in the model object (can be slow).\n\n\nCharacter vector: subset of variables (usually faster).\n\n\nNamed list: names identify the subset of variables of interest, and values define the type of contrast to compute. Acceptable values depend on the variable type:\n\n\nFactor or character variables:\n\n\n\"reference\": Each factor level is compared to the factor reference (base) level\n\n\n\"all\": All combinations of observed levels\n\n\n\"sequential\": Each factor level is compared to the previous factor level\n\n\n\"pairwise\": Each factor level is compared to all other levels\n\n\n\"minmax\": The highest and lowest levels of a factor.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses.\n\n\nVector of length 2 with the two values to compare.\n\n\nData frame with the same number of rows as newdata, with two columns of \"lo\" and \"hi\" values to compare.\n\n\nFunction that accepts a vector and returns a data frame with two columns of \"lo\" and \"hi\" values to compare. See examples below.\n\n\n\n\nLogical variables:\n\n\nNULL: contrast between TRUE and FALSE\n\n\nData frame with the same number of rows as newdata, with two columns of \"lo\" and \"hi\" values to compare.\n\n\nFunction that accepts a vector and returns a data frame with two columns of \"lo\" and \"hi\" values to compare. See examples below.\n\n\n\n\nNumeric variables:\n\n\nNumeric of length 1: Forward contrast for a gap of x, computed between the observed value and the observed value plus x. Users can set a global option to get a \"center\" or \"backward\" contrast instead: options(marginaleffects_contrast_direction=“center”)\n\n\nNumeric vector of length 2: Contrast between the largest and the smallest elements of the x vector.\n\n\nData frame with the same number of rows as newdata, with two columns of \"lo\" and \"hi\" values to compare.\n\n\nFunction that accepts a vector and returns a data frame with two columns of \"lo\" and \"hi\" values to compare. See examples below.\n\n\n\"iqr\": Contrast across the interquartile range of the regressor.\n\n\n\"sd\": Contrast across one standard deviation around the regressor mean.\n\n\n\"2sd\": Contrast across two standard deviations around the regressor mean.\n\n\n\"minmax\": Contrast between the maximum and the minimum values of the regressor.\n\n\n\n\nExamples:\n\n\nvariables = list(gear = “pairwise”, hp = 10)\n\n\nvariables = list(gear = “sequential”, hp = c(100, 120))\n\n\nvariables = list(hp = (x) data.frame(low = x - 5, high = x + 10))\n\n\nSee the Examples section below for more.\n\n\n\n\n\n\n\n\n\n\ncomparison\n\n\nHow should pairs of predictions be compared? Difference, ratio, odds ratio, or user-defined functions.\n\n\nstring: shortcuts to common contrast functions.\n\n\nSupported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, lift, liftavg, liftavgwts, expdydx, expdydxavg, expdydxavgwts\n\n\nSee the Comparisons section below for definitions of each transformation.\n\n\n\n\nfunction: accept two equal-length numeric vectors of adjusted predictions (hi and lo) and returns a vector of contrasts of the same length, or a unique numeric value.\n\n\nSee the Transformations section below for examples of valid functions.\n\n\n\n\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\ntransform\n\n\nstring or function. Transformation applied to unit-level estimates and confidence intervals just before the function returns results. Functions must accept a vector and return a vector of the same length. Support string shortcuts: \"exp\", \"ln\"\n\n\n\n\ncross\n\n\n\n\nFALSE: Contrasts represent the change in adjusted predictions when one predictor changes and all other variables are held constant.\n\n\nTRUE: Contrasts represent the changes in adjusted predictions when all the predictors specified in the variables argument are manipulated simultaneously (a \"cross-contrast\").\n\n\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\np_adjust\n\n\nAdjust p-values for multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", or \"fdr\". See stats::p.adjust\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When df is Inf, the normal distribution is used. When df is finite, the t distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: slopes(model, df = insight::get_df(model))\n\n\n\n\neps\n\n\nNULL or numeric value which determines the step size to use when calculating numerical derivatives: (f(x+eps)-f(x))/eps. When eps is NULL, the step size is 0.0001 multiplied by the difference between the maximum and minimum values of the variable with respect to which we are taking the derivative. Changing eps may be necessary to avoid numerical problems in certain models.\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA data.frame with one row per observation (per term/group) and several columns:\n\n\nrowid: row number of the newdata data frame\n\n\ntype: prediction type, as defined by the type argument\n\n\ngroup: (optional) value of the grouped outcome (e.g., categorical outcome models)\n\n\nterm: the variable whose marginal effect is computed\n\n\ndydx: slope of the outcome with respect to the term, for a given combination of predictor values\n\n\nstd.error: standard errors computed by via the delta method.\n\n\np.value: p value associated to the estimate column. The null is determined by the hypothesis argument (0 by default), and p values are computed before applying the transform argument.\n\n\ns.value: Shannon information transforms of p values. How many consecutive \"heads\" tosses would provide the same amount of evidence (or \"surprise\") against the null hypothesis that the coin is fair? The purpose of S is to calibrate the analyst’s intuition about the strength of evidence encoded in p against a well-known physical phenomenon. See Greenland (2019) and Cole et al. (2020).\n\n\nconf.low: lower bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nconf.high: upper bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nSee ?print.marginaleffects for printing options.\n\n\n\navg_comparisons(): Average comparisons\n\n\nStandard errors for all quantities estimated by marginaleffects can be obtained via the delta method. This requires differentiating a function with respect to the coefficients in the model using a finite difference approach. In some models, the delta method standard errors can be sensitive to various aspects of the numeric differentiation strategy, including the step size. By default, the step size is set to 1e-8, or to 1e-4 times the smallest absolute model coefficient, whichever is largest.\nmarginaleffects can delegate numeric differentiation to the numDeriv package, which allows more flexibility. To do this, users can pass arguments to the numDeriv::jacobian function through a global option. For example:\n\n\noptions(marginaleffects_numDeriv = list(method = “simple”, method.args = list(eps = 1e-6)))\n\n\noptions(marginaleffects_numDeriv = list(method = “Richardson”, method.args = list(eps = 1e-5)))\n\n\noptions(marginaleffects_numDeriv = NULL)\n\n\nSee the \"Standard Errors and Confidence Intervals\" vignette on the marginaleffects website for more details on the computation of standard errors:\nhttps://marginaleffects.com/vignettes/uncertainty.html\nNote that the inferences() function can be used to compute uncertainty estimates using a bootstrap or simulation-based inference. See the vignette:\nhttps://marginaleffects.com/vignettes/bootstrap.html\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nThe following transformations can be applied by supplying one of the shortcut strings to the comparison argument. hi is a vector of adjusted predictions for the \"high\" side of the contrast. lo is a vector of adjusted predictions for the \"low\" side of the contrast. y is a vector of adjusted predictions for the original data. x is the predictor in the original data. eps is the step size to use to compute derivatives and elasticities.\n\n\n\nShortcut\n\n\nFunction\n\n\n\n\ndifference\n\n\n(hi, lo) hi - lo\n\n\n\n\ndifferenceavg\n\n\n(hi, lo) mean(hi - lo)\n\n\n\n\ndydx\n\n\n(hi, lo, eps) (hi - lo)/eps\n\n\n\n\neyex\n\n\n(hi, lo, eps, y, x) (hi - lo)/eps * (x/y)\n\n\n\n\neydx\n\n\n(hi, lo, eps, y, x) ((hi - lo)/eps)/y\n\n\n\n\ndyex\n\n\n(hi, lo, eps, x) ((hi - lo)/eps) * x\n\n\n\n\ndydxavg\n\n\n(hi, lo, eps) mean((hi - lo)/eps)\n\n\n\n\neyexavg\n\n\n(hi, lo, eps, y, x) mean((hi - lo)/eps * (x/y))\n\n\n\n\neydxavg\n\n\n(hi, lo, eps, y, x) mean(((hi - lo)/eps)/y)\n\n\n\n\ndyexavg\n\n\n(hi, lo, eps, x) mean(((hi - lo)/eps) * x)\n\n\n\n\nratio\n\n\n(hi, lo) hi/lo\n\n\n\n\nratioavg\n\n\n(hi, lo) mean(hi)/mean(lo)\n\n\n\n\nlnratio\n\n\n(hi, lo) log(hi/lo)\n\n\n\n\nlnratioavg\n\n\n(hi, lo) log(mean(hi)/mean(lo))\n\n\n\n\nlnor\n\n\n(hi, lo) log((hi/(1 - hi))/(lo/(1 - lo)))\n\n\n\n\nlnoravg\n\n\n(hi, lo) log((mean(hi)/(1 - mean(hi)))/(mean(lo)/(1 - mean(lo))))\n\n\n\n\nlift\n\n\n(hi, lo) (hi - lo)/lo\n\n\n\n\nliftavg\n\n\n(hi, lo) (mean(hi - lo))/mean(lo)\n\n\n\n\nexpdydx\n\n\n(hi, lo, eps) ((exp(hi) - exp(lo))/exp(eps))/eps\n\n\n\n\nexpdydxavg\n\n\n(hi, lo, eps) mean(((exp(hi) - exp(lo))/exp(eps))/eps)\n\n\n\n\n\n\n\nBy default, credible intervals in bayesian models are built as equal-tailed intervals. This can be changed to a highest density interval by setting a global option:\noptions(“marginaleffects_posterior_interval” = “eti”)\noptions(“marginaleffects_posterior_interval” = “hdi”)\nBy default, the center of the posterior distribution in bayesian models is identified by the median. Users can use a different summary function by setting a global option:\noptions(“marginaleffects_posterior_center” = “mean”)\noptions(“marginaleffects_posterior_center” = “median”)\nWhen estimates are averaged using the by argument, the tidy() function, or the summary() function, the posterior distribution is marginalized twice over. First, we take the average across units but within each iteration of the MCMC chain, according to what the user requested in by argument or tidy()/summary() functions. Then, we identify the center of the resulting posterior using the function supplied to the “marginaleffects_posterior_center” option (the median by default).\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\nBehind the scenes, the arguments of marginaleffects functions are evaluated in this order:\n\n\nnewdata\n\n\nvariables\n\n\ncomparison and slopes\n\n\nby\n\n\nvcov\n\n\nhypothesis\n\n\ntransform\n\n\nThe slopes() and comparisons() functions can use parallelism to speed up computation. Operations are parallelized for the computation of standard errors, at the model coefficient level. There is always considerable overhead when using parallel computation, mainly involved in passing the whole dataset to the different processes. Thus, parallel computation is most likely to be useful when the model includes many parameters and the dataset is relatively small.\nWarning: In many cases, parallel processing will not be useful at all.\nTo activate parallel computation, users must load the future.apply package, call plan() function, and set a global option. For example:\n\nlibrary(future.apply)\nplan(\"multicore\", workers = 4)\noptions(marginaleffects_parallel = TRUE)\n\nslopes(model)\n\n\nTo disable parallelism in marginaleffects altogether, you can set a global option:\n\noptions(marginaleffects_parallel = FALSE)\n\n\n\nThe behavior of marginaleffects functions can be modified by setting global options.\nDisable some safety checks:\n\noptions(marginaleffects_safe = FALSE)`\n\n\nOmit some columns from the printed output:\n\noptions(marginaleffects_print_omit = c(\"p.value\", \"s.value\"))`\n\n\n\n\n\nGreenland S. 2019. \"Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values.\" The American Statistician. 73(S1): 106–114.\n\n\nCole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. \"Surprise!\" American Journal of Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136\n\n\n\nlibrary(\"marginaleffects\")\n\n\n\nlibrary(marginaleffects)\n\n# Linear model\ntmp &lt;- mtcars\ntmp$am &lt;- as.logical(tmp$am)\nmod &lt;- lm(mpg ~ am + factor(cyl), tmp)\navg_comparisons(mod, variables = list(cyl = \"reference\"))\navg_comparisons(mod, variables = list(cyl = \"sequential\"))\navg_comparisons(mod, variables = list(cyl = \"pairwise\"))\n\n# GLM with different scale types\nmod &lt;- glm(am ~ factor(gear), data = mtcars)\navg_comparisons(mod, type = \"response\")\navg_comparisons(mod, type = \"link\")\n\n# Contrasts at the mean\ncomparisons(mod, newdata = \"mean\")\n\n# Contrasts between marginal means\ncomparisons(mod, newdata = \"marginalmeans\")\n\n# Contrasts at user-specified values\ncomparisons(mod, newdata = datagrid(am = 0, gear = tmp$gear))\ncomparisons(mod, newdata = datagrid(am = unique, gear = max))\n\nm &lt;- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars)\ncomparisons(m, variables = \"hp\", newdata = datagrid(FUN_factor = unique, FUN_numeric = median))\n\n# Numeric contrasts\nmod &lt;- lm(mpg ~ hp, data = mtcars)\navg_comparisons(mod, variables = list(hp = 1))\navg_comparisons(mod, variables = list(hp = 5))\navg_comparisons(mod, variables = list(hp = c(90, 100)))\navg_comparisons(mod, variables = list(hp = \"iqr\"))\navg_comparisons(mod, variables = list(hp = \"sd\"))\navg_comparisons(mod, variables = list(hp = \"minmax\"))\n\n# using a function to specify a custom difference in one regressor\ndat &lt;- mtcars\ndat$new_hp &lt;- 49 * (dat$hp - min(dat$hp)) / (max(dat$hp) - min(dat$hp)) + 1\nmodlog &lt;- lm(mpg ~ log(new_hp) + factor(cyl), data = dat)\nfdiff &lt;- \\(x) data.frame(x, x + 10)\navg_comparisons(modlog, variables = list(new_hp = fdiff))\n\n# Adjusted Risk Ratio: see the contrasts vignette\nmod &lt;- glm(vs ~ mpg, data = mtcars, family = binomial)\navg_comparisons(mod, comparison = \"lnratioavg\", transform = exp)\n\n# Adjusted Risk Ratio: Manual specification of the `comparison`\navg_comparisons(\n     mod,\n     comparison = function(hi, lo) log(mean(hi) / mean(lo)),\n     transform = exp)\n# cross contrasts\nmod &lt;- lm(mpg ~ factor(cyl) * factor(gear) + hp, data = mtcars)\navg_comparisons(mod, variables = c(\"cyl\", \"gear\"), cross = TRUE)\n\n# variable-specific contrasts\navg_comparisons(mod, variables = list(gear = \"sequential\", hp = 10))\n\n# hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect\nmod &lt;- lm(mpg ~ wt + drat, data = mtcars)\n\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"wt = drat\")\n\n# same hypothesis test using row indices\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"b1 - b2 = 0\")\n\n# same hypothesis test using numeric vector of weights\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = c(1, -1))\n\n# two custom contrasts using a matrix of weights\nlc &lt;- matrix(c(\n    1, -1,\n    2, 3),\n    ncol = 2)\ncomparisons(\n    mod,\n    newdata = \"mean\",\n    hypothesis = lc)\n\n# Effect of a 1 group-wise standard deviation change\n# First we calculate the SD in each group of `cyl`\n# Second, we use that SD as the treatment size in the `variables` argument\nlibrary(dplyr)\nmod &lt;- lm(mpg ~ hp + factor(cyl), mtcars)\ntmp &lt;- mtcars %&gt;%\n    group_by(cyl) %&gt;%\n    mutate(hp_sd = sd(hp))\navg_comparisons(mod, \n    variables = list(hp = function(x) data.frame(x, x + tmp$hp_sd)),\n    by = \"cyl\")\n\n# `by` argument\nmod &lt;- lm(mpg ~ hp * am * vs, data = mtcars)\ncomparisons(mod, by = TRUE)\n\nmod &lt;- lm(mpg ~ hp * am * vs, data = mtcars)\navg_comparisons(mod, variables = \"hp\", by = c(\"vs\", \"am\"))\n\nlibrary(nnet)\nmod &lt;- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)\nby &lt;- data.frame(\n    group = c(\"3\", \"4\", \"5\"),\n    by = c(\"3,4\", \"3,4\", \"5\"))\ncomparisons(mod, type = \"probs\", by = by)",
    "crumbs": [
      "Get started",
      "Functions",
      "`comparisons`"
    ]
  },
  {
    "objectID": "man/specify_hypothesis.html",
    "href": "man/specify_hypothesis.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "(EXPERIMENTAL) This experimental function will soon be deprecated. Please supply a formula or function to the hypothesis argument to conduct (group-wise) hypothesis tests.\n\n\n\nspecify_hypothesis(\n  hypothesis = \"reference\",\n  comparison = \"difference\",\n  label = NULL,\n  label_columns = NULL,\n  by = c(\"term\", \"group\", \"contrast\"),\n  internal = FALSE\n)\n\n\n\n\n\n\n\nhypothesis\n\n\nString or Function. Compute a test statistic.\n\n\nString: \"reference\" or \"sequential\"\n\n\nFunction: Accepts a single argument named estimate and returns a numeric vector.\n\n\n\n\n\n\ncomparison\n\n\nString. \"ratio\" or \"difference\"\n\n\n\n\nlabel\n\n\nFunction. Accepts a vector of row labels and combines them to create hypothesis labels.\n\n\n\n\nlabel_columns\n\n\nCharacter vector. Column names to use for hypothesis labels. Default is c(“group”, “term”, “rowid”, attr(x, “variables_datagrid”), attr(x, “by”)).\n\n\n\n\nby\n\n\nCharacter vector. Variable names which indicate subgroups in which the hypothesis function should be applied.\n\n\n\n\ninternal\n\n\nLogical. Raises a deprecation warning when FALSE.\n\n\n\n\n\n\nspecify_hypothesis() is a \"function factory\", which means that executing it will return a function suitable for use in the hypothesis argument of a marginaleffects function."
  },
  {
    "objectID": "man/specify_hypothesis.html#experimental-this-experimental-function-will-soon-be-deprecated.-please-supply-a-formula-or-function-to-the-hypothesis-argument-to-conduct-group-wise-hypothesis-tests.",
    "href": "man/specify_hypothesis.html#experimental-this-experimental-function-will-soon-be-deprecated.-please-supply-a-formula-or-function-to-the-hypothesis-argument-to-conduct-group-wise-hypothesis-tests.",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "(EXPERIMENTAL) This experimental function will soon be deprecated. Please supply a formula or function to the hypothesis argument to conduct (group-wise) hypothesis tests.\n\n\n\nspecify_hypothesis(\n  hypothesis = \"reference\",\n  comparison = \"difference\",\n  label = NULL,\n  label_columns = NULL,\n  by = c(\"term\", \"group\", \"contrast\"),\n  internal = FALSE\n)\n\n\n\n\n\n\n\nhypothesis\n\n\nString or Function. Compute a test statistic.\n\n\nString: \"reference\" or \"sequential\"\n\n\nFunction: Accepts a single argument named estimate and returns a numeric vector.\n\n\n\n\n\n\ncomparison\n\n\nString. \"ratio\" or \"difference\"\n\n\n\n\nlabel\n\n\nFunction. Accepts a vector of row labels and combines them to create hypothesis labels.\n\n\n\n\nlabel_columns\n\n\nCharacter vector. Column names to use for hypothesis labels. Default is c(“group”, “term”, “rowid”, attr(x, “variables_datagrid”), attr(x, “by”)).\n\n\n\n\nby\n\n\nCharacter vector. Variable names which indicate subgroups in which the hypothesis function should be applied.\n\n\n\n\ninternal\n\n\nLogical. Raises a deprecation warning when FALSE.\n\n\n\n\n\n\nspecify_hypothesis() is a \"function factory\", which means that executing it will return a function suitable for use in the hypothesis argument of a marginaleffects function."
  },
  {
    "objectID": "man/print.marginaleffects.html",
    "href": "man/print.marginaleffects.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "This function controls the text which is printed to the console when one of the core marginalefffects functions is called and the object is returned: predictions(), comparisons(), slopes(), hypotheses(), avg_predictions(), avg_comparisons(), avg_slopes().\nAll of those functions return standard data frames. Columns can be extracted by name, predictions(model)$estimate, and all the usual data manipulation functions work out-of-the-box: colnames(), head(), subset(), dplyr::filter(), dplyr::arrange(), etc.\nSome of the data columns are not printed by default. You can disable pretty printing and print the full results as a standard data frame using the style argument or by applying as.data.frame() on the object. See examples below.\n\n## S3 method for class 'marginaleffects'\nprint(\n  x,\n  style = getOption(\"marginaleffects_print_style\", default = \"summary\"),\n  digits = getOption(\"marginaleffects_print_digits\", default = 3),\n  p_eps = getOption(\"marginaleffects_print_p_eps\", default = 0.001),\n  topn = getOption(\"marginaleffects_print_topn\", default = 5),\n  nrows = getOption(\"marginaleffects_print_nrows\", default = 30),\n  ncols = getOption(\"marginaleffects_print_ncols\", default = 30),\n  type = getOption(\"marginaleffects_print_type\", default = TRUE),\n  column_names = getOption(\"marginaleffects_print_column_names\", default = TRUE),\n  ...\n)\n\n\n\n\n\nx\n\n\nAn object produced by one of the marginaleffects package functions.\n\n\n\n\nstyle\n\n\n\"summary\", \"data.frame\", or \"tinytable\"\n\n\n\n\ndigits\n\n\nThe number of digits to display.\n\n\n\n\np_eps\n\n\np values smaller than this number are printed in \"&lt;0.001\" style.\n\n\n\n\ntopn\n\n\nThe number of rows to be printed from the beginning and end of tables with more than nrows rows.\n\n\n\n\nnrows\n\n\nThe number of rows which will be printed before truncation.\n\n\n\n\nncols\n\n\nThe maximum number of column names to display at the bottom of the printed output.\n\n\n\n\ntype\n\n\nboolean: should the type be printed?\n\n\n\n\ncolumn_names\n\n\nboolean: should the column names be printed?\n\n\n\n\n…\n\n\nOther arguments are currently ignored.\n\n\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + am + factor(gear), data = mtcars)\np &lt;- predictions(mod, by = c(\"am\", \"gear\"))\np\n\n\n am gear Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  1    4     26.3      1.039 25.3   &lt;0.001 466.1  24.2   28.3\n  0    3     16.1      0.759 21.2   &lt;0.001 329.6  14.6   17.6\n  0    4     21.0      1.470 14.3   &lt;0.001 152.1  18.2   23.9\n  1    5     21.4      1.315 16.3   &lt;0.001 195.2  18.8   24.0\n\nType:  response \nColumns: am, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nsubset(p, am == 1)\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S CI low CI high\n     26.3       1.04 25.3   &lt;0.001 466.1   24.2    28.3\n     21.4       1.31 16.3   &lt;0.001 195.2   18.8    24.0\n\nColumns: am, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nprint(p, style = \"data.frame\")\n\n  am gear estimate std.error statistic       p.value  s.value conf.low\n1  1    4 26.27500 1.0392746  25.28206 5.032257e-141 466.0607 24.23806\n2  0    3 16.10667 0.7589789  21.22150 6.047015e-100 329.5966 14.61910\n3  0    4 21.05000 1.4697592  14.32207  1.592966e-46 152.1370 18.16932\n4  1    5 21.38000 1.3145900  16.26363  1.788354e-59 195.1551 18.80345\n  conf.high\n1  28.31194\n2  17.59424\n3  23.93068\n4  23.95655\n\ndata.frame(p)\n\n  am gear estimate std.error statistic       p.value  s.value conf.low\n1  1    4 26.27500 1.0392746  25.28206 5.032257e-141 466.0607 24.23806\n2  0    3 16.10667 0.7589789  21.22150 6.047015e-100 329.5966 14.61910\n3  0    4 21.05000 1.4697592  14.32207  1.592966e-46 152.1370 18.16932\n4  1    5 21.38000 1.3145900  16.26363  1.788354e-59 195.1551 18.80345\n  conf.high\n1  28.31194\n2  17.59424\n3  23.93068\n4  23.95655",
    "crumbs": [
      "Get started",
      "Functions",
      "`print.marginaleffects`"
    ]
  },
  {
    "objectID": "man/print.marginaleffects.html#print-marginaleffects-objects",
    "href": "man/print.marginaleffects.html#print-marginaleffects-objects",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "This function controls the text which is printed to the console when one of the core marginalefffects functions is called and the object is returned: predictions(), comparisons(), slopes(), hypotheses(), avg_predictions(), avg_comparisons(), avg_slopes().\nAll of those functions return standard data frames. Columns can be extracted by name, predictions(model)$estimate, and all the usual data manipulation functions work out-of-the-box: colnames(), head(), subset(), dplyr::filter(), dplyr::arrange(), etc.\nSome of the data columns are not printed by default. You can disable pretty printing and print the full results as a standard data frame using the style argument or by applying as.data.frame() on the object. See examples below.\n\n## S3 method for class 'marginaleffects'\nprint(\n  x,\n  style = getOption(\"marginaleffects_print_style\", default = \"summary\"),\n  digits = getOption(\"marginaleffects_print_digits\", default = 3),\n  p_eps = getOption(\"marginaleffects_print_p_eps\", default = 0.001),\n  topn = getOption(\"marginaleffects_print_topn\", default = 5),\n  nrows = getOption(\"marginaleffects_print_nrows\", default = 30),\n  ncols = getOption(\"marginaleffects_print_ncols\", default = 30),\n  type = getOption(\"marginaleffects_print_type\", default = TRUE),\n  column_names = getOption(\"marginaleffects_print_column_names\", default = TRUE),\n  ...\n)\n\n\n\n\n\nx\n\n\nAn object produced by one of the marginaleffects package functions.\n\n\n\n\nstyle\n\n\n\"summary\", \"data.frame\", or \"tinytable\"\n\n\n\n\ndigits\n\n\nThe number of digits to display.\n\n\n\n\np_eps\n\n\np values smaller than this number are printed in \"&lt;0.001\" style.\n\n\n\n\ntopn\n\n\nThe number of rows to be printed from the beginning and end of tables with more than nrows rows.\n\n\n\n\nnrows\n\n\nThe number of rows which will be printed before truncation.\n\n\n\n\nncols\n\n\nThe maximum number of column names to display at the bottom of the printed output.\n\n\n\n\ntype\n\n\nboolean: should the type be printed?\n\n\n\n\ncolumn_names\n\n\nboolean: should the column names be printed?\n\n\n\n\n…\n\n\nOther arguments are currently ignored.\n\n\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + am + factor(gear), data = mtcars)\np &lt;- predictions(mod, by = c(\"am\", \"gear\"))\np\n\n\n am gear Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  1    4     26.3      1.039 25.3   &lt;0.001 466.1  24.2   28.3\n  0    3     16.1      0.759 21.2   &lt;0.001 329.6  14.6   17.6\n  0    4     21.0      1.470 14.3   &lt;0.001 152.1  18.2   23.9\n  1    5     21.4      1.315 16.3   &lt;0.001 195.2  18.8   24.0\n\nType:  response \nColumns: am, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nsubset(p, am == 1)\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S CI low CI high\n     26.3       1.04 25.3   &lt;0.001 466.1   24.2    28.3\n     21.4       1.31 16.3   &lt;0.001 195.2   18.8    24.0\n\nColumns: am, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nprint(p, style = \"data.frame\")\n\n  am gear estimate std.error statistic       p.value  s.value conf.low\n1  1    4 26.27500 1.0392746  25.28206 5.032257e-141 466.0607 24.23806\n2  0    3 16.10667 0.7589789  21.22150 6.047015e-100 329.5966 14.61910\n3  0    4 21.05000 1.4697592  14.32207  1.592966e-46 152.1370 18.16932\n4  1    5 21.38000 1.3145900  16.26363  1.788354e-59 195.1551 18.80345\n  conf.high\n1  28.31194\n2  17.59424\n3  23.93068\n4  23.95655\n\ndata.frame(p)\n\n  am gear estimate std.error statistic       p.value  s.value conf.low\n1  1    4 26.27500 1.0392746  25.28206 5.032257e-141 466.0607 24.23806\n2  0    3 16.10667 0.7589789  21.22150 6.047015e-100 329.5966 14.61910\n3  0    4 21.05000 1.4697592  14.32207  1.592966e-46 152.1370 18.16932\n4  1    5 21.38000 1.3145900  16.26363  1.788354e-59 195.1551 18.80345\n  conf.high\n1  28.31194\n2  17.59424\n3  23.93068\n4  23.95655",
    "crumbs": [
      "Get started",
      "Functions",
      "`print.marginaleffects`"
    ]
  },
  {
    "objectID": "man/plot_slopes.html",
    "href": "man/plot_slopes.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Plot slopes on the y-axis against values of one or more predictors (x-axis, colors/shapes, and facets).\nThe by argument is used to plot marginal slopes, that is, slopes made on the original data, but averaged by subgroups. This is analogous to using the by argument in the slopes() function.\nThe condition argument is used to plot conditional slopes, that is, slopes computed on a user-specified grid. This is analogous to using the newdata argument and datagrid() function in a slopes() call. All variables whose values are not specified explicitly are treated as usual by datagrid(), that is, they are held at their mean or mode (or rounded mean for integers). This includes grouping variables in mixed-effects models, so analysts who fit such models may want to specify the groups of interest using the condition argument, or supply model-specific arguments to compute population-level estimates. See details below. See the \"Plots\" vignette and website for tutorials and information on how to customize plots:\n\n\nhttps://marginaleffects.com/vignettes/plot.html\n\n\nhttps://marginaleffects.com\n\n\nplot_slopes(\n  model,\n  variables = NULL,\n  condition = NULL,\n  by = NULL,\n  newdata = NULL,\n  type = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  wts = FALSE,\n  slope = \"dydx\",\n  rug = FALSE,\n  gray = FALSE,\n  draw = TRUE,\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nvariables\n\n\nName of the variable whose marginal effect (slope) we want to plot on the y-axis.\n\n\n\n\ncondition\n\n\nConditional slopes\n\n\nCharacter vector (max length 4): Names of the predictors to display.\n\n\nNamed list (max length 4): List names correspond to predictors. List elements can be:\n\n\nNumeric vector\n\n\nFunction which returns a numeric vector or a set of unique categorical values\n\n\nShortcut strings for common reference values: \"minmax\", \"quartile\", \"threenum\"\n\n\n\n\n1: x-axis. 2: color/shape. 3: facet (wrap if no fourth variable, otherwise cols of grid). 4: facet (rows of grid).\n\n\nNumeric variables in positions 2 and 3 are summarized by Tukey’s five numbers ?stats::fivenum.\n\n\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nnewdata\n\n\nWhen newdata is NULL, the grid is determined by the condition argument. When newdata is not NULL, the argument behaves in the same way as in the slopes() function.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\nslope\n\n\nstring indicates the type of slope or (semi-)elasticity to compute:\n\n\n\"dydx\": dY/dX\n\n\n\"eyex\": dY/dX * Y / X\n\n\n\"eydx\": dY/dX * Y\n\n\n\"dyex\": dY/dX / X\n\n\nY is the predicted value of the outcome; X is the observed value of the predictor.\n\n\n\n\n\n\nrug\n\n\nTRUE displays tick marks on the axes to mark the distribution of raw data.\n\n\n\n\ngray\n\n\nFALSE grayscale or color plot\n\n\n\n\ndraw\n\n\nTRUE returns a ggplot2 plot. FALSE returns a data.frame of the underlying data.\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA ggplot2 object\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp * drat * factor(am), data = mtcars)\n\nplot_slopes(mod, variables = \"hp\", condition = \"drat\")\n\n\n\n\n\n\nplot_slopes(mod, variables = \"hp\", condition = c(\"drat\", \"am\"))\n\n\n\n\n\n\nplot_slopes(mod, variables = \"hp\", condition = list(\"am\", \"drat\" = 3:5))\n\n\n\n\n\n\nplot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = range))\n\n\n\n\n\n\nplot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))",
    "crumbs": [
      "Get started",
      "Functions",
      "`plot_slopes`"
    ]
  },
  {
    "objectID": "man/plot_slopes.html#plot-conditional-or-marginal-slopes",
    "href": "man/plot_slopes.html#plot-conditional-or-marginal-slopes",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Plot slopes on the y-axis against values of one or more predictors (x-axis, colors/shapes, and facets).\nThe by argument is used to plot marginal slopes, that is, slopes made on the original data, but averaged by subgroups. This is analogous to using the by argument in the slopes() function.\nThe condition argument is used to plot conditional slopes, that is, slopes computed on a user-specified grid. This is analogous to using the newdata argument and datagrid() function in a slopes() call. All variables whose values are not specified explicitly are treated as usual by datagrid(), that is, they are held at their mean or mode (or rounded mean for integers). This includes grouping variables in mixed-effects models, so analysts who fit such models may want to specify the groups of interest using the condition argument, or supply model-specific arguments to compute population-level estimates. See details below. See the \"Plots\" vignette and website for tutorials and information on how to customize plots:\n\n\nhttps://marginaleffects.com/vignettes/plot.html\n\n\nhttps://marginaleffects.com\n\n\nplot_slopes(\n  model,\n  variables = NULL,\n  condition = NULL,\n  by = NULL,\n  newdata = NULL,\n  type = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  wts = FALSE,\n  slope = \"dydx\",\n  rug = FALSE,\n  gray = FALSE,\n  draw = TRUE,\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nvariables\n\n\nName of the variable whose marginal effect (slope) we want to plot on the y-axis.\n\n\n\n\ncondition\n\n\nConditional slopes\n\n\nCharacter vector (max length 4): Names of the predictors to display.\n\n\nNamed list (max length 4): List names correspond to predictors. List elements can be:\n\n\nNumeric vector\n\n\nFunction which returns a numeric vector or a set of unique categorical values\n\n\nShortcut strings for common reference values: \"minmax\", \"quartile\", \"threenum\"\n\n\n\n\n1: x-axis. 2: color/shape. 3: facet (wrap if no fourth variable, otherwise cols of grid). 4: facet (rows of grid).\n\n\nNumeric variables in positions 2 and 3 are summarized by Tukey’s five numbers ?stats::fivenum.\n\n\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nnewdata\n\n\nWhen newdata is NULL, the grid is determined by the condition argument. When newdata is not NULL, the argument behaves in the same way as in the slopes() function.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\nslope\n\n\nstring indicates the type of slope or (semi-)elasticity to compute:\n\n\n\"dydx\": dY/dX\n\n\n\"eyex\": dY/dX * Y / X\n\n\n\"eydx\": dY/dX * Y\n\n\n\"dyex\": dY/dX / X\n\n\nY is the predicted value of the outcome; X is the observed value of the predictor.\n\n\n\n\n\n\nrug\n\n\nTRUE displays tick marks on the axes to mark the distribution of raw data.\n\n\n\n\ngray\n\n\nFALSE grayscale or color plot\n\n\n\n\ndraw\n\n\nTRUE returns a ggplot2 plot. FALSE returns a data.frame of the underlying data.\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA ggplot2 object\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp * drat * factor(am), data = mtcars)\n\nplot_slopes(mod, variables = \"hp\", condition = \"drat\")\n\n\n\n\n\n\nplot_slopes(mod, variables = \"hp\", condition = c(\"drat\", \"am\"))\n\n\n\n\n\n\nplot_slopes(mod, variables = \"hp\", condition = list(\"am\", \"drat\" = 3:5))\n\n\n\n\n\n\nplot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = range))\n\n\n\n\n\n\nplot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))",
    "crumbs": [
      "Get started",
      "Functions",
      "`plot_slopes`"
    ]
  },
  {
    "objectID": "man/plot_predictions.html",
    "href": "man/plot_predictions.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Plot predictions on the y-axis against values of one or more predictors (x-axis, colors/shapes, and facets).\nThe by argument is used to plot marginal predictions, that is, predictions made on the original data, but averaged by subgroups. This is analogous to using the by argument in the predictions() function.\nThe condition argument is used to plot conditional predictions, that is, predictions made on a user-specified grid. This is analogous to using the newdata argument and datagrid() function in a predictions() call. All variables whose values are not specified explicitly are treated as usual by datagrid(), that is, they are held at their mean or mode (or rounded mean for integers). This includes grouping variables in mixed-effects models, so analysts who fit such models may want to specify the groups of interest using the condition argument, or supply model-specific arguments to compute population-level estimates. See details below.\nSee the \"Plots\" vignette and website for tutorials and information on how to customize plots:\n\n\nhttps://marginaleffects.com/vignettes/plot.html\n\n\nhttps://marginaleffects.com\n\n\nplot_predictions(\n  model,\n  condition = NULL,\n  by = NULL,\n  newdata = NULL,\n  type = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  wts = FALSE,\n  transform = NULL,\n  points = 0,\n  rug = FALSE,\n  gray = FALSE,\n  draw = TRUE,\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\ncondition\n\n\nConditional predictions\n\n\nCharacter vector (max length 4): Names of the predictors to display.\n\n\nNamed list (max length 4): List names correspond to predictors. List elements can be:\n\n\nNumeric vector\n\n\nFunction which returns a numeric vector or a set of unique categorical values\n\n\nShortcut strings for common reference values: \"minmax\", \"quartile\", \"threenum\"\n\n\n\n\n1: x-axis. 2: color/shape. 3: facet (wrap if no fourth variable, otherwise cols of grid). 4: facet (rows of grid).\n\n\nNumeric variables in positions 2 and 3 are summarized by Tukey’s five numbers ?stats::fivenum\n\n\n\n\n\n\nby\n\n\nMarginal predictions\n\n\nCharacter vector (max length 3): Names of the categorical predictors to marginalize across.\n\n\n1: x-axis. 2: color. 3: facets.\n\n\n\n\n\n\nnewdata\n\n\nWhen newdata is NULL, the grid is determined by the condition argument. When newdata is not NULL, the argument behaves in the same way as in the predictions() function.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\ntransform\n\n\nA function applied to unit-level adjusted predictions and confidence intervals just before the function returns results. For bayesian models, this function is applied to individual draws from the posterior distribution, before computing summaries.\n\n\n\n\npoints\n\n\nNumber between 0 and 1 which controls the transparency of raw data points. 0 (default) does not display any points. Warning: The points displayed are raw data, so the resulting plot is not a \"partial residual plot.\"\n\n\n\n\nrug\n\n\nTRUE displays tick marks on the axes to mark the distribution of raw data.\n\n\n\n\ngray\n\n\nFALSE grayscale or color plot\n\n\n\n\ndraw\n\n\nTRUE returns a ggplot2 plot. FALSE returns a data.frame of the underlying data.\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA ggplot2 object or data frame (if draw=FALSE)\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\n\nlibrary(\"marginaleffects\")\n\nmod &lt;- lm(mpg ~ hp + wt, data = mtcars)\nplot_predictions(mod, condition = \"wt\")\n\n\n\n\n\n\nmod &lt;- lm(mpg ~ hp * wt * am, data = mtcars)\nplot_predictions(mod, condition = c(\"hp\", \"wt\"))\n\n\n\n\n\n\nplot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))\n\n\n\n\n\n\nplot_predictions(mod, condition = list(\"hp\", wt = range))",
    "crumbs": [
      "Get started",
      "Functions",
      "`plot_predictions`"
    ]
  },
  {
    "objectID": "man/plot_predictions.html#plot-conditional-or-marginal-predictions",
    "href": "man/plot_predictions.html#plot-conditional-or-marginal-predictions",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Plot predictions on the y-axis against values of one or more predictors (x-axis, colors/shapes, and facets).\nThe by argument is used to plot marginal predictions, that is, predictions made on the original data, but averaged by subgroups. This is analogous to using the by argument in the predictions() function.\nThe condition argument is used to plot conditional predictions, that is, predictions made on a user-specified grid. This is analogous to using the newdata argument and datagrid() function in a predictions() call. All variables whose values are not specified explicitly are treated as usual by datagrid(), that is, they are held at their mean or mode (or rounded mean for integers). This includes grouping variables in mixed-effects models, so analysts who fit such models may want to specify the groups of interest using the condition argument, or supply model-specific arguments to compute population-level estimates. See details below.\nSee the \"Plots\" vignette and website for tutorials and information on how to customize plots:\n\n\nhttps://marginaleffects.com/vignettes/plot.html\n\n\nhttps://marginaleffects.com\n\n\nplot_predictions(\n  model,\n  condition = NULL,\n  by = NULL,\n  newdata = NULL,\n  type = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  wts = FALSE,\n  transform = NULL,\n  points = 0,\n  rug = FALSE,\n  gray = FALSE,\n  draw = TRUE,\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\ncondition\n\n\nConditional predictions\n\n\nCharacter vector (max length 4): Names of the predictors to display.\n\n\nNamed list (max length 4): List names correspond to predictors. List elements can be:\n\n\nNumeric vector\n\n\nFunction which returns a numeric vector or a set of unique categorical values\n\n\nShortcut strings for common reference values: \"minmax\", \"quartile\", \"threenum\"\n\n\n\n\n1: x-axis. 2: color/shape. 3: facet (wrap if no fourth variable, otherwise cols of grid). 4: facet (rows of grid).\n\n\nNumeric variables in positions 2 and 3 are summarized by Tukey’s five numbers ?stats::fivenum\n\n\n\n\n\n\nby\n\n\nMarginal predictions\n\n\nCharacter vector (max length 3): Names of the categorical predictors to marginalize across.\n\n\n1: x-axis. 2: color. 3: facets.\n\n\n\n\n\n\nnewdata\n\n\nWhen newdata is NULL, the grid is determined by the condition argument. When newdata is not NULL, the argument behaves in the same way as in the predictions() function.\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\ntransform\n\n\nA function applied to unit-level adjusted predictions and confidence intervals just before the function returns results. For bayesian models, this function is applied to individual draws from the posterior distribution, before computing summaries.\n\n\n\n\npoints\n\n\nNumber between 0 and 1 which controls the transparency of raw data points. 0 (default) does not display any points. Warning: The points displayed are raw data, so the resulting plot is not a \"partial residual plot.\"\n\n\n\n\nrug\n\n\nTRUE displays tick marks on the axes to mark the distribution of raw data.\n\n\n\n\ngray\n\n\nFALSE grayscale or color plot\n\n\n\n\ndraw\n\n\nTRUE returns a ggplot2 plot. FALSE returns a data.frame of the underlying data.\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA ggplot2 object or data frame (if draw=FALSE)\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\n\nlibrary(\"marginaleffects\")\n\nmod &lt;- lm(mpg ~ hp + wt, data = mtcars)\nplot_predictions(mod, condition = \"wt\")\n\n\n\n\n\n\nmod &lt;- lm(mpg ~ hp * wt * am, data = mtcars)\nplot_predictions(mod, condition = c(\"hp\", \"wt\"))\n\n\n\n\n\n\nplot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))\n\n\n\n\n\n\nplot_predictions(mod, condition = list(\"hp\", wt = range))",
    "crumbs": [
      "Get started",
      "Functions",
      "`plot_predictions`"
    ]
  },
  {
    "objectID": "man/slopes.html",
    "href": "man/slopes.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Partial derivative of the regression equation with respect to a regressor of interest.\n\n\nslopes(): unit-level (conditional) estimates.\n\n\navg_slopes(): average (marginal) estimates.\n\n\nThe newdata argument and the datagrid() function can be used to control where statistics are evaluated in the predictor space: \"at observed values\", \"at the mean\", \"at representative values\", etc.\nSee the slopes vignette and package website for worked examples and case studies:\n\n\nhttps://marginaleffects.com/vignettes/slopes.html\n\n\nhttps://marginaleffects.com/\n\n\nslopes(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  type = NULL,\n  by = FALSE,\n  vcov = TRUE,\n  conf_level = 0.95,\n  slope = \"dydx\",\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\navg_slopes(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  type = NULL,\n  by = TRUE,\n  vcov = TRUE,\n  conf_level = 0.95,\n  slope = \"dydx\",\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\nGrid of predictor values at which we evaluate the slopes.\n\n\nWarning: Please avoid modifying your dataset between fitting the model and calling a marginaleffects function. This can sometimes lead to unexpected results.\n\n\nNULL (default): Unit-level slopes for each observed value in the dataset (empirical distribution). The dataset is retrieved using insight::get_data(), which tries to extract data from the environment. This may produce unexpected results if the original data frame has been altered since fitting the model.\n\n\ndatagrid() call to specify a custom grid of regressors. For example:\n\n\nnewdata = datagrid(cyl = c(4, 6)): cyl variable equal to 4 and 6 and other regressors fixed at their means or modes.\n\n\nSee the Examples section and the datagrid() documentation.\n\n\n\n\nsubset() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = subset(treatment == 1)\n\n\ndplyr::filter() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = filter(treatment == 1)\n\n\nstring:\n\n\n\"mean\": Slopes evaluated when each predictor is held at its mean or mode.\n\n\n\"median\": Slopes evaluated when each predictor is held at its median or mode.\n\n\n\"balanced\": Slopes evaluated on a balanced grid with every combination of categories and numeric variables held at their means.\n\n\n\"tukey\": Slopes evaluated at Tukey’s 5 numbers.\n\n\n\"grid\": Slopes evaluated on a grid of representative numbers (Tukey’s 5 numbers and unique values of categorical predictors).\n\n\n\n\n\n\n\n\nvariables\n\n\nFocal variables\n\n\nNULL: compute slopes or comparisons for all the variables in the model object (can be slow).\n\n\nCharacter vector: subset of variables (usually faster).\n\n\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nslope\n\n\nstring indicates the type of slope or (semi-)elasticity to compute:\n\n\n\"dydx\": dY/dX\n\n\n\"eyex\": dY/dX * Y / X\n\n\n\"eydx\": dY/dX * Y\n\n\n\"dyex\": dY/dX / X\n\n\nY is the predicted value of the outcome; X is the observed value of the predictor.\n\n\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\np_adjust\n\n\nAdjust p-values for multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", or \"fdr\". See stats::p.adjust\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When df is Inf, the normal distribution is used. When df is finite, the t distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: slopes(model, df = insight::get_df(model))\n\n\n\n\neps\n\n\nNULL or numeric value which determines the step size to use when calculating numerical derivatives: (f(x+eps)-f(x))/eps. When eps is NULL, the step size is 0.0001 multiplied by the difference between the maximum and minimum values of the variable with respect to which we are taking the derivative. Changing eps may be necessary to avoid numerical problems in certain models.\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA \"slope\" or \"marginal effect\" is the partial derivative of the regression equation with respect to a variable in the model. This function uses automatic differentiation to compute slopes for a vast array of models, including non-linear models with transformations (e.g., polynomials). Uncertainty estimates are computed using the delta method.\nNumerical derivatives for the slopes function are calculated using a simple epsilon difference approach: \\(\\partial Y / \\partial X = (f(X + \\varepsilon/2) - f(X-\\varepsilon/2)) / \\varepsilon\\), where f is the predict() method associated with the model class, and \\(\\varepsilon\\) is determined by the eps argument.\n\nA data.frame with one row per observation (per term/group) and several columns:\n\n\nrowid: row number of the newdata data frame\n\n\ntype: prediction type, as defined by the type argument\n\n\ngroup: (optional) value of the grouped outcome (e.g., categorical outcome models)\n\n\nterm: the variable whose marginal effect is computed\n\n\ndydx: slope of the outcome with respect to the term, for a given combination of predictor values\n\n\nstd.error: standard errors computed by via the delta method.\n\n\np.value: p value associated to the estimate column. The null is determined by the hypothesis argument (0 by default), and p values are computed before applying the transform argument. For models of class feglm, Gam, glm and negbin, p values are computed on the link scale by default unless the type argument is specified explicitly.\n\n\ns.value: Shannon information transforms of p values. How many consecutive \"heads\" tosses would provide the same amount of evidence (or \"surprise\") against the null hypothesis that the coin is fair? The purpose of S is to calibrate the analyst’s intuition about the strength of evidence encoded in p against a well-known physical phenomenon. See Greenland (2019) and Cole et al. (2020).\n\n\nconf.low: lower bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nconf.high: upper bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nSee ?print.marginaleffects for printing options.\n\n\n\navg_slopes(): Average slopes\n\n\nStandard errors for all quantities estimated by marginaleffects can be obtained via the delta method. This requires differentiating a function with respect to the coefficients in the model using a finite difference approach. In some models, the delta method standard errors can be sensitive to various aspects of the numeric differentiation strategy, including the step size. By default, the step size is set to 1e-8, or to 1e-4 times the smallest absolute model coefficient, whichever is largest.\nmarginaleffects can delegate numeric differentiation to the numDeriv package, which allows more flexibility. To do this, users can pass arguments to the numDeriv::jacobian function through a global option. For example:\n\n\noptions(marginaleffects_numDeriv = list(method = “simple”, method.args = list(eps = 1e-6)))\n\n\noptions(marginaleffects_numDeriv = list(method = “Richardson”, method.args = list(eps = 1e-5)))\n\n\noptions(marginaleffects_numDeriv = NULL)\n\n\nSee the \"Standard Errors and Confidence Intervals\" vignette on the marginaleffects website for more details on the computation of standard errors:\nhttps://marginaleffects.com/vignettes/uncertainty.html\nNote that the inferences() function can be used to compute uncertainty estimates using a bootstrap or simulation-based inference. See the vignette:\nhttps://marginaleffects.com/vignettes/bootstrap.html\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nBy default, credible intervals in bayesian models are built as equal-tailed intervals. This can be changed to a highest density interval by setting a global option:\noptions(“marginaleffects_posterior_interval” = “eti”)\noptions(“marginaleffects_posterior_interval” = “hdi”)\nBy default, the center of the posterior distribution in bayesian models is identified by the median. Users can use a different summary function by setting a global option:\noptions(“marginaleffects_posterior_center” = “mean”)\noptions(“marginaleffects_posterior_center” = “median”)\nWhen estimates are averaged using the by argument, the tidy() function, or the summary() function, the posterior distribution is marginalized twice over. First, we take the average across units but within each iteration of the MCMC chain, according to what the user requested in by argument or tidy()/summary() functions. Then, we identify the center of the resulting posterior using the function supplied to the “marginaleffects_posterior_center” option (the median by default).\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\nThe slopes() and comparisons() functions can use parallelism to speed up computation. Operations are parallelized for the computation of standard errors, at the model coefficient level. There is always considerable overhead when using parallel computation, mainly involved in passing the whole dataset to the different processes. Thus, parallel computation is most likely to be useful when the model includes many parameters and the dataset is relatively small.\nWarning: In many cases, parallel processing will not be useful at all.\nTo activate parallel computation, users must load the future.apply package, call plan() function, and set a global option. For example:\n\nlibrary(future.apply)\nplan(\"multicore\", workers = 4)\noptions(marginaleffects_parallel = TRUE)\n\nslopes(model)\n\n\nTo disable parallelism in marginaleffects altogether, you can set a global option:\n\noptions(marginaleffects_parallel = FALSE)\n\n\n\nBehind the scenes, the arguments of marginaleffects functions are evaluated in this order:\n\n\nnewdata\n\n\nvariables\n\n\ncomparison and slopes\n\n\nby\n\n\nvcov\n\n\nhypothesis\n\n\ntransform\n\n\nThe behavior of marginaleffects functions can be modified by setting global options.\nDisable some safety checks:\n\noptions(marginaleffects_safe = FALSE)`\n\n\nOmit some columns from the printed output:\n\noptions(marginaleffects_print_omit = c(\"p.value\", \"s.value\"))`\n\n\n\n\n\nGreenland S. 2019. \"Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values.\" The American Statistician. 73(S1): 106–114.\n\n\nCole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. \"Surprise!\" American Journal of Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136\n\n\n\nlibrary(\"marginaleffects\")\n\n\n\n# Unit-level (conditional) Marginal Effects\nmod &lt;- glm(am ~ hp * wt, data = mtcars, family = binomial)\nmfx &lt;- slopes(mod)\nhead(mfx)\n\n# Average Marginal Effect (AME)\navg_slopes(mod, by = TRUE)\n\n\n# Marginal Effect at the Mean (MEM)\nslopes(mod, newdata = datagrid())\n\n# Marginal Effect at User-Specified Values\n# Variables not explicitly included in `datagrid()` are held at their means\nslopes(mod, newdata = datagrid(hp = c(100, 110)))\n\n# Group-Average Marginal Effects (G-AME)\n# Calculate marginal effects for each observation, and then take the average\n# marginal effect within each subset of observations with different observed\n# values for the `cyl` variable:\nmod2 &lt;- lm(mpg ~ hp * cyl, data = mtcars)\navg_slopes(mod2, variables = \"hp\", by = \"cyl\")\n\n# Marginal Effects at User-Specified Values (counterfactual)\n# Variables not explicitly included in `datagrid()` are held at their\n# original values, and the whole dataset is duplicated once for each\n# combination of the values in `datagrid()`\nmfx &lt;- slopes(mod,\n    newdata = datagrid(\n        hp = c(100, 110),\n        grid_type = \"counterfactual\"))\nhead(mfx)\n\n# Heteroskedasticity robust standard errors\nmfx &lt;- slopes(mod, vcov = sandwich::vcovHC(mod))\nhead(mfx)\n\n# hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect\nmod &lt;- lm(mpg ~ wt + drat, data = mtcars)\n\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"wt = drat\")\n\n# same hypothesis test using row indices\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"b1 - b2 = 0\")\n\n# same hypothesis test using numeric vector of weights\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = c(1, -1))\n\n# two custom contrasts using a matrix of weights\nlc &lt;- matrix(\n    c(\n        1, -1,\n        2, 3),\n    ncol = 2)\ncolnames(lc) &lt;- c(\"Contrast A\", \"Contrast B\")\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = lc)",
    "crumbs": [
      "Get started",
      "Functions",
      "`slopes`"
    ]
  },
  {
    "objectID": "man/slopes.html#slopes-aka-partial-derivatives-marginal-effects-or-trends",
    "href": "man/slopes.html#slopes-aka-partial-derivatives-marginal-effects-or-trends",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Partial derivative of the regression equation with respect to a regressor of interest.\n\n\nslopes(): unit-level (conditional) estimates.\n\n\navg_slopes(): average (marginal) estimates.\n\n\nThe newdata argument and the datagrid() function can be used to control where statistics are evaluated in the predictor space: \"at observed values\", \"at the mean\", \"at representative values\", etc.\nSee the slopes vignette and package website for worked examples and case studies:\n\n\nhttps://marginaleffects.com/vignettes/slopes.html\n\n\nhttps://marginaleffects.com/\n\n\nslopes(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  type = NULL,\n  by = FALSE,\n  vcov = TRUE,\n  conf_level = 0.95,\n  slope = \"dydx\",\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\navg_slopes(\n  model,\n  newdata = NULL,\n  variables = NULL,\n  type = NULL,\n  by = TRUE,\n  vcov = TRUE,\n  conf_level = 0.95,\n  slope = \"dydx\",\n  wts = FALSE,\n  hypothesis = NULL,\n  equivalence = NULL,\n  p_adjust = NULL,\n  df = Inf,\n  eps = NULL,\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object\n\n\n\n\nnewdata\n\n\nGrid of predictor values at which we evaluate the slopes.\n\n\nWarning: Please avoid modifying your dataset between fitting the model and calling a marginaleffects function. This can sometimes lead to unexpected results.\n\n\nNULL (default): Unit-level slopes for each observed value in the dataset (empirical distribution). The dataset is retrieved using insight::get_data(), which tries to extract data from the environment. This may produce unexpected results if the original data frame has been altered since fitting the model.\n\n\ndatagrid() call to specify a custom grid of regressors. For example:\n\n\nnewdata = datagrid(cyl = c(4, 6)): cyl variable equal to 4 and 6 and other regressors fixed at their means or modes.\n\n\nSee the Examples section and the datagrid() documentation.\n\n\n\n\nsubset() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = subset(treatment == 1)\n\n\ndplyr::filter() call with a single argument to select a subset of the dataset used to fit the model, ex: newdata = filter(treatment == 1)\n\n\nstring:\n\n\n\"mean\": Slopes evaluated when each predictor is held at its mean or mode.\n\n\n\"median\": Slopes evaluated when each predictor is held at its median or mode.\n\n\n\"balanced\": Slopes evaluated on a balanced grid with every combination of categories and numeric variables held at their means.\n\n\n\"tukey\": Slopes evaluated at Tukey’s 5 numbers.\n\n\n\"grid\": Slopes evaluated on a grid of representative numbers (Tukey’s 5 numbers and unique values of categorical predictors).\n\n\n\n\n\n\n\n\nvariables\n\n\nFocal variables\n\n\nNULL: compute slopes or comparisons for all the variables in the model object (can be slow).\n\n\nCharacter vector: subset of variables (usually faster).\n\n\n\n\n\n\ntype\n\n\nstring indicates the type (scale) of the predictions used to compute contrasts or slopes. This can differ based on the model type, but will typically be a string such as: \"response\", \"link\", \"probs\", or \"zero\". When an unsupported string is entered, the model-specific list of acceptable values is returned in an error message. When type is NULL, the first entry in the error message is used by default.\n\n\n\n\nby\n\n\nAggregate unit-level estimates (aka, marginalize, average over). Valid inputs:\n\n\nFALSE: return the original unit-level estimates.\n\n\nTRUE: aggregate estimates for each term.\n\n\nCharacter vector of column names in newdata or in the data frame produced by calling the function without the by argument.\n\n\nData frame with a by column of group labels, and merging columns shared by newdata or the data frame produced by calling the same function without the by argument.\n\n\nSee examples below.\n\n\nFor more complex aggregations, you can use the FUN argument of the hypotheses() function. See that function’s documentation and the Hypothesis Test vignettes on the marginaleffects website.\n\n\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\nslope\n\n\nstring indicates the type of slope or (semi-)elasticity to compute:\n\n\n\"dydx\": dY/dX\n\n\n\"eyex\": dY/dX * Y / X\n\n\n\"eydx\": dY/dX * Y\n\n\n\"dyex\": dY/dX / X\n\n\nY is the predicted value of the outcome; X is the observed value of the predictor.\n\n\n\n\n\n\nwts\n\n\nlogical, string or numeric: weights to use when computing average predictions, contrasts or slopes. These weights only affect the averaging in avg_*() or with the by argument, and not unit-level estimates. See ?weighted.mean\n\n\nstring: column name of the weights variable in newdata. When supplying a column name to wts, it is recommended to supply the original data (including the weights variable) explicitly to newdata.\n\n\nnumeric: vector of length equal to the number of rows in the original data or in newdata (if supplied).\n\n\nFALSE: Equal weights.\n\n\nTRUE: Extract weights from the fitted object with insight::find_weights() and use them when taking weighted averages of estimates. Warning: newdata=datagrid() returns a single average weight, which is equivalent to using wts=FALSE\n\n\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\np_adjust\n\n\nAdjust p-values for multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", or \"fdr\". See stats::p.adjust\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When df is Inf, the normal distribution is used. When df is finite, the t distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: slopes(model, df = insight::get_df(model))\n\n\n\n\neps\n\n\nNULL or numeric value which determines the step size to use when calculating numerical derivatives: (f(x+eps)-f(x))/eps. When eps is NULL, the step size is 0.0001 multiplied by the difference between the maximum and minimum values of the variable with respect to which we are taking the derivative. Changing eps may be necessary to avoid numerical problems in certain models.\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nA \"slope\" or \"marginal effect\" is the partial derivative of the regression equation with respect to a variable in the model. This function uses automatic differentiation to compute slopes for a vast array of models, including non-linear models with transformations (e.g., polynomials). Uncertainty estimates are computed using the delta method.\nNumerical derivatives for the slopes function are calculated using a simple epsilon difference approach: \\(\\partial Y / \\partial X = (f(X + \\varepsilon/2) - f(X-\\varepsilon/2)) / \\varepsilon\\), where f is the predict() method associated with the model class, and \\(\\varepsilon\\) is determined by the eps argument.\n\nA data.frame with one row per observation (per term/group) and several columns:\n\n\nrowid: row number of the newdata data frame\n\n\ntype: prediction type, as defined by the type argument\n\n\ngroup: (optional) value of the grouped outcome (e.g., categorical outcome models)\n\n\nterm: the variable whose marginal effect is computed\n\n\ndydx: slope of the outcome with respect to the term, for a given combination of predictor values\n\n\nstd.error: standard errors computed by via the delta method.\n\n\np.value: p value associated to the estimate column. The null is determined by the hypothesis argument (0 by default), and p values are computed before applying the transform argument. For models of class feglm, Gam, glm and negbin, p values are computed on the link scale by default unless the type argument is specified explicitly.\n\n\ns.value: Shannon information transforms of p values. How many consecutive \"heads\" tosses would provide the same amount of evidence (or \"surprise\") against the null hypothesis that the coin is fair? The purpose of S is to calibrate the analyst’s intuition about the strength of evidence encoded in p against a well-known physical phenomenon. See Greenland (2019) and Cole et al. (2020).\n\n\nconf.low: lower bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nconf.high: upper bound of the confidence interval (or equal-tailed interval for bayesian models)\n\n\nSee ?print.marginaleffects for printing options.\n\n\n\navg_slopes(): Average slopes\n\n\nStandard errors for all quantities estimated by marginaleffects can be obtained via the delta method. This requires differentiating a function with respect to the coefficients in the model using a finite difference approach. In some models, the delta method standard errors can be sensitive to various aspects of the numeric differentiation strategy, including the step size. By default, the step size is set to 1e-8, or to 1e-4 times the smallest absolute model coefficient, whichever is largest.\nmarginaleffects can delegate numeric differentiation to the numDeriv package, which allows more flexibility. To do this, users can pass arguments to the numDeriv::jacobian function through a global option. For example:\n\n\noptions(marginaleffects_numDeriv = list(method = “simple”, method.args = list(eps = 1e-6)))\n\n\noptions(marginaleffects_numDeriv = list(method = “Richardson”, method.args = list(eps = 1e-5)))\n\n\noptions(marginaleffects_numDeriv = NULL)\n\n\nSee the \"Standard Errors and Confidence Intervals\" vignette on the marginaleffects website for more details on the computation of standard errors:\nhttps://marginaleffects.com/vignettes/uncertainty.html\nNote that the inferences() function can be used to compute uncertainty estimates using a bootstrap or simulation-based inference. See the vignette:\nhttps://marginaleffects.com/vignettes/bootstrap.html\n\nSome model types allow model-specific arguments to modify the nature of marginal effects, predictions, marginal means, and contrasts. Please report other package-specific predict() arguments on Github so we can add them to the table below.\nhttps://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\nPackage\n\n\nClass\n\n\nArgument\n\n\nDocumentation\n\n\n\n\nbrms\n\n\nbrmsfit\n\n\nndraws\n\n\nbrms::posterior_predict\n\n\n\n\n\n\n\n\nre_formula\n\n\nbrms::posterior_predict\n\n\n\n\nlme4\n\n\nmerMod\n\n\nre.form\n\n\nlme4::predict.merMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nlme4::predict.merMod\n\n\n\n\nglmmTMB\n\n\nglmmTMB\n\n\nre.form\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\n\n\n\n\nzitype\n\n\nglmmTMB::predict.glmmTMB\n\n\n\n\nmgcv\n\n\nbam\n\n\nexclude\n\n\nmgcv::predict.bam\n\n\n\n\n\n\ngam\n\n\nexclude\n\n\nmgcv::predict.gam\n\n\n\n\nrobustlmm\n\n\nrlmerMod\n\n\nre.form\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\n\n\n\n\nallow.new.levels\n\n\nrobustlmm::predict.rlmerMod\n\n\n\n\nMCMCglmm\n\n\nMCMCglmm\n\n\nndraws\n\n\n\n\n\n\nsampleSelection\n\n\nselection\n\n\npart\n\n\nsampleSelection::predict.selection\n\n\n\n\n\n\n\nBy default, credible intervals in bayesian models are built as equal-tailed intervals. This can be changed to a highest density interval by setting a global option:\noptions(“marginaleffects_posterior_interval” = “eti”)\noptions(“marginaleffects_posterior_interval” = “hdi”)\nBy default, the center of the posterior distribution in bayesian models is identified by the median. Users can use a different summary function by setting a global option:\noptions(“marginaleffects_posterior_center” = “mean”)\noptions(“marginaleffects_posterior_center” = “median”)\nWhen estimates are averaged using the by argument, the tidy() function, or the summary() function, the posterior distribution is marginalized twice over. First, we take the average across units but within each iteration of the MCMC chain, according to what the user requested in by argument or tidy()/summary() functions. Then, we identify the center of the resulting posterior using the function supplied to the “marginaleffects_posterior_center” option (the median by default).\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\nThe type argument determines the scale of the predictions used to compute quantities of interest with functions from the marginaleffects package. Admissible values for type depend on the model object. When users specify an incorrect value for type, marginaleffects will raise an informative error with a list of valid type values for the specific model object. The first entry in the list in that error message is the default type.\nThe invlink(link) is a special type defined by marginaleffects. It is available for some (but not all) models, and only for the predictions() function. With this link type, we first compute predictions on the link scale, then we use the inverse link function to backtransform the predictions to the response scale. This is useful for models with non-linear link functions as it can ensure that confidence intervals stay within desirable bounds, ex: 0 to 1 for a logit model. Note that an average of estimates with type=“invlink(link)” will not always be equivalent to the average of estimates with type=“response”. This type is default when calling predictions(). It is available—but not default—when calling avg_predictions() or predictions() with the by argument.\nSome of the most common type values are:\nresponse, link, E, Ep, average, class, conditional, count, cum.prob, cumhaz, cumprob, density, detection, disp, ev, expected, expvalue, fitted, hazard, invlink(link), latent, latent_N, linear, linear.predictor, linpred, location, lp, mean, numeric, p, ppd, pr, precision, prediction, prob, probability, probs, quantile, risk, rmst, scale, survival, unconditional, utility, variance, xb, zero, zlink, zprob\n\nThe slopes() and comparisons() functions can use parallelism to speed up computation. Operations are parallelized for the computation of standard errors, at the model coefficient level. There is always considerable overhead when using parallel computation, mainly involved in passing the whole dataset to the different processes. Thus, parallel computation is most likely to be useful when the model includes many parameters and the dataset is relatively small.\nWarning: In many cases, parallel processing will not be useful at all.\nTo activate parallel computation, users must load the future.apply package, call plan() function, and set a global option. For example:\n\nlibrary(future.apply)\nplan(\"multicore\", workers = 4)\noptions(marginaleffects_parallel = TRUE)\n\nslopes(model)\n\n\nTo disable parallelism in marginaleffects altogether, you can set a global option:\n\noptions(marginaleffects_parallel = FALSE)\n\n\n\nBehind the scenes, the arguments of marginaleffects functions are evaluated in this order:\n\n\nnewdata\n\n\nvariables\n\n\ncomparison and slopes\n\n\nby\n\n\nvcov\n\n\nhypothesis\n\n\ntransform\n\n\nThe behavior of marginaleffects functions can be modified by setting global options.\nDisable some safety checks:\n\noptions(marginaleffects_safe = FALSE)`\n\n\nOmit some columns from the printed output:\n\noptions(marginaleffects_print_omit = c(\"p.value\", \"s.value\"))`\n\n\n\n\n\nGreenland S. 2019. \"Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values.\" The American Statistician. 73(S1): 106–114.\n\n\nCole, Stephen R, Jessie K Edwards, and Sander Greenland. 2020. \"Surprise!\" American Journal of Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136\n\n\n\nlibrary(\"marginaleffects\")\n\n\n\n# Unit-level (conditional) Marginal Effects\nmod &lt;- glm(am ~ hp * wt, data = mtcars, family = binomial)\nmfx &lt;- slopes(mod)\nhead(mfx)\n\n# Average Marginal Effect (AME)\navg_slopes(mod, by = TRUE)\n\n\n# Marginal Effect at the Mean (MEM)\nslopes(mod, newdata = datagrid())\n\n# Marginal Effect at User-Specified Values\n# Variables not explicitly included in `datagrid()` are held at their means\nslopes(mod, newdata = datagrid(hp = c(100, 110)))\n\n# Group-Average Marginal Effects (G-AME)\n# Calculate marginal effects for each observation, and then take the average\n# marginal effect within each subset of observations with different observed\n# values for the `cyl` variable:\nmod2 &lt;- lm(mpg ~ hp * cyl, data = mtcars)\navg_slopes(mod2, variables = \"hp\", by = \"cyl\")\n\n# Marginal Effects at User-Specified Values (counterfactual)\n# Variables not explicitly included in `datagrid()` are held at their\n# original values, and the whole dataset is duplicated once for each\n# combination of the values in `datagrid()`\nmfx &lt;- slopes(mod,\n    newdata = datagrid(\n        hp = c(100, 110),\n        grid_type = \"counterfactual\"))\nhead(mfx)\n\n# Heteroskedasticity robust standard errors\nmfx &lt;- slopes(mod, vcov = sandwich::vcovHC(mod))\nhead(mfx)\n\n# hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect\nmod &lt;- lm(mpg ~ wt + drat, data = mtcars)\n\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"wt = drat\")\n\n# same hypothesis test using row indices\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = \"b1 - b2 = 0\")\n\n# same hypothesis test using numeric vector of weights\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = c(1, -1))\n\n# two custom contrasts using a matrix of weights\nlc &lt;- matrix(\n    c(\n        1, -1,\n        2, 3),\n    ncol = 2)\ncolnames(lc) &lt;- c(\"Contrast A\", \"Contrast B\")\nslopes(\n    mod,\n    newdata = \"mean\",\n    hypothesis = lc)",
    "crumbs": [
      "Get started",
      "Functions",
      "`slopes`"
    ]
  },
  {
    "objectID": "man/inferences.html",
    "href": "man/inferences.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Warning: This function is experimental. It may be renamed, the user interface may change, or the functionality may migrate to arguments in other marginaleffects functions.\nApply this function to a marginaleffects object to change the inferential method used to compute uncertainty estimates.\n\ninferences(\n  x,\n  method,\n  R = 1000,\n  conf_type = \"perc\",\n  conformal_test = NULL,\n  conformal_calibration = NULL,\n  conformal_score = \"residual_abs\",\n  ...\n)\n\n\n\n\n\nx\n\n\nObject produced by one of the core marginaleffects functions.\n\n\n\n\nmethod\n\n\nString\n\n\n\"delta\": delta method standard errors\n\n\n\"boot\" package\n\n\n\"fwb\": fractional weighted bootstrap\n\n\n\"rsample\" package\n\n\n\"simulation\" from a multivariate normal distribution (Krinsky & Robb, 1986)\n\n\n\"mi\" multiple imputation for missing data\n\n\n\"conformal_split\": prediction intervals using split conformal prediction (see Angelopoulos & Bates, 2022)\n\n\n\"conformal_cv+\": prediction intervals using cross-validation+ conformal prediction (see Barber et al., 2020)\n\n\n\n\n\n\nR\n\n\nNumber of resamples, simulations, or cross-validation folds.\n\n\n\n\nconf_type\n\n\nString: type of bootstrap interval to construct.\n\n\nboot: \"perc\", \"norm\", \"basic\", or \"bca\"\n\n\nfwb: \"perc\", \"norm\", \"basic\", \"bc\", or \"bca\"\n\n\nrsample: \"perc\" or \"bca\"\n\n\nsimulation: argument ignored.\n\n\n\n\n\n\nconformal_test\n\n\nData frame of test data for conformal prediction.\n\n\n\n\nconformal_calibration\n\n\nData frame of calibration data for split conformal prediction (method=“conformal_split).\n\n\n\n\nconformal_score\n\n\nString. Warning: The type argument in predictions() must generate predictions which are on the same scale as the outcome variable. Typically, this means that type must be \"response\" or \"probs\".\n\n\n\"residual_abs\" or \"residual_sq\" for regression tasks (numeric outcome)\n\n\n\"softmax\" for classification tasks (when predictions() returns a group columns, such as multinomial or ordinal logit models.\n\n\n\n\n\n\n…\n\n\n\n\nIf method=“boot”, additional arguments are passed to boot::boot().\n\n\nIf method=“fwb”, additional arguments are passed to fwb::fwb().\n\n\nIf method=“rsample”, additional arguments are passed to rsample::bootstraps().\n\n\nAdditional arguments are ignored for all other methods.\n\n\n\n\n\nWhen method=“simulation”, we conduct simulation-based inference following the method discussed in Krinsky & Robb (1986):\n\n\nDraw R sets of simulated coefficients from a multivariate normal distribution with mean equal to the original model’s estimated coefficients and variance equal to the model’s variance-covariance matrix (classical, \"HC3\", or other).\n\n\nUse the R sets of coefficients to compute R sets of estimands: predictions, comparisons, slopes, or hypotheses.\n\n\nTake quantiles of the resulting distribution of estimands to obtain a confidence interval and the standard deviation of simulated estimates to estimate the standard error.\n\n\nWhen method=“fwb”, drawn weights are supplied to the model fitting function’s weights argument; if the model doesn’t accept non-integer weights, this method should not be used. If weights were included in the original model fit, they are extracted by weights() and multiplied by the drawn weights. These weights are supplied to the wts argument of the estimation function (e.g., comparisons()).\n\nA marginaleffects object with simulation or bootstrap resamples and objects attached.\n\nKrinsky, I., and A. L. Robb. 1986. “On Approximating the Statistical Properties of Elasticities.” Review of Economics and Statistics 68 (4): 715–9.\nKing, Gary, Michael Tomz, and Jason Wittenberg. \"Making the most of statistical analyses: Improving interpretation and presentation.\" American journal of political science (2000): 347-361\nDowd, Bryan E., William H. Greene, and Edward C. Norton. \"Computation of standard errors.\" Health services research 49.2 (2014): 731-750.\nAngelopoulos, Anastasios N., and Stephen Bates. 2022. \"A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.\" arXiv. https://doi.org/10.48550/arXiv.2107.07511.\nBarber, Rina Foygel, Emmanuel J. Candes, Aaditya Ramdas, and Ryan J. Tibshirani. 2020. “Predictive Inference with the Jackknife+.” arXiv. http://arxiv.org/abs/1905.02928.\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nlibrary(magrittr)\nset.seed(1024)\nmod &lt;- lm(Sepal.Length ~ Sepal.Width * Species, data = iris)\n\n# bootstrap\navg_predictions(mod, by = \"Species\") %&gt;%\n  inferences(method = \"boot\")\n\navg_predictions(mod, by = \"Species\") %&gt;%\n  inferences(method = \"rsample\")\n\n# Fractional (bayesian) bootstrap\navg_slopes(mod, by = \"Species\") %&gt;%\n  inferences(method = \"fwb\") %&gt;%\n  posterior_draws(\"rvar\") %&gt;%\n  data.frame()\n\n# Simulation-based inference\nslopes(mod) %&gt;%\n  inferences(method = \"simulation\") %&gt;%\n  head()",
    "crumbs": [
      "Get started",
      "Functions",
      "`inferences`"
    ]
  },
  {
    "objectID": "man/inferences.html#experimental-bootstrap-conformal-and-simulation-based-inference",
    "href": "man/inferences.html#experimental-bootstrap-conformal-and-simulation-based-inference",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Warning: This function is experimental. It may be renamed, the user interface may change, or the functionality may migrate to arguments in other marginaleffects functions.\nApply this function to a marginaleffects object to change the inferential method used to compute uncertainty estimates.\n\ninferences(\n  x,\n  method,\n  R = 1000,\n  conf_type = \"perc\",\n  conformal_test = NULL,\n  conformal_calibration = NULL,\n  conformal_score = \"residual_abs\",\n  ...\n)\n\n\n\n\n\nx\n\n\nObject produced by one of the core marginaleffects functions.\n\n\n\n\nmethod\n\n\nString\n\n\n\"delta\": delta method standard errors\n\n\n\"boot\" package\n\n\n\"fwb\": fractional weighted bootstrap\n\n\n\"rsample\" package\n\n\n\"simulation\" from a multivariate normal distribution (Krinsky & Robb, 1986)\n\n\n\"mi\" multiple imputation for missing data\n\n\n\"conformal_split\": prediction intervals using split conformal prediction (see Angelopoulos & Bates, 2022)\n\n\n\"conformal_cv+\": prediction intervals using cross-validation+ conformal prediction (see Barber et al., 2020)\n\n\n\n\n\n\nR\n\n\nNumber of resamples, simulations, or cross-validation folds.\n\n\n\n\nconf_type\n\n\nString: type of bootstrap interval to construct.\n\n\nboot: \"perc\", \"norm\", \"basic\", or \"bca\"\n\n\nfwb: \"perc\", \"norm\", \"basic\", \"bc\", or \"bca\"\n\n\nrsample: \"perc\" or \"bca\"\n\n\nsimulation: argument ignored.\n\n\n\n\n\n\nconformal_test\n\n\nData frame of test data for conformal prediction.\n\n\n\n\nconformal_calibration\n\n\nData frame of calibration data for split conformal prediction (method=“conformal_split).\n\n\n\n\nconformal_score\n\n\nString. Warning: The type argument in predictions() must generate predictions which are on the same scale as the outcome variable. Typically, this means that type must be \"response\" or \"probs\".\n\n\n\"residual_abs\" or \"residual_sq\" for regression tasks (numeric outcome)\n\n\n\"softmax\" for classification tasks (when predictions() returns a group columns, such as multinomial or ordinal logit models.\n\n\n\n\n\n\n…\n\n\n\n\nIf method=“boot”, additional arguments are passed to boot::boot().\n\n\nIf method=“fwb”, additional arguments are passed to fwb::fwb().\n\n\nIf method=“rsample”, additional arguments are passed to rsample::bootstraps().\n\n\nAdditional arguments are ignored for all other methods.\n\n\n\n\n\nWhen method=“simulation”, we conduct simulation-based inference following the method discussed in Krinsky & Robb (1986):\n\n\nDraw R sets of simulated coefficients from a multivariate normal distribution with mean equal to the original model’s estimated coefficients and variance equal to the model’s variance-covariance matrix (classical, \"HC3\", or other).\n\n\nUse the R sets of coefficients to compute R sets of estimands: predictions, comparisons, slopes, or hypotheses.\n\n\nTake quantiles of the resulting distribution of estimands to obtain a confidence interval and the standard deviation of simulated estimates to estimate the standard error.\n\n\nWhen method=“fwb”, drawn weights are supplied to the model fitting function’s weights argument; if the model doesn’t accept non-integer weights, this method should not be used. If weights were included in the original model fit, they are extracted by weights() and multiplied by the drawn weights. These weights are supplied to the wts argument of the estimation function (e.g., comparisons()).\n\nA marginaleffects object with simulation or bootstrap resamples and objects attached.\n\nKrinsky, I., and A. L. Robb. 1986. “On Approximating the Statistical Properties of Elasticities.” Review of Economics and Statistics 68 (4): 715–9.\nKing, Gary, Michael Tomz, and Jason Wittenberg. \"Making the most of statistical analyses: Improving interpretation and presentation.\" American journal of political science (2000): 347-361\nDowd, Bryan E., William H. Greene, and Edward C. Norton. \"Computation of standard errors.\" Health services research 49.2 (2014): 731-750.\nAngelopoulos, Anastasios N., and Stephen Bates. 2022. \"A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.\" arXiv. https://doi.org/10.48550/arXiv.2107.07511.\nBarber, Rina Foygel, Emmanuel J. Candes, Aaditya Ramdas, and Ryan J. Tibshirani. 2020. “Predictive Inference with the Jackknife+.” arXiv. http://arxiv.org/abs/1905.02928.\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nlibrary(magrittr)\nset.seed(1024)\nmod &lt;- lm(Sepal.Length ~ Sepal.Width * Species, data = iris)\n\n# bootstrap\navg_predictions(mod, by = \"Species\") %&gt;%\n  inferences(method = \"boot\")\n\navg_predictions(mod, by = \"Species\") %&gt;%\n  inferences(method = \"rsample\")\n\n# Fractional (bayesian) bootstrap\navg_slopes(mod, by = \"Species\") %&gt;%\n  inferences(method = \"fwb\") %&gt;%\n  posterior_draws(\"rvar\") %&gt;%\n  data.frame()\n\n# Simulation-based inference\nslopes(mod) %&gt;%\n  inferences(method = \"simulation\") %&gt;%\n  head()",
    "crumbs": [
      "Get started",
      "Functions",
      "`inferences`"
    ]
  },
  {
    "objectID": "man/hypotheses.html",
    "href": "man/hypotheses.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Uncertainty estimates are calculated as first-order approximate standard errors for linear or non-linear functions of a vector of random variables with known or estimated covariance matrix. In that sense, hypotheses emulates the behavior of the excellent and well-established car::deltaMethod and car::linearHypothesis functions, but it supports more models; requires fewer dependencies; expands the range of tests to equivalence and superiority/inferiority; and offers convenience features like robust standard errors.\nTo learn more, read the hypothesis tests vignette, visit the package website, or scroll down this page for a full list of vignettes:\n\n\nhttps://marginaleffects.com/vignettes/hypothesis.html\n\n\nhttps://marginaleffects.com/\n\n\nWarning #1: Tests are conducted directly on the scale defined by the type argument. For some models, it can make sense to conduct hypothesis or equivalence tests on the “link” scale instead of the “response” scale which is often the default.\nWarning #2: For hypothesis tests on objects produced by the marginaleffects package, it is safer to use the hypothesis argument of the original function. Using hypotheses() may not work in certain environments, in lists, or when working programmatically with *apply style functions.\nWarning #3: The tests assume that the hypothesis expression is (approximately) normally distributed, which for non-linear functions of the parameters may not be realistic. More reliable confidence intervals can be obtained using the inferences() function with method = “boot”.\n\nhypotheses(\n  model,\n  hypothesis = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  df = NULL,\n  equivalence = NULL,\n  joint = FALSE,\n  joint_test = \"f\",\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object or object generated by the comparisons(), slopes(), or predictions() functions.\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When using joint_test=“f”, the df argument should be a numeric vector of length 2.\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\njoint\n\n\nJoint test of statistical significance. The null hypothesis value can be set using the hypothesis argument.\n\n\nFALSE: Hypotheses are not tested jointly.\n\n\nTRUE: All parameters are tested jointly.\n\n\nString: A regular expression to match parameters to be tested jointly. grep(joint, perl = TRUE)\n\n\nCharacter vector of parameter names to be tested. Characters refer to the names of the vector returned by coef(object).\n\n\nInteger vector of indices. Which parameters positions to test jointly.\n\n\n\n\n\n\njoint_test\n\n\nA character string specifying the type of test, either \"f\" or \"chisq\". The null hypothesis is set by the hypothesis argument, with default null equal to 0 for all parameters.\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nThe test statistic for the joint Wald test is calculated as (R * theta_hat - r)’ * inv(R * V_hat * R’) * (R * theta_hat - r) / Q, where theta_hat is the vector of estimated parameters, V_hat is the estimated covariance matrix, R is a Q x P matrix for testing Q hypotheses on P parameters, r is a Q x 1 vector for the null hypothesis, and Q is the number of rows in R. If the test is a Chi-squared test, the test statistic is not normalized.\nThe p-value is then calculated based on either the F-distribution (for F-test) or the Chi-squared distribution (for Chi-squared test). For the F-test, the degrees of freedom are Q and (n - P), where n is the sample size and P is the number of parameters. For the Chi-squared test, the degrees of freedom are Q.\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)\n\nhypotheses(mod)\n\n\n         Term Estimate Std. Error     z Pr(&gt;|z|)     S   2.5 %    97.5 %\n (Intercept)   35.8460      2.041 17.56   &lt;0.001 227.0 31.8457 39.846319\n hp            -0.0231      0.012 -1.93   0.0531   4.2 -0.0465  0.000306\n wt            -3.1814      0.720 -4.42   &lt;0.001  16.6 -4.5918 -1.771012\n factor(cyl)6  -3.3590      1.402 -2.40   0.0166   5.9 -6.1062 -0.611803\n factor(cyl)8  -3.1859      2.170 -1.47   0.1422   2.8 -7.4399  1.068169\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Test of equality between coefficients\nhypotheses(mod, hypothesis = \"hp = wt\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.16       0.72 4.39   &lt;0.001 16.4  1.75   4.57\n\nTerm: hp = wt\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Non-linear function\nhypotheses(mod, hypothesis = \"exp(hp + wt) = 0.1\")\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 %\n  -0.0594     0.0292 -2.04   0.0418 4.6 -0.117 -0.0022\n\nTerm: exp(hp + wt) = 0.1\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Robust standard errors\nhypotheses(mod, hypothesis = \"hp = wt\", vcov = \"HC3\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.16      0.805 3.92   &lt;0.001 13.5  1.58   4.74\n\nTerm: hp = wt\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# b1, b2, ... shortcuts can be used to identify the position of the\n# parameters of interest in the output of\nhypotheses(mod, hypothesis = \"b2 = b3\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.16       0.72 4.39   &lt;0.001 16.4  1.75   4.57\n\nTerm: b2 = b3\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# wildcard\nhypotheses(mod, hypothesis = \"b* / b2 = 1\")\n\n\n        Term Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 % 97.5 %\n b1 / b2 = 1    -1551      764.0 -2.03   0.0423 4.6 -3048.9    -54\n b2 / b2 = 1        0         NA    NA       NA  NA      NA     NA\n b3 / b2 = 1      137       78.1  1.75   0.0804 3.6   -16.6    290\n b4 / b2 = 1      144      111.0  1.30   0.1938 2.4   -73.3    362\n b5 / b2 = 1      137      151.9  0.90   0.3679 1.4  -161.0    435\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# term names with special characters have to be enclosed in backticks\nhypotheses(mod, hypothesis = \"`factor(cyl)6` = `factor(cyl)8`\")\n\n\n Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n   -0.173       1.65 -0.105    0.917 0.1 -3.41   3.07\n\nTerm: `factor(cyl)6` = `factor(cyl)8`\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nmod2 &lt;- lm(mpg ~ hp * drat, data = mtcars)\nhypotheses(mod2, hypothesis = \"`hp:drat` = drat\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    -6.08       2.89 -2.1   0.0357 4.8 -11.8 -0.405\n\nTerm: `hp:drat` = drat\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# predictions(), comparisons(), and slopes()\nmod &lt;- glm(am ~ hp + mpg, data = mtcars, family = binomial)\ncmp &lt;- comparisons(mod, newdata = \"mean\")\nhypotheses(cmp, hypothesis = \"b1 = b2\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 %  97.5 %\n    -0.28      0.104 -2.7  0.00684 7.2 -0.483 -0.0771\n\nTerm: b1=b2\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nmfx &lt;- slopes(mod, newdata = \"mean\")\nhypotheses(cmp, hypothesis = \"b2 = 0.2\")\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 % 97.5 %\n   0.0938      0.109 0.857    0.391 1.4 -0.121  0.308\n\nTerm: b2=0.2\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\npre &lt;- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35)))\nhypotheses(pre, hypothesis = \"b1 = b2\")\n\n\n  Estimate Std. Error      z Pr(&gt;|z|)   S     2.5 %   97.5 %\n -3.57e-05   0.000172 -0.207    0.836 0.3 -0.000373 0.000302\n\nTerm: b1=b2\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# The `hypothesis` argument can be used to compute standard errors for fitted values\nmod &lt;- glm(am ~ hp + mpg, data = mtcars, family = binomial)\n\nf &lt;- function(x) predict(x, type = \"link\", newdata = mtcars)\np &lt;- hypotheses(mod, hypothesis = f)\nhead(p)\n\n\n Term Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    1   -1.098      0.716 -1.534    0.125 3.0 -2.50  0.305\n    2   -1.098      0.716 -1.534    0.125 3.0 -2.50  0.305\n    3    0.233      0.781  0.299    0.765 0.4 -1.30  1.764\n    4   -0.595      0.647 -0.919    0.358 1.5 -1.86  0.674\n    5   -0.418      0.647 -0.645    0.519 0.9 -1.69  0.851\n    6   -5.026      2.195 -2.290    0.022 5.5 -9.33 -0.725\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nf &lt;- function(x) predict(x, type = \"response\", newdata = mtcars)\np &lt;- hypotheses(mod, hypothesis = f)\nhead(p)\n\n\n Term Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 % 97.5 %\n    1  0.25005     0.1343 1.862  0.06257 4.0 -0.0131 0.5132\n    2  0.25005     0.1343 1.862  0.06257 4.0 -0.0131 0.5132\n    3  0.55803     0.1926 2.898  0.00376 8.1  0.1806 0.9355\n    4  0.35560     0.1483 2.398  0.01648 5.9  0.0650 0.6462\n    5  0.39710     0.1550 2.562  0.01041 6.6  0.0933 0.7009\n    6  0.00652     0.0142 0.459  0.64653 0.6 -0.0213 0.0344\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Complex aggregation\n# Step 1: Collapse predicted probabilities by outcome level, for each individual\n# Step 2: Take the mean of the collapsed probabilities by group and `cyl`\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(dplyr)\n\ndat &lt;- transform(mtcars, gear = factor(gear))\nmod &lt;- polr(gear ~ factor(cyl) + hp, dat)\n\naggregation_fun &lt;- function(x) {\n    predictions(x, vcov = FALSE) |&gt;\n        mutate(group = ifelse(group %in% c(\"3\", \"4\"), \"3 & 4\", \"5\")) |&gt;\n        summarize(estimate = sum(estimate), .by = c(\"rowid\", \"cyl\", \"group\")) |&gt;\n        summarize(estimate = mean(estimate), .by = c(\"cyl\", \"group\")) |&gt;\n        rename(term = cyl)\n}\n\nhypotheses(mod, hypothesis = aggregation_fun)\n\n\n Group Term Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n 3 & 4    6   0.8390     0.0651 12.89   &lt;0.001 123.9 0.7115  0.967\n 3 & 4    4   0.7197     0.1099  6.55   &lt;0.001  34.0 0.5044  0.935\n 3 & 4    8   0.9283     0.0174 53.45   &lt;0.001   Inf 0.8943  0.962\n 5        6   0.1610     0.0651  2.47   0.0134   6.2 0.0334  0.289\n 5        4   0.2803     0.1099  2.55   0.0108   6.5 0.0649  0.496\n 5        8   0.0717     0.0174  4.13   &lt;0.001  14.7 0.0377  0.106\n\nColumns: term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Equivalence, non-inferiority, and non-superiority tests\nmod &lt;- lm(mpg ~ hp + factor(gear), data = mtcars)\np &lt;- predictions(mod, newdata = \"median\")\nhypotheses(p, equivalence = c(17, 18))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % p (NonSup) p (NonInf)\n     19.7          1 19.6   &lt;0.001 281.3  17.7   21.6      0.951    0.00404\n p (Equiv)  hp gear\n     0.951 123    3\n\nType:  response \nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, gear, mpg, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\nmfx &lt;- avg_slopes(mod, variables = \"hp\")\nhypotheses(mfx, equivalence = c(-.1, .1))\n\n\n Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 % p (NonSup) p (NonInf)\n  -0.0669      0.011 -6.05   &lt;0.001 29.4 -0.0885 -0.0452     &lt;0.001    0.00135\n p (Equiv)\n   0.00135\n\nTerm: hp\nType:  response \nComparison: mean(dY/dX)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\ncmp &lt;- avg_comparisons(mod, variables = \"gear\", hypothesis = \"pairwise\")\nhypotheses(cmp, equivalence = c(0, 10))\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 % p (NonSup) p (NonInf)\n    -3.94       2.05 -1.92   0.0543 4.2 -7.95 0.0727     &lt;0.001      0.973\n p (Equiv)\n     0.973\n\nTerm: (mean(4) - mean(3)) - (mean(5) - mean(3))\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\n# joint hypotheses: character vector\nmodel &lt;- lm(mpg ~ as.factor(cyl) * hp, data = mtcars)\nhypotheses(model, joint = c(\"as.factor(cyl)6:hp\", \"as.factor(cyl)8:hp\"))\n\n\n\nJoint hypothesis test:\nas.factor(cyl)6:hp = 0\nas.factor(cyl)8:hp = 0\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 2.11    0.142    2   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: regular expression\nhypotheses(model, joint = \"cyl\")\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 0\n as.factor(cyl)8 = 0\n as.factor(cyl)6:hp = 0\n as.factor(cyl)8:hp = 0\n \n   F Pr(&gt;|F|) Df 1 Df 2\n 5.7  0.00197    4   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: integer indices\nhypotheses(model, joint = 2:3)\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 0\n as.factor(cyl)8 = 0\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 6.12  0.00665    2   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: different null hypotheses\nhypotheses(model, joint = 2:3, hypothesis = 1)\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 1\n as.factor(cyl)8 = 1\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 6.84  0.00411    2   26\n\nColumns: statistic, p.value, df1, df2 \n\nhypotheses(model, joint = 2:3, hypothesis = 1:2)\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 1\n as.factor(cyl)8 = 2\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 7.47  0.00273    2   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: marginaleffects object\ncmp &lt;- avg_comparisons(model)\nhypotheses(cmp, joint = \"cyl\")\n\n\n\nJoint hypothesis test:\n cyl mean(6) - mean(4) = 0\n cyl mean(8) - mean(4) = 0\n \n   F Pr(&gt;|F|) Df 1 Df 2\n 1.6    0.221    2   26\n\nColumns: statistic, p.value, df1, df2",
    "crumbs": [
      "Get started",
      "Functions",
      "`hypotheses`"
    ]
  },
  {
    "objectID": "man/hypotheses.html#non-linear-tests-for-null-hypotheses-joint-hypotheses-equivalence-non-superiority-and-non-inferiority",
    "href": "man/hypotheses.html#non-linear-tests-for-null-hypotheses-joint-hypotheses-equivalence-non-superiority-and-non-inferiority",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Uncertainty estimates are calculated as first-order approximate standard errors for linear or non-linear functions of a vector of random variables with known or estimated covariance matrix. In that sense, hypotheses emulates the behavior of the excellent and well-established car::deltaMethod and car::linearHypothesis functions, but it supports more models; requires fewer dependencies; expands the range of tests to equivalence and superiority/inferiority; and offers convenience features like robust standard errors.\nTo learn more, read the hypothesis tests vignette, visit the package website, or scroll down this page for a full list of vignettes:\n\n\nhttps://marginaleffects.com/vignettes/hypothesis.html\n\n\nhttps://marginaleffects.com/\n\n\nWarning #1: Tests are conducted directly on the scale defined by the type argument. For some models, it can make sense to conduct hypothesis or equivalence tests on the “link” scale instead of the “response” scale which is often the default.\nWarning #2: For hypothesis tests on objects produced by the marginaleffects package, it is safer to use the hypothesis argument of the original function. Using hypotheses() may not work in certain environments, in lists, or when working programmatically with *apply style functions.\nWarning #3: The tests assume that the hypothesis expression is (approximately) normally distributed, which for non-linear functions of the parameters may not be realistic. More reliable confidence intervals can be obtained using the inferences() function with method = “boot”.\n\nhypotheses(\n  model,\n  hypothesis = NULL,\n  vcov = NULL,\n  conf_level = 0.95,\n  df = NULL,\n  equivalence = NULL,\n  joint = FALSE,\n  joint_test = \"f\",\n  numderiv = \"fdforward\",\n  ...\n)\n\n\n\n\n\nmodel\n\n\nModel object or object generated by the comparisons(), slopes(), or predictions() functions.\n\n\n\n\nhypothesis\n\n\nspecify a hypothesis test or custom contrast using a numeric value, vector, or matrix; a string equation; string; a formula, or a function.\n\n\nNumeric:\n\n\nSingle value: the null hypothesis used in the computation of Z and p (before applying transform).\n\n\nVector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the hypothesis argument.\n\n\nMatrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.\n\n\n\n\nString equation to specify linear or non-linear hypothesis tests. If the term column uniquely identifies rows, terms can be used in the formula. Otherwise, use b1, b2, etc. to identify the position of each parameter. The b* wildcard can be used to test hypotheses on all estimates. If a named vector is used, the names are used as labels in the output. Examples:\n\n\nhp = drat\n\n\nhp + drat = 12\n\n\nb1 + b2 + b3 = 0\n\n\nb* / b1 = 1\n\n\n\n\nString:\n\n\n\"pairwise\": pairwise differences between estimates in each row.\n\n\n\"reference\": differences between the estimates in each row and the estimate in the first row.\n\n\n\"sequential\": difference between an estimate and the estimate in the next row.\n\n\n\"meandev\": difference between an estimate and the mean of all estimates.\n\n\n\"meanotherdev\": difference between an estimate and the mean of all other estimates, excluding the current one.\n\n\n\"revpairwise\", \"revreference\", \"revsequential\": inverse of the corresponding hypotheses, as described above.\n\n\n\n\nFormula:\n\n\ncomparison ~ pairs | group\n\n\nLeft-hand side determines the type of comparison to conduct: difference or ratio. If the left-hand side is empty, difference is chosen.\n\n\nRight-hand side determines the pairs of estimates to compare: reference, sequential, or meandev\n\n\nOptional: Users can supply grouping variables after a vertical bar to conduct comparisons withing subsets.\n\n\nExamples:\n\n\n~ reference\n\n\nratio ~ pairwise\n\n\ndifference ~ pairwise | groupid\n\n\n\n\n\n\nFunction:\n\n\nAccepts an argument x: object produced by a marginaleffects function or a data frame with column rowid and estimate\n\n\nReturns a data frame with columns term and estimate (mandatory) and rowid (optional).\n\n\nThe function can also accept optional input arguments: newdata, by, draws.\n\n\nThis function approach will not work for Bayesian models or with bootstrapping. In those cases, it is easy to use posterior_draws() to extract and manipulate the draws directly.\n\n\n\n\nSee the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html\n\n\n\n\n\n\nvcov\n\n\nType of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:\n\n\nFALSE: Do not compute standard errors. This can speed up computation considerably.\n\n\nTRUE: Unit-level standard errors using the default vcov(model) variance-covariance matrix.\n\n\nString which indicates the kind of uncertainty estimates to return.\n\n\nHeteroskedasticity-consistent: “HC”, “HC0”, “HC1”, “HC2”, “HC3”, “HC4”, “HC4m”, “HC5”. See ?sandwich::vcovHC\n\n\nHeteroskedasticity and autocorrelation consistent: “HAC”\n\n\nMixed-Models degrees of freedom: \"satterthwaite\", \"kenward-roger\"\n\n\nOther: “NeweyWest”, “KernHAC”, “OPG”. See the sandwich package documentation.\n\n\n\n\nOne-sided formula which indicates the name of cluster variables (e.g., ~unit_id). This formula is passed to the cluster argument of the sandwich::vcovCL function.\n\n\nSquare covariance matrix\n\n\nFunction which returns a covariance matrix (e.g., stats::vcov(model))\n\n\n\n\n\n\nconf_level\n\n\nnumeric value between 0 and 1. Confidence level to use to build a confidence interval.\n\n\n\n\ndf\n\n\nDegrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and Inf. When using joint_test=“f”, the df argument should be a numeric vector of length 2.\n\n\n\n\nequivalence\n\n\nNumeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.\n\n\n\n\njoint\n\n\nJoint test of statistical significance. The null hypothesis value can be set using the hypothesis argument.\n\n\nFALSE: Hypotheses are not tested jointly.\n\n\nTRUE: All parameters are tested jointly.\n\n\nString: A regular expression to match parameters to be tested jointly. grep(joint, perl = TRUE)\n\n\nCharacter vector of parameter names to be tested. Characters refer to the names of the vector returned by coef(object).\n\n\nInteger vector of indices. Which parameters positions to test jointly.\n\n\n\n\n\n\njoint_test\n\n\nA character string specifying the type of test, either \"f\" or \"chisq\". The null hypothesis is set by the hypothesis argument, with default null equal to 0 for all parameters.\n\n\n\n\nnumderiv\n\n\nstring or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.\n\n\n\"fdforward\": finite difference method with forward differences\n\n\n\"fdcenter\": finite difference method with central differences (default)\n\n\n\"richardson\": Richardson extrapolation method\n\n\nExtra arguments can be specified by passing a list to the numDeriv argument, with the name of the method first and named arguments following, ex: numderiv=list(“fdcenter”, eps = 1e-5). When an unknown argument is used, marginaleffects prints the list of valid arguments for each method.\n\n\n\n\n\n\n…\n\n\nAdditional arguments are passed to the predict() method supplied by the modeling package.These arguments are particularly useful for mixed-effects or bayesian models (see the online vignettes on the marginaleffects website). Available arguments can vary from model to model, depending on the range of supported arguments by each modeling package. See the \"Model-Specific Arguments\" section of the ?slopes documentation for a non-exhaustive list of available arguments.\n\n\n\nThe test statistic for the joint Wald test is calculated as (R * theta_hat - r)’ * inv(R * V_hat * R’) * (R * theta_hat - r) / Q, where theta_hat is the vector of estimated parameters, V_hat is the estimated covariance matrix, R is a Q x P matrix for testing Q hypotheses on P parameters, r is a Q x 1 vector for the null hypothesis, and Q is the number of rows in R. If the test is a Chi-squared test, the test statistic is not normalized.\nThe p-value is then calculated based on either the F-distribution (for F-test) or the Chi-squared distribution (for Chi-squared test). For the F-test, the degrees of freedom are Q and (n - P), where n is the sample size and P is the number of parameters. For the Chi-squared test, the degrees of freedom are Q.\n\n\\(\\theta\\) is an estimate, \\(\\sigma_\\theta\\) its estimated standard error, and \\([a, b]\\) are the bounds of the interval supplied to the equivalence argument.\nNon-inferiority:\n\n\n\\(H_0\\): \\(\\theta \\leq a\\)\n\n\n\\(H_1\\): \\(\\theta &gt; a\\)\n\n\n\\(t=(\\theta - a)/\\sigma_\\theta\\)\n\n\np: Upper-tail probability\n\n\nNon-superiority:\n\n\n\\(H_0\\): \\(\\theta \\geq b\\)\n\n\n\\(H_1\\): \\(\\theta &lt; b\\)\n\n\n\\(t=(\\theta - b)/\\sigma_\\theta\\)\n\n\np: Lower-tail probability\n\n\nEquivalence: Two One-Sided Tests (TOST)\n\n\np: Maximum of the non-inferiority and non-superiority p values.\n\n\nThanks to Russell V. Lenth for the excellent emmeans package and documentation which inspired this feature.\n\n\nlibrary(\"marginaleffects\")\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)\n\nhypotheses(mod)\n\n\n         Term Estimate Std. Error     z Pr(&gt;|z|)     S   2.5 %    97.5 %\n (Intercept)   35.8460      2.041 17.56   &lt;0.001 227.0 31.8457 39.846319\n hp            -0.0231      0.012 -1.93   0.0531   4.2 -0.0465  0.000306\n wt            -3.1814      0.720 -4.42   &lt;0.001  16.6 -4.5918 -1.771012\n factor(cyl)6  -3.3590      1.402 -2.40   0.0166   5.9 -6.1062 -0.611803\n factor(cyl)8  -3.1859      2.170 -1.47   0.1422   2.8 -7.4399  1.068169\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Test of equality between coefficients\nhypotheses(mod, hypothesis = \"hp = wt\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.16       0.72 4.39   &lt;0.001 16.4  1.75   4.57\n\nTerm: hp = wt\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Non-linear function\nhypotheses(mod, hypothesis = \"exp(hp + wt) = 0.1\")\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 %\n  -0.0594     0.0292 -2.04   0.0418 4.6 -0.117 -0.0022\n\nTerm: exp(hp + wt) = 0.1\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Robust standard errors\nhypotheses(mod, hypothesis = \"hp = wt\", vcov = \"HC3\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.16      0.805 3.92   &lt;0.001 13.5  1.58   4.74\n\nTerm: hp = wt\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# b1, b2, ... shortcuts can be used to identify the position of the\n# parameters of interest in the output of\nhypotheses(mod, hypothesis = \"b2 = b3\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n     3.16       0.72 4.39   &lt;0.001 16.4  1.75   4.57\n\nTerm: b2 = b3\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# wildcard\nhypotheses(mod, hypothesis = \"b* / b2 = 1\")\n\n\n        Term Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 % 97.5 %\n b1 / b2 = 1    -1551      764.0 -2.03   0.0423 4.6 -3048.9    -54\n b2 / b2 = 1        0         NA    NA       NA  NA      NA     NA\n b3 / b2 = 1      137       78.1  1.75   0.0804 3.6   -16.6    290\n b4 / b2 = 1      144      111.0  1.30   0.1938 2.4   -73.3    362\n b5 / b2 = 1      137      151.9  0.90   0.3679 1.4  -161.0    435\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# term names with special characters have to be enclosed in backticks\nhypotheses(mod, hypothesis = \"`factor(cyl)6` = `factor(cyl)8`\")\n\n\n Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n   -0.173       1.65 -0.105    0.917 0.1 -3.41   3.07\n\nTerm: `factor(cyl)6` = `factor(cyl)8`\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nmod2 &lt;- lm(mpg ~ hp * drat, data = mtcars)\nhypotheses(mod2, hypothesis = \"`hp:drat` = drat\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    -6.08       2.89 -2.1   0.0357 4.8 -11.8 -0.405\n\nTerm: `hp:drat` = drat\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# predictions(), comparisons(), and slopes()\nmod &lt;- glm(am ~ hp + mpg, data = mtcars, family = binomial)\ncmp &lt;- comparisons(mod, newdata = \"mean\")\nhypotheses(cmp, hypothesis = \"b1 = b2\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 %  97.5 %\n    -0.28      0.104 -2.7  0.00684 7.2 -0.483 -0.0771\n\nTerm: b1=b2\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nmfx &lt;- slopes(mod, newdata = \"mean\")\nhypotheses(cmp, hypothesis = \"b2 = 0.2\")\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 % 97.5 %\n   0.0938      0.109 0.857    0.391 1.4 -0.121  0.308\n\nTerm: b2=0.2\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\npre &lt;- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35)))\nhypotheses(pre, hypothesis = \"b1 = b2\")\n\n\n  Estimate Std. Error      z Pr(&gt;|z|)   S     2.5 %   97.5 %\n -3.57e-05   0.000172 -0.207    0.836 0.3 -0.000373 0.000302\n\nTerm: b1=b2\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# The `hypothesis` argument can be used to compute standard errors for fitted values\nmod &lt;- glm(am ~ hp + mpg, data = mtcars, family = binomial)\n\nf &lt;- function(x) predict(x, type = \"link\", newdata = mtcars)\np &lt;- hypotheses(mod, hypothesis = f)\nhead(p)\n\n\n Term Estimate Std. Error      z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    1   -1.098      0.716 -1.534    0.125 3.0 -2.50  0.305\n    2   -1.098      0.716 -1.534    0.125 3.0 -2.50  0.305\n    3    0.233      0.781  0.299    0.765 0.4 -1.30  1.764\n    4   -0.595      0.647 -0.919    0.358 1.5 -1.86  0.674\n    5   -0.418      0.647 -0.645    0.519 0.9 -1.69  0.851\n    6   -5.026      2.195 -2.290    0.022 5.5 -9.33 -0.725\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\nf &lt;- function(x) predict(x, type = \"response\", newdata = mtcars)\np &lt;- hypotheses(mod, hypothesis = f)\nhead(p)\n\n\n Term Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 % 97.5 %\n    1  0.25005     0.1343 1.862  0.06257 4.0 -0.0131 0.5132\n    2  0.25005     0.1343 1.862  0.06257 4.0 -0.0131 0.5132\n    3  0.55803     0.1926 2.898  0.00376 8.1  0.1806 0.9355\n    4  0.35560     0.1483 2.398  0.01648 5.9  0.0650 0.6462\n    5  0.39710     0.1550 2.562  0.01041 6.6  0.0933 0.7009\n    6  0.00652     0.0142 0.459  0.64653 0.6 -0.0213 0.0344\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Complex aggregation\n# Step 1: Collapse predicted probabilities by outcome level, for each individual\n# Step 2: Take the mean of the collapsed probabilities by group and `cyl`\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(dplyr)\n\ndat &lt;- transform(mtcars, gear = factor(gear))\nmod &lt;- polr(gear ~ factor(cyl) + hp, dat)\n\naggregation_fun &lt;- function(x) {\n    predictions(x, vcov = FALSE) |&gt;\n        mutate(group = ifelse(group %in% c(\"3\", \"4\"), \"3 & 4\", \"5\")) |&gt;\n        summarize(estimate = sum(estimate), .by = c(\"rowid\", \"cyl\", \"group\")) |&gt;\n        summarize(estimate = mean(estimate), .by = c(\"cyl\", \"group\")) |&gt;\n        rename(term = cyl)\n}\n\nhypotheses(mod, hypothesis = aggregation_fun)\n\n\n Group Term Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n 3 & 4    6   0.8390     0.0651 12.89   &lt;0.001 123.9 0.7115  0.967\n 3 & 4    4   0.7197     0.1099  6.55   &lt;0.001  34.0 0.5044  0.935\n 3 & 4    8   0.9283     0.0174 53.45   &lt;0.001   Inf 0.8943  0.962\n 5        6   0.1610     0.0651  2.47   0.0134   6.2 0.0334  0.289\n 5        4   0.2803     0.1099  2.55   0.0108   6.5 0.0649  0.496\n 5        8   0.0717     0.0174  4.13   &lt;0.001  14.7 0.0377  0.106\n\nColumns: term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n# Equivalence, non-inferiority, and non-superiority tests\nmod &lt;- lm(mpg ~ hp + factor(gear), data = mtcars)\np &lt;- predictions(mod, newdata = \"median\")\nhypotheses(p, equivalence = c(17, 18))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % p (NonSup) p (NonInf)\n     19.7          1 19.6   &lt;0.001 281.3  17.7   21.6      0.951    0.00404\n p (Equiv)  hp gear\n     0.951 123    3\n\nType:  response \nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, gear, mpg, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\nmfx &lt;- avg_slopes(mod, variables = \"hp\")\nhypotheses(mfx, equivalence = c(-.1, .1))\n\n\n Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 % p (NonSup) p (NonInf)\n  -0.0669      0.011 -6.05   &lt;0.001 29.4 -0.0885 -0.0452     &lt;0.001    0.00135\n p (Equiv)\n   0.00135\n\nTerm: hp\nType:  response \nComparison: mean(dY/dX)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\ncmp &lt;- avg_comparisons(mod, variables = \"gear\", hypothesis = \"pairwise\")\nhypotheses(cmp, equivalence = c(0, 10))\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 % p (NonSup) p (NonInf)\n    -3.94       2.05 -1.92   0.0543 4.2 -7.95 0.0727     &lt;0.001      0.973\n p (Equiv)\n     0.973\n\nTerm: (mean(4) - mean(3)) - (mean(5) - mean(3))\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n\n# joint hypotheses: character vector\nmodel &lt;- lm(mpg ~ as.factor(cyl) * hp, data = mtcars)\nhypotheses(model, joint = c(\"as.factor(cyl)6:hp\", \"as.factor(cyl)8:hp\"))\n\n\n\nJoint hypothesis test:\nas.factor(cyl)6:hp = 0\nas.factor(cyl)8:hp = 0\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 2.11    0.142    2   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: regular expression\nhypotheses(model, joint = \"cyl\")\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 0\n as.factor(cyl)8 = 0\n as.factor(cyl)6:hp = 0\n as.factor(cyl)8:hp = 0\n \n   F Pr(&gt;|F|) Df 1 Df 2\n 5.7  0.00197    4   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: integer indices\nhypotheses(model, joint = 2:3)\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 0\n as.factor(cyl)8 = 0\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 6.12  0.00665    2   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: different null hypotheses\nhypotheses(model, joint = 2:3, hypothesis = 1)\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 1\n as.factor(cyl)8 = 1\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 6.84  0.00411    2   26\n\nColumns: statistic, p.value, df1, df2 \n\nhypotheses(model, joint = 2:3, hypothesis = 1:2)\n\n\n\nJoint hypothesis test:\n as.factor(cyl)6 = 1\n as.factor(cyl)8 = 2\n \n    F Pr(&gt;|F|) Df 1 Df 2\n 7.47  0.00273    2   26\n\nColumns: statistic, p.value, df1, df2 \n\n# joint hypotheses: marginaleffects object\ncmp &lt;- avg_comparisons(model)\nhypotheses(cmp, joint = \"cyl\")\n\n\n\nJoint hypothesis test:\n cyl mean(6) - mean(4) = 0\n cyl mean(8) - mean(4) = 0\n \n   F Pr(&gt;|F|) Df 1 Df 2\n 1.6    0.221    2   26\n\nColumns: statistic, p.value, df1, df2",
    "crumbs": [
      "Get started",
      "Functions",
      "`hypotheses`"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html",
    "href": "vignettes/multiple_imputation.html",
    "title": "Missing Data",
    "section": "",
    "text": "The marginaleffects package offers convenience functions to compute and display predictions, contrasts, and marginal effects from models with multiple imputation from the mice and Amelia packages. The workflow follows Rubin’s rules (Rubin, 1987, p. 76), via the following steps:\n\nImpute \\(M\\) data sets.\nFit a model in each of the \\(M\\) imputed data sets.\nCompute marginal effects in each of the \\(M\\) data sets.\nPool results.\n\nTo highlight the workflow, we consider a simple linear regression model, although the same workflow should work with any model type that is fit using a formula interface and a data argument.\nmarginaleffects directly supports the mice and Amelia imputation packages, as well as any other package that can return a list of imputed data frames. This is demonstrated below using the iris dataset, in which we insert missing observations randomly and then impute missing values using several packages.\n\nlibrary(marginaleffects)\nset.seed(1024)\n\ndat &lt;- iris\ndat$Sepal.Length[sample(seq_len(nrow(iris)), 40)] &lt;- NA\ndat$Sepal.Width[sample(seq_len(nrow(iris)), 40)] &lt;- NA\ndat$Species[sample(seq_len(nrow(iris)), 40)] &lt;- NA\n\n\nFirst, we impute the dataset using the mice package:\n\nlibrary(mice)\n\ndat_mice &lt;- mice(dat, m = 20, printFlag = FALSE, .Random.seed = 1024)\n\nThen, we use the standard mice syntax to produce an object of class mira with all the models:\n\nmod_mice &lt;- with(dat_mice, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))\n\nFinally, we feed the mira object to a marginaleffects function:\n\nmfx_mice &lt;- avg_slopes(mod_mice, by = \"Species\")\nmfx_mice\n#&gt; \n#&gt;          Term                        Contrast    Species Estimate Std. Error      t Pr(&gt;|t|)     S   2.5 % 97.5 %    Df\n#&gt;  Sepal.Length mean(dY/dX)                     setosa       0.0684     0.0560  1.222  0.22412   2.2 -0.0424  0.179 120.0\n#&gt;  Sepal.Length mean(dY/dX)                     versicolor   0.0540     0.0558  0.968  0.33553   1.6 -0.0567  0.165  93.6\n#&gt;  Sepal.Length mean(dY/dX)                     virginica    0.0582     0.0512  1.137  0.25814   2.0 -0.0433  0.160 101.2\n#&gt;  Sepal.Width  mean(dY/dX)                     setosa       0.1890     0.0836  2.260  0.02436   5.4  0.0246  0.353 400.5\n#&gt;  Sepal.Width  mean(dY/dX)                     versicolor   0.2092     0.0772  2.710  0.00807   7.0  0.0558  0.363  89.0\n#&gt;  Sepal.Width  mean(dY/dX)                     virginica    0.2242     0.1041  2.155  0.03505   4.8  0.0162  0.432  61.8\n#&gt;  Species      mean(versicolor) - mean(setosa) setosa       1.1399     0.0977 11.668  &lt; 0.001  68.1  0.9464  1.333 114.8\n#&gt;  Species      mean(versicolor) - mean(setosa) versicolor   1.1399     0.0977 11.668  &lt; 0.001  68.1  0.9464  1.333 114.8\n#&gt;  Species      mean(versicolor) - mean(setosa) virginica    1.1399     0.0977 11.668  &lt; 0.001  68.1  0.9464  1.333 114.8\n#&gt;  Species      mean(virginica) - mean(setosa)  setosa       1.7408     0.1108 15.709  &lt; 0.001 100.7  1.5214  1.960 121.6\n#&gt;  Species      mean(virginica) - mean(setosa)  versicolor   1.7408     0.1108 15.709  &lt; 0.001 100.7  1.5214  1.960 121.6\n#&gt;  Species      mean(virginica) - mean(setosa)  virginica    1.7408     0.1108 15.709  &lt; 0.001 100.7  1.5214  1.960 121.6\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, Species, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high\n\n\nWith Amelia, the workflow is essentially the same. First, we impute using Amelia:\n\nlibrary(Amelia)\n\ndat_amelia &lt;- amelia(dat, m = 20, noms = \"Species\", p2s = 0)\n\nThen, we use Amelia syntax to produce an object of class amest with all the models:\n\nmod_amelia &lt;- with(dat_amelia, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))\n\nFinally, we feed the amest object to a marginaleffects function:\n\nmfx_amelia &lt;- avg_slopes(mod_amelia, by = \"Species\")\nmfx_amelia\n#&gt; \n#&gt;          Term                        Contrast    Species Estimate Std. Error      t Pr(&gt;|t|)    S  2.5 % 97.5 %   Df\n#&gt;  Sepal.Length mean(dY/dX)                     setosa       0.3878     0.0907  4.278  &lt; 0.001 13.3  0.205 0.5705 44.0\n#&gt;  Sepal.Length mean(dY/dX)                     versicolor   0.3231     0.0802  4.030  &lt; 0.001 12.5  0.163 0.4838 55.9\n#&gt;  Sepal.Length mean(dY/dX)                     virginica    0.3467     0.0799  4.340  &lt; 0.001 13.6  0.186 0.5077 44.7\n#&gt;  Sepal.Width  mean(dY/dX)                     setosa      -0.2079     0.1491 -1.395  0.16877  2.6 -0.507 0.0909 55.0\n#&gt;  Sepal.Width  mean(dY/dX)                     versicolor  -0.1157     0.1168 -0.991  0.32646  1.6 -0.350 0.1187 51.8\n#&gt;  Sepal.Width  mean(dY/dX)                     virginica   -0.0452     0.1272 -0.355  0.72325  0.5 -0.298 0.2079 82.2\n#&gt;  Species      mean(versicolor) - mean(setosa) setosa       0.6127     0.1731  3.541  0.00111  9.8  0.262 0.9635 36.7\n#&gt;  Species      mean(versicolor) - mean(setosa) versicolor   0.6127     0.1731  3.541  0.00111  9.8  0.262 0.9635 36.7\n#&gt;  Species      mean(versicolor) - mean(setosa) virginica    0.6127     0.1731  3.541  0.00111  9.8  0.262 0.9635 36.7\n#&gt;  Species      mean(virginica) - mean(setosa)  setosa       1.0364     0.2004  5.171  &lt; 0.001 16.6  0.629 1.4436 34.2\n#&gt;  Species      mean(virginica) - mean(setosa)  versicolor   1.0364     0.2004  5.171  &lt; 0.001 16.6  0.629 1.4436 34.2\n#&gt;  Species      mean(virginica) - mean(setosa)  virginica    1.0364     0.2004  5.171  &lt; 0.001 16.6  0.629 1.4436 34.2\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, Species, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high\n\n\nSeveral R packages can impute missing data. Indeed, the Missing Data CRAN View lists at least a dozen alternatives. Since user interfaces change a lot from package to package, marginaleffects supports a single workflow that can be used, with some adaptation, with all imputation packages:\n\nUse an external package to create a list of imputed data frames.\nApply the datalist2mids() function from the miceadds package to convert the list of imputed data frames to a mids object.\nUse the with() function to fit models to create mira object, as illustrated in the mice and Amelia sections above.\nPass the mira object to a marginaleffects function.\n\nConsider the imputation package missRanger, which generates a list of imputed datasets:\n\nlibrary(miceadds)\nlibrary(missRanger)\n\n## convert lists of imputed datasets to `mids` objects\ndat_missRanger &lt;- replicate(20, missRanger(dat, verbose = 0), simplify = FALSE)\nmids_missRanger &lt;- datlist2mids(dat_missRanger)\n\n## fit models\nmod_missRanger &lt;- with(mids_missRanger, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))\n\n## `missRanger` slopes\nmfx_missRanger &lt;- avg_slopes(mod_missRanger, by = \"Species\")\nmfx_missRanger\n#&gt; \n#&gt;          Term                        Contrast    Species Estimate Std. Error     t Pr(&gt;|t|)     S    2.5 % 97.5 %      Df\n#&gt;  Sepal.Length mean(dY/dX)                     setosa       0.0589     0.0415  1.42  0.15558   2.7 -0.02238  0.140 6733392\n#&gt;  Sepal.Length mean(dY/dX)                     versicolor   0.0682     0.0393  1.74  0.08228   3.6 -0.00873  0.145 1145162\n#&gt;  Sepal.Length mean(dY/dX)                     virginica    0.0649     0.0368  1.76  0.07792   3.7 -0.00726  0.137 2020701\n#&gt;  Sepal.Width  mean(dY/dX)                     setosa       0.2300     0.0692  3.32  &lt; 0.001  10.1  0.09434  0.366 3128781\n#&gt;  Sepal.Width  mean(dY/dX)                     versicolor   0.2166     0.0551  3.93  &lt; 0.001  13.5  0.10854  0.325  687227\n#&gt;  Sepal.Width  mean(dY/dX)                     virginica    0.2063     0.0687  3.00  0.00266   8.6  0.07174  0.341  458858\n#&gt;  Species      mean(versicolor) - mean(setosa) setosa       1.1572     0.0706 16.38  &lt; 0.001 197.9  1.01871  1.296 3882586\n#&gt;  Species      mean(versicolor) - mean(setosa) versicolor   1.1572     0.0706 16.38  &lt; 0.001 197.9  1.01871  1.296 3882586\n#&gt;  Species      mean(versicolor) - mean(setosa) virginica    1.1572     0.0706 16.38  &lt; 0.001 197.9  1.01871  1.296 3882586\n#&gt;  Species      mean(virginica) - mean(setosa)  setosa       1.7763     0.0825 21.52  &lt; 0.001 338.9  1.61452  1.938 5384985\n#&gt;  Species      mean(virginica) - mean(setosa)  versicolor   1.7763     0.0825 21.52  &lt; 0.001 338.9  1.61452  1.938 5384985\n#&gt;  Species      mean(virginica) - mean(setosa)  virginica    1.7763     0.0825 21.52  &lt; 0.001 338.9  1.61452  1.938 5384985\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, Species, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high\n\n\nWe can use the modelsummary package to compare the results with listwise deletion to the results using different imputations software:\n\nlibrary(modelsummary)\n\n## listwise deletion slopes\nmod_lwd &lt;- lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species, data = dat)\nmfx_lwd &lt;- avg_slopes(mod_lwd, by = \"Species\")\n\n## regression table\nmodels &lt;- list(\n    \"LWD\" = mfx_lwd,\n    \"mice\" = mfx_mice,\n    \"Amelia\" = mfx_amelia,\n    \"missRanger\" = mfx_missRanger)\nmodelsummary(models, shape = term : contrast + Species ~ model)\n\n\n\n    \n\n      \n\n \n                Species\n                LWD\n                mice\n                Amelia\n                missRanger\n              \n\n\nSepal.Length mean(dY/dX)               \n                  setosa    \n                  0.033  \n                  0.068  \n                  0.388  \n                  0.059  \n                \n\n                                       \n                            \n                  (0.061)\n                  (0.056)\n                  (0.091)\n                  (0.041)\n                \n\n                                       \n                  versicolor\n                  0.050  \n                  0.054  \n                  0.323  \n                  0.068  \n                \n\n                                       \n                            \n                  (0.061)\n                  (0.056)\n                  (0.080)\n                  (0.039)\n                \n\n                                       \n                  virginica \n                  0.043  \n                  0.058  \n                  0.347  \n                  0.065  \n                \n\n                                       \n                            \n                  (0.058)\n                  (0.051)\n                  (0.080)\n                  (0.037)\n                \n\nSepal.Width mean(dY/dX)                \n                  setosa    \n                  0.274  \n                  0.189  \n                  -0.208 \n                  0.230  \n                \n\n                                       \n                            \n                  (0.091)\n                  (0.084)\n                  (0.149)\n                  (0.069)\n                \n\n                                       \n                  versicolor\n                  0.255  \n                  0.209  \n                  -0.116 \n                  0.217  \n                \n\n                                       \n                            \n                  (0.074)\n                  (0.077)\n                  (0.117)\n                  (0.055)\n                \n\n                                       \n                  virginica \n                  0.234  \n                  0.224  \n                  -0.045 \n                  0.206  \n                \n\n                                       \n                            \n                  (0.083)\n                  (0.104)\n                  (0.127)\n                  (0.069)\n                \n\nSpecies mean(versicolor) - mean(setosa)\n                  setosa    \n                  1.157  \n                  1.140  \n                  0.613  \n                  1.157  \n                \n\n                                       \n                            \n                  (0.097)\n                  (0.098)\n                  (0.173)\n                  (0.071)\n                \n\n                                       \n                  versicolor\n                  1.157  \n                  1.140  \n                  0.613  \n                  1.157  \n                \n\n                                       \n                            \n                  (0.097)\n                  (0.098)\n                  (0.173)\n                  (0.071)\n                \n\n                                       \n                  virginica \n                  1.157  \n                  1.140  \n                  0.613  \n                  1.157  \n                \n\n                                       \n                            \n                  (0.097)\n                  (0.098)\n                  (0.173)\n                  (0.071)\n                \n\nSpecies mean(virginica) - mean(setosa) \n                  setosa    \n                  1.839  \n                  1.741  \n                  1.036  \n                  1.776  \n                \n\n                                       \n                            \n                  (0.123)\n                  (0.111)\n                  (0.200)\n                  (0.083)\n                \n\n                                       \n                  versicolor\n                  1.839  \n                  1.741  \n                  1.036  \n                  1.776  \n                \n\n                                       \n                            \n                  (0.123)\n                  (0.111)\n                  (0.200)\n                  (0.083)\n                \n\n                                       \n                  virginica \n                  1.839  \n                  1.741  \n                  1.036  \n                  1.776  \n                \n\n                                       \n                            \n                  (0.123)\n                  (0.111)\n                  (0.200)\n                  (0.083)\n                \n\nNum.Obs.                               \n                            \n                  60     \n                  150    \n                  150    \n                  150    \n                \n\nNum.Imp.                               \n                            \n                         \n                  20     \n                  20     \n                  20     \n                \n\nR2                                     \n                            \n                  0.953  \n                  0.930  \n                  0.853  \n                  0.947  \n                \n\nR2 Adj.                                \n                            \n                  0.949  \n                  0.928  \n                  0.848  \n                  0.945  \n                \n\nAIC                                    \n                            \n                  -34.0  \n                         \n                         \n                         \n                \n\nBIC                                    \n                            \n                  -19.3  \n                         \n                         \n                         \n                \n\nLog.Lik.                               \n                            \n                  23.997 \n                         \n                         \n                         \n                \n\nF                                      \n                            \n                  220.780\n                         \n                         \n                         \n                \n\nRMSE                                   \n                            \n                  0.16   \n                         \n                         \n                         \n                \n\n\n\n\n\n\n\nSometimes we want to pass arguments changing or specifying the data on which we will do our analysis using marginaleffects. This can be for reasons such as wanting to specify the values or weights at which we evaluate e.g. avg_slopes(), or due to the underlying models not robustly preserving all the original data columns (such as fixest objects not saving their data in the fit object making it potentially challenging to retrieve, and even if retrievable it will not include the weights used during fitting as a column as wts expects when given a string).\nIf we are not using multiple imputation, or if we want to just pass a single dataset to the several fitted models after multiple imputation, we can pass a single dataset to the newdata argument. However, if we wish to supply each model in our list resulting after multiple imputation with a /different/ dataset on which to calculate results, we cannot use newdata. Instead, in this case it can be useful to revert to a more manual (but still very easy) approach. Here is an example calculating avg_slopes using a different set of weights for each of the fixest models which we fit after multiple imputation.\n\nset.seed(1024)\nlibrary(mice)\nlibrary(fixest)\nlibrary(marginaleffects)\n\ndat &lt;- mtcars\n\n## insert missing values\ndat$hp[sample(seq_len(nrow(mtcars)), 10)] &lt;- NA\ndat$mpg[sample(seq_len(nrow(mtcars)), 10)] &lt;- NA\ndat$gear[sample(seq_len(nrow(mtcars)), 10)] &lt;- NA\n\n## multiple imputation\ndat &lt;- mice(dat, m = 5, method = \"sample\", printFlag = FALSE)\ndat &lt;- complete(dat, action = \"all\")\n\n## fit models\nmod &lt;- lapply(dat, \\(x) \n    feglm(am ~ mpg * cyl + hp,\n        weight = ~gear,\n        family = binomial,\n        data = x))\n\n## slopes without weights\nlapply(seq_along(mod), \\(i) \n    avg_slopes(mod[[i]], newdata = dat[[i]])) |&gt;\n    mice::pool()\n#&gt; Class: mipo    m = 5 \n#&gt;   term    contrast m     estimate         ubar            b            t dfcom       df      riv    lambda       fmi\n#&gt; 1  cyl mean(dY/dX) 5 -0.134280454 7.097467e-04 2.347331e-03 3.526544e-03    29 2.921797 3.968736 0.7987416 0.8667137\n#&gt; 2   hp mean(dY/dX) 5  0.001649773 5.709036e-07 1.375452e-06 2.221446e-06    29 3.557014 2.891105 0.7430036 0.8213918\n#&gt; 3  mpg mean(dY/dX) 5  0.006082804 1.080647e-04 2.722234e-04 4.347329e-04    29 3.458682 3.022893 0.7514227 0.8283973\n\n## slopes with weights\nlapply(seq_along(mod), \\(i) \n    avg_slopes(mod[[i]], newdata = dat[[i]], wts = \"gear\")) |&gt;\n    mice::pool()\n#&gt; Class: mipo    m = 5 \n#&gt;   term    contrast m     estimate         ubar            b            t dfcom       df      riv    lambda       fmi\n#&gt; 1  cyl mean(dY/dX) 5 -0.135839444 7.281041e-04 2.481021e-03 3.705329e-03    29 2.868747 4.089010 0.8034981 0.8704636\n#&gt; 2   hp mean(dY/dX) 5  0.001671173 5.697747e-07 1.424648e-06 2.279352e-06    29 3.474898 3.000446 0.7500278 0.8272405\n#&gt; 3  mpg mean(dY/dX) 5  0.006251144 1.056103e-04 2.705239e-04 4.302390e-04    29 3.422648 3.073835 0.7545310 0.8309696\n\n\nIn some contexts (ex: Average Treatment effects on the Treated), users want to apply a function like subset() to the data in newdata. Unfortunately, there is no subset() method applicable to mice-generated objects. One alternative is to generate estimates for each imputed datasets separately and pool the results after. For example:\n\nlibrary(mice)\nlibrary(marginaleffects)\ndata(\"lalonde_mis\", package = \"cobalt\")\n\nimp &lt;- mice(lalonde_mis, m = 5, print = FALSE)\nest &lt;- lapply(1:5, \\(i) {\n    data &lt;- complete(imp, i)\n    mod &lt;- lm(re78 ~ treat * (age + educ + re74), data = data)\n    avg_predictions(mod, variables = \"treat\", newdata = subset(treat == 1))\n})\nmice::pool(est)\n#&gt; Class: mipo    m = 5 \n#&gt;   term m estimate     ubar            b        t dfcom       df          riv       lambda        fmi\n#&gt; 1    0 5 5558.439 142974.4 3.331491e+03 146972.2   612 534.7224 2.796156e-02 2.720098e-02 0.03081920\n#&gt; 2    1 5 6349.144 263028.0 4.652891e-22 263028.0   612 609.9478 2.122766e-27 2.122766e-27 0.00326292",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html#mice",
    "href": "vignettes/multiple_imputation.html#mice",
    "title": "Missing Data",
    "section": "",
    "text": "First, we impute the dataset using the mice package:\n\nlibrary(mice)\n\ndat_mice &lt;- mice(dat, m = 20, printFlag = FALSE, .Random.seed = 1024)\n\nThen, we use the standard mice syntax to produce an object of class mira with all the models:\n\nmod_mice &lt;- with(dat_mice, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))\n\nFinally, we feed the mira object to a marginaleffects function:\n\nmfx_mice &lt;- avg_slopes(mod_mice, by = \"Species\")\nmfx_mice\n#&gt; \n#&gt;          Term                        Contrast    Species Estimate Std. Error      t Pr(&gt;|t|)     S   2.5 % 97.5 %    Df\n#&gt;  Sepal.Length mean(dY/dX)                     setosa       0.0684     0.0560  1.222  0.22412   2.2 -0.0424  0.179 120.0\n#&gt;  Sepal.Length mean(dY/dX)                     versicolor   0.0540     0.0558  0.968  0.33553   1.6 -0.0567  0.165  93.6\n#&gt;  Sepal.Length mean(dY/dX)                     virginica    0.0582     0.0512  1.137  0.25814   2.0 -0.0433  0.160 101.2\n#&gt;  Sepal.Width  mean(dY/dX)                     setosa       0.1890     0.0836  2.260  0.02436   5.4  0.0246  0.353 400.5\n#&gt;  Sepal.Width  mean(dY/dX)                     versicolor   0.2092     0.0772  2.710  0.00807   7.0  0.0558  0.363  89.0\n#&gt;  Sepal.Width  mean(dY/dX)                     virginica    0.2242     0.1041  2.155  0.03505   4.8  0.0162  0.432  61.8\n#&gt;  Species      mean(versicolor) - mean(setosa) setosa       1.1399     0.0977 11.668  &lt; 0.001  68.1  0.9464  1.333 114.8\n#&gt;  Species      mean(versicolor) - mean(setosa) versicolor   1.1399     0.0977 11.668  &lt; 0.001  68.1  0.9464  1.333 114.8\n#&gt;  Species      mean(versicolor) - mean(setosa) virginica    1.1399     0.0977 11.668  &lt; 0.001  68.1  0.9464  1.333 114.8\n#&gt;  Species      mean(virginica) - mean(setosa)  setosa       1.7408     0.1108 15.709  &lt; 0.001 100.7  1.5214  1.960 121.6\n#&gt;  Species      mean(virginica) - mean(setosa)  versicolor   1.7408     0.1108 15.709  &lt; 0.001 100.7  1.5214  1.960 121.6\n#&gt;  Species      mean(virginica) - mean(setosa)  virginica    1.7408     0.1108 15.709  &lt; 0.001 100.7  1.5214  1.960 121.6\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, Species, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html#amelia",
    "href": "vignettes/multiple_imputation.html#amelia",
    "title": "Missing Data",
    "section": "",
    "text": "With Amelia, the workflow is essentially the same. First, we impute using Amelia:\n\nlibrary(Amelia)\n\ndat_amelia &lt;- amelia(dat, m = 20, noms = \"Species\", p2s = 0)\n\nThen, we use Amelia syntax to produce an object of class amest with all the models:\n\nmod_amelia &lt;- with(dat_amelia, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))\n\nFinally, we feed the amest object to a marginaleffects function:\n\nmfx_amelia &lt;- avg_slopes(mod_amelia, by = \"Species\")\nmfx_amelia\n#&gt; \n#&gt;          Term                        Contrast    Species Estimate Std. Error      t Pr(&gt;|t|)    S  2.5 % 97.5 %   Df\n#&gt;  Sepal.Length mean(dY/dX)                     setosa       0.3878     0.0907  4.278  &lt; 0.001 13.3  0.205 0.5705 44.0\n#&gt;  Sepal.Length mean(dY/dX)                     versicolor   0.3231     0.0802  4.030  &lt; 0.001 12.5  0.163 0.4838 55.9\n#&gt;  Sepal.Length mean(dY/dX)                     virginica    0.3467     0.0799  4.340  &lt; 0.001 13.6  0.186 0.5077 44.7\n#&gt;  Sepal.Width  mean(dY/dX)                     setosa      -0.2079     0.1491 -1.395  0.16877  2.6 -0.507 0.0909 55.0\n#&gt;  Sepal.Width  mean(dY/dX)                     versicolor  -0.1157     0.1168 -0.991  0.32646  1.6 -0.350 0.1187 51.8\n#&gt;  Sepal.Width  mean(dY/dX)                     virginica   -0.0452     0.1272 -0.355  0.72325  0.5 -0.298 0.2079 82.2\n#&gt;  Species      mean(versicolor) - mean(setosa) setosa       0.6127     0.1731  3.541  0.00111  9.8  0.262 0.9635 36.7\n#&gt;  Species      mean(versicolor) - mean(setosa) versicolor   0.6127     0.1731  3.541  0.00111  9.8  0.262 0.9635 36.7\n#&gt;  Species      mean(versicolor) - mean(setosa) virginica    0.6127     0.1731  3.541  0.00111  9.8  0.262 0.9635 36.7\n#&gt;  Species      mean(virginica) - mean(setosa)  setosa       1.0364     0.2004  5.171  &lt; 0.001 16.6  0.629 1.4436 34.2\n#&gt;  Species      mean(virginica) - mean(setosa)  versicolor   1.0364     0.2004  5.171  &lt; 0.001 16.6  0.629 1.4436 34.2\n#&gt;  Species      mean(virginica) - mean(setosa)  virginica    1.0364     0.2004  5.171  &lt; 0.001 16.6  0.629 1.4436 34.2\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, Species, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html#other-imputation-packages-missranger-or-lists-of-imputed-data-frames.",
    "href": "vignettes/multiple_imputation.html#other-imputation-packages-missranger-or-lists-of-imputed-data-frames.",
    "title": "Missing Data",
    "section": "",
    "text": "Several R packages can impute missing data. Indeed, the Missing Data CRAN View lists at least a dozen alternatives. Since user interfaces change a lot from package to package, marginaleffects supports a single workflow that can be used, with some adaptation, with all imputation packages:\n\nUse an external package to create a list of imputed data frames.\nApply the datalist2mids() function from the miceadds package to convert the list of imputed data frames to a mids object.\nUse the with() function to fit models to create mira object, as illustrated in the mice and Amelia sections above.\nPass the mira object to a marginaleffects function.\n\nConsider the imputation package missRanger, which generates a list of imputed datasets:\n\nlibrary(miceadds)\nlibrary(missRanger)\n\n## convert lists of imputed datasets to `mids` objects\ndat_missRanger &lt;- replicate(20, missRanger(dat, verbose = 0), simplify = FALSE)\nmids_missRanger &lt;- datlist2mids(dat_missRanger)\n\n## fit models\nmod_missRanger &lt;- with(mids_missRanger, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))\n\n## `missRanger` slopes\nmfx_missRanger &lt;- avg_slopes(mod_missRanger, by = \"Species\")\nmfx_missRanger\n#&gt; \n#&gt;          Term                        Contrast    Species Estimate Std. Error     t Pr(&gt;|t|)     S    2.5 % 97.5 %      Df\n#&gt;  Sepal.Length mean(dY/dX)                     setosa       0.0589     0.0415  1.42  0.15558   2.7 -0.02238  0.140 6733392\n#&gt;  Sepal.Length mean(dY/dX)                     versicolor   0.0682     0.0393  1.74  0.08228   3.6 -0.00873  0.145 1145162\n#&gt;  Sepal.Length mean(dY/dX)                     virginica    0.0649     0.0368  1.76  0.07792   3.7 -0.00726  0.137 2020701\n#&gt;  Sepal.Width  mean(dY/dX)                     setosa       0.2300     0.0692  3.32  &lt; 0.001  10.1  0.09434  0.366 3128781\n#&gt;  Sepal.Width  mean(dY/dX)                     versicolor   0.2166     0.0551  3.93  &lt; 0.001  13.5  0.10854  0.325  687227\n#&gt;  Sepal.Width  mean(dY/dX)                     virginica    0.2063     0.0687  3.00  0.00266   8.6  0.07174  0.341  458858\n#&gt;  Species      mean(versicolor) - mean(setosa) setosa       1.1572     0.0706 16.38  &lt; 0.001 197.9  1.01871  1.296 3882586\n#&gt;  Species      mean(versicolor) - mean(setosa) versicolor   1.1572     0.0706 16.38  &lt; 0.001 197.9  1.01871  1.296 3882586\n#&gt;  Species      mean(versicolor) - mean(setosa) virginica    1.1572     0.0706 16.38  &lt; 0.001 197.9  1.01871  1.296 3882586\n#&gt;  Species      mean(virginica) - mean(setosa)  setosa       1.7763     0.0825 21.52  &lt; 0.001 338.9  1.61452  1.938 5384985\n#&gt;  Species      mean(virginica) - mean(setosa)  versicolor   1.7763     0.0825 21.52  &lt; 0.001 338.9  1.61452  1.938 5384985\n#&gt;  Species      mean(virginica) - mean(setosa)  virginica    1.7763     0.0825 21.52  &lt; 0.001 338.9  1.61452  1.938 5384985\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, Species, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html#comparing-results-with-different-imputation-software",
    "href": "vignettes/multiple_imputation.html#comparing-results-with-different-imputation-software",
    "title": "Missing Data",
    "section": "",
    "text": "We can use the modelsummary package to compare the results with listwise deletion to the results using different imputations software:\n\nlibrary(modelsummary)\n\n## listwise deletion slopes\nmod_lwd &lt;- lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species, data = dat)\nmfx_lwd &lt;- avg_slopes(mod_lwd, by = \"Species\")\n\n## regression table\nmodels &lt;- list(\n    \"LWD\" = mfx_lwd,\n    \"mice\" = mfx_mice,\n    \"Amelia\" = mfx_amelia,\n    \"missRanger\" = mfx_missRanger)\nmodelsummary(models, shape = term : contrast + Species ~ model)\n\n\n\n    \n\n      \n\n \n                Species\n                LWD\n                mice\n                Amelia\n                missRanger\n              \n\n\nSepal.Length mean(dY/dX)               \n                  setosa    \n                  0.033  \n                  0.068  \n                  0.388  \n                  0.059  \n                \n\n                                       \n                            \n                  (0.061)\n                  (0.056)\n                  (0.091)\n                  (0.041)\n                \n\n                                       \n                  versicolor\n                  0.050  \n                  0.054  \n                  0.323  \n                  0.068  \n                \n\n                                       \n                            \n                  (0.061)\n                  (0.056)\n                  (0.080)\n                  (0.039)\n                \n\n                                       \n                  virginica \n                  0.043  \n                  0.058  \n                  0.347  \n                  0.065  \n                \n\n                                       \n                            \n                  (0.058)\n                  (0.051)\n                  (0.080)\n                  (0.037)\n                \n\nSepal.Width mean(dY/dX)                \n                  setosa    \n                  0.274  \n                  0.189  \n                  -0.208 \n                  0.230  \n                \n\n                                       \n                            \n                  (0.091)\n                  (0.084)\n                  (0.149)\n                  (0.069)\n                \n\n                                       \n                  versicolor\n                  0.255  \n                  0.209  \n                  -0.116 \n                  0.217  \n                \n\n                                       \n                            \n                  (0.074)\n                  (0.077)\n                  (0.117)\n                  (0.055)\n                \n\n                                       \n                  virginica \n                  0.234  \n                  0.224  \n                  -0.045 \n                  0.206  \n                \n\n                                       \n                            \n                  (0.083)\n                  (0.104)\n                  (0.127)\n                  (0.069)\n                \n\nSpecies mean(versicolor) - mean(setosa)\n                  setosa    \n                  1.157  \n                  1.140  \n                  0.613  \n                  1.157  \n                \n\n                                       \n                            \n                  (0.097)\n                  (0.098)\n                  (0.173)\n                  (0.071)\n                \n\n                                       \n                  versicolor\n                  1.157  \n                  1.140  \n                  0.613  \n                  1.157  \n                \n\n                                       \n                            \n                  (0.097)\n                  (0.098)\n                  (0.173)\n                  (0.071)\n                \n\n                                       \n                  virginica \n                  1.157  \n                  1.140  \n                  0.613  \n                  1.157  \n                \n\n                                       \n                            \n                  (0.097)\n                  (0.098)\n                  (0.173)\n                  (0.071)\n                \n\nSpecies mean(virginica) - mean(setosa) \n                  setosa    \n                  1.839  \n                  1.741  \n                  1.036  \n                  1.776  \n                \n\n                                       \n                            \n                  (0.123)\n                  (0.111)\n                  (0.200)\n                  (0.083)\n                \n\n                                       \n                  versicolor\n                  1.839  \n                  1.741  \n                  1.036  \n                  1.776  \n                \n\n                                       \n                            \n                  (0.123)\n                  (0.111)\n                  (0.200)\n                  (0.083)\n                \n\n                                       \n                  virginica \n                  1.839  \n                  1.741  \n                  1.036  \n                  1.776  \n                \n\n                                       \n                            \n                  (0.123)\n                  (0.111)\n                  (0.200)\n                  (0.083)\n                \n\nNum.Obs.                               \n                            \n                  60     \n                  150    \n                  150    \n                  150    \n                \n\nNum.Imp.                               \n                            \n                         \n                  20     \n                  20     \n                  20     \n                \n\nR2                                     \n                            \n                  0.953  \n                  0.930  \n                  0.853  \n                  0.947  \n                \n\nR2 Adj.                                \n                            \n                  0.949  \n                  0.928  \n                  0.848  \n                  0.945  \n                \n\nAIC                                    \n                            \n                  -34.0  \n                         \n                         \n                         \n                \n\nBIC                                    \n                            \n                  -19.3  \n                         \n                         \n                         \n                \n\nLog.Lik.                               \n                            \n                  23.997 \n                         \n                         \n                         \n                \n\nF                                      \n                            \n                  220.780\n                         \n                         \n                         \n                \n\nRMSE                                   \n                            \n                  0.16",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html#passing-new-data-arguments-newdata-wts-by-etc.",
    "href": "vignettes/multiple_imputation.html#passing-new-data-arguments-newdata-wts-by-etc.",
    "title": "Missing Data",
    "section": "",
    "text": "Sometimes we want to pass arguments changing or specifying the data on which we will do our analysis using marginaleffects. This can be for reasons such as wanting to specify the values or weights at which we evaluate e.g. avg_slopes(), or due to the underlying models not robustly preserving all the original data columns (such as fixest objects not saving their data in the fit object making it potentially challenging to retrieve, and even if retrievable it will not include the weights used during fitting as a column as wts expects when given a string).\nIf we are not using multiple imputation, or if we want to just pass a single dataset to the several fitted models after multiple imputation, we can pass a single dataset to the newdata argument. However, if we wish to supply each model in our list resulting after multiple imputation with a /different/ dataset on which to calculate results, we cannot use newdata. Instead, in this case it can be useful to revert to a more manual (but still very easy) approach. Here is an example calculating avg_slopes using a different set of weights for each of the fixest models which we fit after multiple imputation.\n\nset.seed(1024)\nlibrary(mice)\nlibrary(fixest)\nlibrary(marginaleffects)\n\ndat &lt;- mtcars\n\n## insert missing values\ndat$hp[sample(seq_len(nrow(mtcars)), 10)] &lt;- NA\ndat$mpg[sample(seq_len(nrow(mtcars)), 10)] &lt;- NA\ndat$gear[sample(seq_len(nrow(mtcars)), 10)] &lt;- NA\n\n## multiple imputation\ndat &lt;- mice(dat, m = 5, method = \"sample\", printFlag = FALSE)\ndat &lt;- complete(dat, action = \"all\")\n\n## fit models\nmod &lt;- lapply(dat, \\(x) \n    feglm(am ~ mpg * cyl + hp,\n        weight = ~gear,\n        family = binomial,\n        data = x))\n\n## slopes without weights\nlapply(seq_along(mod), \\(i) \n    avg_slopes(mod[[i]], newdata = dat[[i]])) |&gt;\n    mice::pool()\n#&gt; Class: mipo    m = 5 \n#&gt;   term    contrast m     estimate         ubar            b            t dfcom       df      riv    lambda       fmi\n#&gt; 1  cyl mean(dY/dX) 5 -0.134280454 7.097467e-04 2.347331e-03 3.526544e-03    29 2.921797 3.968736 0.7987416 0.8667137\n#&gt; 2   hp mean(dY/dX) 5  0.001649773 5.709036e-07 1.375452e-06 2.221446e-06    29 3.557014 2.891105 0.7430036 0.8213918\n#&gt; 3  mpg mean(dY/dX) 5  0.006082804 1.080647e-04 2.722234e-04 4.347329e-04    29 3.458682 3.022893 0.7514227 0.8283973\n\n## slopes with weights\nlapply(seq_along(mod), \\(i) \n    avg_slopes(mod[[i]], newdata = dat[[i]], wts = \"gear\")) |&gt;\n    mice::pool()\n#&gt; Class: mipo    m = 5 \n#&gt;   term    contrast m     estimate         ubar            b            t dfcom       df      riv    lambda       fmi\n#&gt; 1  cyl mean(dY/dX) 5 -0.135839444 7.281041e-04 2.481021e-03 3.705329e-03    29 2.868747 4.089010 0.8034981 0.8704636\n#&gt; 2   hp mean(dY/dX) 5  0.001671173 5.697747e-07 1.424648e-06 2.279352e-06    29 3.474898 3.000446 0.7500278 0.8272405\n#&gt; 3  mpg mean(dY/dX) 5  0.006251144 1.056103e-04 2.705239e-04 4.302390e-04    29 3.422648 3.073835 0.7545310 0.8309696",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/multiple_imputation.html#newdata-with-imputed-datasets",
    "href": "vignettes/multiple_imputation.html#newdata-with-imputed-datasets",
    "title": "Missing Data",
    "section": "",
    "text": "In some contexts (ex: Average Treatment effects on the Treated), users want to apply a function like subset() to the data in newdata. Unfortunately, there is no subset() method applicable to mice-generated objects. One alternative is to generate estimates for each imputed datasets separately and pool the results after. For example:\n\nlibrary(mice)\nlibrary(marginaleffects)\ndata(\"lalonde_mis\", package = \"cobalt\")\n\nimp &lt;- mice(lalonde_mis, m = 5, print = FALSE)\nest &lt;- lapply(1:5, \\(i) {\n    data &lt;- complete(imp, i)\n    mod &lt;- lm(re78 ~ treat * (age + educ + re74), data = data)\n    avg_predictions(mod, variables = \"treat\", newdata = subset(treat == 1))\n})\nmice::pool(est)\n#&gt; Class: mipo    m = 5 \n#&gt;   term m estimate     ubar            b        t dfcom       df          riv       lambda        fmi\n#&gt; 1    0 5 5558.439 142974.4 3.331491e+03 146972.2   612 534.7224 2.796156e-02 2.720098e-02 0.03081920\n#&gt; 2    1 5 6349.144 263028.0 4.652891e-22 263028.0   612 609.9478 2.122766e-27 2.122766e-27 0.00326292",
    "crumbs": [
      "Get started",
      "Case studies",
      "Missing Data"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html",
    "href": "vignettes/uncertainty.html",
    "title": "Standard Errors",
    "section": "",
    "text": "All the standard errors generated by the slopes(), comparisons(), and hypotheses() functions of this package package are estimated using the delta method. Mathematical treatments of this method can be found in most statistics textbooks and on Wikipedia. Roughly speaking, the delta method allows us to approximate the distribution of a smooth function of an asymptotically normal estimator.\nConcretely, this allows us to generate standard errors around functions of a model’s coefficient estimates. Predictions, contrasts, slopes, and other quantities estimated by marginaleffects are all functions of a model’s coefficient estimates, so we can use the delta method to estimate standard errors around all of those quantities (with some assumptions). Since there are a lot of mathematical treatments available elsewhere, this vignette focuses on the implementation in marginaleffects.\nConsider the case of the predictions() function. When a user calls this function, they obtain a vector of adjusted predictions. To estimate standard errors around this vector:\n\nTake the numerical derivative of the predictions vector with respect to the first coefficient in the model:\n\nCompute predictions with the original model: \\(f(\\beta)\\)\n\nIncrement the first (and only the first) coefficient held inside the model object by a small amount, and compute means again: \\(f(\\beta+\\varepsilon)\\)\n\nCalculate: \\(\\frac{f(\\beta+\\varepsilon) - f(\\beta)}{\\varepsilon}\\)\n\n\n\nRepeat step 1 for every coefficient in the model to construct a \\(J\\) matrix.\nExtract the variance-covariance matrix of the coefficient estimates (usually with vcov(model)): \\(V\\)\n\nStandard errors are the square root of the diagonal of \\(JVJ'\\)\n\n\nScroll down this page to the Numerical Derivatives section to see a detailed explanation, along with code for manual computation.\n\nAll standard errors for the slopes() and comparisons() functions are computed using the delta method, as described above. The confidence intervals are calculated as estimate ± qnorm((1 - conf_level) / 2) standard errors (e.g., for 95% confidence intervals, estimate ± 1.96 standard errors) and assume that the (transformed) estimates are normally distributed.\n\nThe predictions() function can compute the confidence intervals in two main ways. For certain models, the type argument accept this value: type=\"invlink(link)\". In those cases, predictions() will first compute estimates on the link scale, and then back transform them using the inverse link function supplied by insight::link_inverse(model) function. In all other cases, standard errors are computed using the delta method directly on the specific scale, and then build symmetric intervals around the estimates.\n\nAll the functions in the marginaleffects package can compute robust standard errors on the fly for any model type supported by the sandwich package. The vcov argument supports string shortcuts like \"HC3\", a one-sided formula to request clustered standard errors, variance-covariance matrices, or functions which return such matrices. Here are a few examples.\nAdjusted predictions with classical or heteroskedasticity-robust standard errors:\n\nlibrary(marginaleffects)\nlibrary(patchwork)\nmod &lt;- lm(mpg ~ hp, data = mtcars)\n\np &lt;- predictions(mod)\nhead(p, 2)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      22.6      0.777 29.1   &lt;0.001 614.7  21.1   24.1\n#&gt;      22.6      0.777 29.1   &lt;0.001 614.7  21.1   24.1\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp\n\np &lt;- predictions(mod, vcov = \"HC3\")\nhead(p, 2)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      22.6      0.863 26.2   &lt;0.001 499.5  20.9   24.3\n#&gt;      22.6      0.863 26.2   &lt;0.001 499.5  20.9   24.3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp\n\nMarginal effects with cluster-robust standard errors:\n\navg_slopes(mod, vcov = ~cyl)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 %\n#&gt;   -0.0682     0.0187 -3.65   &lt;0.001 11.9 -0.105 -0.0316\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nComparing adjusted predictions with classical and robust standard errors:\n\np1 &lt;- plot_predictions(mod, condition = \"hp\")\np2 &lt;- plot_predictions(mod, condition = \"hp\", vcov = \"HC3\")\np1 + p2\n\n\n\n\n\n\n\n\nmarginaleffects offers an experimental inferences function to conduct simulation-based inference following the strategy proposed by Krinsky & Robb (1986):\n\nDraw iter sets of simulated coefficients from a multivariate normal distribution with mean equal to the original model’s estimated coefficients and variance equal to the model’s variance-covariance matrix (classical, “HC3”, or other).\nUse the iter sets of coefficients to compute iter sets of estimands: predictions, comparisons, or slopes.\nTake quantiles of the resulting distribution of estimands to obtain a confidence interval and the standard deviation of simulated estimates to estimate the standard error.\n\nHere are a few examples:\n\nlibrary(marginaleffects)\nlibrary(ggplot2)\nlibrary(ggdist)\n\nmod &lt;- glm(vs ~ hp * wt + factor(gear), data = mtcars, family = binomial)\n\nmod |&gt; predictions() |&gt; inferences(method = \"simulation\")\n#&gt; \n#&gt;  Estimate    2.5 % 97.5 %  hp   wt gear\n#&gt;  7.84e-01 2.69e-01  0.974 110 2.62    4\n#&gt;  7.84e-01 3.37e-01  0.960 110 2.88    4\n#&gt;  8.98e-01 4.62e-01  0.988  93 2.32    4\n#&gt;  8.74e-01 1.94e-01  0.996 110 3.21    3\n#&gt;  1.31e-02 8.64e-05  0.710 175 3.44    3\n#&gt; --- 22 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n#&gt;  3.83e-01 2.19e-02  0.957 113 1.51    5\n#&gt;  1.21e-06 3.82e-12  0.387 264 3.17    5\n#&gt;  6.89e-03 4.14e-05  0.539 175 2.77    5\n#&gt;  8.07e-11 2.22e-16  0.786 335 3.57    5\n#&gt;  7.95e-01 3.34e-01  0.965 109 2.78    4\n#&gt; Type:  invlink(link) \n#&gt; Columns: rowid, estimate, vs, hp, wt, gear, conf.low, conf.high\n\nmod |&gt; avg_slopes(vcov = ~gear) |&gt; inferences(method = \"simulation\")\n#&gt; \n#&gt;  Term          Contrast  Estimate   2.5 %  97.5 %\n#&gt;  gear mean(4) - mean(3) -3.92e-02 -0.0889 0.12086\n#&gt;  gear mean(5) - mean(3) -1.93e-01 -0.4882 0.32973\n#&gt;  hp   mean(dY/dX)       -5.02e-03 -0.0114 0.00582\n#&gt;  wt   mean(dY/dX)       -3.98e-05 -0.7450 0.66780\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high\n\nSince simulation based inference generates iter estimates of the quantities of interest, we can treat them similarly to draws from the posterior distribution in bayesian models. For example, we can extract draws using the posterior_draws() function, and plot their distributions using packages likeggplot2 and ggdist:\n\nmod |&gt;\n  avg_comparisons(variables = \"gear\") |&gt;\n  inferences(method = \"simulation\") |&gt;\n  posterior_draws(\"rvar\") |&gt;\n  ggplot(aes(y = contrast, xdist = rvar)) +\n  stat_slabinterval()\n\n\n\n\n\n\n\n\nIt is easy to use the bootstrap as an alternative strategy to compute standard errors and confidence intervals. Several R packages can help us achieve this, including the long-established boot package:\n\nlibrary(boot)\nset.seed(123)\n\nbootfun &lt;- function(data, indices, ...) {\n    d &lt;- data[indices, ]\n    mod &lt;- lm(mpg ~ am + hp + factor(cyl), data = d)\n    cmp &lt;- comparisons(mod, newdata = d, vcov = FALSE, variables = \"am\")\n    tidy(cmp)$estimate\n}\n\nb &lt;- boot(data = mtcars, statistic = bootfun, R = 1000)\n\nb\n#&gt; \n#&gt; ORDINARY NONPARAMETRIC BOOTSTRAP\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; boot(data = mtcars, statistic = bootfun, R = 1000)\n#&gt; \n#&gt; \n#&gt; Bootstrap Statistics :\n#&gt;      original     bias    std. error\n#&gt; t1*  4.157856 0.01543426    1.003461\n#&gt; t2*  4.157856 0.01543426    1.003461\n#&gt; t3*  4.157856 0.01543426    1.003461\n#&gt; t4*  4.157856 0.01543426    1.003461\n#&gt; t5*  4.157856 0.01543426    1.003461\n#&gt; t6*  4.157856 0.01543426    1.003461\n#&gt; t7*  4.157856 0.01543426    1.003461\n#&gt; t8*  4.157856 0.01543426    1.003461\n#&gt; t9*  4.157856 0.01543426    1.003461\n#&gt; t10* 4.157856 0.01543426    1.003461\n#&gt; t11* 4.157856 0.01543426    1.003461\n#&gt; t12* 4.157856 0.01543426    1.003461\n#&gt; t13* 4.157856 0.01543426    1.003461\n#&gt; t14* 4.157856 0.01543426    1.003461\n#&gt; t15* 4.157856 0.01543426    1.003461\n#&gt; t16* 4.157856 0.01543426    1.003461\n#&gt; t17* 4.157856 0.01543426    1.003461\n#&gt; t18* 4.157856 0.01543426    1.003461\n#&gt; t19* 4.157856 0.01543426    1.003461\n#&gt; t20* 4.157856 0.01543426    1.003461\n#&gt; t21* 4.157856 0.01543426    1.003461\n#&gt; t22* 4.157856 0.01543426    1.003461\n#&gt; t23* 4.157856 0.01543426    1.003461\n#&gt; t24* 4.157856 0.01543426    1.003461\n#&gt; t25* 4.157856 0.01543426    1.003461\n#&gt; t26* 4.157856 0.01543426    1.003461\n#&gt; t27* 4.157856 0.01543426    1.003461\n#&gt; t28* 4.157856 0.01543426    1.003461\n#&gt; t29* 4.157856 0.01543426    1.003461\n#&gt; t30* 4.157856 0.01543426    1.003461\n#&gt; t31* 4.157856 0.01543426    1.003461\n#&gt; t32* 4.157856 0.01543426    1.003461\nboot.ci(b, type = \"perc\")\n#&gt; BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\n#&gt; Based on 1000 bootstrap replicates\n#&gt; \n#&gt; CALL : \n#&gt; boot.ci(boot.out = b, type = \"perc\")\n#&gt; \n#&gt; Intervals : \n#&gt; Level     Percentile     \n#&gt; 95%   ( 2.240,  6.277 )  \n#&gt; Calculations and Intervals on Original Scale\n\nNote that, in the code above, we set vcov=FALSE to avoid computation of delta method standard errors and speed things up.\nCompare to the delta method standard errors:\n\nmod &lt;- lm(mpg ~ am + hp + factor(cyl), data = mtcars)\navg_comparisons(mod, variables = \"am\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      4.16       1.26 3.31   &lt;0.001 10.1   1.7   6.62\n#&gt; \n#&gt; Term: am\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nFor linear mixed effects models we can apply the Satterthwaite and Kenward-Roger corrections in the same way as above:\n\nlibrary(marginaleffects)\nlibrary(patchwork)\nlibrary(lme4)\n\ndat &lt;- mtcars\ndat$cyl &lt;- factor(dat$cyl)\ndat$am &lt;- as.logical(dat$am)\nmod &lt;- lmer(mpg ~ hp + am + (1 | cyl), data = dat)\n\nMarginal effects at the mean with classical standard errors and z-statistic:\n\nslopes(mod, newdata = \"mean\")\n#&gt; \n#&gt;  Term     Contrast Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;    am TRUE - FALSE   4.6661     1.1343  4.11   &lt;0.001 14.6  2.4430  6.8892\n#&gt;    hp dY/dX         -0.0518     0.0115 -4.52   &lt;0.001 17.3 -0.0743 -0.0294\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, am, cyl, mpg\n\nMarginal effects at the mean with Kenward-Roger adjusted variance-covariance and degrees of freedom:\n\nslopes(mod,\n                newdata = \"mean\",\n                vcov = \"kenward-roger\")\n#&gt; \n#&gt;  Term     Contrast Estimate Std. Error     t Pr(&gt;|t|)   S  2.5 %  97.5 %   Df\n#&gt;    am TRUE - FALSE   4.6661     1.2824  3.64   0.0874 3.5 -1.980 11.3121 1.68\n#&gt;    hp dY/dX         -0.0518     0.0152 -3.41   0.0964 3.4 -0.131  0.0269 1.68\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, am, cyl, mpg, df\n\nWe can use the same option in any of the package’s core functions, including:\n\nplot_predictions(mod, condition = \"hp\", vcov = \"satterthwaite\")\n\n\n\n\n\n\n\n\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\ndat$large_penguin &lt;- ifelse(dat$body_mass_g &gt; median(dat$body_mass_g, na.rm = TRUE), 1, 0)\nmod &lt;- glm(large_penguin ~ bill_length_mm * flipper_length_mm + species, data = dat, family = binomial)\n\nmarginaleffects uses numerical derivatives in two contexts:\n\nEstimate the partial derivatives reported by slopes() function.\n\nCentered finite difference\n\n\\(\\frac{f(x + \\varepsilon_1 / 2) - f(x - \\varepsilon_1 / 2)}{\\varepsilon_1}\\), where we take the derivative with respect to a predictor of interest, and \\(f\\) is the predict() function.\n\n\nEstimate standard errors using the delta method.\n\nForward finite difference\n\n\\(\\frac{g(\\hat{\\beta}) - g(\\hat{\\beta} + \\varepsilon_2)}{\\varepsilon_2}\\), where we take the derivative with respect to a model’s coefficients, and \\(g\\) is a marginaleffects function which returns some quantity of interest (e.g., slope, contrasts, predictions, etc.)\n\n\n\nNote that the step sizes used in those two contexts can differ. If the variables and coefficients have very different scales, it may make sense to use different values for \\(\\varepsilon_1\\) and \\(\\varepsilon_2\\).\nBy default, \\(\\varepsilon_1\\) is set to 1e-4 times the range of the variable with respect to which we are taking the derivative. By default, \\(\\varepsilon_2\\) is set to the maximum value of 1e-8, or 1e-4 times the smallest absolute coefficient estimate. (These choices are arbitrary, but I have found that in practice, smaller values can produce unstable results.)\n\\(\\varepsilon_1\\) can be controlled by the eps argument of the slopes() function. \\(\\varepsilon_2\\) can be controlled by setting a global option which tells marginaleffects to compute the jacobian using the numDeriv package instead of its own internal functions. This allows more control over the step size, and also gives access to other differentiation methods, such as Richardson’s. To use numDeriv, we define a list of arguments which will be pushed forward to numDeriv::jacobian:\n\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00595 4.69   &lt;0.001 18.4 0.0162 0.0395\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"Richardson\"))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00595 4.69   &lt;0.001 18.4 0.0162 0.0395\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-3)))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    0.0279      0.568 0.049    0.961 0.1 -1.09   1.14\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-5)))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00601 4.64   &lt;0.001 18.1 0.0161 0.0396\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-7)))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00595 4.68   &lt;0.001 18.4 0.0162 0.0395\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNotice that the standard errors can vary considerably when using different step sizes. It is good practice for analysts to consider the sensitivity of their results to this setting.\nNow, we illustrate the full process of standard error computation, using raw R code. First, we choose two step sizes:\n\neps1 &lt;- 1e-5 # slope\neps2 &lt;- 1e-7 # delta method\n\ns &lt;- slopes(mod, newdata = head(dat, 3), variables = \"bill_length_mm\", eps = eps1)\nprint(s[, 1:5], digits = 6)\n#&gt; \n#&gt;   Estimate Std. Error       z\n#&gt;  0.0179765 0.00881402 2.03954\n#&gt;  0.0359630 0.01254629 2.86642\n#&gt;  0.0849071 0.02137500 3.97226\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Columns: rowid, term, estimate, std.error, statistic\n\nWe can get the same estimates manually with these steps:\n\nlinkinv &lt;- mod$family$linkinv\n\n## increment the variable of interest by h\ndat_hi &lt;- transform(dat, bill_length_mm = bill_length_mm + eps1)\n\n## model matrices: first 3 rows\nmm_lo &lt;- insight::get_modelmatrix(mod, data = dat)[1:3,]\nmm_hi &lt;- insight::get_modelmatrix(mod, data = dat_hi)[1:3,]\n\n## predictions\np_lo &lt;- linkinv(mm_lo %*% coef(mod))\np_hi &lt;- linkinv(mm_hi %*% coef(mod))\n\n## slopes\n(p_hi - p_lo) / eps1\n#&gt;         [,1]\n#&gt; 1 0.01797653\n#&gt; 2 0.03596304\n#&gt; 3 0.08490712\n\nTo get standard errors, we build a jacobian matrix where each column holds derivatives of the vector valued slope function, with respect to each of the coefficients. Using the same example:\n\nb_lo &lt;- b_hi &lt;- coef(mod)\nb_hi[1] &lt;- b_hi[1] + eps2\n\ndydx_lo &lt;- (linkinv(mm_hi %*% b_lo) - linkinv(mm_lo %*% b_lo)) / eps1\ndydx_hi &lt;- (linkinv(mm_hi %*% b_hi) - linkinv(mm_lo %*% b_hi)) / eps1\n(dydx_hi - dydx_lo) / eps2\n#&gt;         [,1]\n#&gt; 1 0.01598721\n#&gt; 2 0.02767231\n#&gt; 3 0.02275957\n\nThis gives us the first column of \\(J\\), which we can recover in full from the marginaleffects object attribute:\n\nJ &lt;- attr(s, \"jacobian\")\nJ\n#&gt;      (Intercept) bill_length_mm flipper_length_mm speciesChinstrap speciesGentoo bill_length_mm:flipper_length_mm\n#&gt; [1,]  0.01601497      0.6777495          2.897231                0             0                         122.6914\n#&gt; [2,]  0.02770006      1.1957657          5.153100                0             0                         222.4989\n#&gt; [3,]  0.02281508      1.1500800          4.440004                0             0                         224.0830\n\nTo build the full matrix, we would simply iterate through the coefficients, incrementing them one after the other. Finally, we get standard errors via:\n\nsqrt(diag(J %*% vcov(mod) %*% t(J)))\n#&gt; [1] 0.008814015 0.012546293 0.021375005\n\nWhich corresponds to our original standard errors:\n\nprint(s[, 1:5], digits = 7)\n#&gt; \n#&gt;    Estimate  Std. Error        z\n#&gt;  0.01797650 0.008814015 2.039536\n#&gt;  0.03596299 0.012546293 2.866424\n#&gt;  0.08490708 0.021375005 3.972260\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Columns: rowid, term, estimate, std.error, statistic\n\nReverting to default settings:\n\noptions(marginaleffects_numDeriv = NULL)\n\nNote that our default results for this model are very similar – but not exactly identical – to those generated by the margins. As should be expected, the results in margins are also very sensitive to the value of eps for this model:\n\nlibrary(margins)\nmargins(mod, variables = \"bill_length_mm\", data = head(dat, 3), unit_ses = TRUE)$SE_dydx_bill_length_mm\n\nmargins(mod, variables = \"bill_length_mm\", data = head(dat, 3), eps = 1e-4, unit_ses = TRUE)$SE_dydx_bill_length_mm\n\nmargins(mod, variables = \"bill_length_mm\", data = head(dat, 3), eps = 1e-5, unit_ses = TRUE)$SE_dydx_bill_length_mm\n\n\nSee the brms vignette for a discussion of bayesian estimates and credible intervals.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#delta-method",
    "href": "vignettes/uncertainty.html#delta-method",
    "title": "Standard Errors",
    "section": "",
    "text": "All the standard errors generated by the slopes(), comparisons(), and hypotheses() functions of this package package are estimated using the delta method. Mathematical treatments of this method can be found in most statistics textbooks and on Wikipedia. Roughly speaking, the delta method allows us to approximate the distribution of a smooth function of an asymptotically normal estimator.\nConcretely, this allows us to generate standard errors around functions of a model’s coefficient estimates. Predictions, contrasts, slopes, and other quantities estimated by marginaleffects are all functions of a model’s coefficient estimates, so we can use the delta method to estimate standard errors around all of those quantities (with some assumptions). Since there are a lot of mathematical treatments available elsewhere, this vignette focuses on the implementation in marginaleffects.\nConsider the case of the predictions() function. When a user calls this function, they obtain a vector of adjusted predictions. To estimate standard errors around this vector:\n\nTake the numerical derivative of the predictions vector with respect to the first coefficient in the model:\n\nCompute predictions with the original model: \\(f(\\beta)\\)\n\nIncrement the first (and only the first) coefficient held inside the model object by a small amount, and compute means again: \\(f(\\beta+\\varepsilon)\\)\n\nCalculate: \\(\\frac{f(\\beta+\\varepsilon) - f(\\beta)}{\\varepsilon}\\)\n\n\n\nRepeat step 1 for every coefficient in the model to construct a \\(J\\) matrix.\nExtract the variance-covariance matrix of the coefficient estimates (usually with vcov(model)): \\(V\\)\n\nStandard errors are the square root of the diagonal of \\(JVJ'\\)\n\n\nScroll down this page to the Numerical Derivatives section to see a detailed explanation, along with code for manual computation.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#standard-errors-and-intervals-for-slopes-and-comparisons",
    "href": "vignettes/uncertainty.html#standard-errors-and-intervals-for-slopes-and-comparisons",
    "title": "Standard Errors",
    "section": "",
    "text": "All standard errors for the slopes() and comparisons() functions are computed using the delta method, as described above. The confidence intervals are calculated as estimate ± qnorm((1 - conf_level) / 2) standard errors (e.g., for 95% confidence intervals, estimate ± 1.96 standard errors) and assume that the (transformed) estimates are normally distributed.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#standard-errors-and-intervals-for-predictions",
    "href": "vignettes/uncertainty.html#standard-errors-and-intervals-for-predictions",
    "title": "Standard Errors",
    "section": "",
    "text": "The predictions() function can compute the confidence intervals in two main ways. For certain models, the type argument accept this value: type=\"invlink(link)\". In those cases, predictions() will first compute estimates on the link scale, and then back transform them using the inverse link function supplied by insight::link_inverse(model) function. In all other cases, standard errors are computed using the delta method directly on the specific scale, and then build symmetric intervals around the estimates.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#robust-standard-errors",
    "href": "vignettes/uncertainty.html#robust-standard-errors",
    "title": "Standard Errors",
    "section": "",
    "text": "All the functions in the marginaleffects package can compute robust standard errors on the fly for any model type supported by the sandwich package. The vcov argument supports string shortcuts like \"HC3\", a one-sided formula to request clustered standard errors, variance-covariance matrices, or functions which return such matrices. Here are a few examples.\nAdjusted predictions with classical or heteroskedasticity-robust standard errors:\n\nlibrary(marginaleffects)\nlibrary(patchwork)\nmod &lt;- lm(mpg ~ hp, data = mtcars)\n\np &lt;- predictions(mod)\nhead(p, 2)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      22.6      0.777 29.1   &lt;0.001 614.7  21.1   24.1\n#&gt;      22.6      0.777 29.1   &lt;0.001 614.7  21.1   24.1\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp\n\np &lt;- predictions(mod, vcov = \"HC3\")\nhead(p, 2)\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      22.6      0.863 26.2   &lt;0.001 499.5  20.9   24.3\n#&gt;      22.6      0.863 26.2   &lt;0.001 499.5  20.9   24.3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp\n\nMarginal effects with cluster-robust standard errors:\n\navg_slopes(mod, vcov = ~cyl)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 %\n#&gt;   -0.0682     0.0187 -3.65   &lt;0.001 11.9 -0.105 -0.0316\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nComparing adjusted predictions with classical and robust standard errors:\n\np1 &lt;- plot_predictions(mod, condition = \"hp\")\np2 &lt;- plot_predictions(mod, condition = \"hp\", vcov = \"HC3\")\np1 + p2",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#simulation-based-inference",
    "href": "vignettes/uncertainty.html#simulation-based-inference",
    "title": "Standard Errors",
    "section": "",
    "text": "marginaleffects offers an experimental inferences function to conduct simulation-based inference following the strategy proposed by Krinsky & Robb (1986):\n\nDraw iter sets of simulated coefficients from a multivariate normal distribution with mean equal to the original model’s estimated coefficients and variance equal to the model’s variance-covariance matrix (classical, “HC3”, or other).\nUse the iter sets of coefficients to compute iter sets of estimands: predictions, comparisons, or slopes.\nTake quantiles of the resulting distribution of estimands to obtain a confidence interval and the standard deviation of simulated estimates to estimate the standard error.\n\nHere are a few examples:\n\nlibrary(marginaleffects)\nlibrary(ggplot2)\nlibrary(ggdist)\n\nmod &lt;- glm(vs ~ hp * wt + factor(gear), data = mtcars, family = binomial)\n\nmod |&gt; predictions() |&gt; inferences(method = \"simulation\")\n#&gt; \n#&gt;  Estimate    2.5 % 97.5 %  hp   wt gear\n#&gt;  7.84e-01 2.69e-01  0.974 110 2.62    4\n#&gt;  7.84e-01 3.37e-01  0.960 110 2.88    4\n#&gt;  8.98e-01 4.62e-01  0.988  93 2.32    4\n#&gt;  8.74e-01 1.94e-01  0.996 110 3.21    3\n#&gt;  1.31e-02 8.64e-05  0.710 175 3.44    3\n#&gt; --- 22 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n#&gt;  3.83e-01 2.19e-02  0.957 113 1.51    5\n#&gt;  1.21e-06 3.82e-12  0.387 264 3.17    5\n#&gt;  6.89e-03 4.14e-05  0.539 175 2.77    5\n#&gt;  8.07e-11 2.22e-16  0.786 335 3.57    5\n#&gt;  7.95e-01 3.34e-01  0.965 109 2.78    4\n#&gt; Type:  invlink(link) \n#&gt; Columns: rowid, estimate, vs, hp, wt, gear, conf.low, conf.high\n\nmod |&gt; avg_slopes(vcov = ~gear) |&gt; inferences(method = \"simulation\")\n#&gt; \n#&gt;  Term          Contrast  Estimate   2.5 %  97.5 %\n#&gt;  gear mean(4) - mean(3) -3.92e-02 -0.0889 0.12086\n#&gt;  gear mean(5) - mean(3) -1.93e-01 -0.4882 0.32973\n#&gt;  hp   mean(dY/dX)       -5.02e-03 -0.0114 0.00582\n#&gt;  wt   mean(dY/dX)       -3.98e-05 -0.7450 0.66780\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted, conf.low, conf.high\n\nSince simulation based inference generates iter estimates of the quantities of interest, we can treat them similarly to draws from the posterior distribution in bayesian models. For example, we can extract draws using the posterior_draws() function, and plot their distributions using packages likeggplot2 and ggdist:\n\nmod |&gt;\n  avg_comparisons(variables = \"gear\") |&gt;\n  inferences(method = \"simulation\") |&gt;\n  posterior_draws(\"rvar\") |&gt;\n  ggplot(aes(y = contrast, xdist = rvar)) +\n  stat_slabinterval()",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#bootstrap",
    "href": "vignettes/uncertainty.html#bootstrap",
    "title": "Standard Errors",
    "section": "",
    "text": "It is easy to use the bootstrap as an alternative strategy to compute standard errors and confidence intervals. Several R packages can help us achieve this, including the long-established boot package:\n\nlibrary(boot)\nset.seed(123)\n\nbootfun &lt;- function(data, indices, ...) {\n    d &lt;- data[indices, ]\n    mod &lt;- lm(mpg ~ am + hp + factor(cyl), data = d)\n    cmp &lt;- comparisons(mod, newdata = d, vcov = FALSE, variables = \"am\")\n    tidy(cmp)$estimate\n}\n\nb &lt;- boot(data = mtcars, statistic = bootfun, R = 1000)\n\nb\n#&gt; \n#&gt; ORDINARY NONPARAMETRIC BOOTSTRAP\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt; boot(data = mtcars, statistic = bootfun, R = 1000)\n#&gt; \n#&gt; \n#&gt; Bootstrap Statistics :\n#&gt;      original     bias    std. error\n#&gt; t1*  4.157856 0.01543426    1.003461\n#&gt; t2*  4.157856 0.01543426    1.003461\n#&gt; t3*  4.157856 0.01543426    1.003461\n#&gt; t4*  4.157856 0.01543426    1.003461\n#&gt; t5*  4.157856 0.01543426    1.003461\n#&gt; t6*  4.157856 0.01543426    1.003461\n#&gt; t7*  4.157856 0.01543426    1.003461\n#&gt; t8*  4.157856 0.01543426    1.003461\n#&gt; t9*  4.157856 0.01543426    1.003461\n#&gt; t10* 4.157856 0.01543426    1.003461\n#&gt; t11* 4.157856 0.01543426    1.003461\n#&gt; t12* 4.157856 0.01543426    1.003461\n#&gt; t13* 4.157856 0.01543426    1.003461\n#&gt; t14* 4.157856 0.01543426    1.003461\n#&gt; t15* 4.157856 0.01543426    1.003461\n#&gt; t16* 4.157856 0.01543426    1.003461\n#&gt; t17* 4.157856 0.01543426    1.003461\n#&gt; t18* 4.157856 0.01543426    1.003461\n#&gt; t19* 4.157856 0.01543426    1.003461\n#&gt; t20* 4.157856 0.01543426    1.003461\n#&gt; t21* 4.157856 0.01543426    1.003461\n#&gt; t22* 4.157856 0.01543426    1.003461\n#&gt; t23* 4.157856 0.01543426    1.003461\n#&gt; t24* 4.157856 0.01543426    1.003461\n#&gt; t25* 4.157856 0.01543426    1.003461\n#&gt; t26* 4.157856 0.01543426    1.003461\n#&gt; t27* 4.157856 0.01543426    1.003461\n#&gt; t28* 4.157856 0.01543426    1.003461\n#&gt; t29* 4.157856 0.01543426    1.003461\n#&gt; t30* 4.157856 0.01543426    1.003461\n#&gt; t31* 4.157856 0.01543426    1.003461\n#&gt; t32* 4.157856 0.01543426    1.003461\nboot.ci(b, type = \"perc\")\n#&gt; BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\n#&gt; Based on 1000 bootstrap replicates\n#&gt; \n#&gt; CALL : \n#&gt; boot.ci(boot.out = b, type = \"perc\")\n#&gt; \n#&gt; Intervals : \n#&gt; Level     Percentile     \n#&gt; 95%   ( 2.240,  6.277 )  \n#&gt; Calculations and Intervals on Original Scale\n\nNote that, in the code above, we set vcov=FALSE to avoid computation of delta method standard errors and speed things up.\nCompare to the delta method standard errors:\n\nmod &lt;- lm(mpg ~ am + hp + factor(cyl), data = mtcars)\navg_comparisons(mod, variables = \"am\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      4.16       1.26 3.31   &lt;0.001 10.1   1.7   6.62\n#&gt; \n#&gt; Term: am\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#mixed-effects-models-satterthwaite-and-kenward-roger-corrections",
    "href": "vignettes/uncertainty.html#mixed-effects-models-satterthwaite-and-kenward-roger-corrections",
    "title": "Standard Errors",
    "section": "",
    "text": "For linear mixed effects models we can apply the Satterthwaite and Kenward-Roger corrections in the same way as above:\n\nlibrary(marginaleffects)\nlibrary(patchwork)\nlibrary(lme4)\n\ndat &lt;- mtcars\ndat$cyl &lt;- factor(dat$cyl)\ndat$am &lt;- as.logical(dat$am)\nmod &lt;- lmer(mpg ~ hp + am + (1 | cyl), data = dat)\n\nMarginal effects at the mean with classical standard errors and z-statistic:\n\nslopes(mod, newdata = \"mean\")\n#&gt; \n#&gt;  Term     Contrast Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;    am TRUE - FALSE   4.6661     1.1343  4.11   &lt;0.001 14.6  2.4430  6.8892\n#&gt;    hp dY/dX         -0.0518     0.0115 -4.52   &lt;0.001 17.3 -0.0743 -0.0294\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, am, cyl, mpg\n\nMarginal effects at the mean with Kenward-Roger adjusted variance-covariance and degrees of freedom:\n\nslopes(mod,\n                newdata = \"mean\",\n                vcov = \"kenward-roger\")\n#&gt; \n#&gt;  Term     Contrast Estimate Std. Error     t Pr(&gt;|t|)   S  2.5 %  97.5 %   Df\n#&gt;    am TRUE - FALSE   4.6661     1.2824  3.64   0.0874 3.5 -1.980 11.3121 1.68\n#&gt;    hp dY/dX         -0.0518     0.0152 -3.41   0.0964 3.4 -0.131  0.0269 1.68\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, am, cyl, mpg, df\n\nWe can use the same option in any of the package’s core functions, including:\n\nplot_predictions(mod, condition = \"hp\", vcov = \"satterthwaite\")",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#numerical-derivatives-sensitivity-to-step-size",
    "href": "vignettes/uncertainty.html#numerical-derivatives-sensitivity-to-step-size",
    "title": "Standard Errors",
    "section": "",
    "text": "dat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\ndat$large_penguin &lt;- ifelse(dat$body_mass_g &gt; median(dat$body_mass_g, na.rm = TRUE), 1, 0)\nmod &lt;- glm(large_penguin ~ bill_length_mm * flipper_length_mm + species, data = dat, family = binomial)\n\nmarginaleffects uses numerical derivatives in two contexts:\n\nEstimate the partial derivatives reported by slopes() function.\n\nCentered finite difference\n\n\\(\\frac{f(x + \\varepsilon_1 / 2) - f(x - \\varepsilon_1 / 2)}{\\varepsilon_1}\\), where we take the derivative with respect to a predictor of interest, and \\(f\\) is the predict() function.\n\n\nEstimate standard errors using the delta method.\n\nForward finite difference\n\n\\(\\frac{g(\\hat{\\beta}) - g(\\hat{\\beta} + \\varepsilon_2)}{\\varepsilon_2}\\), where we take the derivative with respect to a model’s coefficients, and \\(g\\) is a marginaleffects function which returns some quantity of interest (e.g., slope, contrasts, predictions, etc.)\n\n\n\nNote that the step sizes used in those two contexts can differ. If the variables and coefficients have very different scales, it may make sense to use different values for \\(\\varepsilon_1\\) and \\(\\varepsilon_2\\).\nBy default, \\(\\varepsilon_1\\) is set to 1e-4 times the range of the variable with respect to which we are taking the derivative. By default, \\(\\varepsilon_2\\) is set to the maximum value of 1e-8, or 1e-4 times the smallest absolute coefficient estimate. (These choices are arbitrary, but I have found that in practice, smaller values can produce unstable results.)\n\\(\\varepsilon_1\\) can be controlled by the eps argument of the slopes() function. \\(\\varepsilon_2\\) can be controlled by setting a global option which tells marginaleffects to compute the jacobian using the numDeriv package instead of its own internal functions. This allows more control over the step size, and also gives access to other differentiation methods, such as Richardson’s. To use numDeriv, we define a list of arguments which will be pushed forward to numDeriv::jacobian:\n\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00595 4.69   &lt;0.001 18.4 0.0162 0.0395\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"Richardson\"))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00595 4.69   &lt;0.001 18.4 0.0162 0.0395\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-3)))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    0.0279      0.568 0.049    0.961 0.1 -1.09   1.14\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-5)))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00601 4.64   &lt;0.001 18.1 0.0161 0.0396\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\noptions(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-7)))\navg_slopes(mod, variables = \"bill_length_mm\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0279    0.00595 4.68   &lt;0.001 18.4 0.0162 0.0395\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNotice that the standard errors can vary considerably when using different step sizes. It is good practice for analysts to consider the sensitivity of their results to this setting.\nNow, we illustrate the full process of standard error computation, using raw R code. First, we choose two step sizes:\n\neps1 &lt;- 1e-5 # slope\neps2 &lt;- 1e-7 # delta method\n\ns &lt;- slopes(mod, newdata = head(dat, 3), variables = \"bill_length_mm\", eps = eps1)\nprint(s[, 1:5], digits = 6)\n#&gt; \n#&gt;   Estimate Std. Error       z\n#&gt;  0.0179765 0.00881402 2.03954\n#&gt;  0.0359630 0.01254629 2.86642\n#&gt;  0.0849071 0.02137500 3.97226\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Columns: rowid, term, estimate, std.error, statistic\n\nWe can get the same estimates manually with these steps:\n\nlinkinv &lt;- mod$family$linkinv\n\n## increment the variable of interest by h\ndat_hi &lt;- transform(dat, bill_length_mm = bill_length_mm + eps1)\n\n## model matrices: first 3 rows\nmm_lo &lt;- insight::get_modelmatrix(mod, data = dat)[1:3,]\nmm_hi &lt;- insight::get_modelmatrix(mod, data = dat_hi)[1:3,]\n\n## predictions\np_lo &lt;- linkinv(mm_lo %*% coef(mod))\np_hi &lt;- linkinv(mm_hi %*% coef(mod))\n\n## slopes\n(p_hi - p_lo) / eps1\n#&gt;         [,1]\n#&gt; 1 0.01797653\n#&gt; 2 0.03596304\n#&gt; 3 0.08490712\n\nTo get standard errors, we build a jacobian matrix where each column holds derivatives of the vector valued slope function, with respect to each of the coefficients. Using the same example:\n\nb_lo &lt;- b_hi &lt;- coef(mod)\nb_hi[1] &lt;- b_hi[1] + eps2\n\ndydx_lo &lt;- (linkinv(mm_hi %*% b_lo) - linkinv(mm_lo %*% b_lo)) / eps1\ndydx_hi &lt;- (linkinv(mm_hi %*% b_hi) - linkinv(mm_lo %*% b_hi)) / eps1\n(dydx_hi - dydx_lo) / eps2\n#&gt;         [,1]\n#&gt; 1 0.01598721\n#&gt; 2 0.02767231\n#&gt; 3 0.02275957\n\nThis gives us the first column of \\(J\\), which we can recover in full from the marginaleffects object attribute:\n\nJ &lt;- attr(s, \"jacobian\")\nJ\n#&gt;      (Intercept) bill_length_mm flipper_length_mm speciesChinstrap speciesGentoo bill_length_mm:flipper_length_mm\n#&gt; [1,]  0.01601497      0.6777495          2.897231                0             0                         122.6914\n#&gt; [2,]  0.02770006      1.1957657          5.153100                0             0                         222.4989\n#&gt; [3,]  0.02281508      1.1500800          4.440004                0             0                         224.0830\n\nTo build the full matrix, we would simply iterate through the coefficients, incrementing them one after the other. Finally, we get standard errors via:\n\nsqrt(diag(J %*% vcov(mod) %*% t(J)))\n#&gt; [1] 0.008814015 0.012546293 0.021375005\n\nWhich corresponds to our original standard errors:\n\nprint(s[, 1:5], digits = 7)\n#&gt; \n#&gt;    Estimate  Std. Error        z\n#&gt;  0.01797650 0.008814015 2.039536\n#&gt;  0.03596299 0.012546293 2.866424\n#&gt;  0.08490708 0.021375005 3.972260\n#&gt; \n#&gt; Term: bill_length_mm\n#&gt; Columns: rowid, term, estimate, std.error, statistic\n\nReverting to default settings:\n\noptions(marginaleffects_numDeriv = NULL)\n\nNote that our default results for this model are very similar – but not exactly identical – to those generated by the margins. As should be expected, the results in margins are also very sensitive to the value of eps for this model:\n\nlibrary(margins)\nmargins(mod, variables = \"bill_length_mm\", data = head(dat, 3), unit_ses = TRUE)$SE_dydx_bill_length_mm\n\nmargins(mod, variables = \"bill_length_mm\", data = head(dat, 3), eps = 1e-4, unit_ses = TRUE)$SE_dydx_bill_length_mm\n\nmargins(mod, variables = \"bill_length_mm\", data = head(dat, 3), eps = 1e-5, unit_ses = TRUE)$SE_dydx_bill_length_mm",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/uncertainty.html#bayesian-estimates-and-credible-intervals",
    "href": "vignettes/uncertainty.html#bayesian-estimates-and-credible-intervals",
    "title": "Standard Errors",
    "section": "",
    "text": "See the brms vignette for a discussion of bayesian estimates and credible intervals.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Standard Errors"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html",
    "href": "vignettes/equivalence.html",
    "title": "Equivalence Tests",
    "section": "",
    "text": "In many contexts, analysts are less interested in rejecting a null hypothesis, and more interested in testing whether an estimate is “inferior”, “superior”, or “equivalent” to a given threshold or interval. For example, medical researchers may wish to determine if the estimated effect of a new treatment is larger than the effect of prior treatments, or larger than some threshold of “clinical significance.” Alternatively, researchers may wish to support a claim that an estimated parameter is “equivalent to” or “not meaningfully different from” a null hypothesis.\nTo answer these questions, we can use non-inferiority, non-superiority, or equivalence tests like the two-one-sided test (TOST). This article gives a primer and tutorial on TOST:\n\nLakens D, Scheel AM, Isager PM. Equivalence Testing for Psychological Research: A Tutorial. Advances in Methods and Practices in Psychological Science. 2018;1(2):259-269. doi:10.1177/2515245918770963\n\nThe hypotheses() function of the marginaleffects package includes an equivalence argument which allows users to apply these tests to any of the quantities generated by the package, as well as to arbitrary functions of a model’s parameters. To illustrate, we begin by estimating a simple linear regression model:\n\n\nR\nPython\n\n\n\n\nlibrary(marginaleffects)\nmod &lt;- lm(mpg ~ hp + factor(gear), data = mtcars)\n\n\n\n\nimport polars as pl\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nmtcars = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\")\nmtcars = mtcars.cast({\"gear\" : pl.Utf8, \"hp\" : pl.Float64})\n\nmod = smf.ols(\"mpg ~ hp + gear\", data = mtcars.to_pandas()).fit()\n\n\n\n\nThe rest of this section considers several quantities estimated by marginaleffects.\n\nConsider a single prediction, where all predictors are held at their median or mode:\n\n\nR\nPython\n\n\n\n\np &lt;- predictions(mod, newdata = \"median\")\np\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  hp gear\n#&gt;      19.7          1 19.6   &lt;0.001 281.3  17.7   21.6 123    3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, gear, mpg\n\n\n\n\np = predictions(mod, newdata = \"median\")\nprint(p)\n#&gt; shape: (1, 7)\n#&gt; ┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n#&gt; │ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n#&gt; │ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n#&gt; ╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n#&gt; │ 19.7     ┆ 1         ┆ 19.6 ┆ 0       ┆ inf ┆ 17.7 ┆ 21.6  │\n#&gt; └──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n#&gt; \n#&gt; Columns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\nNow we specify an equivalence interval (or “region”) for predictions between 17 and 18:\n\n\nR\nPython\n\n\n\n\nhypotheses(p, equivalence = c(17, 18))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % p (NonSup) p (NonInf) p (Equiv)  hp gear\n#&gt;      19.7          1 19.6   &lt;0.001 281.3  17.7   21.6      0.951    0.00404     0.951 123    3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, gear, mpg, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\n# Not implemented yet\n\n\n\n\nThe results allow us to draw three conclusions:\n\nThe p value for the non-inferiority test is 0.0040. This suggests that we can reject the null hypothesis that the parameter is below 17.\nThe p value for the non-superiority test is 0.9508. This suggests that we cannot reject the null hypothesis that the parameter (19.6589) is above 18.\nThe p value for the equivalence test is 0.9508. This suggests that we cannot reject the hypothesis that the parameter falls outside the equivalence interval.\n\nThe hypotheses function also allows users to conduct equivalence, non-inferiority, and non-superiority tests for model coefficients, and for arbitrary functions of model coefficients.\nOur estimate of the coefficient affecting factor(gear)5 in the model is:\n\n\nR\nPython\n\n\n\n\ncoef(mod)[4]\n#&gt; factor(gear)5 \n#&gt;      6.574763\n\n\n\n\nmod.params['gear[T.5]']\n#&gt; 6.574762842180771\n\n\n\n\nWe can test if this parameter is likely to fall in the [5,7] interval by:\n\n\nR\nPython\n\n\n\n\nhypotheses(mod, equivalence = c(5, 7))[4, ]\n#&gt; \n#&gt;  Estimate Std. Error z Pr(&gt;|z|)    S 2.5 % 97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;      6.57       1.64 4   &lt;0.001 14.0  3.36   9.79      0.398      0.169     0.398\n#&gt; \n#&gt; Term: factor(gear)5\n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\nh = pl.DataFrame(hypotheses(mod, equivalence = [5., 7.]))[2,:]\nprint(h)\n#&gt; shape: (1, 13)\n#&gt; ┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n#&gt; │ term      ┆ estimate ┆ std_error ┆ statistic ┆ … ┆ statistic ┆ p_value_n ┆ p_value_n ┆ p_value_e │\n#&gt; │ ---       ┆ ---      ┆ ---       ┆ ---       ┆   ┆ _nonsup   ┆ oninf     ┆ onsup     ┆ quiv      │\n#&gt; │ str       ┆ f64      ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n#&gt; │           ┆          ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n#&gt; ╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n#&gt; │ gear[T.5] ┆ 6.574763 ┆ 1.642684  ┆ 4.002452  ┆ … ┆ -0.258867 ┆ 0.168867  ┆ 0.397869  ┆ 0.397869  │\n#&gt; └───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n\n\n\n\nThe p value is 0.3979, so we cannot reject the hypothesis that the factor(gear)5 parameter falls outside the [5,7] interval.\n\nThe same syntax can be used to conduct tests for all the quantities produced by the marginaleffects package. For example, imagine that, for substantive or theoretical reasons, an average slope between -0.1 and 0.1 is uninteresting. We can conduct an equivalence test to check if this is the case:\n\n\nR\nPython\n\n\n\n\navg_slopes(mod, variables = \"hp\", equivalence = c(-.1, .1))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;   -0.0669      0.011 -6.05   &lt;0.001 29.4 -0.0885 -0.0452     &lt;0.001    0.00135   0.00135\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\ns = pl.DataFrame(avg_slopes(mod, variables = \"hp\", equivalence = [-.1, .1]))\nprint(s)\n#&gt; shape: (1, 14)\n#&gt; ┌──────┬────────────┬───────────┬───────────┬───┬────────────┬────────────┬────────────┬───────────┐\n#&gt; │ term ┆ contrast   ┆ estimate  ┆ std_error ┆ … ┆ statistic_ ┆ p_value_no ┆ p_value_no ┆ p_value_e │\n#&gt; │ ---  ┆ ---        ┆ ---       ┆ ---       ┆   ┆ nonsup     ┆ ninf       ┆ nsup       ┆ quiv      │\n#&gt; │ str  ┆ str        ┆ f64       ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n#&gt; │      ┆            ┆           ┆           ┆   ┆ f64        ┆ f64        ┆ f64        ┆ f64       │\n#&gt; ╞══════╪════════════╪═══════════╪═══════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n#&gt; │ hp   ┆ mean(dY/dX ┆ -0.066854 ┆ 0.011039  ┆ … ┆ -15.114693 ┆ 0.001339   ┆ 6.4786e-52 ┆ 0.001339  │\n#&gt; │      ┆ )          ┆           ┆           ┆   ┆            ┆            ┆            ┆           │\n#&gt; └──────┴────────────┴───────────┴───────────┴───┴────────────┴────────────┴────────────┴───────────┘\n\n\n\n\nThe p value is 0.0013, which suggests that we can reject the hypothesis that the parameter falls outside the region of “substantive equivalence” that we have defined by the interval.\n\nConsider a model with a multiplicative interaction:\n\n\nR\nPython\n\n\n\n\nint &lt;- lm(mpg ~ hp * factor(gear), data = mtcars)\n\n\n\n\ninter = smf.ols(\"mpg ~ hp * gear\", data = mtcars.to_pandas()).fit()\n\n\n\n\nThe average contrast for a change of 1 unit in hp differs based on the value of gear:\n\n\nR\nPython\n\n\n\n\navg_comparisons(int, variables = \"hp\", by = \"gear\")\n#&gt; \n#&gt;  gear Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;     3  -0.0522     0.0146 -3.59   &lt;0.001 11.6 -0.0808 -0.0237\n#&gt;     4  -0.1792     0.0303 -5.92   &lt;0.001 28.2 -0.2385 -0.1199\n#&gt;     5  -0.0583     0.0126 -4.61   &lt;0.001 17.9 -0.0830 -0.0335\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\nprint(avg_comparisons(inter, variables = \"hp\", by = \"gear\"))\n#&gt; shape: (3, 10)\n#&gt; ┌──────┬──────┬──────────┬──────────┬───┬──────────┬──────┬─────────┬─────────┐\n#&gt; │ gear ┆ Term ┆ Contrast ┆ Estimate ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%    ┆ 97.5%   │\n#&gt; │ ---  ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---  ┆ ---     ┆ ---     │\n#&gt; │ str  ┆ str  ┆ str      ┆ str      ┆   ┆ str      ┆ str  ┆ str     ┆ str     │\n#&gt; ╞══════╪══════╪══════════╪══════════╪═══╪══════════╪══════╪═════════╪═════════╡\n#&gt; │ 3    ┆ hp   ┆ +1       ┆ -0.0522  ┆ … ┆ 0.000333 ┆ 11.6 ┆ -0.0808 ┆ -0.0237 │\n#&gt; │ 4    ┆ hp   ┆ +1       ┆ -0.179   ┆ … ┆ 3.16e-09 ┆ 28.2 ┆ -0.238  ┆ -0.12   │\n#&gt; │ 5    ┆ hp   ┆ +1       ┆ -0.0583  ┆ … ┆ 3.98e-06 ┆ 17.9 ┆ -0.083  ┆ -0.0335 │\n#&gt; └──────┴──────┴──────────┴──────────┴───┴──────────┴──────┴─────────┴─────────┘\n#&gt; \n#&gt; Columns: gear, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\nAre these contrasts different from one another? Let’s look at the pairwise differences between them:\n\n\nR\nPython\n\n\n\n\navg_comparisons(int, variables = \"hp\", by = \"gear\",\n    hypothesis = \"pairwise\")\n#&gt; \n#&gt;   Term Estimate Std. Error      z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;  3 - 4  0.12695     0.0336  3.781   &lt;0.001 12.6  0.0611  0.1928\n#&gt;  3 - 5  0.00603     0.0193  0.313    0.754  0.4 -0.0318  0.0438\n#&gt;  4 - 5 -0.12092     0.0328 -3.688   &lt;0.001 12.1 -0.1852 -0.0567\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\n\n\n\nprint(avg_comparisons(inter, variables = \"hp\", by = \"gear\",\n    hypothesis = \"pairwise\"))\n#&gt; shape: (3, 8)\n#&gt; ┌───────────────┬──────────┬───────────┬───────┬──────────┬───────┬─────────┬─────────┐\n#&gt; │ Term          ┆ Estimate ┆ Std.Error ┆ z     ┆ P(&gt;|z|)  ┆ S     ┆ 2.5%    ┆ 97.5%   │\n#&gt; │ ---           ┆ ---      ┆ ---       ┆ ---   ┆ ---      ┆ ---   ┆ ---     ┆ ---     │\n#&gt; │ str           ┆ str      ┆ str       ┆ str   ┆ str      ┆ str   ┆ str     ┆ str     │\n#&gt; ╞═══════════════╪══════════╪═══════════╪═══════╪══════════╪═══════╪═════════╪═════════╡\n#&gt; │ Row 1 - Row 2 ┆ 0.127    ┆ 0.0336    ┆ 3.78  ┆ 0.000156 ┆ 12.6  ┆ 0.0611  ┆ 0.193   │\n#&gt; │ Row 1 - Row 3 ┆ 0.00603  ┆ 0.0193    ┆ 0.313 ┆ 0.754    ┆ 0.406 ┆ -0.0318 ┆ 0.0438  │\n#&gt; │ Row 2 - Row 3 ┆ -0.121   ┆ 0.0328    ┆ -3.69 ┆ 0.000226 ┆ 12.1  ┆ -0.185  ┆ -0.0567 │\n#&gt; └───────────────┴──────────┴───────────┴───────┴──────────┴───────┴─────────┴─────────┘\n#&gt; \n#&gt; Columns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\nWe consider that these pairwise comparisons are “equivalent to zero” when they fall in the [-.1, .1] interval:\n\n\nR\nPython\n\n\n\n\navg_comparisons(int, variables = \"hp\", by = \"gear\",\n    hypothesis = \"pairwise\",\n    equivalence = c(-.1, .1))\n#&gt; \n#&gt;   Term Estimate Std. Error      z Pr(&gt;|z|)    S   2.5 %  97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;  3 - 4  0.12695     0.0336  3.781   &lt;0.001 12.6  0.0611  0.1928      0.789     &lt;0.001     0.789\n#&gt;  3 - 5  0.00603     0.0193  0.313    0.754  0.4 -0.0318  0.0438     &lt;0.001     &lt;0.001    &lt;0.001\n#&gt;  4 - 5 -0.12092     0.0328 -3.688   &lt;0.001 12.1 -0.1852 -0.0567     &lt;0.001      0.738     0.738\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\nc = pl.DataFrame(\n    avg_comparisons(inter, variables = \"hp\", by = \"gear\",\n        hypothesis = \"pairwise\",\n        equivalence = [-.1, .1])\n    )\nprint(c)\n#&gt; shape: (3, 13)\n#&gt; ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n#&gt; │ term      ┆ estimate  ┆ std_error ┆ statistic ┆ … ┆ statistic ┆ p_value_n ┆ p_value_n ┆ p_value_ │\n#&gt; │ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _nonsup   ┆ oninf     ┆ onsup     ┆ equiv    │\n#&gt; │ str       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n#&gt; │           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n#&gt; ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n#&gt; │ Row 1 -   ┆ 0.126946  ┆ 0.033575  ┆ 3.78103   ┆ … ┆ 0.802581  ┆ 6.9245e-1 ┆ 0.788891  ┆ 0.788891 │\n#&gt; │ Row 2     ┆           ┆           ┆           ┆   ┆           ┆ 2         ┆           ┆          │\n#&gt; │ Row 1 -   ┆ 0.006029  ┆ 0.019276  ┆ 0.312767  ┆ … ┆ -4.874941 ┆ 1.8938e-8 ┆ 5.4421e-7 ┆ 5.4421e- │\n#&gt; │ Row 3     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n#&gt; │ Row 2 -   ┆ -0.120917 ┆ 0.032785  ┆ -3.688238 ┆ … ┆ -6.738455 ┆ 0.73827   ┆ 8.0040e-1 ┆ 0.73827  │\n#&gt; │ Row 3     ┆           ┆           ┆           ┆   ┆           ┆           ┆ 2         ┆          │\n#&gt; └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n\n\n\n\nThe p (Equiv) column shows that the difference between the average contrasts when gear is 3 and gear is 5 can be said to be equivalent to the specified interval. However, there are good reasons to think that the other two pairwise comparisons may fall outside the interval.\n\nThis example shows the equivalence between results produced by the emmeans package and the predictions() function:\n\nlibrary(emmeans)\n\nmod &lt;- lm(log(conc) ~ source + factor(percent), data = pigs)\n\n## {emmeans}\nemmeans(mod, specs = \"source\") |&gt;\n    pairs() |&gt;\n    test(df = Inf,\n         null = 0,\n         delta = log(1.25),\n         side = \"equivalence\",\n         adjust = \"none\")\n#&gt;  contrast    estimate     SE  df z.ratio p.value\n#&gt;  fish - soy    -0.273 0.0529 Inf   0.937  0.8257\n#&gt;  fish - skim   -0.402 0.0542 Inf   3.308  0.9995\n#&gt;  soy - skim    -0.130 0.0530 Inf  -1.765  0.0388\n#&gt; \n#&gt; Results are averaged over the levels of: percent \n#&gt; Degrees-of-freedom method: user-specified \n#&gt; Results are given on the log (not the response) scale. \n#&gt; Statistics are tests of equivalence with a threshold of 0.22314 \n#&gt; P values are left-tailed\n\n## {marginaleffects}\npredictions(\n    mod,\n    newdata = \"balanced\",\n    by = \"source\",\n    hypothesis = \"pairwise\",\n    equivalence = c(-log(1.25), log(1.25))\n)\n#&gt; \n#&gt;         Term Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;  fish - soy    -0.273     0.0529 -5.15   &lt;0.001 21.9 -0.377 -0.1690     &lt;0.001     0.8257    0.8257\n#&gt;  fish - skim   -0.402     0.0542 -7.43   &lt;0.001 43.0 -0.508 -0.2961     &lt;0.001     0.9995    0.9995\n#&gt;  soy - skim    -0.130     0.0530 -2.44   0.0146  6.1 -0.233 -0.0255     &lt;0.001     0.0388    0.0388\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\nNow we show that the results produced by hypotheses() are identical to the results produced by the equivalence package in the case of a simple t-test:\n\nlibrary(equivalence)\n\nset.seed(1024)\n\n## simulate data data\nN &lt;- 20\ndat &lt;- data.frame(\n    y = rnorm(N),\n    x = sample(c(rep(0, N / 2), rep(1, N / 2)), N))\n\n## fit model\nmod &lt;- lm(y ~ x, data = dat)\n\n## test with the {equivalence} package\ne &lt;- tost(\n    x = dat$y[dat$x == 0],\n    y = dat$y[dat$x == 1],\n    epsilon = 10)\ne\n#&gt; \n#&gt;  Welch Two Sample TOST\n#&gt; \n#&gt; data:  dat$y[dat$x == 0] and dat$y[dat$x == 1]\n#&gt; df = 17.607\n#&gt; sample estimates:\n#&gt;  mean of x  mean of y \n#&gt; -0.3788551 -0.2724594 \n#&gt; \n#&gt; Epsilon: 10 \n#&gt; 95 percent two one-sided confidence interval (TOST interval):\n#&gt;  -1.058539  0.845747\n#&gt; Null hypothesis of statistical difference is: rejected \n#&gt; TOST p-value: 4.248528e-13\n\n## test with {marginaleffects} package\nh &lt;- hypotheses(mod, equivalence = c(-10, 10), df = e$parameter)[2, ]\nh\n#&gt; \n#&gt;  Estimate Std. Error     t Pr(&gt;|t|)   S 2.5 % 97.5 % p (NonSup) p (NonInf) p (Equiv)   Df\n#&gt;     0.106      0.548 0.194    0.848 0.2 -1.05   1.26     &lt;0.001     &lt;0.001    &lt;0.001 17.6\n#&gt; \n#&gt; Term: x\n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, df, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n# identical p values\nh$p.value.equiv |&gt; as.vector()\n#&gt; [1] 4.248528e-13\n\ne$tost.p.value |&gt; as.vector()\n#&gt; [1] 4.248528e-13",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html#predictions",
    "href": "vignettes/equivalence.html#predictions",
    "title": "Equivalence Tests",
    "section": "",
    "text": "Consider a single prediction, where all predictors are held at their median or mode:\n\n\nR\nPython\n\n\n\n\np &lt;- predictions(mod, newdata = \"median\")\np\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  hp gear\n#&gt;      19.7          1 19.6   &lt;0.001 281.3  17.7   21.6 123    3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, gear, mpg\n\n\n\n\np = predictions(mod, newdata = \"median\")\nprint(p)\n#&gt; shape: (1, 7)\n#&gt; ┌──────────┬───────────┬──────┬─────────┬─────┬──────┬───────┐\n#&gt; │ Estimate ┆ Std.Error ┆ z    ┆ P(&gt;|z|) ┆ S   ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---      ┆ ---       ┆ ---  ┆ ---     ┆ --- ┆ ---  ┆ ---   │\n#&gt; │ str      ┆ str       ┆ str  ┆ str     ┆ str ┆ str  ┆ str   │\n#&gt; ╞══════════╪═══════════╪══════╪═════════╪═════╪══════╪═══════╡\n#&gt; │ 19.7     ┆ 1         ┆ 19.6 ┆ 0       ┆ inf ┆ 17.7 ┆ 21.6  │\n#&gt; └──────────┴───────────┴──────┴─────────┴─────┴──────┴───────┘\n#&gt; \n#&gt; Columns: rowid, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high, rownames, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\n\n\n\nNow we specify an equivalence interval (or “region”) for predictions between 17 and 18:\n\n\nR\nPython\n\n\n\n\nhypotheses(p, equivalence = c(17, 18))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % p (NonSup) p (NonInf) p (Equiv)  hp gear\n#&gt;      19.7          1 19.6   &lt;0.001 281.3  17.7   21.6      0.951    0.00404     0.951 123    3\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, gear, mpg, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\n# Not implemented yet\n\n\n\n\nThe results allow us to draw three conclusions:\n\nThe p value for the non-inferiority test is 0.0040. This suggests that we can reject the null hypothesis that the parameter is below 17.\nThe p value for the non-superiority test is 0.9508. This suggests that we cannot reject the null hypothesis that the parameter (19.6589) is above 18.\nThe p value for the equivalence test is 0.9508. This suggests that we cannot reject the hypothesis that the parameter falls outside the equivalence interval.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html#model-coefficients",
    "href": "vignettes/equivalence.html#model-coefficients",
    "title": "Equivalence Tests",
    "section": "",
    "text": "The hypotheses function also allows users to conduct equivalence, non-inferiority, and non-superiority tests for model coefficients, and for arbitrary functions of model coefficients.\nOur estimate of the coefficient affecting factor(gear)5 in the model is:\n\n\nR\nPython\n\n\n\n\ncoef(mod)[4]\n#&gt; factor(gear)5 \n#&gt;      6.574763\n\n\n\n\nmod.params['gear[T.5]']\n#&gt; 6.574762842180771\n\n\n\n\nWe can test if this parameter is likely to fall in the [5,7] interval by:\n\n\nR\nPython\n\n\n\n\nhypotheses(mod, equivalence = c(5, 7))[4, ]\n#&gt; \n#&gt;  Estimate Std. Error z Pr(&gt;|z|)    S 2.5 % 97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;      6.57       1.64 4   &lt;0.001 14.0  3.36   9.79      0.398      0.169     0.398\n#&gt; \n#&gt; Term: factor(gear)5\n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\nh = pl.DataFrame(hypotheses(mod, equivalence = [5., 7.]))[2,:]\nprint(h)\n#&gt; shape: (1, 13)\n#&gt; ┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n#&gt; │ term      ┆ estimate ┆ std_error ┆ statistic ┆ … ┆ statistic ┆ p_value_n ┆ p_value_n ┆ p_value_e │\n#&gt; │ ---       ┆ ---      ┆ ---       ┆ ---       ┆   ┆ _nonsup   ┆ oninf     ┆ onsup     ┆ quiv      │\n#&gt; │ str       ┆ f64      ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n#&gt; │           ┆          ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n#&gt; ╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n#&gt; │ gear[T.5] ┆ 6.574763 ┆ 1.642684  ┆ 4.002452  ┆ … ┆ -0.258867 ┆ 0.168867  ┆ 0.397869  ┆ 0.397869  │\n#&gt; └───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n\n\n\n\nThe p value is 0.3979, so we cannot reject the hypothesis that the factor(gear)5 parameter falls outside the [5,7] interval.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html#slopes",
    "href": "vignettes/equivalence.html#slopes",
    "title": "Equivalence Tests",
    "section": "",
    "text": "The same syntax can be used to conduct tests for all the quantities produced by the marginaleffects package. For example, imagine that, for substantive or theoretical reasons, an average slope between -0.1 and 0.1 is uninteresting. We can conduct an equivalence test to check if this is the case:\n\n\nR\nPython\n\n\n\n\navg_slopes(mod, variables = \"hp\", equivalence = c(-.1, .1))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;   -0.0669      0.011 -6.05   &lt;0.001 29.4 -0.0885 -0.0452     &lt;0.001    0.00135   0.00135\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\ns = pl.DataFrame(avg_slopes(mod, variables = \"hp\", equivalence = [-.1, .1]))\nprint(s)\n#&gt; shape: (1, 14)\n#&gt; ┌──────┬────────────┬───────────┬───────────┬───┬────────────┬────────────┬────────────┬───────────┐\n#&gt; │ term ┆ contrast   ┆ estimate  ┆ std_error ┆ … ┆ statistic_ ┆ p_value_no ┆ p_value_no ┆ p_value_e │\n#&gt; │ ---  ┆ ---        ┆ ---       ┆ ---       ┆   ┆ nonsup     ┆ ninf       ┆ nsup       ┆ quiv      │\n#&gt; │ str  ┆ str        ┆ f64       ┆ f64       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n#&gt; │      ┆            ┆           ┆           ┆   ┆ f64        ┆ f64        ┆ f64        ┆ f64       │\n#&gt; ╞══════╪════════════╪═══════════╪═══════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n#&gt; │ hp   ┆ mean(dY/dX ┆ -0.066854 ┆ 0.011039  ┆ … ┆ -15.114693 ┆ 0.001339   ┆ 6.4786e-52 ┆ 0.001339  │\n#&gt; │      ┆ )          ┆           ┆           ┆   ┆            ┆            ┆            ┆           │\n#&gt; └──────┴────────────┴───────────┴───────────┴───┴────────────┴────────────┴────────────┴───────────┘\n\n\n\n\nThe p value is 0.0013, which suggests that we can reject the hypothesis that the parameter falls outside the region of “substantive equivalence” that we have defined by the interval.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html#difference-between-comparisons-contrasts",
    "href": "vignettes/equivalence.html#difference-between-comparisons-contrasts",
    "title": "Equivalence Tests",
    "section": "",
    "text": "Consider a model with a multiplicative interaction:\n\n\nR\nPython\n\n\n\n\nint &lt;- lm(mpg ~ hp * factor(gear), data = mtcars)\n\n\n\n\ninter = smf.ols(\"mpg ~ hp * gear\", data = mtcars.to_pandas()).fit()\n\n\n\n\nThe average contrast for a change of 1 unit in hp differs based on the value of gear:\n\n\nR\nPython\n\n\n\n\navg_comparisons(int, variables = \"hp\", by = \"gear\")\n#&gt; \n#&gt;  gear Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;     3  -0.0522     0.0146 -3.59   &lt;0.001 11.6 -0.0808 -0.0237\n#&gt;     4  -0.1792     0.0303 -5.92   &lt;0.001 28.2 -0.2385 -0.1199\n#&gt;     5  -0.0583     0.0126 -4.61   &lt;0.001 17.9 -0.0830 -0.0335\n#&gt; \n#&gt; Term: hp\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\nprint(avg_comparisons(inter, variables = \"hp\", by = \"gear\"))\n#&gt; shape: (3, 10)\n#&gt; ┌──────┬──────┬──────────┬──────────┬───┬──────────┬──────┬─────────┬─────────┐\n#&gt; │ gear ┆ Term ┆ Contrast ┆ Estimate ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5%    ┆ 97.5%   │\n#&gt; │ ---  ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---  ┆ ---     ┆ ---     │\n#&gt; │ str  ┆ str  ┆ str      ┆ str      ┆   ┆ str      ┆ str  ┆ str     ┆ str     │\n#&gt; ╞══════╪══════╪══════════╪══════════╪═══╪══════════╪══════╪═════════╪═════════╡\n#&gt; │ 3    ┆ hp   ┆ +1       ┆ -0.0522  ┆ … ┆ 0.000333 ┆ 11.6 ┆ -0.0808 ┆ -0.0237 │\n#&gt; │ 4    ┆ hp   ┆ +1       ┆ -0.179   ┆ … ┆ 3.16e-09 ┆ 28.2 ┆ -0.238  ┆ -0.12   │\n#&gt; │ 5    ┆ hp   ┆ +1       ┆ -0.0583  ┆ … ┆ 3.98e-06 ┆ 17.9 ┆ -0.083  ┆ -0.0335 │\n#&gt; └──────┴──────┴──────────┴──────────┴───┴──────────┴──────┴─────────┴─────────┘\n#&gt; \n#&gt; Columns: gear, term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\nAre these contrasts different from one another? Let’s look at the pairwise differences between them:\n\n\nR\nPython\n\n\n\n\navg_comparisons(int, variables = \"hp\", by = \"gear\",\n    hypothesis = \"pairwise\")\n#&gt; \n#&gt;   Term Estimate Std. Error      z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;  3 - 4  0.12695     0.0336  3.781   &lt;0.001 12.6  0.0611  0.1928\n#&gt;  3 - 5  0.00603     0.0193  0.313    0.754  0.4 -0.0318  0.0438\n#&gt;  4 - 5 -0.12092     0.0328 -3.688   &lt;0.001 12.1 -0.1852 -0.0567\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\n\n\n\nprint(avg_comparisons(inter, variables = \"hp\", by = \"gear\",\n    hypothesis = \"pairwise\"))\n#&gt; shape: (3, 8)\n#&gt; ┌───────────────┬──────────┬───────────┬───────┬──────────┬───────┬─────────┬─────────┐\n#&gt; │ Term          ┆ Estimate ┆ Std.Error ┆ z     ┆ P(&gt;|z|)  ┆ S     ┆ 2.5%    ┆ 97.5%   │\n#&gt; │ ---           ┆ ---      ┆ ---       ┆ ---   ┆ ---      ┆ ---   ┆ ---     ┆ ---     │\n#&gt; │ str           ┆ str      ┆ str       ┆ str   ┆ str      ┆ str   ┆ str     ┆ str     │\n#&gt; ╞═══════════════╪══════════╪═══════════╪═══════╪══════════╪═══════╪═════════╪═════════╡\n#&gt; │ Row 1 - Row 2 ┆ 0.127    ┆ 0.0336    ┆ 3.78  ┆ 0.000156 ┆ 12.6  ┆ 0.0611  ┆ 0.193   │\n#&gt; │ Row 1 - Row 3 ┆ 0.00603  ┆ 0.0193    ┆ 0.313 ┆ 0.754    ┆ 0.406 ┆ -0.0318 ┆ 0.0438  │\n#&gt; │ Row 2 - Row 3 ┆ -0.121   ┆ 0.0328    ┆ -3.69 ┆ 0.000226 ┆ 12.1  ┆ -0.185  ┆ -0.0567 │\n#&gt; └───────────────┴──────────┴───────────┴───────┴──────────┴───────┴─────────┴─────────┘\n#&gt; \n#&gt; Columns: term, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\nWe consider that these pairwise comparisons are “equivalent to zero” when they fall in the [-.1, .1] interval:\n\n\nR\nPython\n\n\n\n\navg_comparisons(int, variables = \"hp\", by = \"gear\",\n    hypothesis = \"pairwise\",\n    equivalence = c(-.1, .1))\n#&gt; \n#&gt;   Term Estimate Std. Error      z Pr(&gt;|z|)    S   2.5 %  97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;  3 - 4  0.12695     0.0336  3.781   &lt;0.001 12.6  0.0611  0.1928      0.789     &lt;0.001     0.789\n#&gt;  3 - 5  0.00603     0.0193  0.313    0.754  0.4 -0.0318  0.0438     &lt;0.001     &lt;0.001    &lt;0.001\n#&gt;  4 - 5 -0.12092     0.0328 -3.688   &lt;0.001 12.1 -0.1852 -0.0567     &lt;0.001      0.738     0.738\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n\n\n\nc = pl.DataFrame(\n    avg_comparisons(inter, variables = \"hp\", by = \"gear\",\n        hypothesis = \"pairwise\",\n        equivalence = [-.1, .1])\n    )\nprint(c)\n#&gt; shape: (3, 13)\n#&gt; ┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n#&gt; │ term      ┆ estimate  ┆ std_error ┆ statistic ┆ … ┆ statistic ┆ p_value_n ┆ p_value_n ┆ p_value_ │\n#&gt; │ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _nonsup   ┆ oninf     ┆ onsup     ┆ equiv    │\n#&gt; │ str       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n#&gt; │           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n#&gt; ╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n#&gt; │ Row 1 -   ┆ 0.126946  ┆ 0.033575  ┆ 3.78103   ┆ … ┆ 0.802581  ┆ 6.9245e-1 ┆ 0.788891  ┆ 0.788891 │\n#&gt; │ Row 2     ┆           ┆           ┆           ┆   ┆           ┆ 2         ┆           ┆          │\n#&gt; │ Row 1 -   ┆ 0.006029  ┆ 0.019276  ┆ 0.312767  ┆ … ┆ -4.874941 ┆ 1.8938e-8 ┆ 5.4421e-7 ┆ 5.4421e- │\n#&gt; │ Row 3     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n#&gt; │ Row 2 -   ┆ -0.120917 ┆ 0.032785  ┆ -3.688238 ┆ … ┆ -6.738455 ┆ 0.73827   ┆ 8.0040e-1 ┆ 0.73827  │\n#&gt; │ Row 3     ┆           ┆           ┆           ┆   ┆           ┆           ┆ 2         ┆          │\n#&gt; └───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n\n\n\n\nThe p (Equiv) column shows that the difference between the average contrasts when gear is 3 and gear is 5 can be said to be equivalent to the specified interval. However, there are good reasons to think that the other two pairwise comparisons may fall outside the interval.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html#marginal-means-and-emmeans",
    "href": "vignettes/equivalence.html#marginal-means-and-emmeans",
    "title": "Equivalence Tests",
    "section": "",
    "text": "This example shows the equivalence between results produced by the emmeans package and the predictions() function:\n\nlibrary(emmeans)\n\nmod &lt;- lm(log(conc) ~ source + factor(percent), data = pigs)\n\n## {emmeans}\nemmeans(mod, specs = \"source\") |&gt;\n    pairs() |&gt;\n    test(df = Inf,\n         null = 0,\n         delta = log(1.25),\n         side = \"equivalence\",\n         adjust = \"none\")\n#&gt;  contrast    estimate     SE  df z.ratio p.value\n#&gt;  fish - soy    -0.273 0.0529 Inf   0.937  0.8257\n#&gt;  fish - skim   -0.402 0.0542 Inf   3.308  0.9995\n#&gt;  soy - skim    -0.130 0.0530 Inf  -1.765  0.0388\n#&gt; \n#&gt; Results are averaged over the levels of: percent \n#&gt; Degrees-of-freedom method: user-specified \n#&gt; Results are given on the log (not the response) scale. \n#&gt; Statistics are tests of equivalence with a threshold of 0.22314 \n#&gt; P values are left-tailed\n\n## {marginaleffects}\npredictions(\n    mod,\n    newdata = \"balanced\",\n    by = \"source\",\n    hypothesis = \"pairwise\",\n    equivalence = c(-log(1.25), log(1.25))\n)\n#&gt; \n#&gt;         Term Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 %  97.5 % p (NonSup) p (NonInf) p (Equiv)\n#&gt;  fish - soy    -0.273     0.0529 -5.15   &lt;0.001 21.9 -0.377 -0.1690     &lt;0.001     0.8257    0.8257\n#&gt;  fish - skim   -0.402     0.0542 -7.43   &lt;0.001 43.0 -0.508 -0.2961     &lt;0.001     0.9995    0.9995\n#&gt;  soy - skim    -0.130     0.0530 -2.44   0.0146  6.1 -0.233 -0.0255     &lt;0.001     0.0388    0.0388\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/equivalence.html#t-test",
    "href": "vignettes/equivalence.html#t-test",
    "title": "Equivalence Tests",
    "section": "",
    "text": "Now we show that the results produced by hypotheses() are identical to the results produced by the equivalence package in the case of a simple t-test:\n\nlibrary(equivalence)\n\nset.seed(1024)\n\n## simulate data data\nN &lt;- 20\ndat &lt;- data.frame(\n    y = rnorm(N),\n    x = sample(c(rep(0, N / 2), rep(1, N / 2)), N))\n\n## fit model\nmod &lt;- lm(y ~ x, data = dat)\n\n## test with the {equivalence} package\ne &lt;- tost(\n    x = dat$y[dat$x == 0],\n    y = dat$y[dat$x == 1],\n    epsilon = 10)\ne\n#&gt; \n#&gt;  Welch Two Sample TOST\n#&gt; \n#&gt; data:  dat$y[dat$x == 0] and dat$y[dat$x == 1]\n#&gt; df = 17.607\n#&gt; sample estimates:\n#&gt;  mean of x  mean of y \n#&gt; -0.3788551 -0.2724594 \n#&gt; \n#&gt; Epsilon: 10 \n#&gt; 95 percent two one-sided confidence interval (TOST interval):\n#&gt;  -1.058539  0.845747\n#&gt; Null hypothesis of statistical difference is: rejected \n#&gt; TOST p-value: 4.248528e-13\n\n## test with {marginaleffects} package\nh &lt;- hypotheses(mod, equivalence = c(-10, 10), df = e$parameter)[2, ]\nh\n#&gt; \n#&gt;  Estimate Std. Error     t Pr(&gt;|t|)   S 2.5 % 97.5 % p (NonSup) p (NonInf) p (Equiv)   Df\n#&gt;     0.106      0.548 0.194    0.848 0.2 -1.05   1.26     &lt;0.001     &lt;0.001    &lt;0.001 17.6\n#&gt; \n#&gt; Term: x\n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, df, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv\n\n# identical p values\nh$p.value.equiv |&gt; as.vector()\n#&gt; [1] 4.248528e-13\n\ne$tost.p.value |&gt; as.vector()\n#&gt; [1] 4.248528e-13",
    "crumbs": [
      "Get started",
      "Case studies",
      "Equivalence Tests"
    ]
  },
  {
    "objectID": "vignettes/conformal.html",
    "href": "vignettes/conformal.html",
    "title": "Conformal prediction",
    "section": "",
    "text": "This notebook shows how to estimate conformal prediction intervals with the marginaleffects package for R.\n\nThe predictions() function from the marginaleffects() package can compute confidence intervals for fitted values in over 80 model classes in R. These intervals quantify the uncertainty about the expected value of the response. A common misunderstanding is that these confidence intervals should be calibrated to cover a certain percentage of unseen data points. This is not the case. In fact, a 95% confidence interval reported by predictions() will typically cover a much smaller share of out-of-sample outcomes.\nConsider this simulation where \\(Y_{train}\\) and \\(Y_{test}\\) are drawn from a normal distribution with mean \\(\\pi\\) and standard deviation 1. We estimate a linear model with an intercept only, and compute a 90% confidence interval for the expected value of the response:\n\nlibrary(marginaleffects)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(nnet)\nlibrary(MASS)\n\nset.seed(1024)\n\nsimulation &lt;- function(...) {\n    Y_train &lt;- rnorm(25, mean = pi)\n    Y_test &lt;- rnorm(25, mean = pi)\n    m &lt;- lm(Y_train ~ 1)\n    p &lt;- predictions(m, conf_level = .90)\n    out &lt;- data.table(\n        `Test set coverage` = mean(Y_test &gt;= p$conf.low & Y_test &lt;= p$conf.high),\n        `True mean coverage` = pi &gt;= p$conf.low[1] & pi &lt;= p$conf.high[1]\n    )\n    return(out)\n}\nresults &lt;- rbindlist(lapply(1:1000, simulation))\n\ncolMeans(results)\n\n Test set coverage True mean coverage \n            0.2498             0.8770 \n\n\nWe see that the confidence interval around predictions covers the true mean of \\(\\pi\\) about 90% of the time, whereas coverage of individual observations in the test set is much lower.\nIf we care about out of sample predictions, that is, if we want our interval to cover a specific share of the actual outcome for unobserved individuals, we must compute “prediction intervals” instead of “confidence intervals.” How do we do this? Conformal prediction is very flexible and powerful approach.\n\nIn their excellent tutorial, @AngBat2022 write that conformal prediction is\n\n“a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions.\n\nThese are extraordinary claims which deserve to be underlined: In principle, conformal prediction should offer well-calibrated intervals, regardless of the prediction model we use, and even if that model is misspecified.\nThe main caveats are:\n\nThe conformal prediction algorithms implemented in marginaleffects are designed for exchangeable data.1 They do not offer coverage guarantees in contexts where exchangeability is violated, such as in time series data, when there is spatial dependence between observations, or when there is distribution drift between the training and test data.\nThe conformal prediction algorithms implemented in marginaleffects offer marginal coverage guarantees, that is, they guarantee that a random test point will fall within the interval with a given probability. Below, we show an example where the prediction interval covers the right number of test points overall, but is not well calibrated locally, in different strata of the predictors. Different algorithms have recently been proposed to offer class-conditional coverage guarantees (see @Din2023 for an example).\nThe width of the conformal prediction interval will typically depend on the quality of the prediction model and of the score function.\nThe score functions implemented in marginaleffects simply take the residual—or difference between the observed outcome and predicted value. This means that the type argument must ensure that observations and predictions are on commensurable scales (usually type=\"response\" or type=\"prob\").\n\nDownload data, split it into training and testing sets, and estimate a few different models:\n\n# download data\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/military.csv\")\n\n\n# create a binary outcome variable\ndat &lt;- transform(dat, officer = as.numeric(grepl(\"officer\", grade)))\n\n# train/test split\nidx &lt;- sample(seq_len(nrow(dat)), 60000)\ntest &lt;- dat[idx[1:10000], ]\ntrain &lt;- dat[idx[10001:length(idx)], ]\n\n# linear regression\nm_lm &lt;- lm(rank ~ gender * race, data = train)\np_lm &lt;- predictions(m_lm, newdata = train)\n\n# logit regression\nm_glm &lt;- glm(officer ~ gender * race, data = train, family = binomial)\np_glm &lt;- predictions(m_glm, newdata = train)\n\n# multinomial logit regression\nm_mult &lt;- multinom(branch ~ gender * race, data = train, trace = FALSE)\np_mult &lt;- predictions(m_mult, newdata = train)\n\nFor LM and GLM models, predictions() returns a data frame with one prediction for each row of the original data. This data frame includes confidence intervals:\n\np_glm\n\n\n Estimate Pr(&gt;|z|)     S  2.5 % 97.5 %\n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.1006   &lt;0.001 668.6 0.0885  0.114\n--- 49990 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.2080   &lt;0.001 837.6 0.1956  0.221\nType:  invlink(link) \nColumns: rowid, estimate, p.value, s.value, conf.low, conf.high, rownames, grade, branch, gender, race, hisp, rank, officer \n\n\nFor multinomial models, predictions() returns a data frame with one prediction for each row and for each outcome level. We can see the predicted probabilities of each outcome level for the first observation in the original data:\n\np_mult |&gt; subset(rowid == 1)\n\n\n        Group Estimate Std. Error    z Pr(&gt;|z|)     S CI low CI high\n air force       0.181    0.00479 37.8   &lt;0.001   Inf  0.171   0.190\n army            0.473    0.00621 76.2   &lt;0.001   Inf  0.461   0.485\n marine corps    0.101    0.00376 27.0   &lt;0.001 530.9  0.094   0.109\n navy            0.245    0.00535 45.7   &lt;0.001   Inf  0.234   0.255\n\nColumns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rownames, grade, branch, gender, race, hisp, rank, officer \n\n\n\nIn the “Bootstrap and Simultation” vignette, we saw that the inferences() function can be used to compute confidence intervals for any marginaleffects package estimates. The workflow is simple:\n\nGenerate estimates with predictions().\nPass the resulting object to inferences(), along with arguments to specify how to perform inference to obtain uncertainty estimates.\n\ninferences() supports two strategies for conformal prediction: split or CV+ [@AngBat2022,@Din2023]. The former is faster but less efficient. In the rest of this vignette, we illustrate how to use this same workflow to compute conformal prediction intervals.\n\nThe p_lm, p_glm, and p_mult objects are predictions objects. They contain the point predictions and confidence intervals for each observation in the training set. Now, we use the inferences() function to compute predictions and prediction intervals for every observation in the test set:\n\np &lt;- predictions(m_lm, conf_level = .9) |&gt; \n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_test = test)\np\n\n\n Estimate Std. Error   z Pr(&gt;|z|)   S 5.0 % 95.0 % Pred. 5.0 % Pred. 95.0 %\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     5.86     0.0283 207   &lt;0.001 Inf  5.82   5.91        3.00         8.73\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     6.51     0.0220 296   &lt;0.001 Inf  6.48   6.55        3.65         9.38\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n--- 9990 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     6.51     0.0220 296   &lt;0.001 Inf  6.48   6.55        3.65         9.38\n     6.51     0.0220 296   &lt;0.001 Inf  6.48   6.55        3.65         9.38\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\nType:  response \nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rownames, grade, branch, gender, race, hisp, rank, officer, pred.low, pred.high \n\n\nThe prediction interval is expected to cover the (known) true value about 90% of the time:\n\nmean(p$rank &lt;= p$pred.high & p$rank &gt;= p$pred.low)\n\n[1] 0.9082\n\n\nThe coverage also seems adequate (about 80%) for the logit model:\n\np &lt;- predictions(m_glm, conf_level = .8) |&gt;\n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_test = test)\nmean(p$officer &lt;= p$pred.high & p$officer &gt;= p$pred.low)\n\n[1] 0.7998\n\n\nWhen the outcome is categorical, we use conformal_score=\"softmax\". With this argument, inferences() generates “conformal prediction sets,” that is, sets of possible outcome classes with coverage guarantees. inferences() returns a list column of sets for each observation. On average, those sets should cover the true value about 70% of the time:\n\np &lt;- predictions(m_mult, conf_level = .7) |&gt;\n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_score = \"softmax\",\n        conformal_test = test)\nhead(p)\n\n\n    branch                        Pred Set\n army                 air force, army     \n navy      air force, army     , navy     \n navy                 air force, army     \n army                           army, navy\n air force            air force, army     \n army                           army, navy\n\nColumns: rowid, branch, pred.set \n\n\nFor example, for the first observation in the dataset, the conformal prediction is {air force, army} and the true value is army. The conformal prediction set thus covers the true value. The coverage rate is:\n\nmean(sapply(seq_len(nrow(p)), \\(i) p$branch[i] %in% p$pred.set[[i]]))\n\n[1] 0.6928\n\n\n\nFor split conformal prediction, we must first split the training set into a training and a calibration set (see @AngBat2022). Then, we pass the calibration set to the inferences() function:\n\ncalibration &lt;- train[1:1000,]\ntrain &lt;- train[1001:nrow(train),]\np &lt;- predictions(m_lm, conf_level = .9) |&gt;\n    inferences(\n        method = \"conformal_split\",\n        conformal_calibration = calibration,\n        conformal_test = test)\nmean(p$rank &lt;= p$pred.high & p$rank &gt;= p$pred.low)\n\n[1] 0.9112\n\n\n\n\nAs noted above, the conformal prediction interval should be valid even if the model is misspecified. To illustrate this, we generate data from a linear model with polynomials, but estimate a linear model without polynomials. Then, we plot the results and compute the coverage of the prediction interval:\n\nN &lt;- 1000\nX &lt;- rnorm(N * 2)\ndat &lt;- data.frame(\n    X = X,\n    Y = X + X^2 + X^3 + rnorm(N * 2))\ntrain &lt;- dat[1:N,]\ntest &lt;- dat[(N + 1):nrow(dat),]\n\nm &lt;- lm(Y ~ X, data = train)\np &lt;- predictions(m) |&gt;\n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_test = test)\n\nmean(p$Y &lt;= p$pred.high & p$Y &gt;= p$pred.low)\n\n[1] 0.953\n\nggplot(p, aes(X, Y)) +\n    geom_point(alpha = .1) +\n    geom_ribbon(aes(X, ymin = pred.low, ymax = pred.high), alpha = .2, fill = \"#F0E442\") +\n    geom_ribbon(aes(X, ymin = conf.low, ymax = conf.high), alpha = .4, fill = \"#D55E00\") +\n    theme_bw() +\n    labs(\n        title = \"Confidence and prediction intervals for a misspecified linear model\",\n        subtitle = sprintf(\n            \"Confidence coverage (orange): %.2f%%; Prediction coverage (yellow): %.2f%%.\",\n            mean(p$Y &lt;= p$conf.high & p$Y &gt;= p$conf.low),\n            mean(p$Y &lt;= p$pred.high & p$Y &gt;= p$pred.low)))\n\n\n\n\n\n\n\nThis example is interesting, because it shows that the prediction interval has adquate marginal coverage. However, the intervals are not necessarily well calibrated “locally”, in different strata of \\(X\\). In the figure above, our model is misspecified, so we make more mistakes in the tails, where predictions are bad. In contrast, the interval catches more observations in the middle of the distribution, which ensures that the overall error rate is adequate.\n\nHere is a second example of model misspecification. We generate data from a negative binomial model, but estimate a Poisson model. Nevertheless, the conformal prediction interval has good coverage:\n\nn &lt;- 10000\nX &lt;- rnorm(n)\neta &lt;- -1 + 2*X\nmu &lt;- exp(eta)\nY &lt;- rnegbin(n, mu = mu, theta = 1)\ndat &lt;- data.frame(X = X, Y = Y)\ntrain &lt;- dat[1:5000,]\ntest &lt;- dat[5001:nrow(dat),]\n\nmod &lt;- glm(Y ~ X, data = train, family = poisson)\n\np &lt;- predictions(mod, conf_level = .9) |&gt;\n    inferences(\n        method = \"conformal_cv+\",\n        R = 10,\n        conformal_test = test)\n\nmean(p$Y &gt;= p$pred.low & p$Y &lt;= p$pred.high)\n\n[1] 0.8968",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/conformal.html#confidence-vs.-prediction-intervals",
    "href": "vignettes/conformal.html#confidence-vs.-prediction-intervals",
    "title": "Conformal prediction",
    "section": "",
    "text": "The predictions() function from the marginaleffects() package can compute confidence intervals for fitted values in over 80 model classes in R. These intervals quantify the uncertainty about the expected value of the response. A common misunderstanding is that these confidence intervals should be calibrated to cover a certain percentage of unseen data points. This is not the case. In fact, a 95% confidence interval reported by predictions() will typically cover a much smaller share of out-of-sample outcomes.\nConsider this simulation where \\(Y_{train}\\) and \\(Y_{test}\\) are drawn from a normal distribution with mean \\(\\pi\\) and standard deviation 1. We estimate a linear model with an intercept only, and compute a 90% confidence interval for the expected value of the response:\n\nlibrary(marginaleffects)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(nnet)\nlibrary(MASS)\n\nset.seed(1024)\n\nsimulation &lt;- function(...) {\n    Y_train &lt;- rnorm(25, mean = pi)\n    Y_test &lt;- rnorm(25, mean = pi)\n    m &lt;- lm(Y_train ~ 1)\n    p &lt;- predictions(m, conf_level = .90)\n    out &lt;- data.table(\n        `Test set coverage` = mean(Y_test &gt;= p$conf.low & Y_test &lt;= p$conf.high),\n        `True mean coverage` = pi &gt;= p$conf.low[1] & pi &lt;= p$conf.high[1]\n    )\n    return(out)\n}\nresults &lt;- rbindlist(lapply(1:1000, simulation))\n\ncolMeans(results)\n\n Test set coverage True mean coverage \n            0.2498             0.8770 \n\n\nWe see that the confidence interval around predictions covers the true mean of \\(\\pi\\) about 90% of the time, whereas coverage of individual observations in the test set is much lower.\nIf we care about out of sample predictions, that is, if we want our interval to cover a specific share of the actual outcome for unobserved individuals, we must compute “prediction intervals” instead of “confidence intervals.” How do we do this? Conformal prediction is very flexible and powerful approach.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/conformal.html#conformal-prediction-1",
    "href": "vignettes/conformal.html#conformal-prediction-1",
    "title": "Conformal prediction",
    "section": "",
    "text": "In their excellent tutorial, @AngBat2022 write that conformal prediction is\n\n“a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions.\n\nThese are extraordinary claims which deserve to be underlined: In principle, conformal prediction should offer well-calibrated intervals, regardless of the prediction model we use, and even if that model is misspecified.\nThe main caveats are:\n\nThe conformal prediction algorithms implemented in marginaleffects are designed for exchangeable data.1 They do not offer coverage guarantees in contexts where exchangeability is violated, such as in time series data, when there is spatial dependence between observations, or when there is distribution drift between the training and test data.\nThe conformal prediction algorithms implemented in marginaleffects offer marginal coverage guarantees, that is, they guarantee that a random test point will fall within the interval with a given probability. Below, we show an example where the prediction interval covers the right number of test points overall, but is not well calibrated locally, in different strata of the predictors. Different algorithms have recently been proposed to offer class-conditional coverage guarantees (see @Din2023 for an example).\nThe width of the conformal prediction interval will typically depend on the quality of the prediction model and of the score function.\nThe score functions implemented in marginaleffects simply take the residual—or difference between the observed outcome and predicted value. This means that the type argument must ensure that observations and predictions are on commensurable scales (usually type=\"response\" or type=\"prob\").",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/conformal.html#data-and-models-linear-logit-multinomial-logit",
    "href": "vignettes/conformal.html#data-and-models-linear-logit-multinomial-logit",
    "title": "Conformal prediction",
    "section": "",
    "text": "Download data, split it into training and testing sets, and estimate a few different models:\n\n# download data\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/military.csv\")\n\n\n# create a binary outcome variable\ndat &lt;- transform(dat, officer = as.numeric(grepl(\"officer\", grade)))\n\n# train/test split\nidx &lt;- sample(seq_len(nrow(dat)), 60000)\ntest &lt;- dat[idx[1:10000], ]\ntrain &lt;- dat[idx[10001:length(idx)], ]\n\n# linear regression\nm_lm &lt;- lm(rank ~ gender * race, data = train)\np_lm &lt;- predictions(m_lm, newdata = train)\n\n# logit regression\nm_glm &lt;- glm(officer ~ gender * race, data = train, family = binomial)\np_glm &lt;- predictions(m_glm, newdata = train)\n\n# multinomial logit regression\nm_mult &lt;- multinom(branch ~ gender * race, data = train, trace = FALSE)\np_mult &lt;- predictions(m_mult, newdata = train)\n\nFor LM and GLM models, predictions() returns a data frame with one prediction for each row of the original data. This data frame includes confidence intervals:\n\np_glm\n\n\n Estimate Pr(&gt;|z|)     S  2.5 % 97.5 %\n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.1006   &lt;0.001 668.6 0.0885  0.114\n--- 49990 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.1775   &lt;0.001   Inf 0.1733  0.182\n   0.0859   &lt;0.001   Inf 0.0793  0.093\n   0.2080   &lt;0.001 837.6 0.1956  0.221\nType:  invlink(link) \nColumns: rowid, estimate, p.value, s.value, conf.low, conf.high, rownames, grade, branch, gender, race, hisp, rank, officer \n\n\nFor multinomial models, predictions() returns a data frame with one prediction for each row and for each outcome level. We can see the predicted probabilities of each outcome level for the first observation in the original data:\n\np_mult |&gt; subset(rowid == 1)\n\n\n        Group Estimate Std. Error    z Pr(&gt;|z|)     S CI low CI high\n air force       0.181    0.00479 37.8   &lt;0.001   Inf  0.171   0.190\n army            0.473    0.00621 76.2   &lt;0.001   Inf  0.461   0.485\n marine corps    0.101    0.00376 27.0   &lt;0.001 530.9  0.094   0.109\n navy            0.245    0.00535 45.7   &lt;0.001   Inf  0.234   0.255\n\nColumns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rownames, grade, branch, gender, race, hisp, rank, officer",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/conformal.html#conformal-predictions-with-inferences",
    "href": "vignettes/conformal.html#conformal-predictions-with-inferences",
    "title": "Conformal prediction",
    "section": "",
    "text": "In the “Bootstrap and Simultation” vignette, we saw that the inferences() function can be used to compute confidence intervals for any marginaleffects package estimates. The workflow is simple:\n\nGenerate estimates with predictions().\nPass the resulting object to inferences(), along with arguments to specify how to perform inference to obtain uncertainty estimates.\n\ninferences() supports two strategies for conformal prediction: split or CV+ [@AngBat2022,@Din2023]. The former is faster but less efficient. In the rest of this vignette, we illustrate how to use this same workflow to compute conformal prediction intervals.\n\nThe p_lm, p_glm, and p_mult objects are predictions objects. They contain the point predictions and confidence intervals for each observation in the training set. Now, we use the inferences() function to compute predictions and prediction intervals for every observation in the test set:\n\np &lt;- predictions(m_lm, conf_level = .9) |&gt; \n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_test = test)\np\n\n\n Estimate Std. Error   z Pr(&gt;|z|)   S 5.0 % 95.0 % Pred. 5.0 % Pred. 95.0 %\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     5.86     0.0283 207   &lt;0.001 Inf  5.82   5.91        3.00         8.73\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     6.51     0.0220 296   &lt;0.001 Inf  6.48   6.55        3.65         9.38\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n--- 9990 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\n     6.51     0.0220 296   &lt;0.001 Inf  6.48   6.55        3.65         9.38\n     6.51     0.0220 296   &lt;0.001 Inf  6.48   6.55        3.65         9.38\n     6.15     0.0100 612   &lt;0.001 Inf  6.13   6.17        3.29         9.01\nType:  response \nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rownames, grade, branch, gender, race, hisp, rank, officer, pred.low, pred.high \n\n\nThe prediction interval is expected to cover the (known) true value about 90% of the time:\n\nmean(p$rank &lt;= p$pred.high & p$rank &gt;= p$pred.low)\n\n[1] 0.9082\n\n\nThe coverage also seems adequate (about 80%) for the logit model:\n\np &lt;- predictions(m_glm, conf_level = .8) |&gt;\n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_test = test)\nmean(p$officer &lt;= p$pred.high & p$officer &gt;= p$pred.low)\n\n[1] 0.7998\n\n\nWhen the outcome is categorical, we use conformal_score=\"softmax\". With this argument, inferences() generates “conformal prediction sets,” that is, sets of possible outcome classes with coverage guarantees. inferences() returns a list column of sets for each observation. On average, those sets should cover the true value about 70% of the time:\n\np &lt;- predictions(m_mult, conf_level = .7) |&gt;\n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_score = \"softmax\",\n        conformal_test = test)\nhead(p)\n\n\n    branch                        Pred Set\n army                 air force, army     \n navy      air force, army     , navy     \n navy                 air force, army     \n army                           army, navy\n air force            air force, army     \n army                           army, navy\n\nColumns: rowid, branch, pred.set \n\n\nFor example, for the first observation in the dataset, the conformal prediction is {air force, army} and the true value is army. The conformal prediction set thus covers the true value. The coverage rate is:\n\nmean(sapply(seq_len(nrow(p)), \\(i) p$branch[i] %in% p$pred.set[[i]]))\n\n[1] 0.6928\n\n\n\nFor split conformal prediction, we must first split the training set into a training and a calibration set (see @AngBat2022). Then, we pass the calibration set to the inferences() function:\n\ncalibration &lt;- train[1:1000,]\ntrain &lt;- train[1001:nrow(train),]\np &lt;- predictions(m_lm, conf_level = .9) |&gt;\n    inferences(\n        method = \"conformal_split\",\n        conformal_calibration = calibration,\n        conformal_test = test)\nmean(p$rank &lt;= p$pred.high & p$rank &gt;= p$pred.low)\n\n[1] 0.9112",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/conformal.html#misspecification",
    "href": "vignettes/conformal.html#misspecification",
    "title": "Conformal prediction",
    "section": "",
    "text": "As noted above, the conformal prediction interval should be valid even if the model is misspecified. To illustrate this, we generate data from a linear model with polynomials, but estimate a linear model without polynomials. Then, we plot the results and compute the coverage of the prediction interval:\n\nN &lt;- 1000\nX &lt;- rnorm(N * 2)\ndat &lt;- data.frame(\n    X = X,\n    Y = X + X^2 + X^3 + rnorm(N * 2))\ntrain &lt;- dat[1:N,]\ntest &lt;- dat[(N + 1):nrow(dat),]\n\nm &lt;- lm(Y ~ X, data = train)\np &lt;- predictions(m) |&gt;\n    inferences(\n        R = 5,\n        method = \"conformal_cv+\",\n        conformal_test = test)\n\nmean(p$Y &lt;= p$pred.high & p$Y &gt;= p$pred.low)\n\n[1] 0.953\n\nggplot(p, aes(X, Y)) +\n    geom_point(alpha = .1) +\n    geom_ribbon(aes(X, ymin = pred.low, ymax = pred.high), alpha = .2, fill = \"#F0E442\") +\n    geom_ribbon(aes(X, ymin = conf.low, ymax = conf.high), alpha = .4, fill = \"#D55E00\") +\n    theme_bw() +\n    labs(\n        title = \"Confidence and prediction intervals for a misspecified linear model\",\n        subtitle = sprintf(\n            \"Confidence coverage (orange): %.2f%%; Prediction coverage (yellow): %.2f%%.\",\n            mean(p$Y &lt;= p$conf.high & p$Y &gt;= p$conf.low),\n            mean(p$Y &lt;= p$pred.high & p$Y &gt;= p$pred.low)))\n\n\n\n\n\n\n\nThis example is interesting, because it shows that the prediction interval has adquate marginal coverage. However, the intervals are not necessarily well calibrated “locally”, in different strata of \\(X\\). In the figure above, our model is misspecified, so we make more mistakes in the tails, where predictions are bad. In contrast, the interval catches more observations in the middle of the distribution, which ensures that the overall error rate is adequate.\n\nHere is a second example of model misspecification. We generate data from a negative binomial model, but estimate a Poisson model. Nevertheless, the conformal prediction interval has good coverage:\n\nn &lt;- 10000\nX &lt;- rnorm(n)\neta &lt;- -1 + 2*X\nmu &lt;- exp(eta)\nY &lt;- rnegbin(n, mu = mu, theta = 1)\ndat &lt;- data.frame(X = X, Y = Y)\ntrain &lt;- dat[1:5000,]\ntest &lt;- dat[5001:nrow(dat),]\n\nmod &lt;- glm(Y ~ X, data = train, family = poisson)\n\np &lt;- predictions(mod, conf_level = .9) |&gt;\n    inferences(\n        method = \"conformal_cv+\",\n        R = 10,\n        conformal_test = test)\n\nmean(p$Y &gt;= p$pred.low & p$Y &lt;= p$pred.high)\n\n[1] 0.8968",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/conformal.html#footnotes",
    "href": "vignettes/conformal.html#footnotes",
    "title": "Conformal prediction",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe usual “independent and identically distributed” assumption is a special case of exchangeability.↩︎",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conformal prediction"
    ]
  },
  {
    "objectID": "vignettes/mrp.html",
    "href": "vignettes/mrp.html",
    "title": "MrP",
    "section": "",
    "text": "Data analysts often want to learn about a population using samples that are not representative of that population. Consider a few examples:\n\n\nMarket research: A supermarket chain wants to assess consumer preferences in each of the markets where it operates, but it would be too expensive to collect distinct representative samples for many cities.\n\nPolitical polling: A newspaper conducts a nationally representative survey in the lead up to a Presidential election, and wishes to compute state-by-state estimates of voting intentions.\n\nOnline surveys: A researcher conducts a poll online, but the respondents are younger and more highly educated than the general population.\n\nThis notebook introduces Multilevel Regression with Poststratification (MrP), a popular strategy which can be used to limit the distortions in unrepresentative data, or to estimate subgroup characteristics on the basis of data gathered at a different level of aggregation. MrP can be deployed in a wide range of contexts (see this paper and this blog post by the always excellent Monica Alexander).\nAs we will see below, MrP is super easy to implement using the marginaleffects package for R. marginaleffects also offers tremendous benefits to analysts, including a consistent user interface to over 100 classes of statistical models, as well as many post-estimation and hypothesis testing tools. To illustrate these benefits, we will consider a hypothetical example with simulated data.1\n\n\nMrP, not Mister T.\n\n\nImagine that a national supermarket chain plans to introduce a line of meat substitutes in some of its stores. To guide marketing and distribution efforts, the company would like to know the share of the population in each city that is interested in tasting meat substitutes.\nThe company conducts a telephone survey of 1000 randomly selected adults from 40 large American cities. For each survey respondent, we record the city of residence, age, level of education, and whether they are interested in tasting meat substitutes. The variable we focus on is “interest in meat substitutes,” measured on a scale of 1 to 7 where 7 means “very interested” and 1 means “not at all interested”. Our ultimate goal is to estimate the average of this 7 point scale for each city.\nThe (simulated) data that we will use is stored in a R data frame called survey. We can use the nrow() function to confirm the sample size, and the datasummary_df() function from the modelsummary package to display the first few rows of data:\n\nlibrary(marginaleffects)\nlibrary(modelsummary)\nlibrary(tidyverse)\nlibrary(ggridges)\nlibrary(brms)\n\nnrow(survey)\n#&gt; [1] 1000\n\ndatasummary_df(survey[1:5, ])\n\n\n\n    \n\n      \n\nrespondent\n                city\n                age\n                education\n                meat_substitute\n              \n\n\n0001\n                  Tucson, AZ   \n                  18-54\n                  High school or less\n                  1.00\n                \n\n0002\n                  Miami, FL    \n                  55+  \n                  High school or less\n                  6.00\n                \n\n0003\n                  Austin, TX   \n                  55+  \n                  Post-secondary     \n                  3.00\n                \n\n0004\n                  Atlanta, GA  \n                  18-54\n                  Post-secondary     \n                  5.00\n                \n\n0005\n                  Milwaukee, WI\n                  18-54\n                  High school or less\n                  5.00\n                \n\n\n\n\n\n\nThis dataset includes 1000 observations: one per survey respondent. Unfortunately, it is not straightforward to compute precise city-by-city estimates, because although the number of respondents is large overall, the number of respondents within each of the 40 cities is relatively small. Moreover, the company’s sampling strategy does not guarantee that subsamples are representative of each city’s population. MrP can help us circumvent these problems in two steps:\n\n\nMultilevel regression (Mr): Estimate a multilevel regression at the individual level, with random intercepts for cities.\n\nPoststratification (P): Adjust the predictions of the model based on the demographic characteristics of each city.\n\nIn the rest of this notebook, we show that the marginaleffects package makes it very easy to apply these steps.\n\nThe first step of MrP is to use individual-level data to estimate a model that predicts the value of the variable of interest. One of the great benefits of using marginaleffects for MrP, is that this package is agnostic to the type of model used to make predictions. Analysts can use almost any model they like, and the workflow described below would remain the same.\nOne popular choice for MrP is to estimate a multilevel regression model with random intercepts for each of the geographic regions of interest. To do so, analysts could use many different R packages, including lme4, glmmTMB, or brms. In this notebook, we use the brms::brm() function to estimate a bayesian multilevel model, with the age and education variables as fixed components, and random intercepts at the city level:\n\nmod &lt;- brm(meat_substitute ~ age + education + (1 | city), data = survey)\n\nWe can visualize the model estimates using the modelplot() function from the modelsummary package:\n\nmodelplot(mod)\n\n\n\n\n\n\n\nWe are now ready for the second MrP step: poststratification.\n\nIn the second MrP step, we use data from the US Census (or a similar source) to create a “poststratification table.” This table includes one row for each combination of the predictor values in our model. In our model, the age variable has 2 categories (“18-54” and “54+”); the education variables has 2 categories (“High school or less” and “Post-secondary”); and the city variable has 40 unique entries. Therefore, the poststratification table must have \\(2 \\times 2 \\times 40 = 160\\) entries.\nCrucially, the poststratification dataset must also include a column with the population share of each combination of predictor values. Consider the table used by our hypothetical supermarket chain. This table includes 160 rows:\n\nnrow(stratification)\n#&gt; [1] 160\n\nAnd here are the entries for the city of Tucson, AZ:\n\ntucson &lt;- subset(stratification, city == \"Tucson, AZ\")\ndatasummary_df(tucson)\n\n\n\n    \n\n      \n\ncity\n                education\n                age\n                population_share\n              \n\n\nTucson, AZ\n                  High school or less\n                  18-54\n                  0.16\n                \n\nTucson, AZ\n                  Post-secondary     \n                  18-54\n                  0.38\n                \n\nTucson, AZ\n                  High school or less\n                  55+  \n                  0.20\n                \n\nTucson, AZ\n                  Post-secondary     \n                  55+  \n                  0.25\n                \n\n\n\n\n\n\nAccording to these (simulated) data, the share of Tucson residents who are between 18 and 54 year old and have a High School degree or less is about 16%.\nWe can use the predictions() function from the marginaleffects package to predict the value of the meat_substitute variable for each of the four categories of residents in Tucson:\n\npredictions(mod, newdata = tucson)\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      1.81  1.49   2.12\n#&gt;      3.03  2.71   3.33\n#&gt;      3.01  2.69   3.32\n#&gt;      4.22  3.90   4.53\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, city, education, age, population_share, meat_substitute\n\nThe MrP estimate for this city is simply the weighted average of predicted values, where weights are the population shares of each category of residents. In this context, we have:\n\\[0.16 \\times 1.81 + 0.38 \\times 3.03 + 0.20 \\times 3.01 + 0.25 \\times 4.22 = 3.13\\]\nInstead of computing estimates by hand for each city, we can use the by and wts arguments of the predictions() function to do everything everywhere all at once:\n\np &lt;- predictions(              # Compute predictions,\n    model = mod,               # using the multilevel regression model `mod`, \n    newdata = stratification,  # for each row of the `stratification` table.\n    by = \"city\",               # Then, take the weighted average of predictions by city,\n    wts = \"population_share\")  # using demographic weights.\np\n#&gt; \n#&gt;               city Estimate 2.5 % 97.5 %\n#&gt;  Washington, DC        4.30  3.97   4.63\n#&gt;  Tucson, AZ            3.13  2.83   3.43\n#&gt;  Seattle, WA           5.06  4.74   5.38\n#&gt;  San Jose, CA          3.92  3.58   4.26\n#&gt;  San Francisco, CA     5.06  4.72   5.41\n#&gt; --- 30 rows omitted. See ?print.marginaleffects --- \n#&gt;  Boston, MA            3.65  3.37   3.93\n#&gt;  Baltimore, MD         2.93  2.58   3.30\n#&gt;  Austin, TX            2.88  2.57   3.19\n#&gt;  Atlanta, GA           4.60  4.27   4.92\n#&gt;  Albuquerque, NM       2.67  2.35   2.99\n#&gt; Type:  response \n#&gt; Columns: city, estimate, conf.low, conf.high\n\nSince we estimated a bayesian model in the “Mr” step, we can now use the posterior_draws() function to extract draws from the posterior distribution of the MrP estimates. This allows us to compute credible intervals for each city, and draw many fancy plots like this one:\n\np |&gt; \n    # extract draws from the posterior distribution\n    posterior_draws() |&gt;\n    # sort cities by interest in meat substitutes\n    arrange(estimate) |&gt;\n    mutate(city = factor(city, levels = rev(unique(city)))) |&gt;\n    # plot the results\n    ggplot(aes(x = draw, y = city)) +\n    geom_density_ridges() +\n    theme_minimal() +\n    theme(panel.grid = element_blank()) +\n    labs(\n        x = \"Average interest in meat substitutes\",\n        y = NULL,\n        title = \"Estimated interest in meat substitutes by city\",\n        subtitle = \"Multilevel Regression and Poststratification\",\n        caption = \"Source: Simulated data\")\n\n\n\n\n\n\n\n\nAll the data used on this page were simulated using this code:\n\nlibrary(marginaleffects)\nlibrary(countrycode)\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(brms)\nset.seed(1024)\n\ncities &lt;- c(\"New York City, NY\", \"Los Angeles, CA\", \"Chicago, IL\", \"Houston, TX\", \"Phoenix, AZ\", \"Philadelphia, PA\", \"San Antonio, TX\", \"San Diego, CA\", \"Dallas, TX\", \"San Jose, CA\", \"Austin, TX\", \"Jacksonville, FL\", \"Fort Worth, TX\", \"Columbus, OH\", \"San Francisco, CA\", \"Charlotte, NC\", \"Indianapolis, IN\", \"Seattle, WA\", \"Denver, CO\", \"Washington, DC\", \"Boston, MA\", \"Nashville, TN\", \"El Paso, TX\", \"Detroit, MI\", \"Memphis, TN\", \"Portland, OR\", \"Oklahoma City, OK\", \"Las Vegas, NV\", \"Louisville, KY\", \"Baltimore, MD\", \"Milwaukee, WI\", \"Albuquerque, NM\", \"Tucson, AZ\", \"Fresno, CA\", \"Sacramento, CA\", \"Mesa, AZ\", \"Atlanta, GA\", \"Kansas City, MO\", \"Colorado Springs, CO\", \"Miami, FL\")\ncities &lt;- rev(sort(cities))\neducation &lt;- c(\"High school or less\", \"Post-secondary\")\nage &lt;- c(\"18-54\", \"55+\")\nstratification &lt;- expand.grid(\n    city = cities,\n    education = education,\n    age = age) |&gt;\n    mutate(\n        population_share = runif(n(), min = .25, max = .75),\n        population_share = population_share / sum(population_share),\n        .by = \"city\",) |&gt;\n    arrange(city)\nN &lt;- 1000\nsurvey &lt;- data.frame(\n    city = sample(cities, N, replace = TRUE),\n    age = sample(age, N, replace = TRUE),\n    education = sample(education, N, replace = TRUE)\n)\nsurvey &lt;- data.frame(\n    respondent = sprintf(\"%04d\", 1:N),\n    survey)\nM &lt;- model.matrix(~., survey)\nb &lt;- runif(ncol(M))\nsurvey$meat_substitute &lt;- as.numeric(cut(M %*% b, breaks = 7))",
    "crumbs": [
      "Get started",
      "Case studies",
      "MrP"
    ]
  },
  {
    "objectID": "vignettes/mrp.html#mrp-for-surveys-and-market-research",
    "href": "vignettes/mrp.html#mrp-for-surveys-and-market-research",
    "title": "MrP",
    "section": "",
    "text": "Imagine that a national supermarket chain plans to introduce a line of meat substitutes in some of its stores. To guide marketing and distribution efforts, the company would like to know the share of the population in each city that is interested in tasting meat substitutes.\nThe company conducts a telephone survey of 1000 randomly selected adults from 40 large American cities. For each survey respondent, we record the city of residence, age, level of education, and whether they are interested in tasting meat substitutes. The variable we focus on is “interest in meat substitutes,” measured on a scale of 1 to 7 where 7 means “very interested” and 1 means “not at all interested”. Our ultimate goal is to estimate the average of this 7 point scale for each city.\nThe (simulated) data that we will use is stored in a R data frame called survey. We can use the nrow() function to confirm the sample size, and the datasummary_df() function from the modelsummary package to display the first few rows of data:\n\nlibrary(marginaleffects)\nlibrary(modelsummary)\nlibrary(tidyverse)\nlibrary(ggridges)\nlibrary(brms)\n\nnrow(survey)\n#&gt; [1] 1000\n\ndatasummary_df(survey[1:5, ])\n\n\n\n    \n\n      \n\nrespondent\n                city\n                age\n                education\n                meat_substitute\n              \n\n\n0001\n                  Tucson, AZ   \n                  18-54\n                  High school or less\n                  1.00\n                \n\n0002\n                  Miami, FL    \n                  55+  \n                  High school or less\n                  6.00\n                \n\n0003\n                  Austin, TX   \n                  55+  \n                  Post-secondary     \n                  3.00\n                \n\n0004\n                  Atlanta, GA  \n                  18-54\n                  Post-secondary     \n                  5.00\n                \n\n0005\n                  Milwaukee, WI\n                  18-54\n                  High school or less\n                  5.00\n                \n\n\n\n\n\n\nThis dataset includes 1000 observations: one per survey respondent. Unfortunately, it is not straightforward to compute precise city-by-city estimates, because although the number of respondents is large overall, the number of respondents within each of the 40 cities is relatively small. Moreover, the company’s sampling strategy does not guarantee that subsamples are representative of each city’s population. MrP can help us circumvent these problems in two steps:\n\n\nMultilevel regression (Mr): Estimate a multilevel regression at the individual level, with random intercepts for cities.\n\nPoststratification (P): Adjust the predictions of the model based on the demographic characteristics of each city.\n\nIn the rest of this notebook, we show that the marginaleffects package makes it very easy to apply these steps.",
    "crumbs": [
      "Get started",
      "Case studies",
      "MrP"
    ]
  },
  {
    "objectID": "vignettes/mrp.html#mr-for-multilevel-regression",
    "href": "vignettes/mrp.html#mr-for-multilevel-regression",
    "title": "MrP",
    "section": "",
    "text": "The first step of MrP is to use individual-level data to estimate a model that predicts the value of the variable of interest. One of the great benefits of using marginaleffects for MrP, is that this package is agnostic to the type of model used to make predictions. Analysts can use almost any model they like, and the workflow described below would remain the same.\nOne popular choice for MrP is to estimate a multilevel regression model with random intercepts for each of the geographic regions of interest. To do so, analysts could use many different R packages, including lme4, glmmTMB, or brms. In this notebook, we use the brms::brm() function to estimate a bayesian multilevel model, with the age and education variables as fixed components, and random intercepts at the city level:\n\nmod &lt;- brm(meat_substitute ~ age + education + (1 | city), data = survey)\n\nWe can visualize the model estimates using the modelplot() function from the modelsummary package:\n\nmodelplot(mod)\n\n\n\n\n\n\n\nWe are now ready for the second MrP step: poststratification.",
    "crumbs": [
      "Get started",
      "Case studies",
      "MrP"
    ]
  },
  {
    "objectID": "vignettes/mrp.html#p-for-poststratification",
    "href": "vignettes/mrp.html#p-for-poststratification",
    "title": "MrP",
    "section": "",
    "text": "In the second MrP step, we use data from the US Census (or a similar source) to create a “poststratification table.” This table includes one row for each combination of the predictor values in our model. In our model, the age variable has 2 categories (“18-54” and “54+”); the education variables has 2 categories (“High school or less” and “Post-secondary”); and the city variable has 40 unique entries. Therefore, the poststratification table must have \\(2 \\times 2 \\times 40 = 160\\) entries.\nCrucially, the poststratification dataset must also include a column with the population share of each combination of predictor values. Consider the table used by our hypothetical supermarket chain. This table includes 160 rows:\n\nnrow(stratification)\n#&gt; [1] 160\n\nAnd here are the entries for the city of Tucson, AZ:\n\ntucson &lt;- subset(stratification, city == \"Tucson, AZ\")\ndatasummary_df(tucson)\n\n\n\n    \n\n      \n\ncity\n                education\n                age\n                population_share\n              \n\n\nTucson, AZ\n                  High school or less\n                  18-54\n                  0.16\n                \n\nTucson, AZ\n                  Post-secondary     \n                  18-54\n                  0.38\n                \n\nTucson, AZ\n                  High school or less\n                  55+  \n                  0.20\n                \n\nTucson, AZ\n                  Post-secondary     \n                  55+  \n                  0.25\n                \n\n\n\n\n\n\nAccording to these (simulated) data, the share of Tucson residents who are between 18 and 54 year old and have a High School degree or less is about 16%.\nWe can use the predictions() function from the marginaleffects package to predict the value of the meat_substitute variable for each of the four categories of residents in Tucson:\n\npredictions(mod, newdata = tucson)\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;      1.81  1.49   2.12\n#&gt;      3.03  2.71   3.33\n#&gt;      3.01  2.69   3.32\n#&gt;      4.22  3.90   4.53\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, conf.low, conf.high, city, education, age, population_share, meat_substitute\n\nThe MrP estimate for this city is simply the weighted average of predicted values, where weights are the population shares of each category of residents. In this context, we have:\n\\[0.16 \\times 1.81 + 0.38 \\times 3.03 + 0.20 \\times 3.01 + 0.25 \\times 4.22 = 3.13\\]\nInstead of computing estimates by hand for each city, we can use the by and wts arguments of the predictions() function to do everything everywhere all at once:\n\np &lt;- predictions(              # Compute predictions,\n    model = mod,               # using the multilevel regression model `mod`, \n    newdata = stratification,  # for each row of the `stratification` table.\n    by = \"city\",               # Then, take the weighted average of predictions by city,\n    wts = \"population_share\")  # using demographic weights.\np\n#&gt; \n#&gt;               city Estimate 2.5 % 97.5 %\n#&gt;  Washington, DC        4.30  3.97   4.63\n#&gt;  Tucson, AZ            3.13  2.83   3.43\n#&gt;  Seattle, WA           5.06  4.74   5.38\n#&gt;  San Jose, CA          3.92  3.58   4.26\n#&gt;  San Francisco, CA     5.06  4.72   5.41\n#&gt; --- 30 rows omitted. See ?print.marginaleffects --- \n#&gt;  Boston, MA            3.65  3.37   3.93\n#&gt;  Baltimore, MD         2.93  2.58   3.30\n#&gt;  Austin, TX            2.88  2.57   3.19\n#&gt;  Atlanta, GA           4.60  4.27   4.92\n#&gt;  Albuquerque, NM       2.67  2.35   2.99\n#&gt; Type:  response \n#&gt; Columns: city, estimate, conf.low, conf.high\n\nSince we estimated a bayesian model in the “Mr” step, we can now use the posterior_draws() function to extract draws from the posterior distribution of the MrP estimates. This allows us to compute credible intervals for each city, and draw many fancy plots like this one:\n\np |&gt; \n    # extract draws from the posterior distribution\n    posterior_draws() |&gt;\n    # sort cities by interest in meat substitutes\n    arrange(estimate) |&gt;\n    mutate(city = factor(city, levels = rev(unique(city)))) |&gt;\n    # plot the results\n    ggplot(aes(x = draw, y = city)) +\n    geom_density_ridges() +\n    theme_minimal() +\n    theme(panel.grid = element_blank()) +\n    labs(\n        x = \"Average interest in meat substitutes\",\n        y = NULL,\n        title = \"Estimated interest in meat substitutes by city\",\n        subtitle = \"Multilevel Regression and Poststratification\",\n        caption = \"Source: Simulated data\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "MrP"
    ]
  },
  {
    "objectID": "vignettes/mrp.html#data-simulation",
    "href": "vignettes/mrp.html#data-simulation",
    "title": "MrP",
    "section": "",
    "text": "All the data used on this page were simulated using this code:\n\nlibrary(marginaleffects)\nlibrary(countrycode)\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(brms)\nset.seed(1024)\n\ncities &lt;- c(\"New York City, NY\", \"Los Angeles, CA\", \"Chicago, IL\", \"Houston, TX\", \"Phoenix, AZ\", \"Philadelphia, PA\", \"San Antonio, TX\", \"San Diego, CA\", \"Dallas, TX\", \"San Jose, CA\", \"Austin, TX\", \"Jacksonville, FL\", \"Fort Worth, TX\", \"Columbus, OH\", \"San Francisco, CA\", \"Charlotte, NC\", \"Indianapolis, IN\", \"Seattle, WA\", \"Denver, CO\", \"Washington, DC\", \"Boston, MA\", \"Nashville, TN\", \"El Paso, TX\", \"Detroit, MI\", \"Memphis, TN\", \"Portland, OR\", \"Oklahoma City, OK\", \"Las Vegas, NV\", \"Louisville, KY\", \"Baltimore, MD\", \"Milwaukee, WI\", \"Albuquerque, NM\", \"Tucson, AZ\", \"Fresno, CA\", \"Sacramento, CA\", \"Mesa, AZ\", \"Atlanta, GA\", \"Kansas City, MO\", \"Colorado Springs, CO\", \"Miami, FL\")\ncities &lt;- rev(sort(cities))\neducation &lt;- c(\"High school or less\", \"Post-secondary\")\nage &lt;- c(\"18-54\", \"55+\")\nstratification &lt;- expand.grid(\n    city = cities,\n    education = education,\n    age = age) |&gt;\n    mutate(\n        population_share = runif(n(), min = .25, max = .75),\n        population_share = population_share / sum(population_share),\n        .by = \"city\",) |&gt;\n    arrange(city)\nN &lt;- 1000\nsurvey &lt;- data.frame(\n    city = sample(cities, N, replace = TRUE),\n    age = sample(age, N, replace = TRUE),\n    education = sample(education, N, replace = TRUE)\n)\nsurvey &lt;- data.frame(\n    respondent = sprintf(\"%04d\", 1:N),\n    survey)\nM &lt;- model.matrix(~., survey)\nb &lt;- runif(ncol(M))\nsurvey$meat_substitute &lt;- as.numeric(cut(M %*% b, breaks = 7))",
    "crumbs": [
      "Get started",
      "Case studies",
      "MrP"
    ]
  },
  {
    "objectID": "vignettes/mrp.html#footnotes",
    "href": "vignettes/mrp.html#footnotes",
    "title": "MrP",
    "section": "Footnotes",
    "text": "Footnotes\n\nSee the bottom of this page for the simulation code.↩︎",
    "crumbs": [
      "Get started",
      "Case studies",
      "MrP"
    ]
  },
  {
    "objectID": "vignettes/functions.html",
    "href": "vignettes/functions.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Goal\nFunction\n\n\n\nPredictions\npredictions()\n\n\n\navg_predictions()\n\n\n\nplot_predictions()\n\n\nComparisons: Difference, Ratio, Odds, Lift, etc.\ncomparisons()\n\n\n\navg_comparisons()\n\n\n\nplot_comparisons()\n\n\nSlopes\nslopes()\n\n\n\navg_slopes()\n\n\n\nplot_slopes()\n\n\nGrids\ndatagrid()\n\n\nHypothesis & Equivalence\nhypotheses()\n\n\nBayes, Bootstrap, Simulation\nposterior_draws()\n\n\n\ninferences()"
  },
  {
    "objectID": "vignettes/functions.html#functions",
    "href": "vignettes/functions.html#functions",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "Goal\nFunction\n\n\n\nPredictions\npredictions()\n\n\n\navg_predictions()\n\n\n\nplot_predictions()\n\n\nComparisons: Difference, Ratio, Odds, Lift, etc.\ncomparisons()\n\n\n\navg_comparisons()\n\n\n\nplot_comparisons()\n\n\nSlopes\nslopes()\n\n\n\navg_slopes()\n\n\n\nplot_slopes()\n\n\nGrids\ndatagrid()\n\n\nHypothesis & Equivalence\nhypotheses()\n\n\nBayes, Bootstrap, Simulation\nposterior_draws()\n\n\n\ninferences()"
  },
  {
    "objectID": "vignettes/alternative_software.html",
    "href": "vignettes/alternative_software.html",
    "title": "Alternative Software",
    "section": "",
    "text": "If you do not like marginaleffects, you may want to consider one of the alternatives described below:\n\n\nmargins: https://cran.r-project.org/web/packages/margins/index.html\n\nprediction: https://cran.r-project.org/web/packages/prediction/index.html\n\nemmeans: https://cran.r-project.org/web/packages/emmeans/index.html\n\nbrmsmargins: https://joshuawiley.com/brmsmargins/\n\neffects: https://cran.r-project.org/package=effects\n\nmodelbased: https://easystats.github.io/modelbased/\n\nggeffects: https://strengejacke.github.io/ggeffects/\n\nStata by StataCorp LLC\n\n\nThe emmeans package is developed by Russell V. Lenth and colleagues. emmeans is a truly incredible piece of software, and a trailblazer in the R ecosystem. It is an extremely powerful package whose functionality overlaps marginaleffects to a significant degree: marginal means, contrasts, and slopes. Even if the two packages can compute many of the same quantities, emmeans and marginaleffects have pretty different philosophies with respect to user interface and computation.\nAn emmeans analysis typically starts by computing “marginal means” by holding all numeric covariates at their means, and by averaging across a balanced grid of categorical predictors. Then, users can use the contrast() function to estimate the difference between marginal means.\nThe marginaleffects package supplies a predictions function which can replicate most emmeans analyses by computing marginal means. However, the typical analysis is more squarely centered on predicted/fitted values. This is a useful starting point because, in many cases, analysts will find it easy and intuitive to express their scientific queries in terms of changes in predicted values. For example,\n\nHow does the average predicted probability of survival differ between treatment and control group?\nWhat is the difference between the predicted wage of college and high school graduates?\n\nLet’s say we estimate a linear regression model with two continuous regressors and a multiplicative interaction:\n\\[y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\beta_3 x \\cdot z + \\varepsilon\\]\nIn this model, the effect of \\(x\\) on \\(y\\) will depend on the value of covariate \\(z\\). Let’s say the user wants to estimate what happens to the predicted value of \\(y\\) when \\(x\\) increases by 1 unit, when \\(z \\in \\{-1, 0, 1\\}\\). To do this, we use the comparisons() function. The variables argument determines the scientific query of interest, and the newdata argument determines the grid of covariate values on which we want to evaluate the query:\n\nmodel &lt;- lm(y ~ x * z, data)\n\ncomparisons(\n  model,\n  variables = list(x = 1), # what is the effect of 1-unit change in x?\n  newdata = datagrid(z = -1:1) # when z is held at values -1, 0, or 1\n)\n\nAs the vignettes show, marginaleffects can also compute contrasts on marginal means. It can also compute various quantities of interest like raw fitted values, slopes (partial derivatives), and contrasts between marginal means. It also offers a flexible mechanism to run (non-)linear hypothesis tests using the delta method, and it offers fully customizable strategy to compute quantities like odds ratios (or completely arbitrary functions of predicted outcome).\nThus, in my (Vincent’s) biased opinion, the main benefits of marginaleffects over emmeans are:\n\nSupport more model types.\nSimpler, more intuitive, and highly consistent user interface.\nEasier to compute average slopes or unit-level contrasts for whole datasets.\nEasier to compute slopes (aka marginal effects, trends, or partial derivatives) for custom grids and continuous regressors.\nEasier to implement causal inference strategies like the parametric g-formula and regression adjustment in experiments (see vignettes).\nAllows the computation of arbitrary quantities of interest via user-supplied functions and automatic delta method inference.\nCommon plots are easy with the plot_predictions(), plot_comparisons(), and plot_slopes() functions.\n\nTo be fair, many of the marginaleffects advantages listed above come down to subjective preferences over user interface. Readers are thus encouraged to try both packages to see which interface they prefer.\nThe main advantages of emmeans over marginaleffects arise when users are specifically interested in marginal means, where emmeans tends to be much faster and to have a lot of functionality to handle backtransformations. emmeans also has better functionality for effect sizes; notably, the eff_size() function can return effect size estimates that account for uncertainty in both estimated effects and the population SD.\nPlease let me know if you find other features in emmeans so I can add them to this list.\nThe Marginal Means Vignette includes side-by-side comparisons of emmeans and marginaleffects to compute marginal means. The rest of this section compares the syntax for contrasts and marginaleffects.\n\nAs far as I can tell, emmeans does not provide an easy way to compute unit-level contrasts for every row of the dataset used to fit our model. Therefore, the side-by-side syntax shown below will always include newdata=datagrid() to specify that we want to compute only one contrast: at the mean values of the regressors. In day-to-day practice with slopes(), however, this extra argument would not be necessary.\nFit a model:\n\nlibrary(emmeans)\nlibrary(marginaleffects)\n\nmod &lt;- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)\n\nLink scale, pairwise contrasts:\n\nemm &lt;- emmeans(mod, specs = \"cyl\")\ncontrast(emm, method = \"revpairwise\", adjust = \"none\", df = Inf)\n#&gt;  contrast    estimate      SE  df z.ratio p.value\n#&gt;  cyl6 - cyl4   -0.905    1.63 Inf  -0.555  0.5789\n#&gt;  cyl8 - cyl4  -19.542 4367.17 Inf  -0.004  0.9964\n#&gt;  cyl8 - cyl6  -18.637 4367.16 Inf  -0.004  0.9966\n#&gt; \n#&gt; Degrees-of-freedom method: user-specified \n#&gt; Results are given on the log odds ratio (not the response) scale.\n\ncomparisons(mod,\n            type = \"link\",\n            newdata = \"mean\",\n            variables = list(cyl = \"pairwise\"))\n#&gt; \n#&gt;  Contrast Estimate Std. Error        z Pr(&gt;|z|)   S   2.5 %  97.5 %  hp\n#&gt;     6 - 4   -0.905       1.63 -0.55506    0.579 0.8    -4.1    2.29 147\n#&gt;     8 - 4  -19.542    4367.17 -0.00447    0.996 0.0 -8579.0 8539.95 147\n#&gt;     8 - 6  -18.637    4367.17 -0.00427    0.997 0.0 -8578.1 8540.85 147\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  link \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, cyl, vs\n\nResponse scale, reference groups:\n\nemm &lt;- emmeans(mod, specs = \"cyl\", regrid = \"response\")\ncontrast(emm, method = \"trt.vs.ctrl1\", adjust = \"none\", df = Inf, ratios = FALSE)\n#&gt;  contrast    estimate    SE  df z.ratio p.value\n#&gt;  cyl6 - cyl4   -0.222 0.394 Inf  -0.564  0.5727\n#&gt;  cyl8 - cyl4   -0.595 0.511 Inf  -1.163  0.2447\n#&gt; \n#&gt; Degrees-of-freedom method: user-specified\n\ncomparisons(mod, newdata = \"mean\")\n#&gt; \n#&gt;  Term Contrast  Estimate Std. Error         z Pr(&gt;|z|)   S     2.5 %   97.5 %  hp cyl\n#&gt;   cyl    6 - 4 -2.22e-01   3.94e-01 -0.564103    0.573 0.8 -9.94e-01 5.50e-01 147   8\n#&gt;   cyl    8 - 4 -5.95e-01   5.11e-01 -1.163332    0.245 2.0 -1.60e+00 4.07e-01 147   8\n#&gt;   hp     +1    -1.53e-10   6.69e-07 -0.000229    1.000 0.0 -1.31e-06 1.31e-06 147   8\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, cyl, vs\n\n\nHere is a slightly more complicated example with contrasts estimated by subgroup in a lme4 mixed effects model. First we estimate a model and compute pairwise contrasts by subgroup using emmeans:\n\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(emmeans)\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/VerbAgg.csv\")\ndat$woman &lt;- as.numeric(dat$Gender == \"F\")\n\nmod &lt;- glmer(\n    woman ~ btype * resp + situ + (1 + Anger | item),\n    family = binomial,\n    data = dat)\n\nemmeans(mod, specs = \"btype\", by = \"resp\") |&gt;\n    contrast(method = \"revpairwise\", adjust = \"none\")\n#&gt; resp = no:\n#&gt;  contrast      estimate     SE  df z.ratio p.value\n#&gt;  scold - curse  -0.0152 0.1097 Inf  -0.139  0.8898\n#&gt;  shout - curse  -0.2533 0.1022 Inf  -2.479  0.0132\n#&gt;  shout - scold  -0.2381 0.0886 Inf  -2.686  0.0072\n#&gt; \n#&gt; resp = perhaps:\n#&gt;  contrast      estimate     SE  df z.ratio p.value\n#&gt;  scold - curse  -0.2393 0.1178 Inf  -2.031  0.0422\n#&gt;  shout - curse  -0.0834 0.1330 Inf  -0.627  0.5309\n#&gt;  shout - scold   0.1559 0.1358 Inf   1.148  0.2510\n#&gt; \n#&gt; resp = yes:\n#&gt;  contrast      estimate     SE  df z.ratio p.value\n#&gt;  scold - curse   0.0391 0.1292 Inf   0.302  0.7624\n#&gt;  shout - curse   0.5802 0.1784 Inf   3.252  0.0011\n#&gt;  shout - scold   0.5411 0.1888 Inf   2.866  0.0042\n#&gt; \n#&gt; Results are averaged over the levels of: situ \n#&gt; Results are given on the log odds ratio (not the response) scale.\n\nWhat did emmeans do to obtain these results? Roughly speaking:\n\nCreate a prediction grid with one cell for each combination of categorical predictors in the model, and all numeric variables held at their means.\nMake adjusted predictions in each cell of the prediction grid.\nTake the average of those predictions (marginal means) for each combination of btype (focal variable) and resp (group by variable).\nCompute pairwise differences (contrasts) in marginal means across different levels of the focal variable btype.\n\nIn short, emmeans computes pairwise contrasts between marginal means, which are themselves averages of adjusted predictions. This is different from the default types of contrasts produced by comparisons(), which reports contrasts between adjusted predictions, without averaging across a pre-specified grid of predictors. What does comparisons() do instead?\nLet newdata be a data frame supplied by the user (or the original data frame used to fit the model), then:\n\nCreate a new data frame called newdata2, which is identical to newdata except that the focal variable is incremented by one level.\nCompute contrasts as the difference between adjusted predictions made on the two datasets:\n\npredict(model, newdata = newdata2) - predict(model, newdata = newdata)\n\n\n\nAlthough it is not idiomatic, we can use still use comparisons() to emulate the emmeans results. First, we create a prediction grid with one cell for each combination of categorical predictor in the model:\n\nnd &lt;- datagrid(\n    model = mod,\n    resp = dat$resp,\n    situ = dat$situ,\n    btype = dat$btype)\nnrow(nd)\n#&gt; [1] 18\n\nThis grid has 18 rows, one for each combination of levels for the resp (3), situ (2), and btype (3) variables (3 * 2 * 3 = 18).\nThen we compute pairwise contrasts over this grid:\n\ncmp &lt;- comparisons(mod,\n    variables = list(\"btype\" = \"pairwise\"),\n    newdata = nd,\n    type = \"link\")\nnrow(cmp)\n#&gt; [1] 54\n\nThere are 3 pairwise contrasts, corresponding to the 3 pairwise comparisons possible between the 3 levels of the focal variable btype: scold-curse, shout-scold, shout-curse. The comparisons() function estimates those 3 contrasts for each row of newdata, so we get \\(18 \\times 3 = 54\\) rows.\nFinally, if we wanted contrasts averaged over each subgroup of the resp variable, we can use the avg_comparisons() function with the by argument:\n\navg_comparisons(mod,\n    by = \"resp\",\n    variables = list(\"btype\" = \"pairwise\"),\n    newdata = nd,\n    type = \"link\")\n#&gt; \n#&gt;   Term                  Contrast    resp Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 %   97.5 %\n#&gt;  btype mean(scold) - mean(curse) no       -0.0152     0.1097 -0.139  0.88976 0.2 -0.230  0.19971\n#&gt;  btype mean(scold) - mean(curse) perhaps  -0.2393     0.1178 -2.031  0.04221 4.6 -0.470 -0.00842\n#&gt;  btype mean(scold) - mean(curse) yes       0.0391     0.1292  0.302  0.76239 0.4 -0.214  0.29234\n#&gt;  btype mean(shout) - mean(curse) no       -0.2533     0.1022 -2.479  0.01319 6.2 -0.454 -0.05301\n#&gt;  btype mean(shout) - mean(curse) perhaps  -0.0834     0.1330 -0.627  0.53091 0.9 -0.344  0.17738\n#&gt;  btype mean(shout) - mean(curse) yes       0.5802     0.1784  3.252  0.00115 9.8  0.230  0.92987\n#&gt;  btype mean(shout) - mean(scold) no       -0.2381     0.0886 -2.686  0.00723 7.1 -0.412 -0.06436\n#&gt;  btype mean(shout) - mean(scold) perhaps   0.1559     0.1358  1.148  0.25103 2.0 -0.110  0.42215\n#&gt;  btype mean(shout) - mean(scold) yes       0.5411     0.1888  2.866  0.00416 7.9  0.171  0.91116\n#&gt; \n#&gt; Type:  link \n#&gt; Columns: term, contrast, resp, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThese results are identical to those produced by emmeans (except for \\(t\\) vs. \\(z\\)).\n\nAs far as I can tell, emmeans::emtrends makes it easier to compute marginal effects for a few user-specified values than for large grids or for the full original dataset.\nResponse scale, user-specified values:\n\nmod &lt;- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)\n\nemtrends(mod, ~hp, \"hp\", regrid = \"response\", at = list(cyl = 4))\n#&gt;   hp hp.trend    SE  df asymp.LCL asymp.UCL\n#&gt;  147 -0.00786 0.011 Inf   -0.0294    0.0137\n#&gt; \n#&gt; Confidence level used: 0.95\n\nslopes(mod, newdata = datagrid(cyl = 4))\n#&gt; \n#&gt;  Contrast cyl Estimate Std. Error      z Pr(&gt;|z|)   S   2.5 % 97.5 %\n#&gt;     6 - 4   4 -0.22219      0.394 -0.564    0.573 0.8 -0.9942 0.5498\n#&gt;     8 - 4   4 -0.59469      0.511 -1.163    0.245 2.0 -1.5966 0.4072\n#&gt;     dY/dX   4 -0.00785      0.011 -0.713    0.476 1.1 -0.0294 0.0137\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cyl, predicted_lo, predicted_hi, predicted, hp, vs\n\nLink scale, user-specified values:\n\nemtrends(mod, ~hp, \"hp\", at = list(cyl = 4))\n#&gt;   hp hp.trend     SE  df asymp.LCL asymp.UCL\n#&gt;  147  -0.0326 0.0339 Inf    -0.099    0.0338\n#&gt; \n#&gt; Confidence level used: 0.95\n\nslopes(mod, type = \"link\", newdata = datagrid(cyl = 4))\n#&gt; \n#&gt;  Contrast cyl Estimate Std. Error        z Pr(&gt;|z|)   S     2.5 %   97.5 %\n#&gt;     6 - 4   4  -0.9049   1.63e+00 -0.55506    0.579 0.8    -4.100 2.29e+00\n#&gt;     8 - 4   4 -19.5418   4.37e+03 -0.00447    0.996 0.0 -8579.030 8.54e+03\n#&gt;     dY/dX   4  -0.0326   3.39e-02 -0.96144    0.336 1.6    -0.099 3.38e-02\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  link \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cyl, predicted_lo, predicted_hi, predicted, hp, vs\n\n\nHere are a few more emmeans vs. marginaleffects comparisons:\n\n## Example of examining a continuous x categorical interaction using emmeans and marginaleffects\n## Authors: Cameron Patrick and Vincent Arel-Bundock\n\nlibrary(tidyverse)\nlibrary(emmeans)\nlibrary(marginaleffects)\n\n## use the mtcars data, set up am as a factor\ndata(mtcars)\nmc &lt;- mtcars |&gt; mutate(am = factor(am))\n\n## fit a linear model to mpg with wt x am interaction\nm &lt;- lm(mpg ~ wt*am, data = mc)\nsummary(m)\n\n## 1. means for each level of am at mean wt.\nemmeans(m, \"am\")\npredictions(m, newdata = datagrid(am = 0:1))\n\n## 2. means for each level of am at wt = 2.5, 3, 3.5.\nemmeans(m, c(\"am\", \"wt\"), at = list(wt = c(2.5, 3, 3.5)))\npredictions(m, newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5))\n\n## 3. means for wt = 2.5, 3, 3.5, averaged over levels of am (implicitly!).\nemmeans(m, \"wt\", at = list(wt = c(2.5, 3, 3.5)))\n\n## same thing, but the averaging is more explicit, using the `by` argument\npredictions(\n  m,\n  newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5)),\n  by = \"wt\")\n\n## 4. graphical version of 2.\nemmip(m, am ~ wt, at = list(wt = c(2.5, 3, 3.5)), CIs = TRUE)\nplot_predictions(m, condition = c(\"wt\", \"am\"))\n\n## 5. compare levels of am at specific values of wt.\n## this is a bit ugly because the emmeans defaults for pairs() are silly.\n## infer = TRUE: enable confidence intervals.\n## adjust = \"none\": begone, Tukey.\n## reverse = TRUE: contrasts as (later level) - (earlier level)\npairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),\n      infer = TRUE, adjust = \"none\", reverse = TRUE)\n\ncomparisons(\n  m,\n  variables = \"am\",\n  newdata = datagrid(wt = c(2.5, 3, 3.5)))\n\n## 6. plot of pairswise comparisons\nplot(pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),\n      infer = TRUE, adjust = \"none\", reverse = TRUE))\n\n## Since `wt` is numeric, the default is to plot it as a continuous variable on\n## the x-axis.  But not that this is the **exact same info** as in the emmeans plot.\nplot_comparisons(m, variables = \"am\", condition = \"wt\")\n\n## You of course customize everything, set draw=FALSE, and feed the raw data to feed to ggplot2\np &lt;- plot_comparisons(\n  m,\n  variables = \"am\",\n  condition = list(wt = c(2.5, 3, 3.5)),\n  draw = FALSE)\n\nggplot(p, aes(y = wt, x = comparison, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n## 7. slope of wt for each level of am\nemtrends(m, \"am\", \"wt\")\nslopes(m, newdata = datagrid(am = 0:1))\n\n\nThe margins and prediction packages for R were designed by Thomas Leeper to emulate the behavior of the margins command from Stata. These packages are trailblazers and strongly influenced the development of marginaleffects. The main benefits of marginaleffects over these packages are:\n\nSupport more model types\nFaster\nMemory efficient\nPlots using ggplot2 instead of Base R\nMore extensive test suite\nActive development\n\nThe syntax of the two packages is very similar.\n\n\nlibrary(margins)\nlibrary(marginaleffects)\n\nmod &lt;- lm(mpg ~ cyl + hp + wt, data = mtcars)\n\nmar &lt;- margins(mod)\nsummary(mar)\n#&gt;  factor     AME     SE       z      p   lower   upper\n#&gt;     cyl -0.9416 0.5509 -1.7092 0.0874 -2.0214  0.1382\n#&gt;      hp -0.0180 0.0119 -1.5188 0.1288 -0.0413  0.0052\n#&gt;      wt -3.1670 0.7406 -4.2764 0.0000 -4.6185 -1.7155\n\nmfx &lt;- slopes(mod)\n\n\nMarginal effects in a user-specified data frame:\n\nhead(data.frame(mar))\n#&gt;    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt X_weights X_at_number\n#&gt; 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 22.82043 0.6876212 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 22.01285 0.6056817 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.96040 0.7349593 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.93608 0.5800910 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.16780 0.8322986 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 20.25036 0.6638322 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n\nhead(mfx)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.551 -1.71   0.0873 3.5 -2.02  0.138\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, cyl, hp, wt\nnd &lt;- data.frame(cyl = 4, hp = 110, wt = 3)\n\n\n\nmar &lt;- margins(mod, data = data.frame(prediction::mean_or_mode(mtcars)), unit_ses = TRUE)\ndata.frame(mar)\n#&gt;        mpg    cyl     disp       hp     drat      wt     qsec     vs      am   gear   carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt SE_dydx_cyl SE_dydx_hp SE_dydx_wt X_weights X_at_number\n#&gt; 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 20.09062 0.4439832 -0.9416168 -0.0180381 -3.166973    0.3035082 0.0001410453   0.5484409   0.5509157 0.01187625  0.7405679        NA           1\n\nslopes(mod, newdata = \"mean\")\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;   cyl   -0.942     0.5503 -1.71   0.0871  3.5 -2.0202  0.13695\n#&gt;   hp    -0.018     0.0119 -1.52   0.1288  3.0 -0.0413  0.00524\n#&gt;   wt    -3.167     0.7407 -4.28   &lt;0.001 15.7 -4.6187 -1.71521\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, cyl, hp, wt, mpg\n\n\nThe at argument of the margins package emulates Stata by fixing the values of some variables at user-specified values, and by replicating the full dataset several times for each combination of the supplied values (see the Stata section below). For example, if the dataset includes 32 rows and the user calls at=list(cyl=c(4, 6)), margins will compute 64 unit-level marginal effects estimates:\n\ndat &lt;- mtcars\ndat$cyl &lt;- factor(dat$cyl)\nmod &lt;- lm(mpg ~ cyl * hp + wt, data = mtcars)\n\nmar &lt;- margins(mod, at = list(cyl = c(4, 6, 8)))\nsummary(mar)\n#&gt;  factor    cyl     AME     SE       z      p   lower   upper\n#&gt;     cyl 4.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139\n#&gt;     cyl 6.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139\n#&gt;     cyl 8.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139\n#&gt;      hp 4.0000 -0.0878 0.0267 -3.2937 0.0010 -0.1400 -0.0355\n#&gt;      hp 6.0000 -0.0499 0.0154 -3.2397 0.0012 -0.0800 -0.0197\n#&gt;      hp 8.0000 -0.0120 0.0108 -1.1065 0.2685 -0.0332  0.0092\n#&gt;      wt 4.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236\n#&gt;      wt 6.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236\n#&gt;      wt 8.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236\n\navg_slopes(\n    mod,\n    by = \"cyl\",\n    newdata = datagrid(cyl = c(4, 6, 8)), grid_type = \"counterfactual\")\n#&gt; \n#&gt;  Term cyl Estimate Std. Error       z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;   cyl   4   0.0381     0.5998  0.0636  0.94931  0.1 -1.1375  1.21381\n#&gt;   cyl   6   0.0381     0.5999  0.0636  0.94931  0.1 -1.1376  1.21390\n#&gt;   cyl   8   0.0381     0.6000  0.0636  0.94932  0.1 -1.1378  1.21412\n#&gt;   hp    4  -0.0878     0.0267 -3.2935  &lt; 0.001 10.0 -0.1400 -0.03554\n#&gt;   hp    6  -0.0499     0.0154 -3.2401  0.00119  9.7 -0.0800 -0.01970\n#&gt;   hp    8  -0.0120     0.0108 -1.1065  0.26851  1.9 -0.0332  0.00923\n#&gt;   wt    4  -3.1198     0.6614 -4.7173  &lt; 0.001 18.7 -4.4161 -1.82358\n#&gt;   wt    6  -3.1198     0.6612 -4.7182  &lt; 0.001 18.7 -4.4158 -1.82384\n#&gt;   wt    8  -3.1198     0.6614 -4.7173  &lt; 0.001 18.7 -4.4161 -1.82358\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: rowid, term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nThe syntax to compute adjusted predictions using the predictions package or marginaleffects is very similar:\n\nprediction::prediction(mod) |&gt; head()\n#&gt;    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted\n#&gt; 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 21.90488 0.6927034\n#&gt; 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 21.10933 0.6266557\n#&gt; 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.64753 0.6652076\n#&gt; 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.04859 0.6041400\n#&gt; 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.25445 0.7436172\n#&gt; 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 19.53360 0.6436862\n\nmarginaleffects::predictions(mod) |&gt; head()\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      21.9      0.693 31.6   &lt;0.001 726.6  20.5   23.3\n#&gt;      21.1      0.627 33.7   &lt;0.001 823.9  19.9   22.3\n#&gt;      25.6      0.665 38.6   &lt;0.001   Inf  24.3   27.0\n#&gt;      20.0      0.604 33.2   &lt;0.001 799.8  18.9   21.2\n#&gt;      17.3      0.744 23.2   &lt;0.001 393.2  15.8   18.7\n#&gt;      19.5      0.644 30.3   &lt;0.001 669.5  18.3   20.8\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, hp, wt\n\n\nStata is a good but expensive software package for statistical analysis. It is published by StataCorp LLC. This section compares Stata’s margins command to marginaleffects.\nThe results produced by marginaleffects are extensively tested against Stata. See the test suite for a list of the dozens of models where we compared estimates and standard errors.\n\nMarginal effects are unit-level quantities. To compute “average marginal effects”, we first calculate marginal effects for each observation in a dataset. Then, we take the mean of those unit-level marginal effects.\n\nBoth Stata’s margins command and the slopes function can calculate average marginal effects (AMEs). Here is an example showing how to estimate AMEs in Stata:\nquietly reg mpg cyl hp wt\nmargins, dydx(*)\n\nAverage marginal effects                        Number of obs     =         32\nModel VCE    : OLS\n \nExpression   : Linear prediction, predict()\ndy/dx w.r.t. : cyl hp wt\n \n------------------------------------------------------------------------------\n    |            Delta-method\n    |      dy/dx   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n------------------------------------------------------------------------------\ncyl |  -.9416168   .5509164    -1.71   0.098    -2.070118    .1868842\n hp |  -.0180381   .0118762    -1.52   0.140    -.0423655    .0062893\n wt |  -3.166973   .7405759    -4.28   0.000    -4.683974   -1.649972\n------------------------------------------------------------------------------\n\nThe same results can be obtained with slopes() and summary() like this:\n\nlibrary(\"marginaleffects\")\nmod &lt;- lm(mpg ~ cyl + hp + wt, data = mtcars)\navg_slopes(mod)\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;   cyl   -0.942     0.5512 -1.71   0.0876  3.5 -2.0220  0.13879\n#&gt;   hp    -0.018     0.0119 -1.52   0.1288  3.0 -0.0413  0.00524\n#&gt;   wt    -3.167     0.7406 -4.28   &lt;0.001 15.7 -4.6184 -1.71552\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that Stata reports t statistics while marginaleffects reports Z. This produces slightly different p-values because this model has low degrees of freedom: mtcars only has 32 rows\n\nA “counterfactual marginal effect” is a special quantity obtained by replicating a dataset while fixing some regressor to user-defined values.\nConcretely, Stata computes counterfactual marginal effects in 3 steps:\n\nDuplicate the whole dataset 3 times and sets the values of cyl to the three specified values in each of those subsets.\nCalculate marginal effects for each observation in that large grid.\nTake the average of marginal effects for each value of the variable of interest.\n\n\nWith the at argument, Stata’s margins command estimates average counterfactual marginal effects. Here is an example:\nquietly reg mpg i.cyl##c.hp wt\nmargins, dydx(hp) at(cyl = (4 6 8))\n\nAverage marginal effects                        Number of obs     =         32\nModel VCE    : OLS\n\nExpression   : Linear prediction, predict()\ndy/dx w.r.t. : hp\n\n1._at        : cyl             =           4\n\n2._at        : cyl             =           6\n\n3._at        : cyl             =           8\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |      dy/dx   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\nhp           |\n         _at |\n          1  |   -.099466   .0348665    -2.85   0.009    -.1712749   -.0276571\n          2  |  -.0213768    .038822    -0.55   0.587    -.1013323    .0585787\n          3  |   -.013441   .0125138    -1.07   0.293    -.0392137    .0123317\n------------------------------------------------------------------------------\n\n\nYou can estimate average counterfactual marginal effects with slopes() by using the datagrid() to create a counterfactual dataset in which the full original dataset is replicated for each potential value of the cyl variable. Then, we tell the by argument to average within groups:\n\nmod &lt;- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)\n\navg_slopes(\n    mod,\n    variables = \"hp\",\n    by = \"cyl\",\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\"))\n#&gt; \n#&gt;  Term cyl Estimate Std. Error      z Pr(&gt;|z|)   S   2.5 %  97.5 %\n#&gt;    hp   4  -0.0995     0.0349 -2.853  0.00433 7.9 -0.1678 -0.0311\n#&gt;    hp   6  -0.0214     0.0388 -0.551  0.58189 0.8 -0.0975  0.0547\n#&gt;    hp   8  -0.0134     0.0125 -1.074  0.28278 1.8 -0.0380  0.0111\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThis is equivalent to taking the group-wise mean of observation-level marginal effects (without the by argument):\n\nmfx &lt;- slopes(\n    mod,\n    variables = \"hp\",\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\"))\naggregate(estimate ~ term + cyl, data = mfx, FUN = mean)\n#&gt;   term cyl    estimate\n#&gt; 1   hp   4 -0.09946598\n#&gt; 2   hp   6 -0.02137679\n#&gt; 3   hp   8 -0.01344103\n\n\nNote that following Stata, the standard errors for group-averaged marginal effects are computed by taking the “Jacobian at the mean:”\n\nJ &lt;- attr(mfx, \"jacobian\")\nJ_mean &lt;- aggregate(J, by = list(mfx$cyl), FUN = mean)\nJ_mean &lt;- as.matrix(J_mean[, 2:ncol(J_mean)])\nsqrt(diag(J_mean %*% vcov(mod) %*% t(J_mean)))\n#&gt; [1] 0.03486634 0.03882234 0.01251371\n\n\n\nJust like Stata’s margins command computes average counterfactual marginal effects, it can also estimate average counterfactual adjusted predictions.\nHere is an example:\nquietly reg mpg i.cyl##c.hp wt\nmargins, at(cyl = (4 6 8))\n\nPredictive margins                              Number of obs     =         32\nModel VCE    : OLS\n\nExpression   : Linear prediction, predict()\n\n1._at        : cyl             =           4\n\n2._at        : cyl             =           6\n\n3._at        : cyl             =           8\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |     Margin   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         _at |\n          1  |   17.44233   2.372914     7.35   0.000     12.55522    22.32944\n          2  |    18.9149   1.291483    14.65   0.000     16.25505    21.57476\n          3  |   18.33318   1.123874    16.31   0.000     16.01852    20.64785\n------------------------------------------------------------------------------\nAgain, this is what Stata does in the background:\n\nIt duplicates the whole dataset 3 times and sets the values of cyl to the three specified values in each of those subsets.\nIt calculates predictions for that large grid.\nIt takes the average prediction for each value of cyl.\n\nIn other words, average counterfactual adjusted predictions as implemented by Stata are a hybrid between predictions at the observed values (the default in marginaleffects::predictions) and predictions at representative values.\n\nYou can estimate average counterfactual adjusted predictions with predictions() by, first, setting the grid_type argument of datagrid() to \"counterfactual\" and, second, by averaging the predictions using the by argument of summary(), or a manual function like dplyr::summarise().\n\nmod &lt;- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)\n\npredictions(\n    mod,\n    by = \"cyl\",\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\"))\n#&gt; \n#&gt;  cyl Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;    4     17.4       2.37  7.35   &lt;0.001  42.2  12.8   22.1\n#&gt;    6     18.9       1.29 14.65   &lt;0.001 158.9  16.4   21.4\n#&gt;    8     18.3       1.12 16.31   &lt;0.001 196.3  16.1   20.5\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\npredictions(\n    mod,\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\")) |&gt;\n    group_by(cyl) |&gt;\n    summarize(AAP = mean(estimate))\n#&gt; # A tibble: 3 × 2\n#&gt;   cyl     AAP\n#&gt;   &lt;fct&gt; &lt;dbl&gt;\n#&gt; 1 4      17.4\n#&gt; 2 6      18.9\n#&gt; 3 8      18.3\n\n\nThe brmsmargins package is developed by Joshua Wiley:\n\nThis package has functions to calculate marginal effects from brms models ( http://paul-buerkner.github.io/brms/ ). A central motivator is to calculate average marginal effects (AMEs) for continuous and discrete predictors in fixed effects only and mixed effects regression models including location scale models.\n\nThe main advantage of brmsmargins over marginaleffects is its ability to compute “Marginal Coefficients” following the method described in Hedeker et al (2012).\nThe main advantages of marginaleffects over brmsmargins are:\n\nSupport for 60+ model types, rather than just the brms package.\nSimpler user interface (subjective).\nAt the time of writing (2022-05-25) brmsmargins did not support certain brms models such as those with multivariate or multinomial outcomes. It also did not support custom outcome transformations.\n\nThe rest of this section presents side-by-side replications of some of the analyses from the brmsmargins vignettes in order to show highlight parallels and differences in syntax.\n\n\nEstimate a logistic regression model with brms:\n\nlibrary(brms)\nlibrary(brmsmargins)\nlibrary(marginaleffects)\nlibrary(data.table)\nlibrary(withr)\nsetDTthreads(5)\nh &lt;- 1e-4\n\nvoid &lt;- capture.output(\n    bayes.logistic &lt;- brm(\n      vs ~ am + mpg, data = mtcars,\n      family = \"bernoulli\", seed = 1234,\n      silent = 2, refresh = 0,\n      backend = \"cmdstanr\",\n      chains = 4L, cores = 4L)\n)\n\nCompute AMEs manually:\n\nd1 &lt;- d2 &lt;- mtcars\nd2$mpg &lt;- d2$mpg + h\np1 &lt;- posterior_epred(bayes.logistic, newdata = d1)\np2 &lt;- posterior_epred(bayes.logistic, newdata = d2)\nm &lt;- (p2 - p1) / h\nquantile(rowMeans(m), c(.5, .025, .975))\n#&gt;        50%       2.5%      97.5% \n#&gt; 0.06981152 0.05372040 0.09159040\n\nCompute AMEs with brmsmargins:\n\nbm &lt;- brmsmargins(\n  bayes.logistic,\n  add = data.frame(mpg = c(0, 0 + h)),\n  contrasts = cbind(\"AME MPG\" = c(-1 / h, 1 / h)),\n  CI = 0.95,\n  CIType = \"ETI\")\ndata.frame(bm$ContrastSummary)\n#&gt;            M        Mdn        LL        UL PercentROPE PercentMID   CI CIType ROPE  MID   Label\n#&gt; 1 0.07098514 0.06981152 0.0537204 0.0915904          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME MPG\n\nCompute AMEs using marginaleffects:\n\navg_slopes(bayes.logistic) \n#&gt; \n#&gt;  Term          Contrast Estimate   2.5 %  97.5 %\n#&gt;   am  mean(1) - mean(0)  -0.2672 -0.4219 -0.0682\n#&gt;   mpg mean(dY/dX)         0.0698  0.0537  0.0916\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nThe mpg element of the Effect column from marginaleffects matches the the M column of the output from brmsmargins.\n\nEstimate a mixed effects logistic regression model with brms:\n\nd &lt;- withr::with_seed(\n  seed = 12345, code = {\n    nGroups &lt;- 100\n    nObs &lt;- 20\n    theta.location &lt;- matrix(rnorm(nGroups * 2), nrow = nGroups, ncol = 2)\n    theta.location[, 1] &lt;- theta.location[, 1] - mean(theta.location[, 1])\n    theta.location[, 2] &lt;- theta.location[, 2] - mean(theta.location[, 2])\n    theta.location[, 1] &lt;- theta.location[, 1] / sd(theta.location[, 1])\n    theta.location[, 2] &lt;- theta.location[, 2] / sd(theta.location[, 2])\n    theta.location &lt;- theta.location %*% chol(matrix(c(1.5, -.25, -.25, .5^2), 2))\n    theta.location[, 1] &lt;- theta.location[, 1] - 2.5\n    theta.location[, 2] &lt;- theta.location[, 2] + 1\n    d &lt;- data.table(\n      x = rep(rep(0:1, each = nObs / 2), times = nGroups))\n    d[, ID := rep(seq_len(nGroups), each = nObs)]\n\n    for (i in seq_len(nGroups)) {\n      d[ID == i, y := rbinom(\n        n = nObs,\n        size = 1,\n        prob = plogis(theta.location[i, 1] + theta.location[i, 2] * x))\n        ]\n    }\n    copy(d)\n  })\n\nvoid &lt;- capture.output(\n    mlogit &lt;- brms::brm(\n      y ~ 1 + x + (1 + x | ID), family = \"bernoulli\",\n      data = d, seed = 1234,\n      backend = \"cmdstanr\",\n      silent = 2, refresh = 0,\n      chains = 4L, cores = 4L)\n)\n\n\n\nbm &lt;- brmsmargins(\n  mlogit,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  effects = \"includeRE\",\n  CI = .95,\n  CIType = \"ETI\")\ndata.frame(bm$ContrastSummary)\n#&gt;           M       Mdn        LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 0.1118135 0.1120303 0.0814249 0.1425242          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(mlogit)\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.111 0.081  0.141\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nbm &lt;- brmsmargins(\n  mlogit,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  effects = \"fixedonly\",\n  CI = .95,\n  CIType = \"ETI\")\ndata.frame(bm$ContrastSummary)\n#&gt;           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 0.1040304 0.1037629 0.06163523 0.1480365          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(mlogit, re_formula = NA)\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;     0.101 0.0607  0.142\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nEstimate a fixed effects location scale model with brms:\n\nd &lt;- withr::with_seed(\n  seed = 12345, code = {\n    nObs &lt;- 1000L\n    d &lt;- data.table(\n      grp = rep(0:1, each = nObs / 2L),\n      x = rnorm(nObs, mean = 0, sd = 0.25))\n    d[, y := rnorm(nObs,\n                   mean = x + grp,\n                   sd = exp(1 + x + grp))]\n    copy(d)\n  })\n\nvoid &lt;- capture.output(\n    ls.fe &lt;- brm(bf(\n      y ~ 1 + x + grp,\n      sigma ~ 1 + x + grp),\n      family = \"gaussian\",\n      data = d, seed = 1234,\n      silent = 2, refresh = 0,\n      backend = \"cmdstanr\",\n      chains = 4L, cores = 4L)\n)\n\n\n\nbm &lt;- brmsmargins(\n  ls.fe,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  CI = 0.95, CIType = \"ETI\",\n  effects = \"fixedonly\")\ndata.frame(bm$ContrastSummary)\n#&gt;          M     Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 1.622142 1.61919 0.765971 2.504324          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(ls.fe, re_formula = NA)\n#&gt; \n#&gt;  Term          Contrast Estimate 2.5 % 97.5 %\n#&gt;   grp mean(1) - mean(0)     1.01 0.366   1.68\n#&gt;   x   mean(dY/dX)           1.62 0.766   2.50\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\nCompute the contrast between adjusted predictions on the sigma parameter, when grp=0 and grp=1:\n\nbm &lt;- brmsmargins(\n  ls.fe,\n  at = data.frame(grp = c(0, 1)),\n  contrasts = cbind(\"AME grp\" = c(-1, 1)),\n  CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",\n  effects = \"fixedonly\")\ndata.frame(bm$ContrastSummary)\n#&gt;          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID   Label\n#&gt; 1 4.907779 4.903996 4.374426 5.449402          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME grp\n\nIn marginaleffects we use the comparisons() function and the variables argument:\n\navg_comparisons(\n  ls.fe,\n  variables = list(grp = 0:1),\n  dpar = \"sigma\")\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;       4.9  4.37   5.45\n#&gt; \n#&gt; Term: grp\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nbm &lt;- brmsmargins(\n  ls.fe,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",\n  effects = \"fixedonly\")\ndata.frame(bm$ContrastSummary)\n#&gt;          M      Mdn      LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 4.474551 4.464982 3.52317 5.484218          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(ls.fe, dpar = \"sigma\", re_formula = NA)\n#&gt; \n#&gt;  Term          Contrast Estimate 2.5 % 97.5 %\n#&gt;   grp mean(1) - mean(0)     4.90  4.37   5.45\n#&gt;   x   mean(dY/dX)           4.46  3.52   5.48\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nWarning: The latest version of fmeffects appear to have introduced breaking changes without notification, and without a note in the NEWS/CHANGELOG. The fmeffects-specific code below is thus not executed.\n\nThe fmeffects package is described as follows:\n\nfmeffects: Model-Agnostic Interpretations with Forward Marginal Effects. Create local, regional, and global explanations for any machine learning model with forward marginal effects. You provide a model and data, and ‘fmeffects’ computes feature effects. The package is based on the theory in: C. A. Scholbeck, G. Casalicchio, C. Molnar, B. Bischl, and C. Heumann (2022)\n\nAs the name says, this package is focused on “forward marginal effects” in the context of machine learning models estimated using the mlr3 or tidymodels frameworks. Since version 0.16.0, marginaleffects also supports these machine learning frameworks, and it covers a superset of the fmeffects functionality. Consider a random forest model trained on the bikes data:\n\nlibrary(\"mlr3verse\")\nlibrary(\"fmeffects\")\ndata(\"bikes\", package = \"fmeffects\")\ntask &lt;- as_task_regr(x = bikes, id = \"bikes\", target = \"count\")\nforest &lt;- lrn(\"regr.ranger\")$train(task)\n\nNow, we use the avg_comparisons() function to compute forward marginal effects:\n\navg_comparisons(forest, variables = list(temp = 1), newdata = bikes)\n#&gt; \n#&gt;  Estimate\n#&gt;      57.8\n#&gt; \n#&gt; Term: temp\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted\n\nThis is equivalent to the key quantity reported by the fmeffects package:\n\nfmeffects::fme(\n    model = forest,\n    data = bikes,\n    target = \"count\",\n    feature = \"temp\",\n    step.size = 1)$ame\n\nAnother interesting feature of fmeffects is the ability treat categorical predictors in an unconventional way: pick a reference level, then compute the average difference between the predicted values for that level, and the predicted values for the observed levels (which may be the same as the reference level).\nIn the bikes example, we can answer the question: how does the expected number of bike rentals increases, on average, if all days were misty? With marginaleffects, we can use a function in the variables argument to specify a custom contrast:\n\nFUN &lt;- function(x) data.frame(lo = x, hi = \"misty\")\n\navg_comparisons(\n  forest,\n  newdata = bikes,\n  variables = list(weather = FUN)\n)\n#&gt; \n#&gt;  Estimate\n#&gt;      -152\n#&gt; \n#&gt; Term: weather\n#&gt; Type:  response \n#&gt; Comparison: custom\n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted\n\nTwo more functionalities deserve to be highlight. First, fmeffects includes functions to explore heterogeneity in marginal effects using recursive partitioning trees. The heterogeneity vignette illustrates how to achieve something similar with marginaleffects.\nSecond, fmeffects also implements a non-linearity measure. At the moment, there is no analogue to this in marginaleffects.\n\nThe effects package was created by John Fox and colleagues.\n\n\nmarginaleffects supports 30+ more model types than effects.\n\neffects focuses on the computation of “adjusted predictions.” The plots it produces are roughly equivalent to the ones produced by the plot_predictions and predictions functions in marginaleffects.\n\neffects does not appear support marginal effects (slopes), marginal means, or contrasts\n\neffects uses Base graphics whereas marginaleffects uses ggplot2\n\n\neffects includes a lot of very powerful options to customize plots. In contrast, marginaleffects produces objects which can be customized by chaining ggplot2 functions. Users can also call plot_predictions(model, draw=FALSE) to create a prediction grid, and then work the raw data directly to create the plot they need\n\neffects offers several options which are not currently available in marginaleffects, including:\n\nPartial residuals plots\nMany types of ways to plot adjusted predictions: package vignette\n\n\nThe modelbased package is developed by the easystats team.\nThis section is incomplete; contributions are welcome.\n\nWrapper around emmeans to compute marginal means and marginal effects.\nPowerful functions to create beautiful plots.\n\nThe ggeffects package is developed by Daniel Lüdecke.\nThis section is incomplete; contributions are welcome.\n\nWrapper around emmeans to compute marginal means.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#emmeans",
    "href": "vignettes/alternative_software.html#emmeans",
    "title": "Alternative Software",
    "section": "",
    "text": "The emmeans package is developed by Russell V. Lenth and colleagues. emmeans is a truly incredible piece of software, and a trailblazer in the R ecosystem. It is an extremely powerful package whose functionality overlaps marginaleffects to a significant degree: marginal means, contrasts, and slopes. Even if the two packages can compute many of the same quantities, emmeans and marginaleffects have pretty different philosophies with respect to user interface and computation.\nAn emmeans analysis typically starts by computing “marginal means” by holding all numeric covariates at their means, and by averaging across a balanced grid of categorical predictors. Then, users can use the contrast() function to estimate the difference between marginal means.\nThe marginaleffects package supplies a predictions function which can replicate most emmeans analyses by computing marginal means. However, the typical analysis is more squarely centered on predicted/fitted values. This is a useful starting point because, in many cases, analysts will find it easy and intuitive to express their scientific queries in terms of changes in predicted values. For example,\n\nHow does the average predicted probability of survival differ between treatment and control group?\nWhat is the difference between the predicted wage of college and high school graduates?\n\nLet’s say we estimate a linear regression model with two continuous regressors and a multiplicative interaction:\n\\[y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\beta_3 x \\cdot z + \\varepsilon\\]\nIn this model, the effect of \\(x\\) on \\(y\\) will depend on the value of covariate \\(z\\). Let’s say the user wants to estimate what happens to the predicted value of \\(y\\) when \\(x\\) increases by 1 unit, when \\(z \\in \\{-1, 0, 1\\}\\). To do this, we use the comparisons() function. The variables argument determines the scientific query of interest, and the newdata argument determines the grid of covariate values on which we want to evaluate the query:\n\nmodel &lt;- lm(y ~ x * z, data)\n\ncomparisons(\n  model,\n  variables = list(x = 1), # what is the effect of 1-unit change in x?\n  newdata = datagrid(z = -1:1) # when z is held at values -1, 0, or 1\n)\n\nAs the vignettes show, marginaleffects can also compute contrasts on marginal means. It can also compute various quantities of interest like raw fitted values, slopes (partial derivatives), and contrasts between marginal means. It also offers a flexible mechanism to run (non-)linear hypothesis tests using the delta method, and it offers fully customizable strategy to compute quantities like odds ratios (or completely arbitrary functions of predicted outcome).\nThus, in my (Vincent’s) biased opinion, the main benefits of marginaleffects over emmeans are:\n\nSupport more model types.\nSimpler, more intuitive, and highly consistent user interface.\nEasier to compute average slopes or unit-level contrasts for whole datasets.\nEasier to compute slopes (aka marginal effects, trends, or partial derivatives) for custom grids and continuous regressors.\nEasier to implement causal inference strategies like the parametric g-formula and regression adjustment in experiments (see vignettes).\nAllows the computation of arbitrary quantities of interest via user-supplied functions and automatic delta method inference.\nCommon plots are easy with the plot_predictions(), plot_comparisons(), and plot_slopes() functions.\n\nTo be fair, many of the marginaleffects advantages listed above come down to subjective preferences over user interface. Readers are thus encouraged to try both packages to see which interface they prefer.\nThe main advantages of emmeans over marginaleffects arise when users are specifically interested in marginal means, where emmeans tends to be much faster and to have a lot of functionality to handle backtransformations. emmeans also has better functionality for effect sizes; notably, the eff_size() function can return effect size estimates that account for uncertainty in both estimated effects and the population SD.\nPlease let me know if you find other features in emmeans so I can add them to this list.\nThe Marginal Means Vignette includes side-by-side comparisons of emmeans and marginaleffects to compute marginal means. The rest of this section compares the syntax for contrasts and marginaleffects.\n\nAs far as I can tell, emmeans does not provide an easy way to compute unit-level contrasts for every row of the dataset used to fit our model. Therefore, the side-by-side syntax shown below will always include newdata=datagrid() to specify that we want to compute only one contrast: at the mean values of the regressors. In day-to-day practice with slopes(), however, this extra argument would not be necessary.\nFit a model:\n\nlibrary(emmeans)\nlibrary(marginaleffects)\n\nmod &lt;- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)\n\nLink scale, pairwise contrasts:\n\nemm &lt;- emmeans(mod, specs = \"cyl\")\ncontrast(emm, method = \"revpairwise\", adjust = \"none\", df = Inf)\n#&gt;  contrast    estimate      SE  df z.ratio p.value\n#&gt;  cyl6 - cyl4   -0.905    1.63 Inf  -0.555  0.5789\n#&gt;  cyl8 - cyl4  -19.542 4367.17 Inf  -0.004  0.9964\n#&gt;  cyl8 - cyl6  -18.637 4367.16 Inf  -0.004  0.9966\n#&gt; \n#&gt; Degrees-of-freedom method: user-specified \n#&gt; Results are given on the log odds ratio (not the response) scale.\n\ncomparisons(mod,\n            type = \"link\",\n            newdata = \"mean\",\n            variables = list(cyl = \"pairwise\"))\n#&gt; \n#&gt;  Contrast Estimate Std. Error        z Pr(&gt;|z|)   S   2.5 %  97.5 %  hp\n#&gt;     6 - 4   -0.905       1.63 -0.55506    0.579 0.8    -4.1    2.29 147\n#&gt;     8 - 4  -19.542    4367.17 -0.00447    0.996 0.0 -8579.0 8539.95 147\n#&gt;     8 - 6  -18.637    4367.17 -0.00427    0.997 0.0 -8578.1 8540.85 147\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  link \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, cyl, vs\n\nResponse scale, reference groups:\n\nemm &lt;- emmeans(mod, specs = \"cyl\", regrid = \"response\")\ncontrast(emm, method = \"trt.vs.ctrl1\", adjust = \"none\", df = Inf, ratios = FALSE)\n#&gt;  contrast    estimate    SE  df z.ratio p.value\n#&gt;  cyl6 - cyl4   -0.222 0.394 Inf  -0.564  0.5727\n#&gt;  cyl8 - cyl4   -0.595 0.511 Inf  -1.163  0.2447\n#&gt; \n#&gt; Degrees-of-freedom method: user-specified\n\ncomparisons(mod, newdata = \"mean\")\n#&gt; \n#&gt;  Term Contrast  Estimate Std. Error         z Pr(&gt;|z|)   S     2.5 %   97.5 %  hp cyl\n#&gt;   cyl    6 - 4 -2.22e-01   3.94e-01 -0.564103    0.573 0.8 -9.94e-01 5.50e-01 147   8\n#&gt;   cyl    8 - 4 -5.95e-01   5.11e-01 -1.163332    0.245 2.0 -1.60e+00 4.07e-01 147   8\n#&gt;   hp     +1    -1.53e-10   6.69e-07 -0.000229    1.000 0.0 -1.31e-06 1.31e-06 147   8\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, hp, cyl, vs\n\n\nHere is a slightly more complicated example with contrasts estimated by subgroup in a lme4 mixed effects model. First we estimate a model and compute pairwise contrasts by subgroup using emmeans:\n\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(emmeans)\n\ndat &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/VerbAgg.csv\")\ndat$woman &lt;- as.numeric(dat$Gender == \"F\")\n\nmod &lt;- glmer(\n    woman ~ btype * resp + situ + (1 + Anger | item),\n    family = binomial,\n    data = dat)\n\nemmeans(mod, specs = \"btype\", by = \"resp\") |&gt;\n    contrast(method = \"revpairwise\", adjust = \"none\")\n#&gt; resp = no:\n#&gt;  contrast      estimate     SE  df z.ratio p.value\n#&gt;  scold - curse  -0.0152 0.1097 Inf  -0.139  0.8898\n#&gt;  shout - curse  -0.2533 0.1022 Inf  -2.479  0.0132\n#&gt;  shout - scold  -0.2381 0.0886 Inf  -2.686  0.0072\n#&gt; \n#&gt; resp = perhaps:\n#&gt;  contrast      estimate     SE  df z.ratio p.value\n#&gt;  scold - curse  -0.2393 0.1178 Inf  -2.031  0.0422\n#&gt;  shout - curse  -0.0834 0.1330 Inf  -0.627  0.5309\n#&gt;  shout - scold   0.1559 0.1358 Inf   1.148  0.2510\n#&gt; \n#&gt; resp = yes:\n#&gt;  contrast      estimate     SE  df z.ratio p.value\n#&gt;  scold - curse   0.0391 0.1292 Inf   0.302  0.7624\n#&gt;  shout - curse   0.5802 0.1784 Inf   3.252  0.0011\n#&gt;  shout - scold   0.5411 0.1888 Inf   2.866  0.0042\n#&gt; \n#&gt; Results are averaged over the levels of: situ \n#&gt; Results are given on the log odds ratio (not the response) scale.\n\nWhat did emmeans do to obtain these results? Roughly speaking:\n\nCreate a prediction grid with one cell for each combination of categorical predictors in the model, and all numeric variables held at their means.\nMake adjusted predictions in each cell of the prediction grid.\nTake the average of those predictions (marginal means) for each combination of btype (focal variable) and resp (group by variable).\nCompute pairwise differences (contrasts) in marginal means across different levels of the focal variable btype.\n\nIn short, emmeans computes pairwise contrasts between marginal means, which are themselves averages of adjusted predictions. This is different from the default types of contrasts produced by comparisons(), which reports contrasts between adjusted predictions, without averaging across a pre-specified grid of predictors. What does comparisons() do instead?\nLet newdata be a data frame supplied by the user (or the original data frame used to fit the model), then:\n\nCreate a new data frame called newdata2, which is identical to newdata except that the focal variable is incremented by one level.\nCompute contrasts as the difference between adjusted predictions made on the two datasets:\n\npredict(model, newdata = newdata2) - predict(model, newdata = newdata)\n\n\n\nAlthough it is not idiomatic, we can use still use comparisons() to emulate the emmeans results. First, we create a prediction grid with one cell for each combination of categorical predictor in the model:\n\nnd &lt;- datagrid(\n    model = mod,\n    resp = dat$resp,\n    situ = dat$situ,\n    btype = dat$btype)\nnrow(nd)\n#&gt; [1] 18\n\nThis grid has 18 rows, one for each combination of levels for the resp (3), situ (2), and btype (3) variables (3 * 2 * 3 = 18).\nThen we compute pairwise contrasts over this grid:\n\ncmp &lt;- comparisons(mod,\n    variables = list(\"btype\" = \"pairwise\"),\n    newdata = nd,\n    type = \"link\")\nnrow(cmp)\n#&gt; [1] 54\n\nThere are 3 pairwise contrasts, corresponding to the 3 pairwise comparisons possible between the 3 levels of the focal variable btype: scold-curse, shout-scold, shout-curse. The comparisons() function estimates those 3 contrasts for each row of newdata, so we get \\(18 \\times 3 = 54\\) rows.\nFinally, if we wanted contrasts averaged over each subgroup of the resp variable, we can use the avg_comparisons() function with the by argument:\n\navg_comparisons(mod,\n    by = \"resp\",\n    variables = list(\"btype\" = \"pairwise\"),\n    newdata = nd,\n    type = \"link\")\n#&gt; \n#&gt;   Term                  Contrast    resp Estimate Std. Error      z Pr(&gt;|z|)   S  2.5 %   97.5 %\n#&gt;  btype mean(scold) - mean(curse) no       -0.0152     0.1097 -0.139  0.88976 0.2 -0.230  0.19971\n#&gt;  btype mean(scold) - mean(curse) perhaps  -0.2393     0.1178 -2.031  0.04221 4.6 -0.470 -0.00842\n#&gt;  btype mean(scold) - mean(curse) yes       0.0391     0.1292  0.302  0.76239 0.4 -0.214  0.29234\n#&gt;  btype mean(shout) - mean(curse) no       -0.2533     0.1022 -2.479  0.01319 6.2 -0.454 -0.05301\n#&gt;  btype mean(shout) - mean(curse) perhaps  -0.0834     0.1330 -0.627  0.53091 0.9 -0.344  0.17738\n#&gt;  btype mean(shout) - mean(curse) yes       0.5802     0.1784  3.252  0.00115 9.8  0.230  0.92987\n#&gt;  btype mean(shout) - mean(scold) no       -0.2381     0.0886 -2.686  0.00723 7.1 -0.412 -0.06436\n#&gt;  btype mean(shout) - mean(scold) perhaps   0.1559     0.1358  1.148  0.25103 2.0 -0.110  0.42215\n#&gt;  btype mean(shout) - mean(scold) yes       0.5411     0.1888  2.866  0.00416 7.9  0.171  0.91116\n#&gt; \n#&gt; Type:  link \n#&gt; Columns: term, contrast, resp, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThese results are identical to those produced by emmeans (except for \\(t\\) vs. \\(z\\)).\n\nAs far as I can tell, emmeans::emtrends makes it easier to compute marginal effects for a few user-specified values than for large grids or for the full original dataset.\nResponse scale, user-specified values:\n\nmod &lt;- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)\n\nemtrends(mod, ~hp, \"hp\", regrid = \"response\", at = list(cyl = 4))\n#&gt;   hp hp.trend    SE  df asymp.LCL asymp.UCL\n#&gt;  147 -0.00786 0.011 Inf   -0.0294    0.0137\n#&gt; \n#&gt; Confidence level used: 0.95\n\nslopes(mod, newdata = datagrid(cyl = 4))\n#&gt; \n#&gt;  Contrast cyl Estimate Std. Error      z Pr(&gt;|z|)   S   2.5 % 97.5 %\n#&gt;     6 - 4   4 -0.22219      0.394 -0.564    0.573 0.8 -0.9942 0.5498\n#&gt;     8 - 4   4 -0.59469      0.511 -1.163    0.245 2.0 -1.5966 0.4072\n#&gt;     dY/dX   4 -0.00785      0.011 -0.713    0.476 1.1 -0.0294 0.0137\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  response \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cyl, predicted_lo, predicted_hi, predicted, hp, vs\n\nLink scale, user-specified values:\n\nemtrends(mod, ~hp, \"hp\", at = list(cyl = 4))\n#&gt;   hp hp.trend     SE  df asymp.LCL asymp.UCL\n#&gt;  147  -0.0326 0.0339 Inf    -0.099    0.0338\n#&gt; \n#&gt; Confidence level used: 0.95\n\nslopes(mod, type = \"link\", newdata = datagrid(cyl = 4))\n#&gt; \n#&gt;  Contrast cyl Estimate Std. Error        z Pr(&gt;|z|)   S     2.5 %   97.5 %\n#&gt;     6 - 4   4  -0.9049   1.63e+00 -0.55506    0.579 0.8    -4.100 2.29e+00\n#&gt;     8 - 4   4 -19.5418   4.37e+03 -0.00447    0.996 0.0 -8579.030 8.54e+03\n#&gt;     dY/dX   4  -0.0326   3.39e-02 -0.96144    0.336 1.6    -0.099 3.38e-02\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  link \n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, cyl, predicted_lo, predicted_hi, predicted, hp, vs\n\n\nHere are a few more emmeans vs. marginaleffects comparisons:\n\n## Example of examining a continuous x categorical interaction using emmeans and marginaleffects\n## Authors: Cameron Patrick and Vincent Arel-Bundock\n\nlibrary(tidyverse)\nlibrary(emmeans)\nlibrary(marginaleffects)\n\n## use the mtcars data, set up am as a factor\ndata(mtcars)\nmc &lt;- mtcars |&gt; mutate(am = factor(am))\n\n## fit a linear model to mpg with wt x am interaction\nm &lt;- lm(mpg ~ wt*am, data = mc)\nsummary(m)\n\n## 1. means for each level of am at mean wt.\nemmeans(m, \"am\")\npredictions(m, newdata = datagrid(am = 0:1))\n\n## 2. means for each level of am at wt = 2.5, 3, 3.5.\nemmeans(m, c(\"am\", \"wt\"), at = list(wt = c(2.5, 3, 3.5)))\npredictions(m, newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5))\n\n## 3. means for wt = 2.5, 3, 3.5, averaged over levels of am (implicitly!).\nemmeans(m, \"wt\", at = list(wt = c(2.5, 3, 3.5)))\n\n## same thing, but the averaging is more explicit, using the `by` argument\npredictions(\n  m,\n  newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5)),\n  by = \"wt\")\n\n## 4. graphical version of 2.\nemmip(m, am ~ wt, at = list(wt = c(2.5, 3, 3.5)), CIs = TRUE)\nplot_predictions(m, condition = c(\"wt\", \"am\"))\n\n## 5. compare levels of am at specific values of wt.\n## this is a bit ugly because the emmeans defaults for pairs() are silly.\n## infer = TRUE: enable confidence intervals.\n## adjust = \"none\": begone, Tukey.\n## reverse = TRUE: contrasts as (later level) - (earlier level)\npairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),\n      infer = TRUE, adjust = \"none\", reverse = TRUE)\n\ncomparisons(\n  m,\n  variables = \"am\",\n  newdata = datagrid(wt = c(2.5, 3, 3.5)))\n\n## 6. plot of pairswise comparisons\nplot(pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),\n      infer = TRUE, adjust = \"none\", reverse = TRUE))\n\n## Since `wt` is numeric, the default is to plot it as a continuous variable on\n## the x-axis.  But not that this is the **exact same info** as in the emmeans plot.\nplot_comparisons(m, variables = \"am\", condition = \"wt\")\n\n## You of course customize everything, set draw=FALSE, and feed the raw data to feed to ggplot2\np &lt;- plot_comparisons(\n  m,\n  variables = \"am\",\n  condition = list(wt = c(2.5, 3, 3.5)),\n  draw = FALSE)\n\nggplot(p, aes(y = wt, x = comparison, xmin = conf.low, xmax = conf.high)) +\n  geom_pointrange()\n\n## 7. slope of wt for each level of am\nemtrends(m, \"am\", \"wt\")\nslopes(m, newdata = datagrid(am = 0:1))",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#margins-and-prediction",
    "href": "vignettes/alternative_software.html#margins-and-prediction",
    "title": "Alternative Software",
    "section": "",
    "text": "The margins and prediction packages for R were designed by Thomas Leeper to emulate the behavior of the margins command from Stata. These packages are trailblazers and strongly influenced the development of marginaleffects. The main benefits of marginaleffects over these packages are:\n\nSupport more model types\nFaster\nMemory efficient\nPlots using ggplot2 instead of Base R\nMore extensive test suite\nActive development\n\nThe syntax of the two packages is very similar.\n\n\nlibrary(margins)\nlibrary(marginaleffects)\n\nmod &lt;- lm(mpg ~ cyl + hp + wt, data = mtcars)\n\nmar &lt;- margins(mod)\nsummary(mar)\n#&gt;  factor     AME     SE       z      p   lower   upper\n#&gt;     cyl -0.9416 0.5509 -1.7092 0.0874 -2.0214  0.1382\n#&gt;      hp -0.0180 0.0119 -1.5188 0.1288 -0.0413  0.0052\n#&gt;      wt -3.1670 0.7406 -4.2764 0.0000 -4.6185 -1.7155\n\nmfx &lt;- slopes(mod)\n\n\nMarginal effects in a user-specified data frame:\n\nhead(data.frame(mar))\n#&gt;    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt X_weights X_at_number\n#&gt; 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 22.82043 0.6876212 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 22.01285 0.6056817 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.96040 0.7349593 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.93608 0.5800910 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.16780 0.8322986 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n#&gt; 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 20.25036 0.6638322 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484513        NA           1\n\nhead(mfx)\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt;    -0.942      0.551 -1.71   0.0873 3.5 -2.02  0.138\n#&gt;    -0.942      0.552 -1.71   0.0879 3.5 -2.02  0.140\n#&gt; \n#&gt; Term: cyl\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, mpg, cyl, hp, wt\nnd &lt;- data.frame(cyl = 4, hp = 110, wt = 3)\n\n\n\nmar &lt;- margins(mod, data = data.frame(prediction::mean_or_mode(mtcars)), unit_ses = TRUE)\ndata.frame(mar)\n#&gt;        mpg    cyl     disp       hp     drat      wt     qsec     vs      am   gear   carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt SE_dydx_cyl SE_dydx_hp SE_dydx_wt X_weights X_at_number\n#&gt; 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 20.09062 0.4439832 -0.9416168 -0.0180381 -3.166973    0.3035082 0.0001410453   0.5484409   0.5509157 0.01187625  0.7405679        NA           1\n\nslopes(mod, newdata = \"mean\")\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;   cyl   -0.942     0.5503 -1.71   0.0871  3.5 -2.0202  0.13695\n#&gt;   hp    -0.018     0.0119 -1.52   0.1288  3.0 -0.0413  0.00524\n#&gt;   wt    -3.167     0.7407 -4.28   &lt;0.001 15.7 -4.6187 -1.71521\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, cyl, hp, wt, mpg\n\n\nThe at argument of the margins package emulates Stata by fixing the values of some variables at user-specified values, and by replicating the full dataset several times for each combination of the supplied values (see the Stata section below). For example, if the dataset includes 32 rows and the user calls at=list(cyl=c(4, 6)), margins will compute 64 unit-level marginal effects estimates:\n\ndat &lt;- mtcars\ndat$cyl &lt;- factor(dat$cyl)\nmod &lt;- lm(mpg ~ cyl * hp + wt, data = mtcars)\n\nmar &lt;- margins(mod, at = list(cyl = c(4, 6, 8)))\nsummary(mar)\n#&gt;  factor    cyl     AME     SE       z      p   lower   upper\n#&gt;     cyl 4.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139\n#&gt;     cyl 6.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139\n#&gt;     cyl 8.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139\n#&gt;      hp 4.0000 -0.0878 0.0267 -3.2937 0.0010 -0.1400 -0.0355\n#&gt;      hp 6.0000 -0.0499 0.0154 -3.2397 0.0012 -0.0800 -0.0197\n#&gt;      hp 8.0000 -0.0120 0.0108 -1.1065 0.2685 -0.0332  0.0092\n#&gt;      wt 4.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236\n#&gt;      wt 6.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236\n#&gt;      wt 8.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236\n\navg_slopes(\n    mod,\n    by = \"cyl\",\n    newdata = datagrid(cyl = c(4, 6, 8)), grid_type = \"counterfactual\")\n#&gt; \n#&gt;  Term cyl Estimate Std. Error       z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;   cyl   4   0.0381     0.5998  0.0636  0.94931  0.1 -1.1375  1.21381\n#&gt;   cyl   6   0.0381     0.5999  0.0636  0.94931  0.1 -1.1376  1.21390\n#&gt;   cyl   8   0.0381     0.6000  0.0636  0.94932  0.1 -1.1378  1.21412\n#&gt;   hp    4  -0.0878     0.0267 -3.2935  &lt; 0.001 10.0 -0.1400 -0.03554\n#&gt;   hp    6  -0.0499     0.0154 -3.2401  0.00119  9.7 -0.0800 -0.01970\n#&gt;   hp    8  -0.0120     0.0108 -1.1065  0.26851  1.9 -0.0332  0.00923\n#&gt;   wt    4  -3.1198     0.6614 -4.7173  &lt; 0.001 18.7 -4.4161 -1.82358\n#&gt;   wt    6  -3.1198     0.6612 -4.7182  &lt; 0.001 18.7 -4.4158 -1.82384\n#&gt;   wt    8  -3.1198     0.6614 -4.7173  &lt; 0.001 18.7 -4.4161 -1.82358\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: rowid, term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nThe syntax to compute adjusted predictions using the predictions package or marginaleffects is very similar:\n\nprediction::prediction(mod) |&gt; head()\n#&gt;    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted\n#&gt; 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 21.90488 0.6927034\n#&gt; 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 21.10933 0.6266557\n#&gt; 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.64753 0.6652076\n#&gt; 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.04859 0.6041400\n#&gt; 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.25445 0.7436172\n#&gt; 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 19.53360 0.6436862\n\nmarginaleffects::predictions(mod) |&gt; head()\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;      21.9      0.693 31.6   &lt;0.001 726.6  20.5   23.3\n#&gt;      21.1      0.627 33.7   &lt;0.001 823.9  19.9   22.3\n#&gt;      25.6      0.665 38.6   &lt;0.001   Inf  24.3   27.0\n#&gt;      20.0      0.604 33.2   &lt;0.001 799.8  18.9   21.2\n#&gt;      17.3      0.744 23.2   &lt;0.001 393.2  15.8   18.7\n#&gt;      19.5      0.644 30.3   &lt;0.001 669.5  18.3   20.8\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, hp, wt",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#stata",
    "href": "vignettes/alternative_software.html#stata",
    "title": "Alternative Software",
    "section": "",
    "text": "Stata is a good but expensive software package for statistical analysis. It is published by StataCorp LLC. This section compares Stata’s margins command to marginaleffects.\nThe results produced by marginaleffects are extensively tested against Stata. See the test suite for a list of the dozens of models where we compared estimates and standard errors.\n\nMarginal effects are unit-level quantities. To compute “average marginal effects”, we first calculate marginal effects for each observation in a dataset. Then, we take the mean of those unit-level marginal effects.\n\nBoth Stata’s margins command and the slopes function can calculate average marginal effects (AMEs). Here is an example showing how to estimate AMEs in Stata:\nquietly reg mpg cyl hp wt\nmargins, dydx(*)\n\nAverage marginal effects                        Number of obs     =         32\nModel VCE    : OLS\n \nExpression   : Linear prediction, predict()\ndy/dx w.r.t. : cyl hp wt\n \n------------------------------------------------------------------------------\n    |            Delta-method\n    |      dy/dx   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n------------------------------------------------------------------------------\ncyl |  -.9416168   .5509164    -1.71   0.098    -2.070118    .1868842\n hp |  -.0180381   .0118762    -1.52   0.140    -.0423655    .0062893\n wt |  -3.166973   .7405759    -4.28   0.000    -4.683974   -1.649972\n------------------------------------------------------------------------------\n\nThe same results can be obtained with slopes() and summary() like this:\n\nlibrary(\"marginaleffects\")\nmod &lt;- lm(mpg ~ cyl + hp + wt, data = mtcars)\navg_slopes(mod)\n#&gt; \n#&gt;  Term Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %   97.5 %\n#&gt;   cyl   -0.942     0.5512 -1.71   0.0876  3.5 -2.0220  0.13879\n#&gt;   hp    -0.018     0.0119 -1.52   0.1288  3.0 -0.0413  0.00524\n#&gt;   wt    -3.167     0.7406 -4.28   &lt;0.001 15.7 -4.6184 -1.71552\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nNote that Stata reports t statistics while marginaleffects reports Z. This produces slightly different p-values because this model has low degrees of freedom: mtcars only has 32 rows\n\nA “counterfactual marginal effect” is a special quantity obtained by replicating a dataset while fixing some regressor to user-defined values.\nConcretely, Stata computes counterfactual marginal effects in 3 steps:\n\nDuplicate the whole dataset 3 times and sets the values of cyl to the three specified values in each of those subsets.\nCalculate marginal effects for each observation in that large grid.\nTake the average of marginal effects for each value of the variable of interest.\n\n\nWith the at argument, Stata’s margins command estimates average counterfactual marginal effects. Here is an example:\nquietly reg mpg i.cyl##c.hp wt\nmargins, dydx(hp) at(cyl = (4 6 8))\n\nAverage marginal effects                        Number of obs     =         32\nModel VCE    : OLS\n\nExpression   : Linear prediction, predict()\ndy/dx w.r.t. : hp\n\n1._at        : cyl             =           4\n\n2._at        : cyl             =           6\n\n3._at        : cyl             =           8\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |      dy/dx   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\nhp           |\n         _at |\n          1  |   -.099466   .0348665    -2.85   0.009    -.1712749   -.0276571\n          2  |  -.0213768    .038822    -0.55   0.587    -.1013323    .0585787\n          3  |   -.013441   .0125138    -1.07   0.293    -.0392137    .0123317\n------------------------------------------------------------------------------\n\n\nYou can estimate average counterfactual marginal effects with slopes() by using the datagrid() to create a counterfactual dataset in which the full original dataset is replicated for each potential value of the cyl variable. Then, we tell the by argument to average within groups:\n\nmod &lt;- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)\n\navg_slopes(\n    mod,\n    variables = \"hp\",\n    by = \"cyl\",\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\"))\n#&gt; \n#&gt;  Term cyl Estimate Std. Error      z Pr(&gt;|z|)   S   2.5 %  97.5 %\n#&gt;    hp   4  -0.0995     0.0349 -2.853  0.00433 7.9 -0.1678 -0.0311\n#&gt;    hp   6  -0.0214     0.0388 -0.551  0.58189 0.8 -0.0975  0.0547\n#&gt;    hp   8  -0.0134     0.0125 -1.074  0.28278 1.8 -0.0380  0.0111\n#&gt; \n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThis is equivalent to taking the group-wise mean of observation-level marginal effects (without the by argument):\n\nmfx &lt;- slopes(\n    mod,\n    variables = \"hp\",\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\"))\naggregate(estimate ~ term + cyl, data = mfx, FUN = mean)\n#&gt;   term cyl    estimate\n#&gt; 1   hp   4 -0.09946598\n#&gt; 2   hp   6 -0.02137679\n#&gt; 3   hp   8 -0.01344103\n\n\nNote that following Stata, the standard errors for group-averaged marginal effects are computed by taking the “Jacobian at the mean:”\n\nJ &lt;- attr(mfx, \"jacobian\")\nJ_mean &lt;- aggregate(J, by = list(mfx$cyl), FUN = mean)\nJ_mean &lt;- as.matrix(J_mean[, 2:ncol(J_mean)])\nsqrt(diag(J_mean %*% vcov(mod) %*% t(J_mean)))\n#&gt; [1] 0.03486634 0.03882234 0.01251371\n\n\n\nJust like Stata’s margins command computes average counterfactual marginal effects, it can also estimate average counterfactual adjusted predictions.\nHere is an example:\nquietly reg mpg i.cyl##c.hp wt\nmargins, at(cyl = (4 6 8))\n\nPredictive margins                              Number of obs     =         32\nModel VCE    : OLS\n\nExpression   : Linear prediction, predict()\n\n1._at        : cyl             =           4\n\n2._at        : cyl             =           6\n\n3._at        : cyl             =           8\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |     Margin   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n         _at |\n          1  |   17.44233   2.372914     7.35   0.000     12.55522    22.32944\n          2  |    18.9149   1.291483    14.65   0.000     16.25505    21.57476\n          3  |   18.33318   1.123874    16.31   0.000     16.01852    20.64785\n------------------------------------------------------------------------------\nAgain, this is what Stata does in the background:\n\nIt duplicates the whole dataset 3 times and sets the values of cyl to the three specified values in each of those subsets.\nIt calculates predictions for that large grid.\nIt takes the average prediction for each value of cyl.\n\nIn other words, average counterfactual adjusted predictions as implemented by Stata are a hybrid between predictions at the observed values (the default in marginaleffects::predictions) and predictions at representative values.\n\nYou can estimate average counterfactual adjusted predictions with predictions() by, first, setting the grid_type argument of datagrid() to \"counterfactual\" and, second, by averaging the predictions using the by argument of summary(), or a manual function like dplyr::summarise().\n\nmod &lt;- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)\n\npredictions(\n    mod,\n    by = \"cyl\",\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\"))\n#&gt; \n#&gt;  cyl Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;    4     17.4       2.37  7.35   &lt;0.001  42.2  12.8   22.1\n#&gt;    6     18.9       1.29 14.65   &lt;0.001 158.9  16.4   21.4\n#&gt;    8     18.3       1.12 16.31   &lt;0.001 196.3  16.1   20.5\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\npredictions(\n    mod,\n    newdata = datagrid(cyl = c(4, 6, 8), grid_type = \"counterfactual\")) |&gt;\n    group_by(cyl) |&gt;\n    summarize(AAP = mean(estimate))\n#&gt; # A tibble: 3 × 2\n#&gt;   cyl     AAP\n#&gt;   &lt;fct&gt; &lt;dbl&gt;\n#&gt; 1 4      17.4\n#&gt; 2 6      18.9\n#&gt; 3 8      18.3",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#brmsmargins",
    "href": "vignettes/alternative_software.html#brmsmargins",
    "title": "Alternative Software",
    "section": "",
    "text": "The brmsmargins package is developed by Joshua Wiley:\n\nThis package has functions to calculate marginal effects from brms models ( http://paul-buerkner.github.io/brms/ ). A central motivator is to calculate average marginal effects (AMEs) for continuous and discrete predictors in fixed effects only and mixed effects regression models including location scale models.\n\nThe main advantage of brmsmargins over marginaleffects is its ability to compute “Marginal Coefficients” following the method described in Hedeker et al (2012).\nThe main advantages of marginaleffects over brmsmargins are:\n\nSupport for 60+ model types, rather than just the brms package.\nSimpler user interface (subjective).\nAt the time of writing (2022-05-25) brmsmargins did not support certain brms models such as those with multivariate or multinomial outcomes. It also did not support custom outcome transformations.\n\nThe rest of this section presents side-by-side replications of some of the analyses from the brmsmargins vignettes in order to show highlight parallels and differences in syntax.\n\n\nEstimate a logistic regression model with brms:\n\nlibrary(brms)\nlibrary(brmsmargins)\nlibrary(marginaleffects)\nlibrary(data.table)\nlibrary(withr)\nsetDTthreads(5)\nh &lt;- 1e-4\n\nvoid &lt;- capture.output(\n    bayes.logistic &lt;- brm(\n      vs ~ am + mpg, data = mtcars,\n      family = \"bernoulli\", seed = 1234,\n      silent = 2, refresh = 0,\n      backend = \"cmdstanr\",\n      chains = 4L, cores = 4L)\n)\n\nCompute AMEs manually:\n\nd1 &lt;- d2 &lt;- mtcars\nd2$mpg &lt;- d2$mpg + h\np1 &lt;- posterior_epred(bayes.logistic, newdata = d1)\np2 &lt;- posterior_epred(bayes.logistic, newdata = d2)\nm &lt;- (p2 - p1) / h\nquantile(rowMeans(m), c(.5, .025, .975))\n#&gt;        50%       2.5%      97.5% \n#&gt; 0.06981152 0.05372040 0.09159040\n\nCompute AMEs with brmsmargins:\n\nbm &lt;- brmsmargins(\n  bayes.logistic,\n  add = data.frame(mpg = c(0, 0 + h)),\n  contrasts = cbind(\"AME MPG\" = c(-1 / h, 1 / h)),\n  CI = 0.95,\n  CIType = \"ETI\")\ndata.frame(bm$ContrastSummary)\n#&gt;            M        Mdn        LL        UL PercentROPE PercentMID   CI CIType ROPE  MID   Label\n#&gt; 1 0.07098514 0.06981152 0.0537204 0.0915904          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME MPG\n\nCompute AMEs using marginaleffects:\n\navg_slopes(bayes.logistic) \n#&gt; \n#&gt;  Term          Contrast Estimate   2.5 %  97.5 %\n#&gt;   am  mean(1) - mean(0)  -0.2672 -0.4219 -0.0682\n#&gt;   mpg mean(dY/dX)         0.0698  0.0537  0.0916\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\nThe mpg element of the Effect column from marginaleffects matches the the M column of the output from brmsmargins.\n\nEstimate a mixed effects logistic regression model with brms:\n\nd &lt;- withr::with_seed(\n  seed = 12345, code = {\n    nGroups &lt;- 100\n    nObs &lt;- 20\n    theta.location &lt;- matrix(rnorm(nGroups * 2), nrow = nGroups, ncol = 2)\n    theta.location[, 1] &lt;- theta.location[, 1] - mean(theta.location[, 1])\n    theta.location[, 2] &lt;- theta.location[, 2] - mean(theta.location[, 2])\n    theta.location[, 1] &lt;- theta.location[, 1] / sd(theta.location[, 1])\n    theta.location[, 2] &lt;- theta.location[, 2] / sd(theta.location[, 2])\n    theta.location &lt;- theta.location %*% chol(matrix(c(1.5, -.25, -.25, .5^2), 2))\n    theta.location[, 1] &lt;- theta.location[, 1] - 2.5\n    theta.location[, 2] &lt;- theta.location[, 2] + 1\n    d &lt;- data.table(\n      x = rep(rep(0:1, each = nObs / 2), times = nGroups))\n    d[, ID := rep(seq_len(nGroups), each = nObs)]\n\n    for (i in seq_len(nGroups)) {\n      d[ID == i, y := rbinom(\n        n = nObs,\n        size = 1,\n        prob = plogis(theta.location[i, 1] + theta.location[i, 2] * x))\n        ]\n    }\n    copy(d)\n  })\n\nvoid &lt;- capture.output(\n    mlogit &lt;- brms::brm(\n      y ~ 1 + x + (1 + x | ID), family = \"bernoulli\",\n      data = d, seed = 1234,\n      backend = \"cmdstanr\",\n      silent = 2, refresh = 0,\n      chains = 4L, cores = 4L)\n)\n\n\n\nbm &lt;- brmsmargins(\n  mlogit,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  effects = \"includeRE\",\n  CI = .95,\n  CIType = \"ETI\")\ndata.frame(bm$ContrastSummary)\n#&gt;           M       Mdn        LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 0.1118135 0.1120303 0.0814249 0.1425242          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(mlogit)\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;     0.111 0.081  0.141\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nbm &lt;- brmsmargins(\n  mlogit,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  effects = \"fixedonly\",\n  CI = .95,\n  CIType = \"ETI\")\ndata.frame(bm$ContrastSummary)\n#&gt;           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 0.1040304 0.1037629 0.06163523 0.1480365          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(mlogit, re_formula = NA)\n#&gt; \n#&gt;  Estimate  2.5 % 97.5 %\n#&gt;     0.101 0.0607  0.142\n#&gt; \n#&gt; Term: x\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nEstimate a fixed effects location scale model with brms:\n\nd &lt;- withr::with_seed(\n  seed = 12345, code = {\n    nObs &lt;- 1000L\n    d &lt;- data.table(\n      grp = rep(0:1, each = nObs / 2L),\n      x = rnorm(nObs, mean = 0, sd = 0.25))\n    d[, y := rnorm(nObs,\n                   mean = x + grp,\n                   sd = exp(1 + x + grp))]\n    copy(d)\n  })\n\nvoid &lt;- capture.output(\n    ls.fe &lt;- brm(bf(\n      y ~ 1 + x + grp,\n      sigma ~ 1 + x + grp),\n      family = \"gaussian\",\n      data = d, seed = 1234,\n      silent = 2, refresh = 0,\n      backend = \"cmdstanr\",\n      chains = 4L, cores = 4L)\n)\n\n\n\nbm &lt;- brmsmargins(\n  ls.fe,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  CI = 0.95, CIType = \"ETI\",\n  effects = \"fixedonly\")\ndata.frame(bm$ContrastSummary)\n#&gt;          M     Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 1.622142 1.61919 0.765971 2.504324          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(ls.fe, re_formula = NA)\n#&gt; \n#&gt;  Term          Contrast Estimate 2.5 % 97.5 %\n#&gt;   grp mean(1) - mean(0)     1.01 0.366   1.68\n#&gt;   x   mean(dY/dX)           1.62 0.766   2.50\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\nCompute the contrast between adjusted predictions on the sigma parameter, when grp=0 and grp=1:\n\nbm &lt;- brmsmargins(\n  ls.fe,\n  at = data.frame(grp = c(0, 1)),\n  contrasts = cbind(\"AME grp\" = c(-1, 1)),\n  CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",\n  effects = \"fixedonly\")\ndata.frame(bm$ContrastSummary)\n#&gt;          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID   Label\n#&gt; 1 4.907779 4.903996 4.374426 5.449402          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME grp\n\nIn marginaleffects we use the comparisons() function and the variables argument:\n\navg_comparisons(\n  ls.fe,\n  variables = list(grp = 0:1),\n  dpar = \"sigma\")\n#&gt; \n#&gt;  Estimate 2.5 % 97.5 %\n#&gt;       4.9  4.37   5.45\n#&gt; \n#&gt; Term: grp\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx\n\n\n\nbm &lt;- brmsmargins(\n  ls.fe,\n  add = data.frame(x = c(0, h)),\n  contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),\n  CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",\n  effects = \"fixedonly\")\ndata.frame(bm$ContrastSummary)\n#&gt;          M      Mdn      LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label\n#&gt; 1 4.474551 4.464982 3.52317 5.484218          NA         NA 0.95    ETI &lt;NA&gt; &lt;NA&gt; AME x\n\navg_slopes(ls.fe, dpar = \"sigma\", re_formula = NA)\n#&gt; \n#&gt;  Term          Contrast Estimate 2.5 % 97.5 %\n#&gt;   grp mean(1) - mean(0)     4.90  4.37   5.45\n#&gt;   x   mean(dY/dX)           4.46  3.52   5.48\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#fmeffects",
    "href": "vignettes/alternative_software.html#fmeffects",
    "title": "Alternative Software",
    "section": "",
    "text": "Warning: The latest version of fmeffects appear to have introduced breaking changes without notification, and without a note in the NEWS/CHANGELOG. The fmeffects-specific code below is thus not executed.\n\nThe fmeffects package is described as follows:\n\nfmeffects: Model-Agnostic Interpretations with Forward Marginal Effects. Create local, regional, and global explanations for any machine learning model with forward marginal effects. You provide a model and data, and ‘fmeffects’ computes feature effects. The package is based on the theory in: C. A. Scholbeck, G. Casalicchio, C. Molnar, B. Bischl, and C. Heumann (2022)\n\nAs the name says, this package is focused on “forward marginal effects” in the context of machine learning models estimated using the mlr3 or tidymodels frameworks. Since version 0.16.0, marginaleffects also supports these machine learning frameworks, and it covers a superset of the fmeffects functionality. Consider a random forest model trained on the bikes data:\n\nlibrary(\"mlr3verse\")\nlibrary(\"fmeffects\")\ndata(\"bikes\", package = \"fmeffects\")\ntask &lt;- as_task_regr(x = bikes, id = \"bikes\", target = \"count\")\nforest &lt;- lrn(\"regr.ranger\")$train(task)\n\nNow, we use the avg_comparisons() function to compute forward marginal effects:\n\navg_comparisons(forest, variables = list(temp = 1), newdata = bikes)\n#&gt; \n#&gt;  Estimate\n#&gt;      57.8\n#&gt; \n#&gt; Term: temp\n#&gt; Type:  response \n#&gt; Comparison: mean(+1)\n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted\n\nThis is equivalent to the key quantity reported by the fmeffects package:\n\nfmeffects::fme(\n    model = forest,\n    data = bikes,\n    target = \"count\",\n    feature = \"temp\",\n    step.size = 1)$ame\n\nAnother interesting feature of fmeffects is the ability treat categorical predictors in an unconventional way: pick a reference level, then compute the average difference between the predicted values for that level, and the predicted values for the observed levels (which may be the same as the reference level).\nIn the bikes example, we can answer the question: how does the expected number of bike rentals increases, on average, if all days were misty? With marginaleffects, we can use a function in the variables argument to specify a custom contrast:\n\nFUN &lt;- function(x) data.frame(lo = x, hi = \"misty\")\n\navg_comparisons(\n  forest,\n  newdata = bikes,\n  variables = list(weather = FUN)\n)\n#&gt; \n#&gt;  Estimate\n#&gt;      -152\n#&gt; \n#&gt; Term: weather\n#&gt; Type:  response \n#&gt; Comparison: custom\n#&gt; Columns: term, contrast, estimate, predicted_lo, predicted_hi, predicted\n\nTwo more functionalities deserve to be highlight. First, fmeffects includes functions to explore heterogeneity in marginal effects using recursive partitioning trees. The heterogeneity vignette illustrates how to achieve something similar with marginaleffects.\nSecond, fmeffects also implements a non-linearity measure. At the moment, there is no analogue to this in marginaleffects.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#effects",
    "href": "vignettes/alternative_software.html#effects",
    "title": "Alternative Software",
    "section": "",
    "text": "The effects package was created by John Fox and colleagues.\n\n\nmarginaleffects supports 30+ more model types than effects.\n\neffects focuses on the computation of “adjusted predictions.” The plots it produces are roughly equivalent to the ones produced by the plot_predictions and predictions functions in marginaleffects.\n\neffects does not appear support marginal effects (slopes), marginal means, or contrasts\n\neffects uses Base graphics whereas marginaleffects uses ggplot2\n\n\neffects includes a lot of very powerful options to customize plots. In contrast, marginaleffects produces objects which can be customized by chaining ggplot2 functions. Users can also call plot_predictions(model, draw=FALSE) to create a prediction grid, and then work the raw data directly to create the plot they need\n\neffects offers several options which are not currently available in marginaleffects, including:\n\nPartial residuals plots\nMany types of ways to plot adjusted predictions: package vignette",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#modelbased",
    "href": "vignettes/alternative_software.html#modelbased",
    "title": "Alternative Software",
    "section": "",
    "text": "The modelbased package is developed by the easystats team.\nThis section is incomplete; contributions are welcome.\n\nWrapper around emmeans to compute marginal means and marginal effects.\nPowerful functions to create beautiful plots.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/alternative_software.html#ggeffects",
    "href": "vignettes/alternative_software.html#ggeffects",
    "title": "Alternative Software",
    "section": "",
    "text": "The ggeffects package is developed by Daniel Lüdecke.\nThis section is incomplete; contributions are welcome.\n\nWrapper around emmeans to compute marginal means.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Alternative Software"
    ]
  },
  {
    "objectID": "vignettes/faq.html",
    "href": "vignettes/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Error: Matrix columns are not supported\nWiggly (non-smooth) confidence intervals in plots.\nplot_predictions() over a range of unobserved values\nPlot the marginal effects from a plm package model\nModels with demeaned, polynomials, or transformed variables\nnlme::lme problem with character predictors\nControlling facet rows and columns in plot_*() functions.\nBayesian diagnostics (Rhat, etc.) with brms\nPooling predictions with multiple imputation\n\nFunctions from the marginaleffects package can sometimes fail when they are called inside a function, loop, or other environments. To see why, it is important to know that marginaleffects often needs to operate on the original data that was used to fit the model. To extract this original data, we use the get_data() function from the insight package.\nIn most cases, get_data() can extract the data which is stored inside the model object created by the modeling package. However, some modeling packages do not save the original data in the model object (in order to save memory). In those cases, get_data() will parse the call to find the name of the data object, and will search for that data object in the global environment. When users fit models in a different environment (e.g., function calls), get_data() may not be able to retrieve the original data.\nA related problem can arise if users fit a model, but then assign a new value to the variable that used to store the dataset.\nRecommendations:\n\nSupply your dataset explicitly to the newdata argument of slopes functions.\nAvoid assigning a new value to a variable that you use to store a dataset for model fitting.\n\nSay we estimate a simple logit regression and want to compute the average log-odds ratio associated with a change from 0 to 1 on the vs variable. We can proceed as follows using the comparisons() function:\n\nlibrary(marginaleffects)\nmod &lt;- glm(am ~ vs + scale(drat), family = binomial, mtcars)\n\navg_comparisons(mod,\n    variables = \"vs\",\n    comparison = \"lnoravg\",\n    type = \"response\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.901      0.368 -2.45   0.0143 6.1 -1.62  -0.18\n#&gt; \n#&gt; Term: vs\n#&gt; Type:  response \n#&gt; Comparison: ln(odds(1) / odds(0))\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nWe can specify the function to compare “hi” predictions to “lo” predictions manually and get the same results:\n\nfun &lt;- function(hi, lo) log((mean(hi) / (1 - mean(hi))) / (mean(lo) / (1 - mean(lo))))\n\ncomparisons(mod,\n    variables = \"vs\",\n    comparison = fun,\n    type = \"response\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.901      0.368 -2.45   0.0143 6.1 -1.62  -0.18\n#&gt; \n#&gt; Term: vs\n#&gt; Type:  response \n#&gt; Comparison: 1, 0\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThe same results can be obtained using the predictions() function. First, we replicate the entire dataset, and substitute the values of vs. Then, we make predictions. Finally, we compute the log odds ratios:\n\ndat0 &lt;- transform(mtcars, vs = 0)\ndat1 &lt;- transform(mtcars, vs = 1)\n\np0 &lt;- predictions(mod, newdata = dat0, type = \"response\")\np1 &lt;- predictions(mod, newdata = dat1, type = \"response\")\n\nfun(p1$estimate, p0$estimate)\n#&gt; [1] -0.9006949\n\nNotice that the following command gives us a different result. This is because instead of duplicating the full dataset, and computing the “hi” and “lo” as the mean predictions over the full data, we only compute the averages on the subsets of rows where vs is 0 or 1, respectively:\n\np &lt;- avg_predictions(mod, by = \"vs\", type = \"response\")\nfun(p$estimate[2], p$estimate[1])\n#&gt; [1] 0.6931472\n\nWhich is equivalent to:\n\ndat0 &lt;- subset(mtcars, vs == 0)\ndat1 &lt;- subset(mtcars, vs == 1)\n\np0 &lt;- predictions(mod, newdata = dat0, type = \"response\")\np1 &lt;- predictions(mod, newdata = dat1, type = \"response\")\n\nfun(p1$estimate, p0$estimate)\n#&gt; [1] 0.6931472\n\n\nAs described in the Plot vignette, there are currently three ways to customize plots in marginaleffects:\n\nUsing the arguments provided by plot_*() functions in the marginaleffects package.\nModifying the plot objects using ggplot2 or an extension package like ggExtra.\nSetting draw=FALSE to extract the plotting data, and then feeding that data to a standalone plotting software like ggplot2, plot, or lattice.\n\nOptions 2 and 3 are extremely flexible, and make it trivial to reproduce the default plots or to draw highly customized visualizations.\nOf course, some users might still prefer to use function arguments directly available in marginaleffects::plot_*(), and the unavailability of some arguments can be frustrating. Nevertheless, a decision was made to keep the number of arguments in plot_*() functions quite low. This is because ggplot2 functions like geom_*(), facet_*(), and aes() each accept a very large number of options, and because users’ needs are incredibly varied. This makes it difficult to accomodate all needs and possibilities, without developing unwieldy functions with dozens of arguments.1\nThus, the marginaleffects package is designed with limited scope, focusing on computation while offering a few visualization options for quick exploration. Users who need highly customized or publication-ready figures are encouraged to use the draw=FALSE argument with standalone plotting software.\nIn an ideal world, someone else would build a richer visualization package on top of marginaleffects. I think this would be a very cool project, and I would be happy to collaborate, advise, and help if I can. In the meantime, feel free to keep the discussion going by opening an issue on Github. I will be happy to consider counter-arguments, suggestions, or pull requests.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "FAQ"
    ]
  },
  {
    "objectID": "vignettes/faq.html#questions-answers",
    "href": "vignettes/faq.html#questions-answers",
    "title": "FAQ",
    "section": "",
    "text": "Error: Matrix columns are not supported\nWiggly (non-smooth) confidence intervals in plots.\nplot_predictions() over a range of unobserved values\nPlot the marginal effects from a plm package model\nModels with demeaned, polynomials, or transformed variables\nnlme::lme problem with character predictors\nControlling facet rows and columns in plot_*() functions.\nBayesian diagnostics (Rhat, etc.) with brms\nPooling predictions with multiple imputation",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "FAQ"
    ]
  },
  {
    "objectID": "vignettes/faq.html#calling-marginaleffects-in-functions-loops-environments-or-after-re-assigning-variables",
    "href": "vignettes/faq.html#calling-marginaleffects-in-functions-loops-environments-or-after-re-assigning-variables",
    "title": "FAQ",
    "section": "",
    "text": "Functions from the marginaleffects package can sometimes fail when they are called inside a function, loop, or other environments. To see why, it is important to know that marginaleffects often needs to operate on the original data that was used to fit the model. To extract this original data, we use the get_data() function from the insight package.\nIn most cases, get_data() can extract the data which is stored inside the model object created by the modeling package. However, some modeling packages do not save the original data in the model object (in order to save memory). In those cases, get_data() will parse the call to find the name of the data object, and will search for that data object in the global environment. When users fit models in a different environment (e.g., function calls), get_data() may not be able to retrieve the original data.\nA related problem can arise if users fit a model, but then assign a new value to the variable that used to store the dataset.\nRecommendations:\n\nSupply your dataset explicitly to the newdata argument of slopes functions.\nAvoid assigning a new value to a variable that you use to store a dataset for model fitting.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "FAQ"
    ]
  },
  {
    "objectID": "vignettes/faq.html#equivalence-between-avg_comparisons-and-avg_predictions",
    "href": "vignettes/faq.html#equivalence-between-avg_comparisons-and-avg_predictions",
    "title": "FAQ",
    "section": "",
    "text": "Say we estimate a simple logit regression and want to compute the average log-odds ratio associated with a change from 0 to 1 on the vs variable. We can proceed as follows using the comparisons() function:\n\nlibrary(marginaleffects)\nmod &lt;- glm(am ~ vs + scale(drat), family = binomial, mtcars)\n\navg_comparisons(mod,\n    variables = \"vs\",\n    comparison = \"lnoravg\",\n    type = \"response\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.901      0.368 -2.45   0.0143 6.1 -1.62  -0.18\n#&gt; \n#&gt; Term: vs\n#&gt; Type:  response \n#&gt; Comparison: ln(odds(1) / odds(0))\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nWe can specify the function to compare “hi” predictions to “lo” predictions manually and get the same results:\n\nfun &lt;- function(hi, lo) log((mean(hi) / (1 - mean(hi))) / (mean(lo) / (1 - mean(lo))))\n\ncomparisons(mod,\n    variables = \"vs\",\n    comparison = fun,\n    type = \"response\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;    -0.901      0.368 -2.45   0.0143 6.1 -1.62  -0.18\n#&gt; \n#&gt; Term: vs\n#&gt; Type:  response \n#&gt; Comparison: 1, 0\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThe same results can be obtained using the predictions() function. First, we replicate the entire dataset, and substitute the values of vs. Then, we make predictions. Finally, we compute the log odds ratios:\n\ndat0 &lt;- transform(mtcars, vs = 0)\ndat1 &lt;- transform(mtcars, vs = 1)\n\np0 &lt;- predictions(mod, newdata = dat0, type = \"response\")\np1 &lt;- predictions(mod, newdata = dat1, type = \"response\")\n\nfun(p1$estimate, p0$estimate)\n#&gt; [1] -0.9006949\n\nNotice that the following command gives us a different result. This is because instead of duplicating the full dataset, and computing the “hi” and “lo” as the mean predictions over the full data, we only compute the averages on the subsets of rows where vs is 0 or 1, respectively:\n\np &lt;- avg_predictions(mod, by = \"vs\", type = \"response\")\nfun(p$estimate[2], p$estimate[1])\n#&gt; [1] 0.6931472\n\nWhich is equivalent to:\n\ndat0 &lt;- subset(mtcars, vs == 0)\ndat1 &lt;- subset(mtcars, vs == 1)\n\np0 &lt;- predictions(mod, newdata = dat0, type = \"response\")\np1 &lt;- predictions(mod, newdata = dat1, type = \"response\")\n\nfun(p1$estimate, p0$estimate)\n#&gt; [1] 0.6931472",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "FAQ"
    ]
  },
  {
    "objectID": "vignettes/faq.html#more-plot-customization",
    "href": "vignettes/faq.html#more-plot-customization",
    "title": "FAQ",
    "section": "",
    "text": "As described in the Plot vignette, there are currently three ways to customize plots in marginaleffects:\n\nUsing the arguments provided by plot_*() functions in the marginaleffects package.\nModifying the plot objects using ggplot2 or an extension package like ggExtra.\nSetting draw=FALSE to extract the plotting data, and then feeding that data to a standalone plotting software like ggplot2, plot, or lattice.\n\nOptions 2 and 3 are extremely flexible, and make it trivial to reproduce the default plots or to draw highly customized visualizations.\nOf course, some users might still prefer to use function arguments directly available in marginaleffects::plot_*(), and the unavailability of some arguments can be frustrating. Nevertheless, a decision was made to keep the number of arguments in plot_*() functions quite low. This is because ggplot2 functions like geom_*(), facet_*(), and aes() each accept a very large number of options, and because users’ needs are incredibly varied. This makes it difficult to accomodate all needs and possibilities, without developing unwieldy functions with dozens of arguments.1\nThus, the marginaleffects package is designed with limited scope, focusing on computation while offering a few visualization options for quick exploration. Users who need highly customized or publication-ready figures are encouraged to use the draw=FALSE argument with standalone plotting software.\nIn an ideal world, someone else would build a richer visualization package on top of marginaleffects. I think this would be a very cool project, and I would be happy to collaborate, advise, and help if I can. In the meantime, feel free to keep the discussion going by opening an issue on Github. I will be happy to consider counter-arguments, suggestions, or pull requests.",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "FAQ"
    ]
  },
  {
    "objectID": "vignettes/faq.html#footnotes",
    "href": "vignettes/faq.html#footnotes",
    "title": "FAQ",
    "section": "Footnotes",
    "text": "Footnotes\n\nNote that we cannot pass visual arguments to ..., because that mechanism is already used to pass arguments to the predict() methods, which is required for some model types.↩︎",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "FAQ"
    ]
  },
  {
    "objectID": "vignettes/links.html",
    "href": "vignettes/links.html",
    "title": "Links",
    "section": "",
    "text": "Links\n\nWhat to do with age? Linear, Discrete, Both, or Spline\nEquivalence Tests Using marginaleffects: Reproducing the Clark and Golder (2006) Example from Rainey (2014) by Carlisle Rainey\nYou are what you ATE: Choosing an effect size measure for binary outcomes by Cameron Patrick\nCausal inference with potential outcomes bootcamp by Solomon Kurz\nMarginal and conditional effects for GLMMs with marginaleffects by Andrew Heiss\nMarginalia: A guide to figuring out what the heck marginal effects, marginal slopes, average marginal effects, marginal effects at the mean, and all these other marginal things are by Andrew Heiss\nMatching by Noah Greifer\nDouble propensity score adjustment using g-computation by Noah Greifer\nSubgroup Analysis After Propensity Score Matching Using R by Noah Greifer\nBayesian Model Averaged Marginal Effects by A. Jordan Nafa",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "Links"
    ]
  },
  {
    "objectID": "vignettes/ipw.html",
    "href": "vignettes/ipw.html",
    "title": "Inverse Probability Weighting",
    "section": "",
    "text": "Inverse Probability Weighting\nInverse Probability Weighting (IPW) is a popular technique to remove confounding in statistical modeling. It essentially involves re-weighting your sample so that it represents the population you’re interested in. Typically, we begin by estimating the predicted probability that each unit is treated. Then, we use these probabilities as weights in model fitting and in the computation of marginal effects, contrasts, risk differences, ratios, etc.\nThis chapter introduces how to use marginaleffects for IPW. The presentation is very short. Readers who seek a more comprehensive understanding and application of these methods should refer to Noah Greifer’s excellent and detailed work on the topic and to the WeightIt package vignettes and website.\nTo illustrate, we use the Lalonde data.\n\nlibrary(marginaleffects)\ndata(\"lalonde\", package = \"MatchIt\")\nhead(lalonde)\n\n     treat age educ   race married nodegree re74 re75       re78\nNSW1     1  37   11  black       1        1    0    0  9930.0460\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940\nNSW3     1  30   12  black       0        0    0    0 24909.4500\nNSW4     1  27   11  black       0        1    0    0  7506.1460\nNSW5     1  33    8  black       0        1    0    0   289.7899\nNSW6     1  22    9  black       0        1    0    0  4056.4940\n\n\nTo begin, we use a logistic regression model to estimate the probability that each unit will treated:\n\nm &lt;- glm(treat ~ age + educ + race + re74, data = lalonde, family = binomial)\n\nThen, we call predictions() to extract predicted probabilities. Note that we supply the original lalonde data explicity to the newdata argument. This ensures that all the original columns are carried over to the new dataset: dat. We also create a new column called wts that contains the inverse of the predicted probabilities:\n\ndat &lt;- predictions(m, newdata = lalonde)\ndat$wts &lt;- ifelse(dat$treat == 1, 1 / dat$estimate, 1 / (1 - dat$estimate))\n\nNow, we use linear regression to model the outcome of interest: personal income in 1978 (re78). Note that we use the predictions as weights in the model fitting process.\n\nmod &lt;- lm(re78 ~ treat * (age + educ + race + re74), data = dat, weights = wts)\n\nFinally, we call avg_comparisons() to compute the average treatment effect. Note that we use the wts argument to specify the weights to be used in the computation.\n\navg_comparisons(mod,\n    variables = \"treat\",\n    wts = \"wts\",\n    vcov = \"HC3\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n      973       1173 0.83    0.407 1.3 -1326   3272\n\nTerm: treat\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nBy default, avg_comparisons() uses the Hajek estimator, that is, the weights are normalized to sum to 1 before computation. If a user wants to use the Horvitz-Thompson estimator—where normalization accounts for sample size—they can easily define a custom comparison function like this one:\n\nht &lt;- \\(hi, lo, w, newdata) {\n    (sum(hi * w) / nrow(newdata)) - (sum(lo * w) / nrow(newdata))\n}\n\ncomparisons(mod,\n    comparison = ht,\n    variables = \"treat\",\n    wts = \"wts\",\n    vcov = \"HC3\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n     1851       2231 0.83    0.407 1.3 -2521   6222\n\nTerm: treat\nType:  response \nComparison: 1, 0\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Case studies",
      "Inverse Probability Weighting"
    ]
  },
  {
    "objectID": "vignettes/machine_learning.html",
    "href": "vignettes/machine_learning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "marginaleffects offers several “model-agnostic” functions to interpret statistical and machine learning models. This vignette highlights how the package can be used to extract meaningful insights from models trained using the mlr3 and tidymodels frameworks.\n\nlibrary(\"marginaleffects\")\nlibrary(\"fmeffects\")\nlibrary(\"ggplot2\")\nlibrary(\"mlr3verse\")\nlibrary(\"modelsummary\")\nlibrary(\"ggokabeito\")\nlibrary(\"tidymodels\") |&gt; suppressPackageStartupMessages()\ntheme_set(theme_bw())\noptions(ggplot2.discrete.colour = palette_okabe_ito())\noptions(width = 10000)\n\n\nmarginaleffects also supports the tidymodels machine learning framework. When the underlying engine used by tidymodels to train the model is itself supported as a standalone package by marginaleffects, we can obtain both estimates and their standard errors:\n\nlibrary(tidymodels)\n\npenguins &lt;- modeldata::penguins |&gt; \n  na.omit() |&gt;\n  select(sex, island, species, bill_length_mm)\n\nmod &lt;- linear_reg(mode = \"regression\") |&gt;\n    set_engine(\"lm\") |&gt;\n    fit(bill_length_mm ~ ., data = penguins)\n\navg_comparisons(mod, type = \"numeric\", newdata = penguins)\n\n\n    Term                       Contrast Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n island  mean(Dream) - mean(Biscoe)       -0.489      0.470 -1.04    0.299   1.7 -1.410  0.433\n island  mean(Torgersen) - mean(Biscoe)    0.103      0.488  0.21    0.833   0.3 -0.853  1.059\n sex     mean(male) - mean(female)         3.697      0.255 14.51   &lt;0.001 156.0  3.198  4.197\n species mean(Chinstrap) - mean(Adelie)   10.347      0.422 24.54   &lt;0.001 439.4  9.521 11.174\n species mean(Gentoo) - mean(Adelie)       8.546      0.410 20.83   &lt;0.001 317.8  7.742  9.350\n\nType:  numeric \nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\navg_predictions(mod, type = \"numeric\", newdata = penguins, by = \"island\")\n\n\n    island Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n Torgersen     39.0      0.339 115   &lt;0.001 Inf  38.4   39.7\n Biscoe        45.2      0.182 248   &lt;0.001 Inf  44.9   45.6\n Dream         44.2      0.210 211   &lt;0.001 Inf  43.8   44.6\n\nType:  numeric \nColumns: island, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nWhen the underlying engine that tidymodels uses to fit the model is not supported by marginaleffects as a standalone model, we can also obtain correct results, but no uncertainy estimates. Here is a random forest model:\n\nlibrary(modelsummary)\n\n# pre-processing\npre &lt;- penguins |&gt;\n    recipe(sex ~ ., data = _) |&gt;\n    step_ns(bill_length_mm, deg_free = 4) |&gt;\n    step_dummy(all_nominal_predictors())\n\n# modelling strategies\nmodels &lt;- list(\n  \"Logit\" = logistic_reg(mode = \"classification\", engine = \"glm\"),\n  \"Random Forest\" = rand_forest(mode = \"classification\", engine = \"ranger\"),\n  \"XGBoost\" = boost_tree(mode = \"classification\", engine = \"xgboost\")\n)\n\n# fit to data\nfits &lt;- lapply(models, \\(x) {\n  pre |&gt;\n  workflow(spec = x) |&gt;\n  fit(penguins)\n})\n\n# marginaleffects\ncmp &lt;- lapply(fits, avg_comparisons, newdata = penguins, type = \"prob\")\n\n# summary table\nmodelsummary(\n  cmp,\n  shape = term + contrast + group ~ model,\n  coef_omit = \"sex\",\n  coef_rename = coef_rename)\n\n\n\n    \n\n      \n\n \n                  \n                   \n                Logit\n                Random Forest\n                XGBoost\n              \n\n\nBill Length Mm\n                  mean(+1)                      \n                  female\n                  -0.101  \n                  -0.077\n                  -0.098\n                \n\n              \n                                                \n                        \n                  (0.004) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  0.101   \n                  0.077 \n                  0.098 \n                \n\n              \n                                                \n                        \n                  (0.004) \n                        \n                        \n                \n\nIsland        \n                  mean(Dream) - mean(Biscoe)    \n                  female\n                  -0.044  \n                  0.002 \n                  -0.004\n                \n\n              \n                                                \n                        \n                  (0.069) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  0.044   \n                  -0.002\n                  0.004 \n                \n\n              \n                                                \n                        \n                  (0.069) \n                        \n                        \n                \n\n              \n                  mean(Torgersen) - mean(Biscoe)\n                  female\n                  0.015   \n                  -0.060\n                  0.008 \n                \n\n              \n                                                \n                        \n                  (0.074) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  -0.015  \n                  0.060 \n                  -0.008\n                \n\n              \n                                                \n                        \n                  (0.074) \n                        \n                        \n                \n\nSpecies       \n                  mean(Chinstrap) - mean(Adelie)\n                  female\n                  0.562   \n                  0.152 \n                  0.441 \n                \n\n              \n                                                \n                        \n                  (0.036) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  -0.562  \n                  -0.152\n                  -0.441\n                \n\n              \n                                                \n                        \n                  (0.036) \n                        \n                        \n                \n\n              \n                  mean(Gentoo) - mean(Adelie)   \n                  female\n                  0.453   \n                  0.108 \n                  0.361 \n                \n\n              \n                                                \n                        \n                  (0.025) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  -0.453  \n                  -0.108\n                  -0.361\n                \n\n              \n                                                \n                        \n                  (0.025) \n                        \n                        \n                \n\nNum.Obs.      \n                                                \n                        \n                  333     \n                        \n                        \n                \n\nAIC           \n                                                \n                        \n                  302.2   \n                        \n                        \n                \n\nBIC           \n                                                \n                        \n                  336.4   \n                        \n                        \n                \n\nLog.Lik.      \n                                                \n                        \n                  -142.082\n                        \n                        \n                \n\n\n\n\n\n\n\nmlr3 is a machine learning framework for R. It makes it possible for users to train a wide range of models, including linear models, random forests, gradient boosting machines, and neural networks.\nIn this example, we use the bikes dataset supplied by the fmeffects package to train a random forest model predicting the number of bikes rented per hour. We then use marginaleffects to interpret the results of the model.\n\nlibrary(mlr3verse)\ndata(\"bikes\", package = \"fmeffects\")\n\ntask &lt;- as_task_regr(x = bikes, id = \"bikes\", target = \"count\")\nforest &lt;- lrn(\"regr.ranger\")$train(task)\n\nAs described in other vignettes, we can use the avg_comparisons() function to compute the average change in predicted outcome that is associated with a change in each feature:\n\navg_comparisons(forest, newdata = bikes)\n\n\n       Term                       Contrast Estimate\n count      mean(+1)                            0.0\n holiday    mean(no) - mean(yes)              133.6\n humidity   mean(+1)                         -859.0\n season     mean(fall) - mean(winter)        1103.6\n season     mean(spring) - mean(winter)       807.4\n season     mean(summer) - mean(winter)       930.3\n temp       mean(+1)                           56.5\n weather    mean(misty) - mean(clear)        -288.4\n weather    mean(rain) - mean(clear)         -858.8\n weekday    mean(Friday) - mean(Monday)       173.1\n weekday    mean(Saturday) - mean(Monday)     218.6\n weekday    mean(Sunday) - mean(Monday)       258.3\n weekday    mean(Thursday) - mean(Monday)     138.6\n weekday    mean(Tuesday) - mean(Monday)       29.5\n weekday    mean(Wednesday) - mean(Monday)     90.0\n windspeed  mean(+1)                          -26.0\n workingday mean(no) - mean(yes)              -48.1\n year       mean(1) - mean(0)                1848.6\n\nType:  response \nColumns: term, contrast, estimate, predicted_lo, predicted_hi, predicted \n\n\nThese results are easy to interpret: An increase of 1 degree Celsius in the temperature is associated with an increase of 56.479 bikes rented per hour.\nWe could obtain the same result manually as follows:\n\nlo &lt;- transform(bikes, temp = temp - 0.5)\nhi &lt;- transform(bikes, temp = temp + 0.5)\nmean(predict(forest, newdata = hi) - predict(forest, newdata = lo))\n\n[1] 67.75768\n\n\n\nWith marginaleffects::avg_comparisons(), we can also compute the average effect of a simultaneous change in multiple predictors, using the variables and cross arguments. In this example, we see what happens (on average) to the predicted outcome when the temp, season, and weather predictors all change together:\n\navg_comparisons(\n    forest,\n    variables = c(\"temp\", \"season\", \"weather\"),\n    cross = TRUE,\n    newdata = bikes)\n\n\n                   C: season  C: temp                C: weather Estimate\n mean(fall) - mean(winter)   mean(+1) mean(misty) - mean(clear)    927.1\n mean(fall) - mean(winter)   mean(+1) mean(rain) - mean(clear)     242.0\n mean(spring) - mean(winter) mean(+1) mean(misty) - mean(clear)    613.2\n mean(spring) - mean(winter) mean(+1) mean(rain) - mean(clear)      36.1\n mean(summer) - mean(winter) mean(+1) mean(misty) - mean(clear)    733.0\n mean(summer) - mean(winter) mean(+1) mean(rain) - mean(clear)     126.6\n\nType:  response \nColumns: term, contrast_season, contrast_temp, contrast_weather, estimate \n\n\n\n\n# https://stackoverflow.com/questions/67634344/r-partial-dependence-plots-from-workflow\nlibrary(\"tidymodels\")\nlibrary(\"marginaleffects\")\ndata(ames, package = \"modeldata\")\n\ndat &lt;- transform(ames,\n    Sale_Price = log10(Sale_Price),\n    Gr_Liv_Area = as.numeric(Gr_Liv_Area))\n\nm &lt;- dat |&gt; \n    recipe(Sale_Price ~ Gr_Liv_Area + Year_Built + Bldg_Type, data = _) |&gt;\n    workflow(spec = rand_forest(mode = \"regression\", trees = 1000, engine = \"ranger\")) |&gt;\n    fit(data = dat)\n\n# Percentiles of the x-axis variable\npctiles &lt;- quantile(dat$Gr_Liv_Area, probs = seq(0, 1, length.out = 101))\n\n# Select 1000 profiles at random, otherwise this is very memory-intensive\nprofiles &lt;- dat[sample(nrow(dat), 1000), ]\n\n# Use a counterfactual grid to replicate the full dataset 101 times. Each time, we\n# replace the value of `Gr_Liv_Area` by one of the percentiles, but keep the\n# other profile features as observed.\nnd &lt;- datagrid(\n  Gr_Liv_Area = pctiles, newdata = profiles,\n  grid_type = \"counterfactual\")\n\n# Partial dependence plot\nplot_predictions(m,\n  newdata = nd,\n  by = c(\"Gr_Liv_Area\", \"Bldg_Type\")) +\n  labs(x = \"Living Area\", y = \"Predicted log10(Sale Price)\", color = \"Building Type\")\n\n\n\n\n\n\n\nWe can replicate this plot using the DALEXtra package:\n\nlibrary(\"DALEXtra\")\npdp_rf &lt;- explain_tidymodels(\n    m,\n    data = dplyr::select(dat, -Sale_Price),\n    y = dat$Sale_Price,\n    label = \"random forest\",\n    verbose = FALSE)\npdp_rf &lt;- model_profile(pdp_rf,\n    N = 1000,\n    variables = \"Gr_Liv_Area\",\n    groups = \"Bldg_Type\")\nplot(pdp_rf)\n\n\n\n\n\n\n\nNote that marginaleffects and DALEXtra plots are not exactly identical because the randomly sampled profiles are not the same. You can try the same procedure without sampling — or equivalently with N=2930 — to see a perfect equivalence.\n\nWe can plot the results using the standard marginaleffects helpers. For example, to plot predictions, we can do:\n\nlibrary(mlr3verse)\ndata(\"bikes\", package = \"fmeffects\")\ntask &lt;- as_task_regr(x = bikes, id = \"bikes\", target = \"count\")\nforest &lt;- lrn(\"regr.ranger\")$train(task)\n\nplot_predictions(forest, condition = \"temp\", newdata = bikes)\n\n\n\n\n\n\n\nAs documented in ?plot_predictions, using condition=\"temp\" is equivalent to creating an equally-spaced grid of temp values, and holding all other predictors at their means or modes. In other words, it is equivalent to:\n\nd &lt;- datagrid(temp = seq(min(bikes$temp), max(bikes$temp), length.out = 100), newdata = bikes)\np &lt;- predict(forest, newdata = d)\nplot(d$temp, p, type = \"l\")\n\nAlternatively, we could plot “marginal” predictions, where replicate the full dataset once for every value of temp, and then average the predicted values over each value of the x-axis:\n\nplot_predictions(forest, by = \"temp\", newdata = bikes)\n\n\n\n\n\n\n\nOf course, we can customize the plot using all the standard ggplot2 functions:\n\nplot_predictions(forest, by = \"temp\", newdata = d) +\n    geom_point(data = bikes, aes(x = temp, y = count), alpha = 0.1) +\n    geom_smooth(data = bikes, aes(x = temp, y = count), se = FALSE, color = \"orange\") +\n    labs(x = \"Temperature (Celsius)\", y = \"Predicted number of bikes rented per hour\",\n         title = \"Black: random forest predictions. Orange: LOESS smoother.\") +\n    theme_bw()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "Get started",
      "Case studies",
      "Machine Learning"
    ]
  },
  {
    "objectID": "vignettes/machine_learning.html#tidymodels",
    "href": "vignettes/machine_learning.html#tidymodels",
    "title": "Machine Learning",
    "section": "",
    "text": "marginaleffects also supports the tidymodels machine learning framework. When the underlying engine used by tidymodels to train the model is itself supported as a standalone package by marginaleffects, we can obtain both estimates and their standard errors:\n\nlibrary(tidymodels)\n\npenguins &lt;- modeldata::penguins |&gt; \n  na.omit() |&gt;\n  select(sex, island, species, bill_length_mm)\n\nmod &lt;- linear_reg(mode = \"regression\") |&gt;\n    set_engine(\"lm\") |&gt;\n    fit(bill_length_mm ~ ., data = penguins)\n\navg_comparisons(mod, type = \"numeric\", newdata = penguins)\n\n\n    Term                       Contrast Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n island  mean(Dream) - mean(Biscoe)       -0.489      0.470 -1.04    0.299   1.7 -1.410  0.433\n island  mean(Torgersen) - mean(Biscoe)    0.103      0.488  0.21    0.833   0.3 -0.853  1.059\n sex     mean(male) - mean(female)         3.697      0.255 14.51   &lt;0.001 156.0  3.198  4.197\n species mean(Chinstrap) - mean(Adelie)   10.347      0.422 24.54   &lt;0.001 439.4  9.521 11.174\n species mean(Gentoo) - mean(Adelie)       8.546      0.410 20.83   &lt;0.001 317.8  7.742  9.350\n\nType:  numeric \nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\navg_predictions(mod, type = \"numeric\", newdata = penguins, by = \"island\")\n\n\n    island Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n Torgersen     39.0      0.339 115   &lt;0.001 Inf  38.4   39.7\n Biscoe        45.2      0.182 248   &lt;0.001 Inf  44.9   45.6\n Dream         44.2      0.210 211   &lt;0.001 Inf  43.8   44.6\n\nType:  numeric \nColumns: island, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nWhen the underlying engine that tidymodels uses to fit the model is not supported by marginaleffects as a standalone model, we can also obtain correct results, but no uncertainy estimates. Here is a random forest model:\n\nlibrary(modelsummary)\n\n# pre-processing\npre &lt;- penguins |&gt;\n    recipe(sex ~ ., data = _) |&gt;\n    step_ns(bill_length_mm, deg_free = 4) |&gt;\n    step_dummy(all_nominal_predictors())\n\n# modelling strategies\nmodels &lt;- list(\n  \"Logit\" = logistic_reg(mode = \"classification\", engine = \"glm\"),\n  \"Random Forest\" = rand_forest(mode = \"classification\", engine = \"ranger\"),\n  \"XGBoost\" = boost_tree(mode = \"classification\", engine = \"xgboost\")\n)\n\n# fit to data\nfits &lt;- lapply(models, \\(x) {\n  pre |&gt;\n  workflow(spec = x) |&gt;\n  fit(penguins)\n})\n\n# marginaleffects\ncmp &lt;- lapply(fits, avg_comparisons, newdata = penguins, type = \"prob\")\n\n# summary table\nmodelsummary(\n  cmp,\n  shape = term + contrast + group ~ model,\n  coef_omit = \"sex\",\n  coef_rename = coef_rename)\n\n\n\n    \n\n      \n\n \n                  \n                   \n                Logit\n                Random Forest\n                XGBoost\n              \n\n\nBill Length Mm\n                  mean(+1)                      \n                  female\n                  -0.101  \n                  -0.077\n                  -0.098\n                \n\n              \n                                                \n                        \n                  (0.004) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  0.101   \n                  0.077 \n                  0.098 \n                \n\n              \n                                                \n                        \n                  (0.004) \n                        \n                        \n                \n\nIsland        \n                  mean(Dream) - mean(Biscoe)    \n                  female\n                  -0.044  \n                  0.002 \n                  -0.004\n                \n\n              \n                                                \n                        \n                  (0.069) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  0.044   \n                  -0.002\n                  0.004 \n                \n\n              \n                                                \n                        \n                  (0.069) \n                        \n                        \n                \n\n              \n                  mean(Torgersen) - mean(Biscoe)\n                  female\n                  0.015   \n                  -0.060\n                  0.008 \n                \n\n              \n                                                \n                        \n                  (0.074) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  -0.015  \n                  0.060 \n                  -0.008\n                \n\n              \n                                                \n                        \n                  (0.074) \n                        \n                        \n                \n\nSpecies       \n                  mean(Chinstrap) - mean(Adelie)\n                  female\n                  0.562   \n                  0.152 \n                  0.441 \n                \n\n              \n                                                \n                        \n                  (0.036) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  -0.562  \n                  -0.152\n                  -0.441\n                \n\n              \n                                                \n                        \n                  (0.036) \n                        \n                        \n                \n\n              \n                  mean(Gentoo) - mean(Adelie)   \n                  female\n                  0.453   \n                  0.108 \n                  0.361 \n                \n\n              \n                                                \n                        \n                  (0.025) \n                        \n                        \n                \n\n              \n                                                \n                  male  \n                  -0.453  \n                  -0.108\n                  -0.361\n                \n\n              \n                                                \n                        \n                  (0.025) \n                        \n                        \n                \n\nNum.Obs.      \n                                                \n                        \n                  333     \n                        \n                        \n                \n\nAIC           \n                                                \n                        \n                  302.2   \n                        \n                        \n                \n\nBIC           \n                                                \n                        \n                  336.4   \n                        \n                        \n                \n\nLog.Lik.      \n                                                \n                        \n                  -142.082",
    "crumbs": [
      "Get started",
      "Case studies",
      "Machine Learning"
    ]
  },
  {
    "objectID": "vignettes/machine_learning.html#mlr3",
    "href": "vignettes/machine_learning.html#mlr3",
    "title": "Machine Learning",
    "section": "",
    "text": "mlr3 is a machine learning framework for R. It makes it possible for users to train a wide range of models, including linear models, random forests, gradient boosting machines, and neural networks.\nIn this example, we use the bikes dataset supplied by the fmeffects package to train a random forest model predicting the number of bikes rented per hour. We then use marginaleffects to interpret the results of the model.\n\nlibrary(mlr3verse)\ndata(\"bikes\", package = \"fmeffects\")\n\ntask &lt;- as_task_regr(x = bikes, id = \"bikes\", target = \"count\")\nforest &lt;- lrn(\"regr.ranger\")$train(task)\n\nAs described in other vignettes, we can use the avg_comparisons() function to compute the average change in predicted outcome that is associated with a change in each feature:\n\navg_comparisons(forest, newdata = bikes)\n\n\n       Term                       Contrast Estimate\n count      mean(+1)                            0.0\n holiday    mean(no) - mean(yes)              133.6\n humidity   mean(+1)                         -859.0\n season     mean(fall) - mean(winter)        1103.6\n season     mean(spring) - mean(winter)       807.4\n season     mean(summer) - mean(winter)       930.3\n temp       mean(+1)                           56.5\n weather    mean(misty) - mean(clear)        -288.4\n weather    mean(rain) - mean(clear)         -858.8\n weekday    mean(Friday) - mean(Monday)       173.1\n weekday    mean(Saturday) - mean(Monday)     218.6\n weekday    mean(Sunday) - mean(Monday)       258.3\n weekday    mean(Thursday) - mean(Monday)     138.6\n weekday    mean(Tuesday) - mean(Monday)       29.5\n weekday    mean(Wednesday) - mean(Monday)     90.0\n windspeed  mean(+1)                          -26.0\n workingday mean(no) - mean(yes)              -48.1\n year       mean(1) - mean(0)                1848.6\n\nType:  response \nColumns: term, contrast, estimate, predicted_lo, predicted_hi, predicted \n\n\nThese results are easy to interpret: An increase of 1 degree Celsius in the temperature is associated with an increase of 56.479 bikes rented per hour.\nWe could obtain the same result manually as follows:\n\nlo &lt;- transform(bikes, temp = temp - 0.5)\nhi &lt;- transform(bikes, temp = temp + 0.5)\nmean(predict(forest, newdata = hi) - predict(forest, newdata = lo))\n\n[1] 67.75768",
    "crumbs": [
      "Get started",
      "Case studies",
      "Machine Learning"
    ]
  },
  {
    "objectID": "vignettes/machine_learning.html#simultaneous-changes",
    "href": "vignettes/machine_learning.html#simultaneous-changes",
    "title": "Machine Learning",
    "section": "",
    "text": "With marginaleffects::avg_comparisons(), we can also compute the average effect of a simultaneous change in multiple predictors, using the variables and cross arguments. In this example, we see what happens (on average) to the predicted outcome when the temp, season, and weather predictors all change together:\n\navg_comparisons(\n    forest,\n    variables = c(\"temp\", \"season\", \"weather\"),\n    cross = TRUE,\n    newdata = bikes)\n\n\n                   C: season  C: temp                C: weather Estimate\n mean(fall) - mean(winter)   mean(+1) mean(misty) - mean(clear)    927.1\n mean(fall) - mean(winter)   mean(+1) mean(rain) - mean(clear)     242.0\n mean(spring) - mean(winter) mean(+1) mean(misty) - mean(clear)    613.2\n mean(spring) - mean(winter) mean(+1) mean(rain) - mean(clear)      36.1\n mean(summer) - mean(winter) mean(+1) mean(misty) - mean(clear)    733.0\n mean(summer) - mean(winter) mean(+1) mean(rain) - mean(clear)     126.6\n\nType:  response \nColumns: term, contrast_season, contrast_temp, contrast_weather, estimate",
    "crumbs": [
      "Get started",
      "Case studies",
      "Machine Learning"
    ]
  },
  {
    "objectID": "vignettes/machine_learning.html#partial-dependence-plots",
    "href": "vignettes/machine_learning.html#partial-dependence-plots",
    "title": "Machine Learning",
    "section": "",
    "text": "# https://stackoverflow.com/questions/67634344/r-partial-dependence-plots-from-workflow\nlibrary(\"tidymodels\")\nlibrary(\"marginaleffects\")\ndata(ames, package = \"modeldata\")\n\ndat &lt;- transform(ames,\n    Sale_Price = log10(Sale_Price),\n    Gr_Liv_Area = as.numeric(Gr_Liv_Area))\n\nm &lt;- dat |&gt; \n    recipe(Sale_Price ~ Gr_Liv_Area + Year_Built + Bldg_Type, data = _) |&gt;\n    workflow(spec = rand_forest(mode = \"regression\", trees = 1000, engine = \"ranger\")) |&gt;\n    fit(data = dat)\n\n# Percentiles of the x-axis variable\npctiles &lt;- quantile(dat$Gr_Liv_Area, probs = seq(0, 1, length.out = 101))\n\n# Select 1000 profiles at random, otherwise this is very memory-intensive\nprofiles &lt;- dat[sample(nrow(dat), 1000), ]\n\n# Use a counterfactual grid to replicate the full dataset 101 times. Each time, we\n# replace the value of `Gr_Liv_Area` by one of the percentiles, but keep the\n# other profile features as observed.\nnd &lt;- datagrid(\n  Gr_Liv_Area = pctiles, newdata = profiles,\n  grid_type = \"counterfactual\")\n\n# Partial dependence plot\nplot_predictions(m,\n  newdata = nd,\n  by = c(\"Gr_Liv_Area\", \"Bldg_Type\")) +\n  labs(x = \"Living Area\", y = \"Predicted log10(Sale Price)\", color = \"Building Type\")\n\n\n\n\n\n\n\nWe can replicate this plot using the DALEXtra package:\n\nlibrary(\"DALEXtra\")\npdp_rf &lt;- explain_tidymodels(\n    m,\n    data = dplyr::select(dat, -Sale_Price),\n    y = dat$Sale_Price,\n    label = \"random forest\",\n    verbose = FALSE)\npdp_rf &lt;- model_profile(pdp_rf,\n    N = 1000,\n    variables = \"Gr_Liv_Area\",\n    groups = \"Bldg_Type\")\nplot(pdp_rf)\n\n\n\n\n\n\n\nNote that marginaleffects and DALEXtra plots are not exactly identical because the randomly sampled profiles are not the same. You can try the same procedure without sampling — or equivalently with N=2930 — to see a perfect equivalence.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Machine Learning"
    ]
  },
  {
    "objectID": "vignettes/machine_learning.html#other-plots",
    "href": "vignettes/machine_learning.html#other-plots",
    "title": "Machine Learning",
    "section": "",
    "text": "We can plot the results using the standard marginaleffects helpers. For example, to plot predictions, we can do:\n\nlibrary(mlr3verse)\ndata(\"bikes\", package = \"fmeffects\")\ntask &lt;- as_task_regr(x = bikes, id = \"bikes\", target = \"count\")\nforest &lt;- lrn(\"regr.ranger\")$train(task)\n\nplot_predictions(forest, condition = \"temp\", newdata = bikes)\n\n\n\n\n\n\n\nAs documented in ?plot_predictions, using condition=\"temp\" is equivalent to creating an equally-spaced grid of temp values, and holding all other predictors at their means or modes. In other words, it is equivalent to:\n\nd &lt;- datagrid(temp = seq(min(bikes$temp), max(bikes$temp), length.out = 100), newdata = bikes)\np &lt;- predict(forest, newdata = d)\nplot(d$temp, p, type = \"l\")\n\nAlternatively, we could plot “marginal” predictions, where replicate the full dataset once for every value of temp, and then average the predicted values over each value of the x-axis:\n\nplot_predictions(forest, by = \"temp\", newdata = bikes)\n\n\n\n\n\n\n\nOf course, we can customize the plot using all the standard ggplot2 functions:\n\nplot_predictions(forest, by = \"temp\", newdata = d) +\n    geom_point(data = bikes, aes(x = temp, y = count), alpha = 0.1) +\n    geom_smooth(data = bikes, aes(x = temp, y = count), se = FALSE, color = \"orange\") +\n    labs(x = \"Temperature (Celsius)\", y = \"Predicted number of bikes rented per hour\",\n         title = \"Black: random forest predictions. Orange: LOESS smoother.\") +\n    theme_bw()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "Get started",
      "Case studies",
      "Machine Learning"
    ]
  },
  {
    "objectID": "vignettes/core.html",
    "href": "vignettes/core.html",
    "title": "Core",
    "section": "",
    "text": "Core\nThe following chapters are on the core aspects of the marginaleffect package."
  },
  {
    "objectID": "vignettes/logit.html",
    "href": "vignettes/logit.html",
    "title": "Logit",
    "section": "",
    "text": "This vignette replicates some of the analyses in this excellent blog post by Frank Harrell: Avoiding One-Number Summaries of Treatment Effects for RCTs with Binary Outcomes. Here, we show how one-number summaries and the entire distribution unit-level contrasts can be easily computed with comparisons().\nDr. Harrell discusses summaries from logistic regression models in the blog post above. He focuses on a context in which one is interested in comparing two groups, such as in randomized controlled trials. He highlights potential pitfalls of presenting “one-number summaries”, e.g., odds ratio and mean proportion difference. Finally, he recommends focusing on the entire distribution of proportion difference between groups.\nFor clarification, we use the following terms interchangeably in the context of logistic regression where the covariate of interest is categorical:\n\nContrast\nProportion difference\nRisk difference\nAbsolute risk reduction\n\n\nWe focus on subset data from the GUSTO-I study, where patients were randomly assigned to accelerated tissue plasminogen activator (tPA) or streptokinase (SK).\nLoad libraries, data and fit a covariate-adjusted logistic regression model.\n\nlibrary(marginaleffects)\nlibrary(modelsummary)\nlibrary(ggplot2)\nlibrary(rms)\n\nload(url(\n\"https://github.com/vincentarelbundock/modelarchive/raw/main/data-raw/gusto.rda\"\n))\n\ngusto &lt;- subset(gusto, tx %in% c(\"tPA\", \"SK\"))\ngusto$tx &lt;- factor(gusto$tx, levels = c(\"tPA\", \"SK\"))\n\nmod &lt;- glm(\n    day30 ~ tx + rcs(age, 4) + Killip + pmin(sysbp, 120) + lsp(pulse, 50) +\n    pmi + miloc + sex, family = \"binomial\",\n    data = gusto)\n\n\nAs usual, we can produce a one-number summary of the relationship of interest by exponentiating the coefficients, which yields an Odds Ratio (OR):\n\nmodelsummary(mod, exponentiate = TRUE, coef_omit = \"^(?!txSK)\") \n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\ntxSK    \n                  1.230    \n                \n\n        \n                  (0.065)  \n                \n\nNum.Obs.\n                  30510    \n                \n\nAIC     \n                  12428.6  \n                \n\nBIC     \n                  12553.5  \n                \n\nLog.Lik.\n                  -6199.317\n                \n\nF       \n                  173.216  \n                \n\nRMSE    \n                  0.24     \n                \n\n\n\n\n\n\nUnlike ORs, adjusted risk differences vary from individual to individual based on the values of the control variables. The comparisons() function can compute adjusted risk differences for every individual. Here, we display only the first 6 of them:\n\ncomparisons(\n    mod,\n    variables = \"tx\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S    2.5 %  97.5 %\n#&gt;  0.001074   0.000497 2.16  0.03060 5.0 0.000100 0.00205\n#&gt;  0.000857   0.000380 2.26  0.02410 5.4 0.000112 0.00160\n#&gt;  0.001780   0.000779 2.29  0.02229 5.5 0.000253 0.00331\n#&gt;  0.001137   0.000500 2.27  0.02302 5.4 0.000157 0.00212\n#&gt;  0.001366   0.000594 2.30  0.02143 5.5 0.000202 0.00253\n#&gt; --- 30500 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n#&gt;  0.002429   0.000808 3.00  0.00266  8.6 0.000844 0.00401\n#&gt;  0.012130   0.003900 3.11  0.00187  9.1 0.004486 0.01977\n#&gt;  0.036812   0.010361 3.55  &lt; 0.001 11.4 0.016505 0.05712\n#&gt;  0.022969   0.006975 3.29  &lt; 0.001 10.0 0.009298 0.03664\n#&gt;  0.049707   0.012843 3.87  &lt; 0.001 13.2 0.024535 0.07488\n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: SK - tPA\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, day30, tx, age, Killip, sysbp, pulse, pmi, miloc, sex\n\nPopulation-averaged (aka “marginal”) adjusted risk difference (see this vignette) can be obtained using the avg_*() functions or using the by argument:\n\navg_comparisons(mod, variables = \"tx\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S   2.5 % 97.5 %\n#&gt;    0.0111    0.00277 4.01   &lt;0.001 14.0 0.00566 0.0165\n#&gt; \n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: mean(SK) - mean(tPA)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThe comparisons() function above computed the predicted probability of mortality (day30==1) for each observed row of the data in two counterfactual cases: when tx is “SK”, and when tx is “tPA”. Then, it computed the differences between these two sets of predictions. Finally, it computed the population-average of risk differences.\nInstead of risk differences, we could compute population-averaged (marginal) adjusted risk ratios:\n\navg_comparisons(\n    mod,\n    variables = \"tx\",\n    comparison = \"lnratioavg\",\n    transform = exp)\n#&gt; \n#&gt;  Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      1.18   &lt;0.001 13.3  1.08   1.28\n#&gt; \n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: ln(mean(SK) / mean(tPA))\n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nPopulation-averaged (marginal) odds ratios:\n\navg_comparisons(\n    mod,\n    variables = \"tx\",\n    comparison = \"lnoravg\",\n    transform = \"exp\")\n#&gt; \n#&gt;  Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      1.19   &lt;0.001 13.4  1.09    1.3\n#&gt; \n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: ln(odds(SK) / odds(tPA))\n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nInstead of estimating one-number summaries, we can focus on unit-level proportion differences using comparisons(). This function applies the fitted logistic regression model to predict outcome probabilities for each patient, i.e., unit-level.\n\ncmp &lt;- comparisons(mod, variables = \"tx\")\ncmp\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S    2.5 %  97.5 %\n#&gt;  0.001074   0.000497 2.16  0.03060 5.0 0.000100 0.00205\n#&gt;  0.000857   0.000380 2.26  0.02410 5.4 0.000112 0.00160\n#&gt;  0.001780   0.000779 2.29  0.02229 5.5 0.000253 0.00331\n#&gt;  0.001137   0.000500 2.27  0.02302 5.4 0.000157 0.00212\n#&gt;  0.001366   0.000594 2.30  0.02143 5.5 0.000202 0.00253\n#&gt; --- 30500 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n#&gt;  0.002429   0.000808 3.00  0.00266  8.6 0.000844 0.00401\n#&gt;  0.012130   0.003900 3.11  0.00187  9.1 0.004486 0.01977\n#&gt;  0.036812   0.010361 3.55  &lt; 0.001 11.4 0.016505 0.05712\n#&gt;  0.022969   0.006975 3.29  &lt; 0.001 10.0 0.009298 0.03664\n#&gt;  0.049707   0.012843 3.87  &lt; 0.001 13.2 0.024535 0.07488\n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: SK - tPA\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, day30, tx, age, Killip, sysbp, pulse, pmi, miloc, sex\n\nShow the predicted probability for individual patients under both treatment alternatives.\n\nggplot(cmp, aes(predicted_hi, predicted_lo)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, linetype = 3) +\n  coord_fixed() +\n  labs(x = \"SK\", y = \"tPA\")\n\n\n\n\n\n\n\nWe can present the entire distribution of unit-level proportion differences an a cumulative distribution function:\n\nggplot(cmp, aes(estimate)) + stat_ecdf()\n\n\n\n\n\n\n\nOr the same information as a histogram with the mean and median.\n\nggplot(cmp, aes(estimate)) +\n  geom_histogram(bins = 100) +\n  geom_vline(xintercept = mean(cmp$estimate), color = \"orange\") +\n  geom_vline(xintercept = median(cmp$estimate), color = \"darkgreen\") +\n  labs(x = \"SK - TPA\", title = \"Distribution of unit-level contrasts\")\n\n\n\n\n\n\n\n\ncomparisons() performed the following calculations under the hood:\n\nd  &lt;- gusto\n\nd$tx = \"SK\"\npredicted_hi &lt;- predict(mod, newdata = d, type = \"response\")\n\nd$tx = \"tPA\"\npredicted_lo &lt;- predict(mod, newdata = d, type = \"response\")\n\ncomparison &lt;- predicted_hi - predicted_lo\n\nThe original dataset contains 30510 patients, thus comparisons() generates an output with same amount of rows.\n\nnrow(gusto)\n#&gt; [1] 30510\n\n\nnrow(cmp)\n#&gt; [1] 30510",
    "crumbs": [
      "Get started",
      "Case studies",
      "Logit"
    ]
  },
  {
    "objectID": "vignettes/logit.html#data",
    "href": "vignettes/logit.html#data",
    "title": "Logit",
    "section": "",
    "text": "We focus on subset data from the GUSTO-I study, where patients were randomly assigned to accelerated tissue plasminogen activator (tPA) or streptokinase (SK).\nLoad libraries, data and fit a covariate-adjusted logistic regression model.\n\nlibrary(marginaleffects)\nlibrary(modelsummary)\nlibrary(ggplot2)\nlibrary(rms)\n\nload(url(\n\"https://github.com/vincentarelbundock/modelarchive/raw/main/data-raw/gusto.rda\"\n))\n\ngusto &lt;- subset(gusto, tx %in% c(\"tPA\", \"SK\"))\ngusto$tx &lt;- factor(gusto$tx, levels = c(\"tPA\", \"SK\"))\n\nmod &lt;- glm(\n    day30 ~ tx + rcs(age, 4) + Killip + pmin(sysbp, 120) + lsp(pulse, 50) +\n    pmi + miloc + sex, family = \"binomial\",\n    data = gusto)\n\n\nAs usual, we can produce a one-number summary of the relationship of interest by exponentiating the coefficients, which yields an Odds Ratio (OR):\n\nmodelsummary(mod, exponentiate = TRUE, coef_omit = \"^(?!txSK)\") \n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\ntxSK    \n                  1.230    \n                \n\n        \n                  (0.065)  \n                \n\nNum.Obs.\n                  30510    \n                \n\nAIC     \n                  12428.6  \n                \n\nBIC     \n                  12553.5  \n                \n\nLog.Lik.\n                  -6199.317\n                \n\nF       \n                  173.216  \n                \n\nRMSE    \n                  0.24     \n                \n\n\n\n\n\n\nUnlike ORs, adjusted risk differences vary from individual to individual based on the values of the control variables. The comparisons() function can compute adjusted risk differences for every individual. Here, we display only the first 6 of them:\n\ncomparisons(\n    mod,\n    variables = \"tx\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S    2.5 %  97.5 %\n#&gt;  0.001074   0.000497 2.16  0.03060 5.0 0.000100 0.00205\n#&gt;  0.000857   0.000380 2.26  0.02410 5.4 0.000112 0.00160\n#&gt;  0.001780   0.000779 2.29  0.02229 5.5 0.000253 0.00331\n#&gt;  0.001137   0.000500 2.27  0.02302 5.4 0.000157 0.00212\n#&gt;  0.001366   0.000594 2.30  0.02143 5.5 0.000202 0.00253\n#&gt; --- 30500 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n#&gt;  0.002429   0.000808 3.00  0.00266  8.6 0.000844 0.00401\n#&gt;  0.012130   0.003900 3.11  0.00187  9.1 0.004486 0.01977\n#&gt;  0.036812   0.010361 3.55  &lt; 0.001 11.4 0.016505 0.05712\n#&gt;  0.022969   0.006975 3.29  &lt; 0.001 10.0 0.009298 0.03664\n#&gt;  0.049707   0.012843 3.87  &lt; 0.001 13.2 0.024535 0.07488\n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: SK - tPA\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, day30, tx, age, Killip, sysbp, pulse, pmi, miloc, sex\n\nPopulation-averaged (aka “marginal”) adjusted risk difference (see this vignette) can be obtained using the avg_*() functions or using the by argument:\n\navg_comparisons(mod, variables = \"tx\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S   2.5 % 97.5 %\n#&gt;    0.0111    0.00277 4.01   &lt;0.001 14.0 0.00566 0.0165\n#&gt; \n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: mean(SK) - mean(tPA)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThe comparisons() function above computed the predicted probability of mortality (day30==1) for each observed row of the data in two counterfactual cases: when tx is “SK”, and when tx is “tPA”. Then, it computed the differences between these two sets of predictions. Finally, it computed the population-average of risk differences.\nInstead of risk differences, we could compute population-averaged (marginal) adjusted risk ratios:\n\navg_comparisons(\n    mod,\n    variables = \"tx\",\n    comparison = \"lnratioavg\",\n    transform = exp)\n#&gt; \n#&gt;  Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      1.18   &lt;0.001 13.3  1.08   1.28\n#&gt; \n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: ln(mean(SK) / mean(tPA))\n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nPopulation-averaged (marginal) odds ratios:\n\navg_comparisons(\n    mod,\n    variables = \"tx\",\n    comparison = \"lnoravg\",\n    transform = \"exp\")\n#&gt; \n#&gt;  Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      1.19   &lt;0.001 13.4  1.09    1.3\n#&gt; \n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: ln(odds(SK) / odds(tPA))\n#&gt; Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\nInstead of estimating one-number summaries, we can focus on unit-level proportion differences using comparisons(). This function applies the fitted logistic regression model to predict outcome probabilities for each patient, i.e., unit-level.\n\ncmp &lt;- comparisons(mod, variables = \"tx\")\ncmp\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S    2.5 %  97.5 %\n#&gt;  0.001074   0.000497 2.16  0.03060 5.0 0.000100 0.00205\n#&gt;  0.000857   0.000380 2.26  0.02410 5.4 0.000112 0.00160\n#&gt;  0.001780   0.000779 2.29  0.02229 5.5 0.000253 0.00331\n#&gt;  0.001137   0.000500 2.27  0.02302 5.4 0.000157 0.00212\n#&gt;  0.001366   0.000594 2.30  0.02143 5.5 0.000202 0.00253\n#&gt; --- 30500 rows omitted. See ?avg_comparisons and ?print.marginaleffects --- \n#&gt;  0.002429   0.000808 3.00  0.00266  8.6 0.000844 0.00401\n#&gt;  0.012130   0.003900 3.11  0.00187  9.1 0.004486 0.01977\n#&gt;  0.036812   0.010361 3.55  &lt; 0.001 11.4 0.016505 0.05712\n#&gt;  0.022969   0.006975 3.29  &lt; 0.001 10.0 0.009298 0.03664\n#&gt;  0.049707   0.012843 3.87  &lt; 0.001 13.2 0.024535 0.07488\n#&gt; Term: tx\n#&gt; Type:  response \n#&gt; Comparison: SK - tPA\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, day30, tx, age, Killip, sysbp, pulse, pmi, miloc, sex\n\nShow the predicted probability for individual patients under both treatment alternatives.\n\nggplot(cmp, aes(predicted_hi, predicted_lo)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, linetype = 3) +\n  coord_fixed() +\n  labs(x = \"SK\", y = \"tPA\")\n\n\n\n\n\n\n\nWe can present the entire distribution of unit-level proportion differences an a cumulative distribution function:\n\nggplot(cmp, aes(estimate)) + stat_ecdf()\n\n\n\n\n\n\n\nOr the same information as a histogram with the mean and median.\n\nggplot(cmp, aes(estimate)) +\n  geom_histogram(bins = 100) +\n  geom_vline(xintercept = mean(cmp$estimate), color = \"orange\") +\n  geom_vline(xintercept = median(cmp$estimate), color = \"darkgreen\") +\n  labs(x = \"SK - TPA\", title = \"Distribution of unit-level contrasts\")\n\n\n\n\n\n\n\n\ncomparisons() performed the following calculations under the hood:\n\nd  &lt;- gusto\n\nd$tx = \"SK\"\npredicted_hi &lt;- predict(mod, newdata = d, type = \"response\")\n\nd$tx = \"tPA\"\npredicted_lo &lt;- predict(mod, newdata = d, type = \"response\")\n\ncomparison &lt;- predicted_hi - predicted_lo\n\nThe original dataset contains 30510 patients, thus comparisons() generates an output with same amount of rows.\n\nnrow(gusto)\n#&gt; [1] 30510\n\n\nnrow(cmp)\n#&gt; [1] 30510",
    "crumbs": [
      "Get started",
      "Case studies",
      "Logit"
    ]
  },
  {
    "objectID": "vignettes/marginalmeans.html",
    "href": "vignettes/marginalmeans.html",
    "title": "Marginal Means",
    "section": "",
    "text": "In the context of this package, “marginal means” refer to the values obtained by this three step process:\n\nConstruct a “grid” of predictor values with all combinations of categorical variables, and where numeric variables are held at their means.\nCalculate adjusted predictions for each cell in that grid.\nTake the average of those adjusted predictions across one dimension of the grid to obtain the marginal means.\n\nFor example, consider a model with a numeric, a factor, and a logical predictor:\n\nlibrary(marginaleffects)\n\ndat &lt;- mtcars\ndat$cyl &lt;- as.factor(dat$cyl)\ndat$am &lt;- as.logical(dat$am)\nmod &lt;- lm(mpg ~ hp + cyl + am, data = dat)\n\nUsing the predictions function, we set the hp variable at its mean and compute predictions for all combinations for am and cyl:\n\np &lt;- predictions(\n    mod,\n    newdata = datagrid(am = unique, cyl = unique))\n\nFor illustration purposes, it is useful to reshape the above results:\n\n\n\n\n\n\n\n\n\n\n\n\n\nam\n\n\n\n\ncyl\nTRUE\nFALSE\nMarginal means by cyl\n\n\n\n\n6\n21.0\n16.9\n19.0\n\n\n4\n25.0\n20.8\n22.9\n\n\n8\n21.4\n17.3\n19.4\n\n\nMarginal means by am\n22.5\n18.3\n\n\n\n\n\n\nThe marginal means by am and cyl are obtained by taking the mean of the adjusted predictions across cells. We can achieve the same results with the predictions() function, with datagrid() to specify a balanced grid, and the by argument to define the marginalization dimension:\n\npredictions(\n    mod,\n    by = \"am\",\n    newdata = datagrid(am = unique, cyl = unique))\n#&gt; \n#&gt;     am Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;   TRUE     22.5      0.834 26.9   &lt;0.001 528.6  20.8   24.1\n#&gt;  FALSE     18.3      0.785 23.3   &lt;0.001 397.4  16.8   19.9\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nAlternatively, we can use the convenient newdata=\"balanced\" argument:\n\npredictions(\n    mod,\n    by = \"cyl\",\n    newdata = \"balanced\")\n#&gt; \n#&gt;  cyl Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;    6     19.0       1.07 17.7   &lt;0.001 229.7  16.9   21.1\n#&gt;    4     22.9       1.36 16.9   &lt;0.001 209.7  20.2   25.5\n#&gt;    8     19.4       1.38 14.1   &lt;0.001 146.6  16.7   22.1\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nWe can of course marginalize over the interaction between more variables, by changing the by argument:\n\npredictions(\n    mod,\n    by = c(\"am\", \"cyl\"),\n    newdata = \"balanced\")\n#&gt; \n#&gt;     am cyl Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %  hp\n#&gt;   TRUE   6     21.0       1.21 17.3   &lt;0.001 221.4  18.7   23.4 147\n#&gt;   TRUE   4     25.0       1.18 21.2   &lt;0.001 329.3  22.7   27.3 147\n#&gt;   TRUE   8     21.4       1.83 11.7   &lt;0.001 103.2  17.9   25.0 147\n#&gt;  FALSE   6     16.9       1.27 13.3   &lt;0.001 130.9  14.4   19.4 147\n#&gt;  FALSE   4     20.8       1.76 11.8   &lt;0.001 105.1  17.4   24.2 147\n#&gt;  FALSE   8     17.3       1.12 15.5   &lt;0.001 176.8  15.1   19.5 147\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, am, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, hp, mpg\n\nThe same results can be achieved using the powerful emmeans package:\n\nlibrary(emmeans)\nemmeans(mod, specs = ~cyl)\n#&gt;  cyl emmean   SE df lower.CL upper.CL\n#&gt;  4     22.9 1.36 27     20.1     25.7\n#&gt;  6     19.0 1.07 27     16.8     21.2\n#&gt;  8     19.4 1.38 27     16.5     22.2\n#&gt; \n#&gt; Results are averaged over the levels of: am \n#&gt; Confidence level used: 0.95\nemmeans(mod, specs = ~cyl + am)\n#&gt;  cyl am    emmean   SE df lower.CL upper.CL\n#&gt;  4   FALSE   20.8 1.76 27     17.2     24.4\n#&gt;  6   FALSE   16.9 1.27 27     14.3     19.5\n#&gt;  8   FALSE   17.3 1.12 27     15.0     19.6\n#&gt;  4    TRUE   25.0 1.18 27     22.5     27.4\n#&gt;  6    TRUE   21.0 1.21 27     18.6     23.5\n#&gt;  8    TRUE   21.4 1.83 27     17.7     25.2\n#&gt; \n#&gt; Confidence level used: 0.95\n\n\nWhat should scientists report? Marginal means or average predictions?\nMany analysts ask this question, but unfortunately there isn’t a single answer. As explained above, marginal means are a special case of predictions, made on a perfectly balanced grid of categorical predictors, with numeric predictors held at their means, and marginalized with respect to some focal variables. Whether the analyst prefers to report this specific type of marginal means or another kind of average prediction will depend on the characteristics of the sample and the population to which they want to generalize.\nAfter reading this vignette and the discussion of emmeans in the Alternative Software vignette, you may want to consult with a statistician to discuss your specific real-world problem and make an informed choice.\n\nThe marginaleffects package offers several functions to plot how some quantities vary as a function of others:\n\n\nplot_predictions: Conditional adjusted predictions – how does the predicted outcome change as a function of regressors?\n\nplot_comparisons: Conditional comparisons – how do contrasts change as a function of regressors?\n\nplot_slopes: Conditional marginal effects – how does the slope change as a function of regressors?\n\nThere is no analogous function for marginal means. However, it is very easy to achieve a similar effect using the predictions() function, its by argument, and standard plotting functions. In the example below, we take these steps:\n\nEstimate a model with one continuous (hp) and one categorical regressor (cyl).\nCreate a perfectly “balanced” data grid for each combination of hp and cyl. This is specified by the user in the datagrid() call.\nCompute fitted values (aka “adjusted predictions”) for each cell of the grid.\nUse the by argument to take the average of predicted values for each value of hp, across margins of cyl.\nCompute standard errors around the averaged predicted values (i.e., marginal means).\nCreate symmetric confidence intervals in the usual manner.\nPlot the results.\n\n\nlibrary(ggplot2)\n\nmod &lt;- lm(mpg ~ hp + factor(cyl), data = mtcars)\n\np &lt;- predictions(mod,\n    by = \"hp\",\n    newdata = datagrid(\n        model = mod,\n        hp = seq(100, 120, length.out = 10),\n        cyl = mtcars$cyl))\n\nggplot(p) +\n    geom_ribbon(aes(hp, ymin = conf.low, ymax = conf.high), alpha = .2) +\n    geom_line(aes(hp, estimate))",
    "crumbs": [
      "Get started",
      "Case studies",
      "Marginal Means"
    ]
  },
  {
    "objectID": "vignettes/marginalmeans.html#marginal-means-vs.-average-predictions",
    "href": "vignettes/marginalmeans.html#marginal-means-vs.-average-predictions",
    "title": "Marginal Means",
    "section": "",
    "text": "What should scientists report? Marginal means or average predictions?\nMany analysts ask this question, but unfortunately there isn’t a single answer. As explained above, marginal means are a special case of predictions, made on a perfectly balanced grid of categorical predictors, with numeric predictors held at their means, and marginalized with respect to some focal variables. Whether the analyst prefers to report this specific type of marginal means or another kind of average prediction will depend on the characteristics of the sample and the population to which they want to generalize.\nAfter reading this vignette and the discussion of emmeans in the Alternative Software vignette, you may want to consult with a statistician to discuss your specific real-world problem and make an informed choice.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Marginal Means"
    ]
  },
  {
    "objectID": "vignettes/marginalmeans.html#plot-conditional-marginal-means",
    "href": "vignettes/marginalmeans.html#plot-conditional-marginal-means",
    "title": "Marginal Means",
    "section": "",
    "text": "The marginaleffects package offers several functions to plot how some quantities vary as a function of others:\n\n\nplot_predictions: Conditional adjusted predictions – how does the predicted outcome change as a function of regressors?\n\nplot_comparisons: Conditional comparisons – how do contrasts change as a function of regressors?\n\nplot_slopes: Conditional marginal effects – how does the slope change as a function of regressors?\n\nThere is no analogous function for marginal means. However, it is very easy to achieve a similar effect using the predictions() function, its by argument, and standard plotting functions. In the example below, we take these steps:\n\nEstimate a model with one continuous (hp) and one categorical regressor (cyl).\nCreate a perfectly “balanced” data grid for each combination of hp and cyl. This is specified by the user in the datagrid() call.\nCompute fitted values (aka “adjusted predictions”) for each cell of the grid.\nUse the by argument to take the average of predicted values for each value of hp, across margins of cyl.\nCompute standard errors around the averaged predicted values (i.e., marginal means).\nCreate symmetric confidence intervals in the usual manner.\nPlot the results.\n\n\nlibrary(ggplot2)\n\nmod &lt;- lm(mpg ~ hp + factor(cyl), data = mtcars)\n\np &lt;- predictions(mod,\n    by = \"hp\",\n    newdata = datagrid(\n        model = mod,\n        hp = seq(100, 120, length.out = 10),\n        cyl = mtcars$cyl))\n\nggplot(p) +\n    geom_ribbon(aes(hp, ymin = conf.low, ymax = conf.high), alpha = .2) +\n    geom_line(aes(hp, estimate))",
    "crumbs": [
      "Get started",
      "Case studies",
      "Marginal Means"
    ]
  },
  {
    "objectID": "vignettes/interactions.html",
    "href": "vignettes/interactions.html",
    "title": "Interactions, polynomials, and splines",
    "section": "",
    "text": "So far, the models that we have considered were relatively simple. In this chapter, we apply the same workflow, framework, and software introduced in Parts I and II of the book to interpret estimates from sligthly more complex specifications. Our goal is to address two related issues: heterogeneity and flexibility.\nHeterogeneity is present in virtually all empirical domains, when the effect of an intervention is stronger in some groups or contexts. For instance, a new treatment might significantly reduce blood pressure in younger adults, but have a weaker effect on older ones. Or a marketing campaign may increase sales in rural areas but not urban ones. This chapter shows how to use marginaleffects to report strata-specific effects, gauge if the impact of a variable is moderated by another, and gain a deeper understanding of context conditionality.\nFlexible statistical models can be useful when studying the complex (potentially non-linear) relationships which are common in many fields.1 In environmental science, for example, the relationship between temperature and crop yield is often non-linear: as temperatures rise, crop yields may initially increase due to optimal growing conditions but eventually decline as heat stress becomes detrimental. This chapter shows how the same toolkit used to study heterogeneity can be leveraged to develop insight about complex empirical patterns.\nWe will focus on three strategies to account for heterogeneity and increase the flexibility of our models: multiplicative interactions, polynomials, and splines.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Interactions, polynomials, and splines"
    ]
  },
  {
    "objectID": "vignettes/interactions.html#multiplicative-interactions",
    "href": "vignettes/interactions.html#multiplicative-interactions",
    "title": "Interactions, polynomials, and splines",
    "section": "Multiplicative interactions",
    "text": "Multiplicative interactions\nWe say that there is heterogeneity when the strength of the association between an explanator \\(X\\) and an outcome \\(Y\\) varies based on the value of a moderator \\(M\\). Typically, \\(M\\) is a variable which measures contextual elements, or characteristics of the individuals, groups, or units under observation. The key characteristic of a moderator is that it modifies the nature of the relationship between two other variables. \\(M\\) can strengthen, weaken, or even reverse the association between an independent variable \\(X\\) and the dependent variable \\(Y\\).\nOne common strategy to study moderation is to fit a statistical model with multiplicative interactions (Brambor, Clark, and Golder 2006; Kam and Jr. 2009; Clark and Golder 2023). This involves creating a new composite variable by multiplying the explanator (\\(X\\)) to the moderator (\\(M\\)). When this composite variable is included in the model specification, its associated coefficient will capture \\(M\\)’s role in effect modification. A popular specification for moderation analysis is this linear model:2\n\\[Y = \\beta_1 + \\beta_2 \\cdot M + \\beta_3 \\cdot X + \\beta_4 \\cdot X \\cdot  M + \\varepsilon,\\]\nwhere \\(Y\\) is the outcome, \\(X\\) is the cause of interest, and \\(M\\) is a contextual variable which moderates the relationship between \\(X\\) and \\(Y\\). In that model, \\(\\beta_3\\) characterizes the association between \\(X\\) and \\(Y\\) when \\(M=0\\). If the moderator \\(M\\) is non-zero, the strength of association between \\(X\\) and \\(Y\\) is represented by more than the simple \\(\\beta_3\\) coefficient. We see this by inspecting the partial derivative:\n\\[\\frac{\\partial Y}{\\partial X} = \\beta_3 + \\beta_4 \\cdot M\\]\nThis equation represents the slope of \\(Y\\) with respect to \\(X\\), that is, the extent to which \\(Y\\) is expected to change in response to a small change in \\(X\\). Clearly, this relationship now depends on more than just \\(X\\) itself: the strength of association between \\(X\\) on \\(Y\\) is driven in part by the value of \\(M\\). Thusly, this model specification allows the effect of an explanator to vary based on the value of a mediator.\nIn the next few sections, we will illustrate how to model heterogeneity using multiplicative interactions and how to interpret our parameter estimates using the software tools and conceptual framework in Parts I and II.\nCategorical-by-categorical\nThe first case to consider is when the association between a categorical explanator X and an outcome Y is moderated by a categorical variable M. This situation could occur when the effect of a binary treatment (treatment vs. control) on patient recovery (outcome) varies across different age groups (young, middle-aged, elderly).\nTo illustrate, we consider simulated data (Section 4) with three variables: the outcome Y is a binary variable; the treatment X is a binary variable; and the moderator M is a categorical variable with 3 levels (a, b, and c).\nWe load the data and fit a logistic regression model:3\n\nlibrary(marginaleffects)\nlibrary(ggplot2)\nlibrary(patchwork)\ndat &lt;- read.csv(\"data/interaction_01.csv\")\nmod &lt;- glm(Y ~ X * M, data = dat, family = binomial)\n\nAs is the case for many of the more complex models that we will consider, the coefficient estimates for this logit model with interactions are difficult to interpret on their own:\n\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Y ~ X * M, family = binomial, data = dat)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  0.43643    0.07195   6.065 1.32e-09 ***\n#&gt; X            0.26039    0.10337   2.519   0.0118 *  \n#&gt; Mb           0.56596    0.10699   5.290 1.23e-07 ***\n#&gt; Mc           0.96967    0.11087   8.746  &lt; 2e-16 ***\n#&gt; X:Mb         0.89492    0.17300   5.173 2.30e-07 ***\n#&gt; X:Mc         1.41219    0.21462   6.580 4.71e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 5284.2  on 4999  degrees of freedom\n#&gt; Residual deviance: 4808.5  on 4994  degrees of freedom\n#&gt; AIC: 4820.5\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 5\n\nThankfully, we can rely on the framework and tools introduced in Parts I and II of this book to make these results intelligible.\nMarginal predictions\nOur first cut is to compute the average predicted outcome for each combination of X and M. As explained in ?@sec-predictions, this is equivalent to computing fitted values for every row in the original data, and then aggregating those fitted values by subgroups.4\n\navg_predictions(mod, by = c(\"X\", \"M\"))\n#&gt; \n#&gt;  X M Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;  0 a    0.607    0.01716  35.4   &lt;0.001 909.5 0.574  0.641\n#&gt;  1 b    0.896    0.01058  84.7   &lt;0.001   Inf 0.876  0.917\n#&gt;  0 c    0.803    0.01334  60.2   &lt;0.001   Inf 0.777  0.829\n#&gt;  1 a    0.667    0.01647  40.5   &lt;0.001   Inf 0.635  0.700\n#&gt;  0 b    0.732    0.01555  47.0   &lt;0.001   Inf 0.701  0.762\n#&gt;  1 c    0.956    0.00707 135.2   &lt;0.001   Inf 0.942  0.970\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, X, M, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, rowid_dedup\n\nThere is considerable variation in the predicted value of Y across subgroups, going from 61% to 96%. This variation can be made starker by plotting our results with the plot_predictions() function:\n\nplot_predictions(mod, by = c(\"M\", \"X\"))\n\n\n\n\n\n\nFigure 1: Average predicted probability that Y=1 for different values of M and X.\n\n\n\n\nFigure 1 shows that, on average, the predicted probability that Y=1 is considerably higher when X=1. Moreover, the difference in predicted outcomes \\(P(Y=1|X=1,M=a)-P(Y=1|X=0,M=a)\\) seems smaller than \\(P(Y=1|X=1,M=c)-P(Y=1|X=0,M=c)\\). This is a hint that we may want to formally check for effect moderation.\nDoes X affect Y?\nWe can build on these preliminary findings by adopting a more explicitly counterfactual approach, using the comparisons() family of function. Recall, from ?@sec-comparisons, that we can compute an average counterfactual comparison by following these steps:\n\nModify the original dataset by fixing X to 0 for all observations, and compute predictions for every row.\nModify the original dataset by fixing X to 1 for all observations, and compute predictions for every row.\nCalculate the average difference between counterfactual predictions computed in steps 1 and 2.\n\nThese three steps can be taken with a single line of code:\n\navg_comparisons(mod, variables = \"X\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;     0.127     0.0112 11.3   &lt;0.001 96.0 0.105  0.149\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nOn average, moving from 0 to 1 on the X variable is associated with an increase of 0.127 on the outcome scale. Since we fit a logistic regression model, predictions are expressed on the probability scale. Thus, the estimate printed above suggests that the average treatment effect of X on Y is about 12.7 percentage points. This estimate is statistically distinguishable from zero, as the small \\(p\\) value attests.\nIs the effect of X on Y moderated by M?\nNow we can dive deeper, exploiting the multiplicative interaction in our model to interrogate heterogeneity. To see if the effect of X on Y depends on M, we make the same function call as above, but add the by argument:\n\navg_comparisons(mod, variables = \"X\", by = \"M\")\n#&gt; \n#&gt;  M Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;  a   0.0601     0.0238  2.53   0.0115  6.4 0.0135  0.107\n#&gt;  b   0.1649     0.0188  8.77   &lt;0.001 58.9 0.1280  0.202\n#&gt;  c   0.1529     0.0151 10.13   &lt;0.001 77.7 0.1233  0.182\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, M, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nOn average, moving from the control (X=0) to the treatment group (X=1) is associated with an increase of 6 percentage points for individuals in category A. The average estimated effect of X for individuals in category C is 15.\nAt first glance, these two estimated effects look different. But is the difference between 6 and 15 percentage points statistically significant? To answer this question, we can use the hypothesis argument and conduct a test of equality between the 1st and the 3rd estimate:\n\navg_comparisons(mod, variables = \"X\", by = \"M\", hypothesis = \"b3 - b1 = 0\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0928     0.0282 3.29   &lt;0.001 10.0 0.0376  0.148\n#&gt; \n#&gt; Term: b3-b1=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThe difference between the average estimated effect of X in categories C and A is: \\(0.1529 - 0.0601 = 0.0928\\). This difference is associated to a large \\(z\\) statistic and a small \\(p\\) value. Therefore, we can conclude that the difference is statistically significant; we can reject the null hypothesis that the effect of X is the same in sub-populations A and C.\nCategorical-by-continuous\nThe second case to consider is an interaction between a categorical explanator (X) and a continuous mediator (M). To illustrate, we fit a new model to simulated data (see Section 4):\n\ndat &lt;- read.csv(\"data/interaction_02.csv\")\nmod &lt;- glm(Y ~ X * M, data = dat, family = binomial)\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Y ~ X * M, family = binomial, data = dat)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.83981    0.04644 -18.083  &lt; 2e-16 ***\n#&gt; X            0.19222    0.06334   3.035  0.00241 ** \n#&gt; M           -0.75891    0.05049 -15.030  &lt; 2e-16 ***\n#&gt; X:M          0.35209    0.06753   5.213 1.85e-07 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 6367.0  on 4999  degrees of freedom\n#&gt; Residual deviance: 6011.4  on 4996  degrees of freedom\n#&gt; AIC: 6019.4\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\nConditional predictions\nIn the previous section, we started by compute average predictions for each combination of the interacted variable. When one of the variables is continuous and takes on many values (like M), it is not practical to report averages for every combination of X and M. Therefore, we focus on “conditional” estimates, obtained by calling the predictions() function. We use the datagrid() and fivenum() functions to create a grid of predictors based on Tukey’s five number summary of M:5\n\npredictions(mod, newdata = datagrid(X = c(0, 1), M = fivenum))\n#&gt; \n#&gt;  X        M Estimate Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;  0 -3.14813   0.8248   &lt;0.001  75.9 0.7766 0.8645\n#&gt;  0 -0.65902   0.4159   &lt;0.001  35.8 0.3921 0.4401\n#&gt;  0  0.00407   0.3009   &lt;0.001 241.6 0.2821 0.3204\n#&gt;  0  0.68359   0.2045   &lt;0.001 329.8 0.1848 0.2256\n#&gt;  0  3.53494   0.0287   &lt;0.001 240.8 0.0198 0.0414\n#&gt;  1 -3.14813   0.6532   &lt;0.001  16.6 0.5871 0.7139\n#&gt;  1 -0.65902   0.4063   &lt;0.001  45.3 0.3830 0.4300\n#&gt;  1  0.00407   0.3432   &lt;0.001 168.1 0.3244 0.3624\n#&gt;  1  0.68359   0.2838   &lt;0.001 206.5 0.2623 0.3063\n#&gt;  1  3.53494   0.1105   &lt;0.001 114.7 0.0820 0.1473\n#&gt; \n#&gt; Type:  invlink(link) \n#&gt; Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, X, M, Y\n\nThe results show considerable variation in the predicted \\(Pr(Y=1)\\), ranging from 0.0 to 0.8.\nInstead of making predictions for discrete values of the continuous moderator M, we can also draw a plot with that variable on the x-axis:\n\nplot_predictions(mod, condition = c(\"M\", \"X\"))\n\n\n\n\n\n\nFigure 2: Predicted probability that Y=1, for different values of X and M\n\n\n\n\nFigure 2 shows that predicted values of Y tend to be lower when M is large. That figure also suggests that the relationship between X and Y has a different character for different values of \\(M\\). When \\(M\\) is small, we see \\(Pr(Y=1|X=1)&lt;Pr(Y=1|X=0)\\). When \\(M\\) is large, the converse seems true.\nDoes X affect Y?\nMoving to the counterfactual analysis, we call avg_comparisons() to get an overall estimate of the effect of X on the predicted \\(Pr(Y=1)\\):\n\navg_comparisons(mod, variables = \"X\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S   2.5 % 97.5 %\n#&gt;    0.0284     0.0129 2.21   0.0273 5.2 0.00318 0.0536\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nOn average, moving from 0 to 1 on X increases the predicted probability that Y=1 by 2.8 percentage points.\nIs the effect of X on Y moderated by M?\nAs explained in ?@sec-comparisons, we can estimate the effect of X for different values of M by using the newdata argument and datagrid() function. Here, we measure the strength of association between X and Y for two different values of M: its minimum and maximum.\n\ncomparisons(mod, variables = \"X\", newdata = datagrid(M = range))\n#&gt; \n#&gt;      M Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;  -3.15  -0.1716     0.0395 -4.35   &lt;0.001 16.2 -0.2489 -0.0943\n#&gt;   3.53   0.0818     0.0174  4.70   &lt;0.001 18.5  0.0477  0.1159\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: 1 - 0\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, M, predicted_lo, predicted_hi, predicted, X, Y\n\nMoving from 0 to 1 on the X variable is associated with a change of -0.172 in the predicted Y when the moderator M is at its minimum. Moving from 0 to 1 on the X variable is associated with a change of 0.082 in the predicted Y when the moderator M is at its maximum. Both of these estimates are associated with small \\(p\\) values, so we can reject the null hypotheses that they are equal to zero.\nBoth estimates are different from zero, but are they different from one another? Is the effect of X on Y different when M takes on different values? To check this, we can add the hypothesis argument to the previous call:\n\ncomparisons(mod, \n  hypothesis = \"b2 - b1 = 0\",\n  variables = \"X\",\n  newdata = datagrid(M = range))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;     0.253     0.0546 4.64   &lt;0.001 18.2 0.146   0.36\n#&gt; \n#&gt; Term: b2-b1=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThis confirms that the estimates are statistically distinguishable. We can reject the null hypothesis that M has no moderating effect the relationship between X and Y.\nContinuous-by-continuous\nThe third case to consider is an interaction between two continuous numeric variables: X and M. To illustrate, we fit a new model to simulated data (see Section 4):\n\ndat &lt;- read.csv(\"data/interaction_03.csv\")\nmod &lt;- glm(Y ~ X * M, data = dat, family = binomial)\n\nConditional predictions\nAs in the previous cases, we begin by computing the predicted outcomes for different values of the predictors. In practice, the analyst should report predictions for predictor values that are meaningful to the domain of application. Here, we hold X and M to fixed arbitrary values:\n\npredictions(mod, newdata = datagrid(X = c(-2, 2), M = c(-1, 0, 1)))\n#&gt; \n#&gt;   X  M Estimate Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;  -2 -1   0.2586   &lt;0.001  78.0 0.2215 0.2995\n#&gt;  -2  0   0.1365   &lt;0.001 380.2 0.1189 0.1563\n#&gt;  -2  1   0.0669   &lt;0.001 326.1 0.0531 0.0839\n#&gt;   2 -1   0.2177   &lt;0.001 104.1 0.1837 0.2561\n#&gt;   2  0   0.4855    0.425   1.2 0.4500 0.5212\n#&gt;   2  1   0.7619   &lt;0.001  87.2 0.7213 0.7982\n#&gt; \n#&gt; Type:  invlink(link) \n#&gt; Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, X, M, Y\n\nRather than focus on arbitrary point estimates, we can plot predicted values to communicate a richer set of estimates. When calling plot_predictions() with these data, we obtain a plot of predicted outcomes with the primary variable of interest (X) on the x-axis, and different lines representing different values of the moderator (M).\n\nplot_predictions(mod, condition = c(\"X\", \"M\"))\n\n\n\n\n\n\nFigure 3: Predicted value of Y for different values of X and M\n\n\n\n\nWe can draw two preliminary conclusions from Figure 3. First, the predicted values of Y depend strongly on the value of X. Moving from left to right in the plot often has a strong effect on the heights of predicted probability curves. Second, M strongly moderates the relationship between X and Y. Indeed, for some values of M the relationship of interest completely flips. For example, when M is around -3, the relationship between X and Y is negative: an increase in X is associated with a decrease in Pr(Y=1). However, for all the other values of M that we considered, the relationship between X and Y is positive: an increase in X is associated withn an increase in Pr(Y=1).\nDoes X affect Y?\nTo measure the “effect” of X on the predicted outcome, we can compute the average slope with respect to our predictor of interest:\n\navg_slopes(mod, variables = \"X\")\n#&gt; \n#&gt;  Estimate Std. Error  z Pr(&gt;|z|)     S  2.5 % 97.5 %\n#&gt;    0.0857    0.00571 15   &lt;0.001 166.7 0.0745 0.0969\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(dY/dX)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nOn average, across all observed values of the moderator M, increasing X by one unit increases the predicted outcome by 0.086.6 This is interesting, but as suggested by Figure 3, there is strong heterogeneity in the relationship of interest, as a function of moderator M. Indeed, this is what we observe by computing slopes for different values of M:\nIs the effect of X on Y moderated by M?\nTo answer this question, we estimate slopes of Y with respect to X, for different values of the moderator M:\n\nslopes(mod, variables = \"X\", newdata = datagrid(M = fivenum))\n#&gt; \n#&gt;        M Estimate Std. Error     z Pr(&gt;|z|)     S    2.5 %  97.5 %\n#&gt;  -3.0788  -0.1525    0.01899 -8.03  &lt; 0.001  49.9 -0.18969 -0.1153\n#&gt;  -0.6759   0.0200    0.00756  2.65  0.00816   6.9  0.00519  0.0348\n#&gt;   0.0137   0.0913    0.00695 13.14  &lt; 0.001 128.7  0.07768  0.1049\n#&gt;   0.6906   0.1698    0.00950 17.86  &lt; 0.001 234.7  0.15113  0.1884\n#&gt;   3.4711   0.5426    0.03363 16.14  &lt; 0.001 192.2  0.47673  0.6085\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, M, predicted_lo, predicted_hi, predicted, X, Y\n\nThe results from this command confirm the intuition we developed based on Figure 3. When M is strongly negative (-3), the slope is negative: increasing X results in a reduction of Y. However, for the other 4 values of M we consider, the slope is positive. This is consistent with Figure 3, which shows one line with downward slope, and four lines with upward slopes.\nFor a more fine grained analysis, we can plot the slope of Y with respect to X for all observed values of the moderator M:\n\nplot_slopes(mod, variables = \"X\", condition = \"M\") +\n    geom_hline(yintercept = 0, linetype = \"dotted\")\n\n\n\n\n\n\nFigure 4: Slope of Y with respect to X, for different values of the moderator M.\n\n\n\n\nFigure 4 plot shows that when the moderator M is below -1, the relationship between X and Y is negative: increasing X decreases Y. However, when M rises to about -1, the relationship between X and Y becomes positive: increasing X increases Y.\nWe can confirm that this moderation effect is statistically significant using the hypothesis argument:\n\nslopes(mod,\n  hypothesis = \"b2 - b1 = 0\", \n  variables = \"X\",\n  newdata = datagrid(M = range))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n#&gt;     0.695     0.0475 14.6   &lt;0.001 158.8 0.602  0.788\n#&gt; \n#&gt; Term: b2-b1=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThe \\(\\frac{\\partial Y}{\\partial X}\\) slope is larger when evaluated at maximum M, than at minimum M. Therefore, we can reject the null hypothesis that M has no moderating effect on the relationship between X and Y.\nMultiple interactions\nThe fourth case to consider is when more than two variables are included in multiplicative interactions. Such models have serious downsides: they can overfit the data, and they impose major costs in terms of statistical power, typically requiring considerably larger sample sizes than models without interaction. On the upside, models with multiple interactions allow more flexibility in modelling, and they can capture complex patterns of moderation between regressors.\nModels with several multiplicative interactions do not pose any particular interpretation challenge, since the tools and workflows introduced in this book can be applied to these models in straightforward fashion. Consider this model, fit to simulated data, with three binary variables multipled to each other:\n\ndat &lt;- read.csv(\"data/interaction_04.csv\")\nmod &lt;- glm(Y ~ X * M1 * M2, data = dat, family = binomial)\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = Y ~ X * M1 * M2, family = binomial, data = dat)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)  -1.0209     0.0908 -11.244  &lt; 2e-16 ***\n#&gt; X             0.4632     0.1229   3.768 0.000165 ***\n#&gt; M1           -0.7954     0.1470  -5.411 6.26e-08 ***\n#&gt; M2            0.5788     0.1217   4.755 1.98e-06 ***\n#&gt; X:M1          0.6746     0.1890   3.569 0.000358 ***\n#&gt; X:M2         -0.9649     0.1716  -5.623 1.87e-08 ***\n#&gt; M1:M2         0.4046     0.1890   2.141 0.032297 *  \n#&gt; X:M1:M2       0.1976     0.2542   0.777 0.436869    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 6176.5  on 4999  degrees of freedom\n#&gt; Residual deviance: 6025.2  on 4992  degrees of freedom\n#&gt; AIC: 6041.2\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\nOnce again, the coefficient estimates of this logistic regression are difficult to interpret on their own, so we use functions from the marginaleffects package.\nMarginal predictions\nAs before, we can compute and display marginal predicted outcomes in any subgroup of interest, using the avg_predictions() or plot_predictions():\n\nplot_predictions(mod, by = c(\"X\", \"M1\", \"M2\"))\n\n\n\n\n\n\nFigure 5: Average predicted outcomes for different combinations of X, M1, and M2.\n\n\n\n\nDoes X affect Y?\nAs before, we can estimate the average change in Y associated with a change from 0 to 1 in the X variable using the avg_comparisons() function:\n\navg_comparisons(mod, variables = \"X\")\n#&gt; \n#&gt;  Estimate Std. Error   z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;    0.0657     0.0129 5.1   &lt;0.001 21.5 0.0405  0.091\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThis suggests that, on average, moving from the control (0) to the treatment (1) group is associated with an increase of 6.6 percentage points in the probability that Y equals 1. The \\(p\\) value is small, which implies that we can reject the null hypothesis that X has no effect on the predicted outcome.\nIs the effect of X on Y moderated by M1?\nWe can also estimate how the effect of X varies based on different values of moderator M1:\n\navg_comparisons(mod, variables = \"X\", by = \"M1\")\n#&gt; \n#&gt;  M1 Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 % 97.5 %\n#&gt;   0 -0.00703     0.0185 -0.38    0.704  0.5 -0.0433 0.0292\n#&gt;   1  0.14026     0.0179  7.83   &lt;0.001 47.6  0.1052 0.1754\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, M1, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nThe results suggest that the change in Y associated with a change in X differs based on the value of M1: -0.0070 vs. 0.1403. By using the hypothesis argument, we can confirm that the difference between these two estimated effect sizes is statistically significant:\n\navg_comparisons(mod, \n  variables = \"X\",\n  by = \"M1\",\n  hypothesis = \"b2 - b1 = 0\")\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;     0.147     0.0258 5.72   &lt;0.001 26.5 0.0968  0.198\n#&gt; \n#&gt; Term: b2-b1=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nDoes the moderating effect of M1 depend on M2?\nThe last question that we pose is more complex. Above, we established that:\n\nOn average, X affects the predicted value of Y.\nOn average, the value of M1 modifies the strength of association between X and Y.\n\nNow we ask if M2 changes the way in which M1 moderates the effect of X on Y. The difference is subtle but important: we are asking if the moderation effect of M1 is itself moderated by M2.\nThe following code computes the average difference in predicted Y associated with a change in X, for every combination of moderators M1 and M2. Each row represents the average effect of X at different points in the sample space:\n\navg_comparisons(mod, \n    variables = \"X\", \n    by = c(\"M2\", \"M1\"))\n#&gt; \n#&gt;  M2 M1 Estimate Std. Error     z Pr(&gt;|z|)    S   2.5 %  97.5 %\n#&gt;   0  0   0.0992     0.0261  3.80  &lt; 0.001 12.8  0.0481  0.1504\n#&gt;   0  1   0.1967     0.0236  8.35  &lt; 0.001 53.7  0.1505  0.2429\n#&gt;   1  0  -0.1111     0.0262 -4.24  &lt; 0.001 15.4 -0.1625 -0.0597\n#&gt;   1  1   0.0834     0.0270  3.09  0.00203  8.9  0.0304  0.1363\n#&gt; \n#&gt; Term: X\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, M2, M1, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nWhen we hold the moderators fixed at M1=0 and M2=0, changing the value of X from 0 to 1 changes the predicted value of Y by 9.9 percentage points. When we hold the moderators fixed at M1=0 and M2=1, changing the value of X from 0 to 1 changes the predicted value of Y by -11.1 percentage points.\nNow, imagine that we hold M2 constant at 0. We can determine if the effect of X is moderated by M1 by using the hypothesis argument to compare estimates in rows 1 and 2. This shows that the estimated effect size of X is larger when M1=1 than when M1=0, holding M2 at 0.\n\navg_comparisons(mod, \n    hypothesis = \"b2 - b1 = 0\",\n    variables = \"X\", \n    by = c(\"M2\", \"M1\"))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n#&gt;    0.0975     0.0351 2.77  0.00555 7.5 0.0286  0.166\n#&gt; \n#&gt; Term: b2-b1=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nSimilarly, imagine that we hold M2 constant at 1. We can determine if the effect of X is moderated by M1 by comparing estimates in rows 3 and 4. This hypothesis test shows that the effect size of X is larger when M1=1 than when M1=0, holding M2 at 1.\n\navg_comparisons(mod, \n    hypothesis = \"b4 - b3 = 0\",\n    variables = \"X\", \n    by = c(\"M2\", \"M1\"))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;     0.194     0.0377 5.16   &lt;0.001 22.0 0.121  0.268\n#&gt; \n#&gt; Term: b4-b3=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThe last two estimates can be interpreted as measuring the extent to which M1 acts as a moderator, holding M2 at different values. To answer the question of whether M2 moderates the moderation effect of M1, we can specify the hypothesis as a difference in differences:\n\navg_comparisons(mod, \n    hypothesis = \"(b2 - b1) - (b4 - b3) = 0\",\n    variables = \"X\", \n    by = c(\"M2\", \"M1\"))\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %  97.5 %\n#&gt;    -0.097     0.0515 -1.88   0.0597 4.1 -0.198 0.00396\n#&gt; \n#&gt; Term: (b2-b1)-(b4-b3)=0\n#&gt; Type:  response \n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThis suggests that M2 may have a second order moderation effect, but we cannot completely completely rule out the null hypothesis because the \\(p\\) value does not cross conventional thresholds of statistical significance (\\(p\\)=0.0597).\nHypothesis tests: effect vs. moderation\nTODO: Two research questions are often conflated:\n\nEffect: Does \\(X\\) affect \\(Y\\)?\n\nIs the \\(\\frac{\\partial Y}{\\partial X}\\) slope different from 0 when \\(M=m\\)?\n\n\nModeration: Does \\(M\\) moderate the relationship between \\(X\\) and \\(Y\\)?\n\nIs the \\(\\frac{\\partial Y}{\\partial X}\\) different when \\(M=m\\) and \\(M=n\\)?",
    "crumbs": [
      "Get started",
      "Case studies",
      "Interactions, polynomials, and splines"
    ]
  },
  {
    "objectID": "vignettes/interactions.html#polynomial-regression",
    "href": "vignettes/interactions.html#polynomial-regression",
    "title": "Interactions, polynomials, and splines",
    "section": "Polynomial regression",
    "text": "Polynomial regression\nPolynomial regression is an extension of linear regression that allows for modeling the relationship between a dependent variable \\(Y\\) and an independent variable \\(X\\) as an nth-degree polynomial. While the model specification remains linear in the coefficients, it is polynomial in the value of \\(X\\). This type of regression is useful when the data shows a non-linear relationship that a straight line cannot adequately capture.\nThe general form of a polynomial regression model is:\n\\[Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\cdots + \\beta_n X^n + \\varepsilon,\\]\nwhere \\(Y\\) is the dependent variable, \\(X\\) is the independent variable, \\(\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_n\\) are the coefficients to be estimated, \\(n\\) is the degree of the polynomial, and \\(\\varepsilon\\) represents the error term. For instance, a second-degree (quadratic) polynomial regression equation can be written as:\n\\[Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\varepsilon\\]\nThis can be treated as a linear regression problem by constructing new variables \\(Z_1=X\\), \\(Z_2=X^2\\), etc. The model then becomes \\(Y=\\beta_0+\\beta_1\\cdot Z_1+\\beta_2\\cdot Z_2+\\varepsilon\\), which can be estimated using standard methods like ordinary least squares.\nPolynomial regression offers several key advantages, particularly in its flexibility and ability to fit a wide range of curves, simply by adjusting the degree of the polynomial. As a result, polynomial regression can reveal underlying patterns in the data that are not immediately apparent with simpler models.\nThis approach also has notable disadvantages. One significant issue is its potential for overfitting, especially when the \\(n\\) order is high. Moreover, polynomial regression can suffer from unreliable extrapolation, where predictions made outside the range of the training data can become erratic and unrealistic. Consequently, while polynomial regression can be powerful, careful consideration must be given to the degree of the polynomial to balance fit and generalization effectively.\nPolynomial regression can be viewed simply as a model specification with several variables interacted with themselves. As such, it can be interpreted using exactly the same tools discussed in the earlier part of this chapter. To illustrate, we consider two simple data generating processes adapted from Hainmueller, Mummolo, and Xu (2019). The first is:\n\\[\\begin{align*}\nY = 2.5 - X^2 + \\nu, && \\text{where }\\nu\\sim N(0,1),X\\sim U(-3,3)\n\\end{align*}\\]\nIf we fit a linear model with only \\(X\\) as predictor, the line of best fit will not be a good representation of the data. However, a cubic polynomial regression can easily detect the curvilinear relationship between \\(X\\) and \\(Y\\). In R and Python, we can use similar syntax to specify polynomials directly in the model formula:7\n\nlibrary(patchwork)\ndat &lt;- read.csv(\"data/polynomial_01.csv\")\nmod_linear &lt;- lm(Y ~ X, data = dat)\nmod_cubic &lt;- lm(Y ~ X + I(X^2) + I(X^3), data = dat)\np1 &lt;- plot_predictions(mod_linear, condition = \"X\", points = .05) + ggtitle(\"Linear\")\np2 &lt;- plot_predictions(mod_cubic, condition = \"X\", points = .05) + ggtitle(\"Cubic\")\np1 + p2\n\n\n\n\n\n\nFigure 6: Modelling a curvilinear relationship with linear or polynomial regression.\n\n\n\n\nClearly, the model with polynomials makes much better predictions, ones that capture the curvilinear relationship between \\(X\\) and \\(Y\\). We can now evaluate the strength of association between \\(X\\) and \\(Y\\) by computing the slope of the outcome equation with respect to \\(X\\), for different values of \\(X\\):\n\nslopes(mod_cubic, variables = \"X\", newdata = datagrid(X = c(-2, 0, 2)))\n#&gt; \n#&gt;  Term  X Estimate Std. Error        z Pr(&gt;|z|)   S   2.5 %  97.5 %\n#&gt;     X -2  3.98616     0.0351  113.596   &lt;0.001 Inf  3.9174  4.0549\n#&gt;     X  0  0.00478     0.0226    0.211    0.833 0.3 -0.0396  0.0491\n#&gt;     X  2 -3.97639     0.0359 -110.705   &lt;0.001 Inf -4.0468 -3.9060\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, X, predicted_lo, predicted_hi, predicted, Y\n\nWhen \\(X\\) is negative (-2), the slope is positive which indicates that an increase of \\(X\\) is associated with an increase in \\(Y\\). When \\(X\\) is around 0, the slope is null, which indicates that the strength of association between \\(X\\) and \\(Y\\) is null (or very weak). When \\(X\\) is around 0, changing \\(X\\) by a small amount will have almost no effect on \\(Y\\). When \\(X\\) is positive (-2), the slope is negative. This indicates that increasing \\(X\\) will result in a decrease in \\(Y\\).\nNow, consider a sligthly different data generating process, where a binary moderator \\(D\\) changes the nature of the relationship between \\(X\\) and \\(Y\\):8\n\\[\\begin{align*}\nY = 2.5 - X^2 - 5 \\cdot M + 2 \\cdot M \\cdot X^2 + \\nu &&  \\text{where }\\nu\\sim N(0,1),X\\sim U(-3,3)\n\\end{align*}\\]\nIf we simply fit a cubic regression, without accounting for \\(M\\), our predictions will be inaccurate. However, if we interact the moderator \\(M\\) with all polynomial terms (using parentheses as a shortcut for the distributive property), we can get an excellent fit for the curvilinear and differentiated relationship between \\(X\\) and \\(Y\\):\n\ndat &lt;- read.csv(\"data/polynomial_02.csv\")\n\n# cubic\nmod_cubic &lt;- lm(Y ~ X + I(X^2) + I(X^3), data = dat)\n\n# cubic + interaction\nmod_cubic_int &lt;- lm(Y ~ M * (X + I(X^2) + I(X^3)), data = dat)\n\np1 &lt;- plot_predictions(mod_cubic, condition = \"X\", points = .05)\np2 &lt;- plot_predictions(mod_cubic_int, condition = c(\"X\", \"M\"), points = .1)\np1 + p2\n\n\n\n\n\n\n\nOf course, we can also estimate the slope of the outcome equation for different values of M and X:\n\nslopes(mod_cubic_int,\n  variables = \"X\",\n  newdata = datagrid(M = c(0, 1), X = fivenum))\n#&gt; \n#&gt;  Term M       X Estimate Std. Error       z Pr(&gt;|z|)     S    2.5 %  97.5 %\n#&gt;     X 0 -2.9974   5.7529     0.2588  22.228   &lt;0.001 361.2  5.24566  6.2602\n#&gt;     X 0 -1.4845   2.9009     0.0582  49.874   &lt;0.001   Inf  2.78693  3.0149\n#&gt;     X 0 -0.0586   0.1324     0.0667   1.986    0.047   4.4  0.00174  0.2631\n#&gt;     X 0  1.4788  -2.9405     0.0575 -51.103   &lt;0.001   Inf -3.05323 -2.8277\n#&gt;     X 0  2.9843  -6.0373     0.2540 -23.769   &lt;0.001 412.4 -6.53517 -5.5395\n#&gt;     X 1 -2.9974  -6.1017     0.2528 -24.137   &lt;0.001 425.2 -6.59716 -5.6062\n#&gt;     X 1 -1.4845  -2.9061     0.0563 -51.628   &lt;0.001   Inf -3.01646 -2.7958\n#&gt;     X 1 -0.0586  -0.0461     0.0634  -0.727    0.467   1.1 -0.17026  0.0781\n#&gt;     X 1  1.4788   2.8730     0.0595  48.279   &lt;0.001   Inf  2.75637  2.9896\n#&gt;     X 1  2.9843   5.5654     0.2592  21.469   &lt;0.001 337.2  5.05733  6.0735\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, M, X, predicted_lo, predicted_hi, predicted, Y",
    "crumbs": [
      "Get started",
      "Case studies",
      "Interactions, polynomials, and splines"
    ]
  },
  {
    "objectID": "vignettes/interactions.html#splines",
    "href": "vignettes/interactions.html#splines",
    "title": "Interactions, polynomials, and splines",
    "section": "Splines",
    "text": "Splines\nTODO:\n\nWhat is a spline?\nWhat is a GAM?\n\n\nlibrary(mgcv)\n\n# mgcv::gam should treat M as categorical (factor)\nmod &lt;- gam(Y ~ s(X, by = factor(M)) + M, data = dat)\n\nplot_predictions(mod, condition = c(\"X\", \"M\"), points = .1)\n\n\n\n\n\n\n\n\nslopes(mod, variables = \"X\", newdata = datagrid(M = c(0, 1), X = c(-1, 0, 1)))\n#&gt; \n#&gt;  Term M  X Estimate Std. Error      z Pr(&gt;|z|)    S  2.5 % 97.5 %\n#&gt;     X 0 -1    2.134      0.212 10.087   &lt;0.001 77.1  1.719  2.548\n#&gt;     X 0  0   -0.141      0.212 -0.662    0.508  1.0 -0.557  0.276\n#&gt;     X 0  1   -1.883      0.201 -9.386   &lt;0.001 67.1 -2.276 -1.489\n#&gt;     X 1 -1   -1.879      0.201 -9.341   &lt;0.001 66.5 -2.274 -1.485\n#&gt;     X 1  0    0.113      0.215  0.526    0.599  0.7 -0.308  0.535\n#&gt;     X 1  1    2.025      0.211  9.595   &lt;0.001 70.0  1.612  2.439\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, M, X, predicted_lo, predicted_hi, predicted, Y",
    "crumbs": [
      "Get started",
      "Case studies",
      "Interactions, polynomials, and splines"
    ]
  },
  {
    "objectID": "vignettes/interactions.html#sec-interactions_simulation",
    "href": "vignettes/interactions.html#sec-interactions_simulation",
    "title": "Interactions, polynomials, and splines",
    "section": "Data simulation",
    "text": "Data simulation\nThis code generates the simulated datasets used in this chapter:\n\n# Multiplicative interactions: X x M\nset.seed(1024)\nN &lt;- 5000\nX &lt;- rbinom(N, 1, .5)\nM &lt;- sample(c(\"a\", \"b\", \"c\"), N, replace = TRUE)\nb &lt;- runif(8, -1, 1)\nY &lt;- rbinom(N, 1, prob = plogis(\n  b[1] + b[2] * X +\n  b[3] * (M == \"b\") + b[4] * (M == \"b\") + b[5] * (M == \"c\") +\n  b[6] * X * (M == \"a\") + b[7] * X + (M == \"b\") + \n  b[8] * X * (M == \"c\")\n))\ndat &lt;- data.frame(Y, X, M)\nwrite.csv(dat, \"data/interaction_01.csv\")\n\n# Multiplicative interactions: X x M\nset.seed(1024)\nN &lt;- 5000\nX &lt;- rbinom(N, 1, .5)\nM &lt;- rnorm(N)\nb &lt;- runif(4, -1, 1)\nY &lt;- rbinom(N, 1, prob = plogis(\n  b[1] + b[2] * X + b[3] * M + b[4] * X * M\n))\ndat &lt;- data.frame(Y, X, M)\nwrite.csv(dat, \"data/interaction_02.csv\")\n\n# Multiplicative interactions: X x M\nset.seed(1024)\nN &lt;- 5000\nX &lt;- rnorm(N)\nM &lt;- rnorm(N)\nb &lt;- runif(4, -1, 1)\nY &lt;- rbinom(N, 1, prob = plogis(\n  b[1] + b[2] * X + b[3] * M + b[4] * X * M\n))\ndat &lt;- data.frame(Y, X, M)\nwrite.csv(dat, \"data/interaction_03.csv\")\n\n# Multiplicative interactions: X x M1 x M2\nset.seed(1024)\nN &lt;- 5000\nX &lt;- rbinom(N, 1, .5)\nM1 &lt;- rbinom(N, 1, .5)\nM2 &lt;- rbinom(N, 1, .5)\nb &lt;- runif(8, -1, 1)\nY &lt;- rbinom(N, 1, prob = plogis(\n  b[1] +\n  b[2] * X + b[3] * M1 + b[4] * M2 + \n  b[5] * X * M1 + b[6] * X * M2 + b[7] * M1 * M2 + \n  b[8] * X * M1 * M2\n))\ndat &lt;- data.frame(Y, X, M1, M2)\nwrite.csv(dat, \"data/interaction_04.csv\")\n\n# Polynomial regression: X and Y\nset.seed(1024)\nN &lt;- 1e3\nFUN &lt;- function(X) 2.5 - X^2\nX &lt;- runif(N, min = -3, max = 3)\nY &lt;- FUN(X) + rnorm(N, sd = .5)\ndat &lt;- data.frame(X, Y)\nwrite.csv(dat, \"data/polynomial_01.csv\")\n\n# Polynomial regression: X, D, and Y\nset.seed(1024)\nN &lt;- 1e3\nX &lt;- runif(N, min = -3, max = 3)\nM &lt;- rbinom(N, size = 1, prob = .5)\nY &lt;- 2.5 - X^2 - 5 * M + 2 * M * X^2 + rnorm(N, .5)\ndat &lt;- data.frame(X, M, Y)\nwrite.csv(dat, \"data/polynomial_02.csv\")",
    "crumbs": [
      "Get started",
      "Case studies",
      "Interactions, polynomials, and splines"
    ]
  },
  {
    "objectID": "vignettes/interactions.html#footnotes",
    "href": "vignettes/interactions.html#footnotes",
    "title": "Interactions, polynomials, and splines",
    "section": "Footnotes",
    "text": "Footnotes\n\nOne downside of estimating more flexible models is that they may overfit the data. See TODO.↩︎\nIn most cases, it is important to include all constitutive terms in addition to interactions. For example, if a model includes a multiplication between three variables \\(X\\cdot W \\cdot Z\\), one would typically want to also include \\(X\\cdot W, X\\cdot Z, W\\cdot Z, X, W,\\) and \\(Z\\). See Clark and Golder (2023) for details.↩︎\nNote that when we insert an expression like X*M in the formula syntax, we instruct R to create binary variables for every level of the M predictor, and also to interact each of those levels with the X variable. Under the hood, R will multiply treatment and moderator to create the appropriate composite variables (X\\(\\times\\)Mb and X\\(\\times\\)Mc), and it will automatically omit one reference category to avoid perfect collinearity.↩︎\nAn alternative would be to compute predictions on a different grid (ex: “balanced”) before aggregating. This could be achieved by calling: avg_predictions(mod, newdata=\"balanced\", by=c(\"X\",\"M\"))↩︎\nThese five numbers correspond to elements of a standard boxplot: minimum, lower-hinge, median, upper-hinge, and maximum.↩︎\nRecall, from ?@sec-slopes, that this interpretation is valid for small changes in the neighborhoods where slopes are evaluated.↩︎\nFor marginaleffects to work properly in this context, it is important to specify the polynomials in the model-fitting formula. Users should not hard-code the values by creating new variables in the dataset before fitting the model.↩︎\nThis data generating process is adapted from Hainmueller, Mummolo, and Xu (2019).↩︎",
    "crumbs": [
      "Get started",
      "Case studies",
      "Interactions, polynomials, and splines"
    ]
  },
  {
    "objectID": "vignettes/numpyro.html",
    "href": "vignettes/numpyro.html",
    "title": "NumPyro",
    "section": "",
    "text": "The Python programming language offers several powerful libraries for (bayesian) statistical analysis, such as NumPyro and PyMC. This vignette shows how to use the the full power of marginaleffects to analyze and interpret the results of models estimated by Markov Chain Monte Carlo using the NumPyro Python library.\n\nTo begin, we load the reticulate package which allows us to interact with the Python interpreter from an R session. Then, we write a NumPyro model and we load it to memory using the source_python() function. The important functions to note in the Python code are:\n\n\nload_df() downloads data on pulmonary fibrosis.\n\nmodel() defines the NumPyro model.\n\nfit_mcmc_model() fits the model using Markov Chain Monte Carlo.\n\npredict_mcmc(): accepts a data frame and returns a matrix of draws from the posterior distribution of adjusted predictions (fitted values).\n\n\nlibrary(reticulate)\nlibrary(marginaleffects)\n\nmodel &lt;- '\n## Model code adapted from the NumPyro documtation under Apache License:\n## https://num.pyro.ai/en/latest/tutorials/bayesian_hierarchical_linear_regression.html\n\nimport pandas as pd\nimport numpy as np\nimport numpyro\nfrom numpyro.infer import SVI, Predictive, MCMC,NUTS, autoguide, TraceMeanField_ELBO\nimport numpyro.distributions as dist\nfrom numpyro.infer.initialization import init_to_median, init_to_uniform,init_to_sample\nfrom jax import random\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\ndef load_df():\n    train = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/osic_pulmonary_fibrosis.csv\")\n    return train\n\n\ndef model(data, predict = False):\n    FVC_obs = data[\"FVC\"].values  if predict == False else None\n    patient_encoder = LabelEncoder()\n    Age_obs = data[\"Age\"].values\n    patient_code = patient_encoder.fit_transform(data[\"Patient\"].values)\n    μ_α = numpyro.sample(\"μ_α\", dist.Normal(0.0, 500.0))\n    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(100.0))\n\n    age = numpyro.sample(\"age\", dist.Normal(0.0, 500.0))\n\n    n_patients = len(np.unique(patient_code))\n\n    with numpyro.plate(\"plate_i\", n_patients):\n        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n\n    σ = numpyro.sample(\"σ\", dist.HalfNormal(100.0))\n    FVC_est = α[patient_code] + age * Age_obs\n\n    with numpyro.plate(\"data\", len(patient_code)):\n        numpyro.sample(\"obs\", dist.Normal(FVC_est, σ), obs=FVC_obs)\n\n\ndef fit_mcmc_model(train_df, samples = 1000):\n    numpyro.set_host_device_count(4)\n    rng_key = random.PRNGKey(0)\n    mcmc = MCMC(\n        NUTS(model),\n        num_samples=samples,\n        num_warmup=1000,\n        progress_bar=True,\n        num_chains = 4\n        )\n    \n    mcmc.run(rng_key, train_df)\n\n    posterior_draws = mcmc.get_samples()\n\n    with open(\"mcmc_posterior_draws.pickle\", \"wb\") as handle:\n        pickle.dump(posterior_draws, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\ndef predict_mcmc(data):\n\n    with open(\"mcmc_posterior_draws.pickle\", \"rb\") as handle:\n        posterior_draws = pickle.load(handle)\n\n    predictive = Predictive(model = model,posterior_samples=posterior_draws)\n    samples = predictive(random.PRNGKey(1), data, predict = True)\n    y_pred = samples[\"obs\"]\n    # transpose so that each column is a draw and each row is an observation\n    y_pred = np.transpose(np.array(y_pred))\n\n    return y_pred \n'\n\n## save python script to temp file\ntmp &lt;- tempfile()\ncat(model, file = tmp)\n\n## load functions\nsource_python(tmp)\n\n## download data\ndf &lt;- load_df()\n\n## fit model\nfit_mcmc_model(df)\n\n\nEach of the functions in the marginaleffects package requires that users supply a model object on which the function will operate. When estimating models outside R, we do not have such a model object. We thus begin by creating a “fake” model object: an empty data frame which we define to be of class “custom”. Then, we set a global option to tell marginaleffects that this “custom” class is supported.\n\nmod &lt;- data.frame()\nclass(mod) &lt;- \"custom\"\n\noptions(\"marginaleffects_model_classes\" = \"custom\")\n\nNext, we define a get_predict method for our new custom class. This method must accept three arguments: model, newdata, and .... The get_predict method must return a data frame with one row for each of the rows in newdata, two columns (rowid and estimate), and an attribute called posterior_draws which hosts a matrix of posterior draws with the same number of rows as newdata.\nThe method below uses reticulate to call the predict_mcmc() function that we defined in the Python script above. The predict_mcmc() function accepts a data frame and returns a matrix with the same number of rows.\n\nget_predict.custom &lt;- function(model, newdata, ...) {\n    pred &lt;- predict_mcmc(newdata)\n    out &lt;- data.frame(\n        rowid = seq_len(nrow(newdata)),\n        predicted = apply(pred, 1, stats::median)\n    )\n    attr(out, \"posterior_draws\") &lt;- pred\n    return(out)\n}\n\nNow we can use most of the marginaleffects package functions to analyze our results. Since we use a “fake” model object, marginaleffects cannot retrieve the original data from the model object, and we always need to supply a newdata argument:\n\n## predictions on the original dataset\npredictions(mod, newdata = df) |&gt; head()\n\n## predictions for user-defined predictor values\npredictions(mod, newdata = datagrid(newdata = df, Age = c(60, 70)))\n\npredictions(mod, newdata = datagrid(newdata = df, Age = range))\n\n## average predictions by group\npredictions(mod, newdata = df, by = \"Sex\")\n\n## contrasts (average)\navg_comparisons(mod, variables = \"Age\", newdata = df)\n\navg_comparisons(mod, variables = list(\"Age\" = \"sd\"), newdata = df)\n\n## slope (elasticity)\navg_slopes(mod, variables = \"Age\", slope = \"eyex\", newdata = df)",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "NumPyro"
    ]
  },
  {
    "objectID": "vignettes/numpyro.html#fitting-a-numpyro-model",
    "href": "vignettes/numpyro.html#fitting-a-numpyro-model",
    "title": "NumPyro",
    "section": "",
    "text": "To begin, we load the reticulate package which allows us to interact with the Python interpreter from an R session. Then, we write a NumPyro model and we load it to memory using the source_python() function. The important functions to note in the Python code are:\n\n\nload_df() downloads data on pulmonary fibrosis.\n\nmodel() defines the NumPyro model.\n\nfit_mcmc_model() fits the model using Markov Chain Monte Carlo.\n\npredict_mcmc(): accepts a data frame and returns a matrix of draws from the posterior distribution of adjusted predictions (fitted values).\n\n\nlibrary(reticulate)\nlibrary(marginaleffects)\n\nmodel &lt;- '\n## Model code adapted from the NumPyro documtation under Apache License:\n## https://num.pyro.ai/en/latest/tutorials/bayesian_hierarchical_linear_regression.html\n\nimport pandas as pd\nimport numpy as np\nimport numpyro\nfrom numpyro.infer import SVI, Predictive, MCMC,NUTS, autoguide, TraceMeanField_ELBO\nimport numpyro.distributions as dist\nfrom numpyro.infer.initialization import init_to_median, init_to_uniform,init_to_sample\nfrom jax import random\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\ndef load_df():\n    train = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/osic_pulmonary_fibrosis.csv\")\n    return train\n\n\ndef model(data, predict = False):\n    FVC_obs = data[\"FVC\"].values  if predict == False else None\n    patient_encoder = LabelEncoder()\n    Age_obs = data[\"Age\"].values\n    patient_code = patient_encoder.fit_transform(data[\"Patient\"].values)\n    μ_α = numpyro.sample(\"μ_α\", dist.Normal(0.0, 500.0))\n    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(100.0))\n\n    age = numpyro.sample(\"age\", dist.Normal(0.0, 500.0))\n\n    n_patients = len(np.unique(patient_code))\n\n    with numpyro.plate(\"plate_i\", n_patients):\n        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n\n    σ = numpyro.sample(\"σ\", dist.HalfNormal(100.0))\n    FVC_est = α[patient_code] + age * Age_obs\n\n    with numpyro.plate(\"data\", len(patient_code)):\n        numpyro.sample(\"obs\", dist.Normal(FVC_est, σ), obs=FVC_obs)\n\n\ndef fit_mcmc_model(train_df, samples = 1000):\n    numpyro.set_host_device_count(4)\n    rng_key = random.PRNGKey(0)\n    mcmc = MCMC(\n        NUTS(model),\n        num_samples=samples,\n        num_warmup=1000,\n        progress_bar=True,\n        num_chains = 4\n        )\n    \n    mcmc.run(rng_key, train_df)\n\n    posterior_draws = mcmc.get_samples()\n\n    with open(\"mcmc_posterior_draws.pickle\", \"wb\") as handle:\n        pickle.dump(posterior_draws, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\ndef predict_mcmc(data):\n\n    with open(\"mcmc_posterior_draws.pickle\", \"rb\") as handle:\n        posterior_draws = pickle.load(handle)\n\n    predictive = Predictive(model = model,posterior_samples=posterior_draws)\n    samples = predictive(random.PRNGKey(1), data, predict = True)\n    y_pred = samples[\"obs\"]\n    # transpose so that each column is a draw and each row is an observation\n    y_pred = np.transpose(np.array(y_pred))\n\n    return y_pred \n'\n\n## save python script to temp file\ntmp &lt;- tempfile()\ncat(model, file = tmp)\n\n## load functions\nsource_python(tmp)\n\n## download data\ndf &lt;- load_df()\n\n## fit model\nfit_mcmc_model(df)",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "NumPyro"
    ]
  },
  {
    "objectID": "vignettes/numpyro.html#analyzing-the-results-in-marginaleffects",
    "href": "vignettes/numpyro.html#analyzing-the-results-in-marginaleffects",
    "title": "NumPyro",
    "section": "",
    "text": "Each of the functions in the marginaleffects package requires that users supply a model object on which the function will operate. When estimating models outside R, we do not have such a model object. We thus begin by creating a “fake” model object: an empty data frame which we define to be of class “custom”. Then, we set a global option to tell marginaleffects that this “custom” class is supported.\n\nmod &lt;- data.frame()\nclass(mod) &lt;- \"custom\"\n\noptions(\"marginaleffects_model_classes\" = \"custom\")\n\nNext, we define a get_predict method for our new custom class. This method must accept three arguments: model, newdata, and .... The get_predict method must return a data frame with one row for each of the rows in newdata, two columns (rowid and estimate), and an attribute called posterior_draws which hosts a matrix of posterior draws with the same number of rows as newdata.\nThe method below uses reticulate to call the predict_mcmc() function that we defined in the Python script above. The predict_mcmc() function accepts a data frame and returns a matrix with the same number of rows.\n\nget_predict.custom &lt;- function(model, newdata, ...) {\n    pred &lt;- predict_mcmc(newdata)\n    out &lt;- data.frame(\n        rowid = seq_len(nrow(newdata)),\n        predicted = apply(pred, 1, stats::median)\n    )\n    attr(out, \"posterior_draws\") &lt;- pred\n    return(out)\n}\n\nNow we can use most of the marginaleffects package functions to analyze our results. Since we use a “fake” model object, marginaleffects cannot retrieve the original data from the model object, and we always need to supply a newdata argument:\n\n## predictions on the original dataset\npredictions(mod, newdata = df) |&gt; head()\n\n## predictions for user-defined predictor values\npredictions(mod, newdata = datagrid(newdata = df, Age = c(60, 70)))\n\npredictions(mod, newdata = datagrid(newdata = df, Age = range))\n\n## average predictions by group\npredictions(mod, newdata = df, by = \"Sex\")\n\n## contrasts (average)\navg_comparisons(mod, variables = \"Age\", newdata = df)\n\navg_comparisons(mod, variables = list(\"Age\" = \"sd\"), newdata = df)\n\n## slope (elasticity)\navg_slopes(mod, variables = \"Age\", slope = \"eyex\", newdata = df)",
    "crumbs": [
      "Get started",
      "Miscellaneous",
      "NumPyro"
    ]
  },
  {
    "objectID": "vignettes/conjoint.html",
    "href": "vignettes/conjoint.html",
    "title": "Conjoint experiments",
    "section": "",
    "text": "A forced-choice conjoint experiment is a research methodology used in many fields such as marketing and political science to understand how people make decisions between “profiles” characterized by multiple “attributes.” In this type of experiment, participants are presented with a series of choices between different products, services, or scenarios. Each option is described by a set of attributes (e.g., price, quality, brand, features), and the levels of these attributes are varied randomly across the options presented.\nConsider an experiment where researchers ask survey respondents “to act as immigration officials and to decide which of a pair of immigrants they would choose for admission” (Hainmueller, Hopkins, and Yamamoto 2014). They display a table in which each column represents a distinct immigrant “profile” with randomized attributes. For example:\nA single forced-choice task in a conjoint experiment. The survey\nrespondent must choose one of the two profiles before seeing a second\ntask.\n        \nAttributes\n                Profile 1\n                Profile 2\n              \n\n\nLanguage Skills\n                  Fluent in English  \n                  Broken English\n                \n\nJob            \n                  Construction worker\n                  Nurse\nThe survey respondent has the “task” of choosing one of the two profiles. Then, the researchers display a new task, including profiles with different randomized attributes, and the respondent chooses again.\nBy analyzing the choices made by participants, researchers can estimate the relative importance of different attributes in the decision-making process.\nThe rest of this vignette shows how to use the marginaleffects package to estimate the main quantities of the quantities of interest in such experiments.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conjoint experiments"
    ]
  },
  {
    "objectID": "vignettes/conjoint.html#hypothesis-tests",
    "href": "vignettes/conjoint.html#hypothesis-tests",
    "title": "Conjoint experiments",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\nUsing the hypothesis argument, we can easily conduct various null hypothesis tests on the estimated marginal means. For example, is the probability of choosing a “fluent” profile equal to the probability of choosing a “tried but unable” profile?\n\navg_predictions(mod, \n  hypothesis = \"b1 = b3\",\n  by = \"language\", \n  vcov = ~respondent)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)    S  2.5 % 97.5 %\n   -0.128     0.0119 -10.8   &lt;0.001 87.6 -0.152 -0.105\n\nTerm: b1=b3\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nIs the difference in probabiliy between “fluent” and “broken” equal to the difference in probability between “tried but unable” and “used interpreter”?\n\navg_predictions(mod, \n  hypothesis = \"b1 - b2 = b3 - b4\",\n  by = \"language\", \n  vcov = ~respondent)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %  97.5 %\n  -0.0264     0.0168 -1.57    0.116 3.1 -0.0594 0.00657\n\nTerm: b1-b2=b3-b4\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conjoint experiments"
    ]
  },
  {
    "objectID": "vignettes/conjoint.html#subgroups",
    "href": "vignettes/conjoint.html#subgroups",
    "title": "Conjoint experiments",
    "section": "Subgroups",
    "text": "Subgroups\nModifying the by allows analysts to report marginal means for different subgroups of their data, and newdata can be used to exclude uninteresting profiles:\n\navg_predictions(mod, \n  by = c(\"language\", \"job\"),\n  newdata = subset(dat, job %in% c(\"doctor\", \"gardener\")),\n  vcov = ~respondent)\n\n\n         language      job Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n fluent           gardener    0.534     0.0243 22.0   &lt;0.001 353.5 0.486  0.581\n fluent           doctor      0.772     0.0332 23.2   &lt;0.001 394.4 0.707  0.837\n used interpreter doctor      0.602     0.0427 14.1   &lt;0.001 147.5 0.518  0.685\n tried but unable gardener    0.416     0.0237 17.5   &lt;0.001 226.5 0.370  0.463\n used interpreter gardener    0.387     0.0244 15.8   &lt;0.001 185.1 0.339  0.435\n broken           gardener    0.509     0.0245 20.8   &lt;0.001 317.0 0.461  0.557\n tried but unable doctor      0.570     0.0443 12.9   &lt;0.001 123.5 0.483  0.657\n broken           doctor      0.712     0.0394 18.1   &lt;0.001 239.6 0.635  0.789\n\nType:  response \nColumns: language, job, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conjoint experiments"
    ]
  },
  {
    "objectID": "vignettes/conjoint.html#empirical-vs.-balanced-grid",
    "href": "vignettes/conjoint.html#empirical-vs.-balanced-grid",
    "title": "Conjoint experiments",
    "section": "Empirical vs. balanced grid",
    "text": "Empirical vs. balanced grid\nIn the example above, avg_predictions() marginalized across the realized distribution of attributes observed in the actual dataset. An alternative would be to marginalzed over a perfectly balanced (“uniform”) grid of treatment conditions. Of course, empirical and uniform grids will yield nearly identical results if the sample is large and randomization successful.\nThe uniform approach is the default in the amce() function from the cjoint package, and the behavior can be replicated using the datagrid() function and the newdata argument in avg_comparisons():\n\nlibrary(cjoint)\n\namce_results &lt;- amce(\n  choice ~ language * job,\n  data = dat,\n  cluster = TRUE,\n  respondent.id = \"respondent\")\n\nsummary(amce_results)$amce |&gt; subset(Attribute == \"language\")\n\n   Attribute            Level    Estimate   Std. Err    z value     Pr(&gt;|z|)    \n11  language           broken -0.06834528 0.01357451  -5.034826 4.782835e-07 ***\n12  language tried but unable -0.12843978 0.01343677  -9.558832 1.190935e-21 ***\n13  language used interpreter -0.16584337 0.01382564 -11.995352 3.758141e-33 ***\n\navg_comparisons(mod,\n  newdata = datagrid(FUN_factor = unique, FUN_character = unique),\n  variables = \"language\",\n  vcov = ~respondent)\n\n\n                              Contrast Estimate Std. Error      z Pr(&gt;|z|)     S  2.5 %  97.5 %\n mean(broken) - mean(fluent)            -0.0683     0.0136  -5.03   &lt;0.001  21.0 -0.095 -0.0417\n mean(tried but unable) - mean(fluent)  -0.1284     0.0134  -9.56   &lt;0.001  69.5 -0.155 -0.1021\n mean(used interpreter) - mean(fluent)  -0.1658     0.0138 -12.00   &lt;0.001 107.7 -0.193 -0.1387\n\nTerm: language\nType:  response \nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conjoint experiments"
    ]
  },
  {
    "objectID": "vignettes/conjoint.html#hypothesis-tests-1",
    "href": "vignettes/conjoint.html#hypothesis-tests-1",
    "title": "Conjoint experiments",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\nA powerful feature of marginaleffects is that all its functions include a hypothesis argument which can be used to conduct hypothesis tests on arbitrary functions of estimates. For example, let’s compute the AFCP for a subset of profile comparisons:\n\np &lt;- avg_predictions(mod, \n  by = c(\"language\", \"alternative\"), \n  newdata = subset(dat, language != alternative & alternative == \"fluent\"),\n  vcov = ~respondent)\np\n\n\n         language alternative Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n broken                fluent    0.407     0.0164 24.8   &lt;0.001 447.7 0.375  0.439\n used interpreter      fluent    0.361     0.0157 22.9   &lt;0.001 384.5 0.330  0.392\n tried but unable      fluent    0.376     0.0165 22.8   &lt;0.001 378.4 0.344  0.409\n\nType:  response \nColumns: language, alternative, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nNow, let’s say we would like to test if any of the pairwise comparisons between AFCP is different from zero. All we need to do is use add a hypothesis=\"pairwise\" argument:\n\navg_predictions(mod, \n  hypothesis = \"pairwise\",\n  by = c(\"language\", \"alternative\"), \n  newdata = subset(dat, language != alternative & alternative == \"fluent\"),\n  vcov = ~respondent)\n\n\n                                Term Estimate Std. Error     z Pr(&gt;|z|)   S    2.5 % 97.5 %\n broken - used interpreter             0.0457     0.0226  2.02   0.0429 4.5  0.00146 0.0899\n broken - tried but unable             0.0304     0.0228  1.34   0.1811 2.5 -0.01417 0.0750\n used interpreter - tried but unable  -0.0152     0.0224 -0.68   0.4968 1.0 -0.05915 0.0287\n\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conjoint experiments"
    ]
  },
  {
    "objectID": "vignettes/conjoint.html#footnotes",
    "href": "vignettes/conjoint.html#footnotes",
    "title": "Conjoint experiments",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe fifelse() function from data.table preserves factor levels, but not the standard ifelse().↩︎",
    "crumbs": [
      "Get started",
      "Case studies",
      "Conjoint experiments"
    ]
  },
  {
    "objectID": "vignettes/experiments.html",
    "href": "vignettes/experiments.html",
    "title": "Experiments",
    "section": "",
    "text": "A 2×2 factorial design is a type of experimental design that allows researchers to understand the effects of two independent variables (each with two levels) on a single dependent variable. The design is popular among academic researchers as well as in industry when running A/B tests.\nIn this notebook, we illustrate how to analyze these designs with the marginaleffects package for R. As we will see, marginaleffects includes many convenient functions for analyzing both experimental and observational data, and for plotting our results.\n\nWe will use the mtcars dataset. We’ll analyze fuel efficiency, mpg (miles per gallon), as a function of am (transmission type) and vs (engine shape).\nvs is an indicator variable for if the car has a straight engine (1 = straight engine, 0 = V-shaped). am is an indicator variable for if the car has manual transmission (1 = manual transmission, 0=automatic transmission). There are then four types of cars (1 type for each of the four combinations of binary indicators).\nLet’s start by creating a model for fuel efficiency. For simplicity, we’ll use linear regression and model the interaction between vs and am.\n\n\nR\nPython\n\n\n\n\nlibrary(tidyverse)\nlibrary(marginaleffects)\nlibrary(modelsummary)\n\n## See ?mtcars for variable definitions\nfit &lt;- lm(mpg ~ vs + am + vs:am, data=mtcars) # equivalent to ~ vs*am\n\n\n\n\nimport polars as pl\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nmtcars = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\")\n\nfit = smf.ols(\"mpg ~ vs + am + vs:am\", data = mtcars).fit() # equivalent to ~ vs*am\n\n\n\n\nWe can plot the predictions from the model using the plot_predictions function. From the plot below, we can see a few things:\n\nStraight engines (vs=1) are estimated to have better expected fuel efficiency than V-shaped engines (vs=0).\nManual transmissions (am=1) are estimated to have better fuel efficiency for both V-shaped and straight engines.\nFor straight engines, the effect of manual transmissions on fuel efficiency seems to increase.\n\n\n\nR\nPython\n\n\n\n\nplot_predictions(fit, by = c(\"vs\", \"am\"))\n\n\n\n\n\n\n\n\n\n\nplot_predictions(fit, by = [\"vs\", \"am\"]).draw(show=True)\n\n\n\n\n\n\n\n\n\n\n\nSince this model is fairly simple the estimated differences between any of the four possible combinations of vs and am can be read from the regression table:\n\n\nR\nPython\n\n\n\nWe create the regression table using the modelsummary package:\n\nmodelsummary(fit, gof_map = c(\"r.squared\", \"nobs\"))\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\n(Intercept)\n                  15.050 \n                \n\n           \n                  (1.002)\n                \n\nvs         \n                  5.693  \n                \n\n           \n                  (1.651)\n                \n\nam         \n                  4.700  \n                \n\n           \n                  (1.736)\n                \n\nvs × am    \n                  2.929  \n                \n\n           \n                  (2.541)\n                \n\nR2         \n                  0.700  \n                \n\nNum.Obs.   \n                  32     \n                \n\n\n\n\n\n\n\n\n\nprint(fit.summary())\n#&gt;                             OLS Regression Results                            \n#&gt; ==============================================================================\n#&gt; Dep. Variable:                    mpg   R-squared:                       0.700\n#&gt; Model:                            OLS   Adj. R-squared:                  0.668\n#&gt; Method:                 Least Squares   F-statistic:                     21.81\n#&gt; Date:                Sun, 01 Sep 2024   Prob (F-statistic):           1.73e-07\n#&gt; Time:                        07:42:01   Log-Likelihood:                -83.098\n#&gt; No. Observations:                  32   AIC:                             174.2\n#&gt; Df Residuals:                      28   BIC:                             180.1\n#&gt; Df Model:                           3                                         \n#&gt; Covariance Type:            nonrobust                                         \n#&gt; ==============================================================================\n#&gt;                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n#&gt; ------------------------------------------------------------------------------\n#&gt; Intercept     15.0500      1.002     15.017      0.000      12.997      17.103\n#&gt; vs             5.6929      1.651      3.448      0.002       2.311       9.075\n#&gt; am             4.7000      1.736      2.708      0.011       1.144       8.256\n#&gt; vs:am          2.9286      2.541      1.153      0.259      -2.276       8.134\n#&gt; ==============================================================================\n#&gt; Omnibus:                        0.609   Durbin-Watson:                   1.520\n#&gt; Prob(Omnibus):                  0.738   Jarque-Bera (JB):                0.713\n#&gt; Skew:                          -0.223   Prob(JB):                        0.700\n#&gt; Kurtosis:                       2.421   Cond. No.                         6.32\n#&gt; ==============================================================================\n#&gt; \n#&gt; Notes:\n#&gt; [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nWe can express the same results in the form of a linear equation:\n\\[ \\mbox{mpg} = 15.050 + 5.693 \\cdot \\mbox{vs} + 4.700 \\cdot \\mbox{am} + 2.929 \\cdot \\mbox{vs} \\cdot \\mbox{am}.\\]\nWith a little arithmetic, we can compute estimated differences in fuel efficiency between different groups:\n\n4.700 mpg between am=1 and am=0, when vs=0.\n5.693 mpg between vs=1 and vs=0, when am=0.\n7.629 mpg between am=1 and am=0, when vs=1.\n8.621 mpg between vs=1 and vs=0, when am=1.\n13.322 mpg between a car with am=1 and vs=1, and a car with am=0 and vs=0.\n\nReading off these differences from the model summary is relatively straightforward in very simple cases like this one. However, it becomes more difficult as more variables are added to the model, not to mention obtaining estimated standard errors becomes nightmarish. To make the process easier, we can leverage the avg_comparisons() function from the marginaleffects package to compute the appropriate quantities and standard errors.\n\nThe grey rectangle in the graph below is the estimated fuel efficiency when vs=0 and am=0, that is, for an automatic transmission car with V-shaped engine.\n\n\n\n\n\n\n\n\nLet’s use avg_comparisons to get the difference between straight engines and V-shaped engines when the car has automatic transmission. In this call, the variables argument indicates that we want to estimate the effect of a change of 1 unit in the vs variable. The newdata=datagrid(am=0) determines the values of the covariates at which we want to evaluate the contrast.\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = \"vs\",\n  newdata = datagrid(am = 0))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      5.69       1.65 3.45   &lt;0.001 10.8  2.46   8.93\n#&gt; \n#&gt; Term: vs\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nAs expected, the results produced by avg_comparisons() are exactly the same as those which we read from the model summary table. The contrast that we just computed corresponds to the change illustrasted by the arrow in this plot:\n\n\n\n\n\n\n\n\n\n\n\nprint(avg_comparisons(fit,\n  variables = \"vs\",\n  newdata = datagrid(am = 0)))\n#&gt; shape: (1, 9)\n#&gt; ┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n#&gt; │ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n#&gt; │ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n#&gt; ╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n#&gt; │ vs   ┆ mean(True) - mean(False) ┆ 5.69     ┆ 1.65      ┆ … ┆ 0.000565 ┆ 10.8 ┆ 2.46 ┆ 8.93  │\n#&gt; └──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\nAs expected, the results produced by avg_comparisons() are exactly the same as those which we read from the model summary table. The contrast that we just computed corresponds to the change illustrasted by the arrow in this plot:\n\n\n\n\n\n\n\n\n\n\n\nThe next difference that we compute is between manual transmissions and automatic transmissions when the car has a V-shaped engine. Again, the call to avg_comparisons is shown below, and the corresponding contrast is indicated in the plot below using an arrow.\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 0))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;       4.7       1.74 2.71  0.00678 7.2   1.3    8.1\n#&gt; \n#&gt; Term: am\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\n\n\n\n\n\n\n\n\nprint(avg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 0)))\n#&gt; shape: (1, 9)\n#&gt; ┌──────┬──────────────────────────┬──────────┬───────────┬───┬─────────┬──────┬──────┬───────┐\n#&gt; │ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S    ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---  ┆ ---  ┆ ---   │\n#&gt; │ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str     ┆ str  ┆ str  ┆ str   │\n#&gt; ╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪═════════╪══════╪══════╪═══════╡\n#&gt; │ am   ┆ mean(True) - mean(False) ┆ 4.7      ┆ 1.74      ┆ … ┆ 0.00678 ┆ 7.21 ┆ 1.3  ┆ 8.1   │\n#&gt; └──────┴──────────────────────────┴──────────┴───────────┴───┴─────────┴──────┴──────┴───────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\n\n\n\n\n\n\n\nThe third difference we estimated was between manual transmissions and automatic transmissions when the car has a straight engine. The model call and contrast are:\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 1))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      7.63       1.86 4.11   &lt;0.001 14.6  3.99   11.3\n#&gt; \n#&gt; Term: am\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\n\n\n\n\n\n\n\n\nprint(avg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 1)))\n#&gt; shape: (1, 9)\n#&gt; ┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n#&gt; │ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n#&gt; │ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n#&gt; ╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n#&gt; │ am   ┆ mean(True) - mean(False) ┆ 7.63     ┆ 1.86      ┆ … ┆ 3.94e-05 ┆ 14.6 ┆ 3.99 ┆ 11.3  │\n#&gt; └──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\n\n\n\n\n\n\n\nThe last difference and contrast between manual transmissions with straight engines and automatic transmissions with V-shaped engines. We call this a “cross-contrast” because we are measuring the difference between two groups that differ on two explanatory variables at the same time. To compute this contrast, we use the cross argument of avg_comparisons:\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = c(\"am\", \"vs\"),\n  cross = TRUE)\n#&gt; \n#&gt;              C: am             C: vs Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;  mean(1) - mean(0) mean(1) - mean(0)     13.3       1.65 8.07   &lt;0.001 50.3  10.1   16.6\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast_am, contrast_vs, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\n\n\n\n\n\n\n\n\n# Not implemented yet\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe 2x2 design is a very popular design, and when using a linear model, the estimated differences between groups can be directly read off from the model summary, if not with a little arithmetic. However, when using models with a non-identity link function, or when seeking to obtain the standard errors for estimated differences, things become considerably more difficult. This vignette showed how to use avg_comparisons to specify contrasts of interests and obtain standard errors for those differences. The approach used applies to all generalized linear models and effects can be further stratified using the by argument (although this is not shown in this vignette.)\n\nMany analysts who conduct and analyze experiments wish to use regression adjustment with a linear regression model to improve the precision of their estimate of the treatment effect. Unfortunately, regression adjustment can introduce small-sample bias and other undesirable properties (Freedman 2008). Lin (2013) proposes a simple strategy to fix these problems in sufficiently large samples:\n\nCenter all predictors by subtracting each of their means.\nEstimate a linear model in which the treatment is interacted with each of the covariates.\n\n\n\nR\nPython\n\n\n\nThe estimatr package includes a convenient function to implement this strategy:\n\nlibrary(estimatr)\nlibrary(marginaleffects)\nlalonde &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MatchIt/lalonde.csv\")\n\nmod &lt;- lm_lin(\n    re78 ~ treat,\n    covariates = ~ age + educ + race,\n    data = lalonde,\n    se_type = \"HC3\")\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; lm_lin(formula = re78 ~ treat, covariates = ~age + educ + race, \n#&gt;     data = lalonde, se_type = \"HC3\")\n#&gt; \n#&gt; Standard error type:  HC3 \n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper  DF\n#&gt; (Intercept)         6488.05     356.71 18.1885 2.809e-59  5787.50   7188.6 604\n#&gt; treat                489.73     878.52  0.5574 5.774e-01 -1235.59   2215.0 604\n#&gt; age_c                 85.88      35.42  2.4248 1.561e-02    16.32    155.4 604\n#&gt; educ_c               464.04     131.51  3.5286 4.495e-04   205.77    722.3 604\n#&gt; racehispan_c        2775.47    1155.40  2.4022 1.660e-02   506.38   5044.6 604\n#&gt; racewhite_c         2291.67     793.30  2.8888 4.006e-03   733.71   3849.6 604\n#&gt; treat:age_c           17.23      76.37  0.2256 8.216e-01  -132.75    167.2 604\n#&gt; treat:educ_c         226.71     308.43  0.7350 4.626e-01  -379.02    832.4 604\n#&gt; treat:racehispan_c -1057.84    2652.42 -0.3988 6.902e-01 -6266.92   4151.2 604\n#&gt; treat:racewhite_c  -1205.68    1805.21 -0.6679 5.045e-01 -4750.92   2339.6 604\n#&gt; \n#&gt; Multiple R-squared:  0.05722 ,   Adjusted R-squared:  0.04317 \n#&gt; F-statistic: 4.238 on 9 and 604 DF,  p-value: 2.424e-05\n\n\n\n\nlalonde = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MatchIt/lalonde.csv\", infer_schema_length=200)\n\nlalonde = lalonde.to_dummies('race')\nlalonde = lalonde.with_columns(\n  pl.col('age').sub(pl.col('age').mean()),\n  pl.col('educ').sub(pl.col('educ').mean()),\n  pl.col('race_hispan').sub(pl.col('race_hispan').mean()),\n  pl.col('race_white').sub(pl.col('race_white').mean()),\n)\n\nmod = smf.ols(\"re78 ~ treat + age + educ + race_hispan + race_white + treat*(age + educ + race_hispan + race_white)\", data = lalonde.to_pandas()).fit()\n\nprint(mod.get_robustcov_results(cov_type='HC3').summary())\n#&gt;                             OLS Regression Results                            \n#&gt; ==============================================================================\n#&gt; Dep. Variable:                   re78   R-squared:                       0.057\n#&gt; Model:                            OLS   Adj. R-squared:                  0.043\n#&gt; Method:                 Least Squares   F-statistic:                     4.238\n#&gt; Date:                Sun, 01 Sep 2024   Prob (F-statistic):           2.42e-05\n#&gt; Time:                        07:42:03   Log-Likelihood:                -6328.8\n#&gt; No. Observations:                 614   AIC:                         1.268e+04\n#&gt; Df Residuals:                     604   BIC:                         1.272e+04\n#&gt; Df Model:                           9                                         \n#&gt; Covariance Type:                  HC3                                         \n#&gt; =====================================================================================\n#&gt;                         coef    std err          t      P&gt;|t|      [0.025      0.975]\n#&gt; -------------------------------------------------------------------------------------\n#&gt; Intercept          6488.0506    356.712     18.188      0.000    5787.505    7188.597\n#&gt; treat               489.7253    878.517      0.557      0.577   -1235.594    2215.045\n#&gt; age                  85.8798     35.417      2.425      0.016      16.324     155.436\n#&gt; educ                464.0448    131.509      3.529      0.000     205.774     722.315\n#&gt; race_hispan        2775.4733   1155.400      2.402      0.017     506.384    5044.563\n#&gt; race_white         2291.6714    793.301      2.889      0.004     733.708    3849.634\n#&gt; treat:age            17.2262     76.367      0.226      0.822    -132.751     167.203\n#&gt; treat:educ          226.7111    308.434      0.735      0.463    -379.023     832.445\n#&gt; treat:race_hispan -1057.8406   2652.417     -0.399      0.690   -6266.921    4151.240\n#&gt; treat:race_white  -1205.6827   1805.205     -0.668      0.504   -4750.925    2339.559\n#&gt; ==============================================================================\n#&gt; Omnibus:                      195.576   Durbin-Watson:                   1.856\n#&gt; Prob(Omnibus):                  0.000   Jarque-Bera (JB):              755.710\n#&gt; Skew:                           1.434   Prob(JB):                    7.94e-165\n#&gt; Kurtosis:                       7.616   Cond. No.                         94.5\n#&gt; ==============================================================================\n#&gt; \n#&gt; Notes:\n#&gt; [1] Standard Errors are heteroscedasticity robust (HC3)\n\n\n\n\nWe can obtain the same results by fitting a model with the standard lm function and using the comparisons() function:\n\n\nR\nPython\n\n\n\n\nmod &lt;- lm(re78 ~ treat * (age + educ + race), data = lalonde)\navg_comparisons(\n    mod,\n    variables = \"treat\",\n    vcov = \"HC3\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;       490        879 0.557    0.577 0.8 -1232   2212\n#&gt; \n#&gt; Term: treat\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\nprint(avg_comparisons(\n    mod,\n    variables = \"treat\",\n    vcov = \"HC3\"))\n#&gt; shape: (1, 9)\n#&gt; ┌───────┬──────────────┬──────────┬───────────┬───┬─────────┬───────┬───────────┬──────────┐\n#&gt; │ Term  ┆ Contrast     ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%      ┆ 97.5%    │\n#&gt; │ ---   ┆ ---          ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---   ┆ ---       ┆ ---      │\n#&gt; │ str   ┆ str          ┆ str      ┆ str       ┆   ┆ str     ┆ str   ┆ str       ┆ str      │\n#&gt; ╞═══════╪══════════════╪══════════╪═══════════╪═══╪═════════╪═══════╪═══════════╪══════════╡\n#&gt; │ treat ┆ mean(True) - ┆ 490      ┆ 879       ┆ … ┆ 0.577   ┆ 0.793 ┆ -1.23e+03 ┆ 2.21e+03 │\n#&gt; │       ┆ mean(False)  ┆          ┆           ┆   ┆         ┆       ┆           ┆          │\n#&gt; └───────┴──────────────┴──────────┴───────────┴───┴─────────┴───────┴───────────┴──────────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\nNotice that the treat coefficient and associate standard error in the lm_lin regression are exactly the same as the estimates produced by the comparisons() function.\n\n\nFreedman, David A. “On Regression Adjustments to Experimental Data.” Advances in Applied Mathematics 40, no. 2 (February 2008): 180–93.\nLin, Winston. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” Annals of Applied Statistics 7, no. 1 (March 2013): 295–318. https://doi.org/10.1214/12-AOAS583.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Experiments"
    ]
  },
  {
    "objectID": "vignettes/experiments.html#x2-experiments",
    "href": "vignettes/experiments.html#x2-experiments",
    "title": "Experiments",
    "section": "",
    "text": "A 2×2 factorial design is a type of experimental design that allows researchers to understand the effects of two independent variables (each with two levels) on a single dependent variable. The design is popular among academic researchers as well as in industry when running A/B tests.\nIn this notebook, we illustrate how to analyze these designs with the marginaleffects package for R. As we will see, marginaleffects includes many convenient functions for analyzing both experimental and observational data, and for plotting our results.\n\nWe will use the mtcars dataset. We’ll analyze fuel efficiency, mpg (miles per gallon), as a function of am (transmission type) and vs (engine shape).\nvs is an indicator variable for if the car has a straight engine (1 = straight engine, 0 = V-shaped). am is an indicator variable for if the car has manual transmission (1 = manual transmission, 0=automatic transmission). There are then four types of cars (1 type for each of the four combinations of binary indicators).\nLet’s start by creating a model for fuel efficiency. For simplicity, we’ll use linear regression and model the interaction between vs and am.\n\n\nR\nPython\n\n\n\n\nlibrary(tidyverse)\nlibrary(marginaleffects)\nlibrary(modelsummary)\n\n## See ?mtcars for variable definitions\nfit &lt;- lm(mpg ~ vs + am + vs:am, data=mtcars) # equivalent to ~ vs*am\n\n\n\n\nimport polars as pl\nimport statsmodels.formula.api as smf\nfrom marginaleffects import *\n\nmtcars = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\")\n\nfit = smf.ols(\"mpg ~ vs + am + vs:am\", data = mtcars).fit() # equivalent to ~ vs*am\n\n\n\n\nWe can plot the predictions from the model using the plot_predictions function. From the plot below, we can see a few things:\n\nStraight engines (vs=1) are estimated to have better expected fuel efficiency than V-shaped engines (vs=0).\nManual transmissions (am=1) are estimated to have better fuel efficiency for both V-shaped and straight engines.\nFor straight engines, the effect of manual transmissions on fuel efficiency seems to increase.\n\n\n\nR\nPython\n\n\n\n\nplot_predictions(fit, by = c(\"vs\", \"am\"))\n\n\n\n\n\n\n\n\n\n\nplot_predictions(fit, by = [\"vs\", \"am\"]).draw(show=True)\n\n\n\n\n\n\n\n\n\n\n\nSince this model is fairly simple the estimated differences between any of the four possible combinations of vs and am can be read from the regression table:\n\n\nR\nPython\n\n\n\nWe create the regression table using the modelsummary package:\n\nmodelsummary(fit, gof_map = c(\"r.squared\", \"nobs\"))\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\n(Intercept)\n                  15.050 \n                \n\n           \n                  (1.002)\n                \n\nvs         \n                  5.693  \n                \n\n           \n                  (1.651)\n                \n\nam         \n                  4.700  \n                \n\n           \n                  (1.736)\n                \n\nvs × am    \n                  2.929  \n                \n\n           \n                  (2.541)\n                \n\nR2         \n                  0.700  \n                \n\nNum.Obs.   \n                  32     \n                \n\n\n\n\n\n\n\n\n\nprint(fit.summary())\n#&gt;                             OLS Regression Results                            \n#&gt; ==============================================================================\n#&gt; Dep. Variable:                    mpg   R-squared:                       0.700\n#&gt; Model:                            OLS   Adj. R-squared:                  0.668\n#&gt; Method:                 Least Squares   F-statistic:                     21.81\n#&gt; Date:                Sun, 01 Sep 2024   Prob (F-statistic):           1.73e-07\n#&gt; Time:                        07:42:01   Log-Likelihood:                -83.098\n#&gt; No. Observations:                  32   AIC:                             174.2\n#&gt; Df Residuals:                      28   BIC:                             180.1\n#&gt; Df Model:                           3                                         \n#&gt; Covariance Type:            nonrobust                                         \n#&gt; ==============================================================================\n#&gt;                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n#&gt; ------------------------------------------------------------------------------\n#&gt; Intercept     15.0500      1.002     15.017      0.000      12.997      17.103\n#&gt; vs             5.6929      1.651      3.448      0.002       2.311       9.075\n#&gt; am             4.7000      1.736      2.708      0.011       1.144       8.256\n#&gt; vs:am          2.9286      2.541      1.153      0.259      -2.276       8.134\n#&gt; ==============================================================================\n#&gt; Omnibus:                        0.609   Durbin-Watson:                   1.520\n#&gt; Prob(Omnibus):                  0.738   Jarque-Bera (JB):                0.713\n#&gt; Skew:                          -0.223   Prob(JB):                        0.700\n#&gt; Kurtosis:                       2.421   Cond. No.                         6.32\n#&gt; ==============================================================================\n#&gt; \n#&gt; Notes:\n#&gt; [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nWe can express the same results in the form of a linear equation:\n\\[ \\mbox{mpg} = 15.050 + 5.693 \\cdot \\mbox{vs} + 4.700 \\cdot \\mbox{am} + 2.929 \\cdot \\mbox{vs} \\cdot \\mbox{am}.\\]\nWith a little arithmetic, we can compute estimated differences in fuel efficiency between different groups:\n\n4.700 mpg between am=1 and am=0, when vs=0.\n5.693 mpg between vs=1 and vs=0, when am=0.\n7.629 mpg between am=1 and am=0, when vs=1.\n8.621 mpg between vs=1 and vs=0, when am=1.\n13.322 mpg between a car with am=1 and vs=1, and a car with am=0 and vs=0.\n\nReading off these differences from the model summary is relatively straightforward in very simple cases like this one. However, it becomes more difficult as more variables are added to the model, not to mention obtaining estimated standard errors becomes nightmarish. To make the process easier, we can leverage the avg_comparisons() function from the marginaleffects package to compute the appropriate quantities and standard errors.\n\nThe grey rectangle in the graph below is the estimated fuel efficiency when vs=0 and am=0, that is, for an automatic transmission car with V-shaped engine.\n\n\n\n\n\n\n\n\nLet’s use avg_comparisons to get the difference between straight engines and V-shaped engines when the car has automatic transmission. In this call, the variables argument indicates that we want to estimate the effect of a change of 1 unit in the vs variable. The newdata=datagrid(am=0) determines the values of the covariates at which we want to evaluate the contrast.\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = \"vs\",\n  newdata = datagrid(am = 0))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      5.69       1.65 3.45   &lt;0.001 10.8  2.46   8.93\n#&gt; \n#&gt; Term: vs\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\nAs expected, the results produced by avg_comparisons() are exactly the same as those which we read from the model summary table. The contrast that we just computed corresponds to the change illustrasted by the arrow in this plot:\n\n\n\n\n\n\n\n\n\n\n\nprint(avg_comparisons(fit,\n  variables = \"vs\",\n  newdata = datagrid(am = 0)))\n#&gt; shape: (1, 9)\n#&gt; ┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n#&gt; │ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n#&gt; │ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n#&gt; ╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n#&gt; │ vs   ┆ mean(True) - mean(False) ┆ 5.69     ┆ 1.65      ┆ … ┆ 0.000565 ┆ 10.8 ┆ 2.46 ┆ 8.93  │\n#&gt; └──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\nAs expected, the results produced by avg_comparisons() are exactly the same as those which we read from the model summary table. The contrast that we just computed corresponds to the change illustrasted by the arrow in this plot:\n\n\n\n\n\n\n\n\n\n\n\nThe next difference that we compute is between manual transmissions and automatic transmissions when the car has a V-shaped engine. Again, the call to avg_comparisons is shown below, and the corresponding contrast is indicated in the plot below using an arrow.\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 0))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;       4.7       1.74 2.71  0.00678 7.2   1.3    8.1\n#&gt; \n#&gt; Term: am\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\n\n\n\n\n\n\n\n\nprint(avg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 0)))\n#&gt; shape: (1, 9)\n#&gt; ┌──────┬──────────────────────────┬──────────┬───────────┬───┬─────────┬──────┬──────┬───────┐\n#&gt; │ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S    ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---  ┆ ---  ┆ ---   │\n#&gt; │ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str     ┆ str  ┆ str  ┆ str   │\n#&gt; ╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪═════════╪══════╪══════╪═══════╡\n#&gt; │ am   ┆ mean(True) - mean(False) ┆ 4.7      ┆ 1.74      ┆ … ┆ 0.00678 ┆ 7.21 ┆ 1.3  ┆ 8.1   │\n#&gt; └──────┴──────────────────────────┴──────────┴───────────┴───┴─────────┴──────┴──────┴───────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\n\n\n\n\n\n\n\nThe third difference we estimated was between manual transmissions and automatic transmissions when the car has a straight engine. The model call and contrast are:\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 1))\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;      7.63       1.86 4.11   &lt;0.001 14.6  3.99   11.3\n#&gt; \n#&gt; Term: am\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\n\n\n\n\n\n\n\n\nprint(avg_comparisons(fit,\n  variables = \"am\",\n  newdata = datagrid(vs = 1)))\n#&gt; shape: (1, 9)\n#&gt; ┌──────┬──────────────────────────┬──────────┬───────────┬───┬──────────┬──────┬──────┬───────┐\n#&gt; │ Term ┆ Contrast                 ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|)  ┆ S    ┆ 2.5% ┆ 97.5% │\n#&gt; │ ---  ┆ ---                      ┆ ---      ┆ ---       ┆   ┆ ---      ┆ ---  ┆ ---  ┆ ---   │\n#&gt; │ str  ┆ str                      ┆ str      ┆ str       ┆   ┆ str      ┆ str  ┆ str  ┆ str   │\n#&gt; ╞══════╪══════════════════════════╪══════════╪═══════════╪═══╪══════════╪══════╪══════╪═══════╡\n#&gt; │ am   ┆ mean(True) - mean(False) ┆ 7.63     ┆ 1.86      ┆ … ┆ 3.94e-05 ┆ 14.6 ┆ 3.99 ┆ 11.3  │\n#&gt; └──────┴──────────────────────────┴──────────┴───────────┴───┴──────────┴──────┴──────┴───────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\n\n\n\n\n\n\n\n\nThe last difference and contrast between manual transmissions with straight engines and automatic transmissions with V-shaped engines. We call this a “cross-contrast” because we are measuring the difference between two groups that differ on two explanatory variables at the same time. To compute this contrast, we use the cross argument of avg_comparisons:\n\n\nR\nPython\n\n\n\n\navg_comparisons(fit,\n  variables = c(\"am\", \"vs\"),\n  cross = TRUE)\n#&gt; \n#&gt;              C: am             C: vs Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n#&gt;  mean(1) - mean(0) mean(1) - mean(0)     13.3       1.65 8.07   &lt;0.001 50.3  10.1   16.6\n#&gt; \n#&gt; Type:  response \n#&gt; Columns: term, contrast_am, contrast_vs, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\n\n\n\n\n\n\n\n\n# Not implemented yet\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe 2x2 design is a very popular design, and when using a linear model, the estimated differences between groups can be directly read off from the model summary, if not with a little arithmetic. However, when using models with a non-identity link function, or when seeking to obtain the standard errors for estimated differences, things become considerably more difficult. This vignette showed how to use avg_comparisons to specify contrasts of interests and obtain standard errors for those differences. The approach used applies to all generalized linear models and effects can be further stratified using the by argument (although this is not shown in this vignette.)",
    "crumbs": [
      "Get started",
      "Case studies",
      "Experiments"
    ]
  },
  {
    "objectID": "vignettes/experiments.html#regression-adjustment",
    "href": "vignettes/experiments.html#regression-adjustment",
    "title": "Experiments",
    "section": "",
    "text": "Many analysts who conduct and analyze experiments wish to use regression adjustment with a linear regression model to improve the precision of their estimate of the treatment effect. Unfortunately, regression adjustment can introduce small-sample bias and other undesirable properties (Freedman 2008). Lin (2013) proposes a simple strategy to fix these problems in sufficiently large samples:\n\nCenter all predictors by subtracting each of their means.\nEstimate a linear model in which the treatment is interacted with each of the covariates.\n\n\n\nR\nPython\n\n\n\nThe estimatr package includes a convenient function to implement this strategy:\n\nlibrary(estimatr)\nlibrary(marginaleffects)\nlalonde &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MatchIt/lalonde.csv\")\n\nmod &lt;- lm_lin(\n    re78 ~ treat,\n    covariates = ~ age + educ + race,\n    data = lalonde,\n    se_type = \"HC3\")\nsummary(mod)\n#&gt; \n#&gt; Call:\n#&gt; lm_lin(formula = re78 ~ treat, covariates = ~age + educ + race, \n#&gt;     data = lalonde, se_type = \"HC3\")\n#&gt; \n#&gt; Standard error type:  HC3 \n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper  DF\n#&gt; (Intercept)         6488.05     356.71 18.1885 2.809e-59  5787.50   7188.6 604\n#&gt; treat                489.73     878.52  0.5574 5.774e-01 -1235.59   2215.0 604\n#&gt; age_c                 85.88      35.42  2.4248 1.561e-02    16.32    155.4 604\n#&gt; educ_c               464.04     131.51  3.5286 4.495e-04   205.77    722.3 604\n#&gt; racehispan_c        2775.47    1155.40  2.4022 1.660e-02   506.38   5044.6 604\n#&gt; racewhite_c         2291.67     793.30  2.8888 4.006e-03   733.71   3849.6 604\n#&gt; treat:age_c           17.23      76.37  0.2256 8.216e-01  -132.75    167.2 604\n#&gt; treat:educ_c         226.71     308.43  0.7350 4.626e-01  -379.02    832.4 604\n#&gt; treat:racehispan_c -1057.84    2652.42 -0.3988 6.902e-01 -6266.92   4151.2 604\n#&gt; treat:racewhite_c  -1205.68    1805.21 -0.6679 5.045e-01 -4750.92   2339.6 604\n#&gt; \n#&gt; Multiple R-squared:  0.05722 ,   Adjusted R-squared:  0.04317 \n#&gt; F-statistic: 4.238 on 9 and 604 DF,  p-value: 2.424e-05\n\n\n\n\nlalonde = pl.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MatchIt/lalonde.csv\", infer_schema_length=200)\n\nlalonde = lalonde.to_dummies('race')\nlalonde = lalonde.with_columns(\n  pl.col('age').sub(pl.col('age').mean()),\n  pl.col('educ').sub(pl.col('educ').mean()),\n  pl.col('race_hispan').sub(pl.col('race_hispan').mean()),\n  pl.col('race_white').sub(pl.col('race_white').mean()),\n)\n\nmod = smf.ols(\"re78 ~ treat + age + educ + race_hispan + race_white + treat*(age + educ + race_hispan + race_white)\", data = lalonde.to_pandas()).fit()\n\nprint(mod.get_robustcov_results(cov_type='HC3').summary())\n#&gt;                             OLS Regression Results                            \n#&gt; ==============================================================================\n#&gt; Dep. Variable:                   re78   R-squared:                       0.057\n#&gt; Model:                            OLS   Adj. R-squared:                  0.043\n#&gt; Method:                 Least Squares   F-statistic:                     4.238\n#&gt; Date:                Sun, 01 Sep 2024   Prob (F-statistic):           2.42e-05\n#&gt; Time:                        07:42:03   Log-Likelihood:                -6328.8\n#&gt; No. Observations:                 614   AIC:                         1.268e+04\n#&gt; Df Residuals:                     604   BIC:                         1.272e+04\n#&gt; Df Model:                           9                                         \n#&gt; Covariance Type:                  HC3                                         \n#&gt; =====================================================================================\n#&gt;                         coef    std err          t      P&gt;|t|      [0.025      0.975]\n#&gt; -------------------------------------------------------------------------------------\n#&gt; Intercept          6488.0506    356.712     18.188      0.000    5787.505    7188.597\n#&gt; treat               489.7253    878.517      0.557      0.577   -1235.594    2215.045\n#&gt; age                  85.8798     35.417      2.425      0.016      16.324     155.436\n#&gt; educ                464.0448    131.509      3.529      0.000     205.774     722.315\n#&gt; race_hispan        2775.4733   1155.400      2.402      0.017     506.384    5044.563\n#&gt; race_white         2291.6714    793.301      2.889      0.004     733.708    3849.634\n#&gt; treat:age            17.2262     76.367      0.226      0.822    -132.751     167.203\n#&gt; treat:educ          226.7111    308.434      0.735      0.463    -379.023     832.445\n#&gt; treat:race_hispan -1057.8406   2652.417     -0.399      0.690   -6266.921    4151.240\n#&gt; treat:race_white  -1205.6827   1805.205     -0.668      0.504   -4750.925    2339.559\n#&gt; ==============================================================================\n#&gt; Omnibus:                      195.576   Durbin-Watson:                   1.856\n#&gt; Prob(Omnibus):                  0.000   Jarque-Bera (JB):              755.710\n#&gt; Skew:                           1.434   Prob(JB):                    7.94e-165\n#&gt; Kurtosis:                       7.616   Cond. No.                         94.5\n#&gt; ==============================================================================\n#&gt; \n#&gt; Notes:\n#&gt; [1] Standard Errors are heteroscedasticity robust (HC3)\n\n\n\n\nWe can obtain the same results by fitting a model with the standard lm function and using the comparisons() function:\n\n\nR\nPython\n\n\n\n\nmod &lt;- lm(re78 ~ treat * (age + educ + race), data = lalonde)\navg_comparisons(\n    mod,\n    variables = \"treat\",\n    vcov = \"HC3\")\n#&gt; \n#&gt;  Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;       490        879 0.557    0.577 0.8 -1232   2212\n#&gt; \n#&gt; Term: treat\n#&gt; Type:  response \n#&gt; Comparison: mean(1) - mean(0)\n#&gt; Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted\n\n\n\n\nprint(avg_comparisons(\n    mod,\n    variables = \"treat\",\n    vcov = \"HC3\"))\n#&gt; shape: (1, 9)\n#&gt; ┌───────┬──────────────┬──────────┬───────────┬───┬─────────┬───────┬───────────┬──────────┐\n#&gt; │ Term  ┆ Contrast     ┆ Estimate ┆ Std.Error ┆ … ┆ P(&gt;|z|) ┆ S     ┆ 2.5%      ┆ 97.5%    │\n#&gt; │ ---   ┆ ---          ┆ ---      ┆ ---       ┆   ┆ ---     ┆ ---   ┆ ---       ┆ ---      │\n#&gt; │ str   ┆ str          ┆ str      ┆ str       ┆   ┆ str     ┆ str   ┆ str       ┆ str      │\n#&gt; ╞═══════╪══════════════╪══════════╪═══════════╪═══╪═════════╪═══════╪═══════════╪══════════╡\n#&gt; │ treat ┆ mean(True) - ┆ 490      ┆ 879       ┆ … ┆ 0.577   ┆ 0.793 ┆ -1.23e+03 ┆ 2.21e+03 │\n#&gt; │       ┆ mean(False)  ┆          ┆           ┆   ┆         ┆       ┆           ┆          │\n#&gt; └───────┴──────────────┴──────────┴───────────┴───┴─────────┴───────┴───────────┴──────────┘\n#&gt; \n#&gt; Columns: term, contrast, estimate, std_error, statistic, p_value, s_value, conf_low, conf_high\n\n\n\n\nNotice that the treat coefficient and associate standard error in the lm_lin regression are exactly the same as the estimates produced by the comparisons() function.\n\n\nFreedman, David A. “On Regression Adjustments to Experimental Data.” Advances in Applied Mathematics 40, no. 2 (February 2008): 180–93.\nLin, Winston. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” Annals of Applied Statistics 7, no. 1 (March 2013): 295–318. https://doi.org/10.1214/12-AOAS583.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Experiments"
    ]
  },
  {
    "objectID": "vignettes/svalues.html",
    "href": "vignettes/svalues.html",
    "title": "S Values",
    "section": "",
    "text": "The S value — “Shannon transform” or “binary surprisal value” — is a cognitive tool to help analysts make intuitive sense of p values [@RafGre2020]. It allows us to compare a p value to the outcome of a familiar game of chance.\nConsider this: We toss a coin 4 times to see if we can reject the null hypothesis that the coin toss is fair. If the null is true, the probability of drawing Heads on any single toss is \\(\\frac{1}{2}\\). The probability of observing 4 Heads in a row is \\(\\left (\\frac{1}{2} \\right )^4=\\frac{1}{16}=0.0625\\). This probability characterizes the “surprise” caused by observing 4 straight heads in a world where the null holds, that is, where the coin toss is fair.\nNow consider a different exercise: We estimate a model and use marginaleffects::hypotheses() to test if two of the estimated coefficients are equal:\n\nlibrary(marginaleffects)\ndat &lt;- transform(mtcars, cyl = factor(cyl))\nmod &lt;- lm(mpg ~ cyl, dat)\nhyp &lt;- hypotheses(mod, \"cyl6 = cyl8\")\nhyp\n#&gt; \n#&gt;  Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n#&gt;      4.64       1.49 3.11  0.00186 9.1  1.72   7.57\n#&gt; \n#&gt; Term: cyl6 = cyl8\n#&gt; Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high\n\nThe difference between cyl6 and cyl8 is 4.64, and the associated p value is 0.0018593. Again, the p value can be interpreted as a measure of the surprise caused by the data if the null were true (i.e., if the two coefficients were in fact equal).\nHow many consecutive Heads tosses would be as surprising as this test of equality? To answer this question, we solve for \\(s\\) in \\(p=\\left (\\frac{1}{2} \\right )^s\\). The solution is the negative \\(log_2\\) of p:\n\n-log2(hyp$p.value)\n#&gt; [1] 9.070986\n\nIndeed, the probability of obtaining 9 straight Heads with fair coin tosses is \\(\\left (\\frac{1}{2} \\right )^9=0.0019531\\), which is very close to the p value we observed in the test of coefficient equality (see the S column in the marginaleffects printout above). Comparing our p value to the outcome of such a familiar game of chance gives us a nice intuitive interpretation:\n\nIf the cyl6 and cyl8 coefficients were truly equal, finding an absolute difference greater than 4.64 purely by chance would be as surprising as tossing 9 straight Heads with a fair coin toss.\n\nThe benefits of S values include [@ColEdwGre2021]:\n\nCalibrates the analyst’s intuitions by reference to a well-known physical process (coin flips).\nAvoids the problematic dichotomization of findings as “significant” and “not significant” [@Rot2021].\nReduces the reliance on arbitrary thresholds of significance like \\(\\alpha=0.05\\).\nGuards against the common misinterpretation of p values as the “probability that the null hypothesis is true” or as the probability of the alternative hypothesis. This is in part because S is above 1 whenever p&lt;0.5.1\n\nRefers to a more natural scale: “The difference between a p value of 0.99 and 0.90 in terms of how surprising the observed test statistic is, is not the same as the difference between 0.10 and 0.01.”2",
    "crumbs": [
      "Get started",
      "Case studies",
      "S Values"
    ]
  },
  {
    "objectID": "vignettes/svalues.html#footnotes",
    "href": "vignettes/svalues.html#footnotes",
    "title": "S Values",
    "section": "Footnotes",
    "text": "Footnotes\n\nThanks to Sander Greenland for this note.↩︎\nThanks to Zad Rafi for noting this and for linking to [@RafGre2020].↩︎",
    "crumbs": [
      "Get started",
      "Case studies",
      "S Values"
    ]
  },
  {
    "objectID": "vignettes/matching.html",
    "href": "vignettes/matching.html",
    "title": "Matching",
    "section": "",
    "text": "author: “Vincent Arel-Bundock”\nThis chapter introduces how to use marginaleffects to estimate treatment effects after pre-processing a dataset to achieve better covariate balance. The presentation is very short. Readers who seek a more comprehensive understanding and application of these methods should refer to Noah Greifer’s excellent and detailed work on the topic and to the MatchIt package vignettes and website\nThe procedure we highlight can be broken down into three steps:\n\nUse MatchIt to pre-process the data and achieve better covariate balance\nFit a regression model to the outcome of interest\nUse marginaleffects and G-Computation to estimate a quantity of interest, such as the Average treatment effect on the treated (ATT)\n\nTo begin, we load libraries and the data from the classic Lalonde experiment:\n\nlibrary(\"MatchIt\")\nlibrary(\"marginaleffects\")\ndata(\"lalonde\", package = \"MatchIt\")\n\nhead(lalonde)\n\n     treat age educ   race married nodegree re74 re75       re78\nNSW1     1  37   11  black       1        1    0    0  9930.0460\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940\nNSW3     1  30   12  black       0        0    0    0 24909.4500\nNSW4     1  27   11  black       0        1    0    0  7506.1460\nNSW5     1  33    8  black       0        1    0    0   289.7899\nNSW6     1  22    9  black       0        1    0    0  4056.4940\n\n\nWe are interested in the treatment effect of the treat variable on the re78 outcome. The treat variable is a binary variable indicating whether the individual received job training. The re78 variable is the individual’s earnings in 1978.\n\nThe first step is to pre-process the dataset to achieve better covariate balance. To do this, we use the MatchIt::matchit() function and a 1-to-1 nearest neighbor matching with replacement on the Mahaloanobis distance. This function supports many other matching methods, see ?matchit.\n\ndat &lt;- matchit(\n    treat ~ age + educ + race + married + nodegree + re74 + re75, \n    data = lalonde, distance = \"mahalanobis\",\n    replace = FALSE)\ndat &lt;- match.data(dat)\n\n\nNow, we estimate a linear regression model with interactions between the treatment and covariates. Note that we use the weights argument to use the weights supplied by our matching method:\n\nfit &lt;- lm(\n    re78 ~ treat * (age + educ + race + married + nodegree),\n    data = dat,\n    weights = weights)\n\n\nFinally, we use the avg_comparisons() function of the marginaleffects package to estimate the ATT and its standard error. In effect, this function applies G-Computation to estimate the quantity of interest. We use the following arguments:\n\n\nvariables=\"treat\" indicates that we are interested in the effect of the treat variable.\n\nnewdata=subset(dat, treat == 1) indicates that we want to estimate the effect for the treated individuals only (i.e., the ATT).\n\nwts=\"weights\" indicates that we want to use the weights supplied by the matching method.\n\n\navg_comparisons(\n    fit,\n    variables = \"treat\",\n    newdata = subset(dat, treat == 1),\n    vcov = ~subclass,\n    wts = \"weights\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n     1221        850 1.44    0.151 2.7  -445   2888\n\nTerm: treat\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\nThe MatchIt vignette titled “Estimating Effects After Matching” describes many more options, including different measures of uncertainty (bootstrap, clustering, etc.), different estimands (ATE, etc.), and different strategies for adjustment.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Matching"
    ]
  },
  {
    "objectID": "vignettes/matching.html#matching-1",
    "href": "vignettes/matching.html#matching-1",
    "title": "Matching",
    "section": "",
    "text": "The first step is to pre-process the dataset to achieve better covariate balance. To do this, we use the MatchIt::matchit() function and a 1-to-1 nearest neighbor matching with replacement on the Mahaloanobis distance. This function supports many other matching methods, see ?matchit.\n\ndat &lt;- matchit(\n    treat ~ age + educ + race + married + nodegree + re74 + re75, \n    data = lalonde, distance = \"mahalanobis\",\n    replace = FALSE)\ndat &lt;- match.data(dat)",
    "crumbs": [
      "Get started",
      "Case studies",
      "Matching"
    ]
  },
  {
    "objectID": "vignettes/matching.html#fitting",
    "href": "vignettes/matching.html#fitting",
    "title": "Matching",
    "section": "",
    "text": "Now, we estimate a linear regression model with interactions between the treatment and covariates. Note that we use the weights argument to use the weights supplied by our matching method:\n\nfit &lt;- lm(\n    re78 ~ treat * (age + educ + race + married + nodegree),\n    data = dat,\n    weights = weights)",
    "crumbs": [
      "Get started",
      "Case studies",
      "Matching"
    ]
  },
  {
    "objectID": "vignettes/matching.html#quantity-of-interest",
    "href": "vignettes/matching.html#quantity-of-interest",
    "title": "Matching",
    "section": "",
    "text": "Finally, we use the avg_comparisons() function of the marginaleffects package to estimate the ATT and its standard error. In effect, this function applies G-Computation to estimate the quantity of interest. We use the following arguments:\n\n\nvariables=\"treat\" indicates that we are interested in the effect of the treat variable.\n\nnewdata=subset(dat, treat == 1) indicates that we want to estimate the effect for the treated individuals only (i.e., the ATT).\n\nwts=\"weights\" indicates that we want to use the weights supplied by the matching method.\n\n\navg_comparisons(\n    fit,\n    variables = \"treat\",\n    newdata = subset(dat, treat == 1),\n    vcov = ~subclass,\n    wts = \"weights\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n     1221        850 1.44    0.151 2.7  -445   2888\n\nTerm: treat\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Get started",
      "Case studies",
      "Matching"
    ]
  },
  {
    "objectID": "vignettes/matching.html#learn-more",
    "href": "vignettes/matching.html#learn-more",
    "title": "Matching",
    "section": "",
    "text": "The MatchIt vignette titled “Estimating Effects After Matching” describes many more options, including different measures of uncertainty (bootstrap, clustering, etc.), different estimands (ATE, etc.), and different strategies for adjustment.",
    "crumbs": [
      "Get started",
      "Case studies",
      "Matching"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "License",
    "section": "",
    "text": "Copyright (C) 2023 Vincent Arel-Bundock vincent.arel-bundock@umontreal.ca\nThis program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.\n\n\nVersion 3, 29 June 2007\nCopyright © 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt;\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\n\n\n\nThe GNU General Public License is a free, copyleft license for software and other kinds of works.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nTo protect your rights, we need to prevent others from denying you these rights or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nDevelopers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and/or modify it.\nFor the developers’ and authors’ protection, the GPL clearly explains that there is no warranty for this free software. For both users’ and authors’ sake, the GPL requires that modified versions be marked as changed, so that their problems will not be attributed erroneously to authors of previous versions.\nSome devices are designed to deny users access to install or run modified versions of the software inside them, although the manufacturer can do so. This is fundamentally incompatible with the aim of protecting users’ freedom to change the software. The systematic pattern of such abuse occurs in the area of products for individuals to use, which is precisely where it is most unacceptable. Therefore, we have designed this version of the GPL to prohibit the practice for those products. If such problems arise substantially in other domains, we stand ready to extend this provision to those domains in future versions of the GPL, as needed to protect the freedom of users.\nFinally, every program is threatened constantly by software patents. States should not allow patents to restrict development and use of software on general-purpose computers, but in those that do, we wish to avoid the special danger that patents applied to a free program could make it effectively proprietary. To prevent this, the GPL assures that patents cannot be used to render the program non-free.\nThe precise terms and conditions for copying, distribution and modification follow.\n\n\n\n\n\n“This License” refers to version 3 of the GNU General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\n\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\n\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\n\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\n\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\n\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\n\na) The work must carry prominent notices stating that you modified it, and giving a relevant date.\nb) The work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to “keep intact all notices”.\nc) You must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it.\nd) If the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so.\n\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\n\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\n\na) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.\nb) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.\nc) Convey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.\nd) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.\ne) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.\n\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\n\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\n\na) Disclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or\nb) Requiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or\nc) Prohibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or\nd) Limiting the use for publicity purposes of names of licensors or authors of the material; or\ne) Declining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or\nf) Requiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors.\n\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\n\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\n\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\n\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\n\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\n\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\n\n\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU Affero General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the special requirements of the GNU Affero General Public License, section 13, concerning interaction through a network will apply to the combination as such.\n\n\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.",
    "crumbs": [
      "Get started",
      "License"
    ]
  },
  {
    "objectID": "LICENSE.html#gnu-general-public-license",
    "href": "LICENSE.html#gnu-general-public-license",
    "title": "License",
    "section": "",
    "text": "Version 3, 29 June 2007\nCopyright © 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt;\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.",
    "crumbs": [
      "Get started",
      "License"
    ]
  },
  {
    "objectID": "LICENSE.html#preamble",
    "href": "LICENSE.html#preamble",
    "title": "License",
    "section": "",
    "text": "The GNU General Public License is a free, copyleft license for software and other kinds of works.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nTo protect your rights, we need to prevent others from denying you these rights or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nDevelopers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and/or modify it.\nFor the developers’ and authors’ protection, the GPL clearly explains that there is no warranty for this free software. For both users’ and authors’ sake, the GPL requires that modified versions be marked as changed, so that their problems will not be attributed erroneously to authors of previous versions.\nSome devices are designed to deny users access to install or run modified versions of the software inside them, although the manufacturer can do so. This is fundamentally incompatible with the aim of protecting users’ freedom to change the software. The systematic pattern of such abuse occurs in the area of products for individuals to use, which is precisely where it is most unacceptable. Therefore, we have designed this version of the GPL to prohibit the practice for those products. If such problems arise substantially in other domains, we stand ready to extend this provision to those domains in future versions of the GPL, as needed to protect the freedom of users.\nFinally, every program is threatened constantly by software patents. States should not allow patents to restrict development and use of software on general-purpose computers, but in those that do, we wish to avoid the special danger that patents applied to a free program could make it effectively proprietary. To prevent this, the GPL assures that patents cannot be used to render the program non-free.\nThe precise terms and conditions for copying, distribution and modification follow.",
    "crumbs": [
      "Get started",
      "License"
    ]
  },
  {
    "objectID": "LICENSE.html#terms-and-conditions",
    "href": "LICENSE.html#terms-and-conditions",
    "title": "License",
    "section": "",
    "text": "“This License” refers to version 3 of the GNU General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\n\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\n\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\n\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\n\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\n\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\n\na) The work must carry prominent notices stating that you modified it, and giving a relevant date.\nb) The work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to “keep intact all notices”.\nc) You must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it.\nd) If the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so.\n\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\n\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\n\na) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.\nb) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.\nc) Convey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.\nd) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.\ne) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.\n\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\n\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\n\na) Disclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or\nb) Requiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or\nc) Prohibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or\nd) Limiting the use for publicity purposes of names of licensors or authors of the material; or\ne) Declining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or\nf) Requiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors.\n\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\n\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\n\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\n\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\n\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\n\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\n\n\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU Affero General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the special requirements of the GNU Affero General Public License, section 13, concerning interaction through a network will apply to the combination as such.\n\n\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.",
    "crumbs": [
      "Get started",
      "License"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Marginal Effects Zoo",
    "section": "",
    "text": "The parameters of a statistical model can sometimes be difficult to interpret substantively, especially when that model includes non-linear components, interactions, or transformations. Analysts who fit such complex models often seek to transform raw parameter estimates into quantities that are easier for domain experts and stakeholders to understand, such as predictions, contrasts, risk differences, ratios, odds, lift, slopes, and so on.\nUnfortunately, computing these quantities—along with associated standard errors—can be a tedious and error-prone task. This problem is compounded by the fact that modeling packages in R and Python produce objects with varied structures, which hold different information. This means that end-users often have to write customized code to interpret the estimates obtained by fitting Linear, GLM, GAM, Bayesian, Mixed Effects, and other model types. This can lead to wasted effort, confusion, and mistakes, and it can hinder the implementation of best practices."
  },
  {
    "objectID": "index.html#book",
    "href": "index.html#book",
    "title": "Marginal Effects Zoo",
    "section": "Book",
    "text": "Book\nThis free online book introduces a conceptual framework to clearly define statistical quantities of interest, and shows how to estimate those quantities using the marginaleffects package for R and Python. The techniques introduced herein can enhance the interpretability of over 100 classes of statistical and machine learning models, including linear, GLM, GAM, mixed-effects, bayesian, categorical outcomes, XGBoost, and more. With a single unified interface, users can compute and plot many estimands, including:\n\nPredictions (aka fitted values or adjusted predictions)\nComparisons such as contrasts, risk differences, risk ratios, odds, etc.\nSlopes (aka marginal effects or partial derivatives)\nMarginal means\nLinear and non-linear hypothesis tests\nEquivalence tests\nUncertainty estimates using the delta method, bootstrapping, simulation, or conformal inference.\nMuch more!\n\nThe Marginal Effects Zoo book includes over 30 chapters of tutorials, case studies, and technical notes. It covers a wide range of topics, including how the marginaleffects package can facilitate the analysis of:\n\nExperiments\nObservational data\nCausal inference with G-Computation\nMachine learning models\nBayesian modeling\nMultilevel regression with post-stratification (MRP)\nMissing data\nMatching\nInverse probability weighting\nConformal prediction\n\nGet started by clicking here!"
  },
  {
    "objectID": "index.html#article",
    "href": "index.html#article",
    "title": "Marginal Effects Zoo",
    "section": "Article",
    "text": "Article\nOur article on marginaleffects is provisionally accepted for publication by the Journal of Statistical Software. You can read the preprint here.\nTo cite marginaleffects in publications please use:\nArel-Bundock V, Greifer N, Heiss A (Forthcoming). “How to Interpret Statistical Models Using marginaleffects in R and Python.” Journal of Statistical Software.\nA BibTeX entry for LaTeX users is:\n@Article{,\n    title = {How to Interpret Statistical Models Using {marginaleffects} in {R} and {Python}},\n    author = {Vincent Arel-Bundock and Noah Greifer and Andrew Heiss},\n    year = {Forthcoming},\n    journal = {Journal of Statistical Software},\n}"
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Marginal Effects Zoo",
    "section": "Software",
    "text": "Software\nThe marginaleffects package for R and Python offers a single point of entry to easily interpret the results of over 100 classes of models, using a simple and consistent user interface. Its benefits include:\n\nPowerful: It can compute and plot predictions; comparisons (contrasts, risk ratios, etc.); slopes; and conduct hypothesis and equivalence tests for over 100 different classes of models in R.\nSimple: All functions share a simple and unified interface.\nDocumented: Each function is thoroughly documented with abundant examples. The Marginal Effects Zoo website includes 20,000+ words of vignettes and case studies.\nEfficient: Some operations can be up to 1000 times faster and use 30 times less memory than with the margins package.\n\nValid: When possible, numerical results are checked against alternative software like Stata or other R packages.\nThin: The R package requires relatively few dependencies.\nStandards-compliant: marginaleffects follows “tidy” principles and returns simple data frames that work with all standard R functions. The outputs are easy to program with and feed to other packages like ggplot2 or modelsummary.\nExtensible: Adding support for new models is very easy, often requiring less than 10 lines of new code. Please submit feature requests on Github.\nActive development: Bugs are fixed promptly."
  }
]