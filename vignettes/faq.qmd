
# FAQ 


```{r, include = FALSE}
options(width = 1000)
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 9,
  fig.asp = .4,
  out.width = "100%",
  warning = FALSE,
  message = FALSE,
  comment = "#>"
)
url <- "https://raw.githubusercontent.com/vincentarelbundock/marginaleffects/main/data-raw/supported_models.csv"
dat <- read.csv(url)
n_support <- nrow(dat)
```

## Questions & Answers

* [Pooling predictions with multiple imputation](https://stackoverflow.com/questions/77686706/how-to-pool-average-predictions-from-a-multinomial-regression-per-category-in-r/77688581#77688581)
* [Wiggly (non-smooth) confidence intervals in plots.](https://stackoverflow.com/questions/77556969/wiggly-confidence-interval-with-marginaleffectsplot-slopes/77620185#77620185)
* [`plot_predictions()` over a range of unobserved values](https://stackoverflow.com/questions/72723687/plot-cap-response-curve-for-counterfactual-data)
* [Plot the marginal effects from a `plm` package model](https://stackoverflow.com/questions/73126378/marginal-effects-plot-of-plm/73127507#73127507)
* [Models with demeaned, polynomials, or transformed variables](https://stackoverflow.com/questions/73303108/marginal-effects-for-de-meaned-polynomials-in-mixed-models/73305398#73305398)
* [`nlme::lme` problem with character predictors](https://stackoverflow.com/questions/77516330/marginaleffects-package-refuses-service-with-nlme/77517278#77517278)
* [Controlling facet rows and columns in `plot_*()` functions.](https://github.com/vincentarelbundock/marginaleffects/issues/1107)
* [Bayesian diagnostics (Rhat, etc.) with `brms`](https://stackoverflow.com/questions/78479179/diagnostic-of-marginal-effects-from-a-brms-model)


## Calling `marginaleffects` in functions, loops, environments, or after re-assigning variables

Functions from the `marginaleffects` package can sometimes fail when they are called inside a function, loop, or other environments. To see why, it is important to know that `marginaleffects` often needs to operate on the original data that was used to fit the model. To extract this original data, we use the `get_data()` function from the `insight` package.

In most cases, `get_data()` can extract the data which is stored inside the model object created by the modeling package. However, some modeling packages do *not* save the original data in the model object (in order to save memory). In those cases, `get_data()` will parse the call to find the name of the data object, and will search for that data object in the global environment. When users fit models in a different environment (e.g., function calls), `get_data()` may not be able to retrieve the original data.

A related problem can arise if users fit a model, but then assign a new value to the variable that used to store the dataset.

Recommendations:

1. Supply your dataset explicitly to the `newdata` argument of `slopes` functions.
2. Avoid assigning a new value to a variable that you use to store a dataset for model fitting.



## Equivalence between `avg_comparisons()` and `avg_predictions()`

Say we estimate a simple logit regression and want to compute the average log-odds ratio associated with a change from 0 to 1 on the `vs` variable. We can proceed as follows using the `comparisons()` function:

```{r}
library(marginaleffects)
mod <- glm(am ~ vs + scale(drat), family = binomial, mtcars)

avg_comparisons(mod,
    variables = "vs",
    comparison = "lnoravg",
    type = "response")
```

We can specify the function to compare "hi" predictions to "lo" predictions manually and get the same results:


```{r}
fun <- function(hi, lo) log((mean(hi) / (1 - mean(hi))) / (mean(lo) / (1 - mean(lo))))

comparisons(mod,
    variables = "vs",
    comparison = fun,
    type = "response")
```

The same results can be obtained using the `predictions()` function. First, we replicate the entire dataset, and substitute the values of `vs`. Then, we make predictions. Finally, we compute the log odds ratios:

```{r}
dat0 <- transform(mtcars, vs = 0)
dat1 <- transform(mtcars, vs = 1)

p0 <- predictions(mod, newdata = dat0, type = "response")
p1 <- predictions(mod, newdata = dat1, type = "response")

fun(p1$estimate, p0$estimate)
```

Notice that the following command gives us a different result. This is because instead of duplicating the full dataset, and computing the "hi" and "lo" as the mean predictions over the full data, we only compute the averages on the subsets of rows where `vs` is 0 or 1, respectively:

```{r}
p <- avg_predictions(mod, by = "vs", type = "response")
fun(p$estimate[2], p$estimate[1])
```

Which is equivalent to:

```{r}
dat0 <- subset(mtcars, vs == 0)
dat1 <- subset(mtcars, vs == 1)

p0 <- predictions(mod, newdata = dat0, type = "response")
p1 <- predictions(mod, newdata = dat1, type = "response")

fun(p1$estimate, p0$estimate)
```