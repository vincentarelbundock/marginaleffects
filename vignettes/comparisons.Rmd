---
title: "Comparisons" 
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Comparisons}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(width = 1000)
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .4,
  warning = FALSE,
  message = FALSE,
  comment = "#>"
)

library(marginaleffects)
library(patchwork)
library(ggplot2)

theme_set(theme_minimal())
```

[In another vignette](https://vincentarelbundock.github.io/marginaleffects/articles/slopes.html), we introduced the "marginal effect" as a partial derivative. Since derivatives are only properly defined for continuous variables, we cannot use them to interpret the effects of changes in categorical variables. For this, we turn to *contrasts* between [Adjusted predictions.](https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html) In the context of this package, a "Contrast" is defined as:

> A difference, ratio, or function of adjusted predictions, calculated for meaningfully different predictor values (e.g., College graduates vs. Others).

The `slopes()` function automatically calculates contrasts instead of derivatives for factor, logical, or character variables. 

The `comparisons()` function gives users more powerful features to compute different contrasts, such as differences, risk ratios, linear combinations, and transformations.

# Simple example: Titanic

Consider a logistic regression model estimated using the Titanic mortality data:

```{r}
library(marginaleffects)

dat <- "https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv"
dat <- read.csv(dat)
mod <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial)
```

The question that interests us is:

> How does the probability of survival (outcome) change if a passenger travels in 1st class vs. 3rd class?

The answer to that question is not straightforward because, in non-linear models with interactions, the effect of a change in one variable depends on the values of all the other covariates in the model. Therefore, we need to refine the question:

> How does the probability of survival (outcome) change if a 25 year old man travels in 1st class vs. 3rd class?

Here, the *estimand* is the difference in probabilities for `PClass="1st"` and `PClass="3rd"`, and this estimand is conditional on the values of the covariates `Age=25` and `SexCode=1`. In the `comparisons()` function, the `variables` argument determines the scientific query (estimand or comparison), and the `newdata` argument determines *where* we estimate this query (conditional on what covariate values). For example:

```{r}
comparisons(
  mod,
  variables = list(PClass = c("3rd", "1st")),
  newdata = datagrid(Age = 25, SexCode = 0))
```

We can compute the same contrast for different "kinds" of individuals, by changing the `datagrid()` call. This function accepts functions or vectors. Here, we compute the contrast between the probabilities of survival in 1st and 3rd class for the oldest men and women passengers:

```{r}
comparisons(
  mod,
  variables = list(PClass = c("3rd", "1st")),
  newdata = datagrid(Age = range, SexCode = 0:1))
```

If we do *not* specify the `newdata` argument, then `comparisons()` will calculate the contrast for every single combination of covariate values in the original data. This means that we will obtain a data frame of results with the same number of rows as the original data. This makes sense, because in non-linear models or in models with interactions, each individual can have a different contrast:

```{r}
cmp <- comparisons(
  mod,
  variables = list(PClass = c("3rd", "1st")))

# number of contrast estimates
nrow(cmp)

# number of observations in the model
nobs(mod)
```

A big dataset of contrasts like this one can be unwieldy. A common strategy is to summarize the unit-level contrasts by taking their average. This can be achieved using the `avg_comparisons()` function or the `by` argument:

```{r}
avg_comparisons(mod, by = "PClass")

avg_comparisons(mod, variables = "SexCode", by = "PClass")
```

Note that average contrasts often have a nice interpretation in a causal inference context, as the outcome of parametric g-formula estimation. See this vignette: https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html

The rest of this vignette highlights some of the other features of the very flexible and powerful `comparisons()` function.

# Predictor types

## Logical and factor predictors

Consider a simple model with a logical and a factor variable:

```{r}
library(marginaleffects)

tmp <- mtcars
tmp$am <- as.logical(tmp$am)
mod <- lm(mpg ~ am + factor(cyl), tmp)
```

The `comparisons` function automatically computes contrasts for each level of the categorical variables, relative to the baseline category (`FALSE` for logicals, and the reference level for factors), while holding all other values at their observed values. The `avg_comparisons()` does the same, but then marginalizes by taking the average of unit-level estimates:

```{r}
cmp <- avg_comparisons(mod)
cmp
```

The summary printed above says that moving from the reference category `4` to the level `6` on the `cyl` factor variable is associated with a change of `r sprintf("%.3f", tidy(cmp)$estimate[2])` in the adjusted prediction. Similarly, the contrast from `FALSE` to `TRUE` on the `am` variable is equal to `r sprintf("%.3f", tidy(cmp)$estimate[1])`.

We can obtain different contrasts by using the `comparisons()` function. For example:

```{r}
avg_comparisons(mod, variables = list(cyl = "sequential"))

avg_comparisons(mod, variables = list(cyl = "pairwise"))

avg_comparisons(mod, variables = list(cyl = "reference"))
```

For comparison, this code produces the same results using the `emmeans` package:

```{r}
library(emmeans)
emm <- emmeans(mod, specs = "cyl")
contrast(emm, method = "revpairwise")

emm <- emmeans(mod, specs = "am")
contrast(emm, method = "revpairwise")
```

Note that these commands also work on for other types of models, such as GLMs, on different scales:

```{r}
mod_logit <- glm(am ~ factor(gear), data = mtcars, family = binomial)

avg_comparisons(mod_logit)

avg_comparisons(mod_logit, type = "link")
```

## Character predictors

All functions of the `marginaleffects` package attempt to treat character predictors as factor predictors. However, using factors instead of characters when modeling is *strongly* encouraged, because they are much safer and faster. This is because factors hold useful information about the full list of levels, which makes them easier to track and handle internally by `marginaleffects`. Users are strongly encouraged to convert their character variables to factor before fitting their models and using `slopes` functions.

## Numeric predictors

We can also compute contrasts for differences in numeric variables. For example, we can see what happens to the adjusted predictions when we increment the `hp` variable by 1 unit (default) or by 5 units:

```{r}
mod <- lm(mpg ~ hp, data = mtcars)

avg_comparisons(mod)

avg_comparisons(mod, variables = list(hp = 5))
```

Compare adjusted predictions for a change in the regressor between two arbitrary values:

```{r}
avg_comparisons(mod, variables = list(hp = c(90, 110)))
```

Compare adjusted predictions when the regressor changes across the interquartile range, across one or two standard deviations about its mean, or from across its full range:

```{r}
avg_comparisons(mod, variables = list(hp = "iqr"))

avg_comparisons(mod, variables = list(hp = "sd"))

avg_comparisons(mod, variables = list(hp = "2sd"))

avg_comparisons(mod, variables = list(hp = "minmax"))
```

# Interactions and Cross-Contrasts

In some contexts we are interested in whether the "effect" of a variable changes, as a function of another variable. A very simple strategy to tackle this question is to estimate a model with a multiplicative interaction like this one:

```{r}
mod <- lm(mpg ~ am * factor(cyl), data = mtcars)
```

Calling `avg_comparisons()` with the `by` argument shows that the estimated comparisons differ based on `cyl`:

```{r}
avg_comparisons(mod, variables = "am", by = "cyl")
```

However, using the `hypothesis` argument for pairwise contrasts between the above comparisons reveals that the heterogeneity is not statistically significant:

```{r}
avg_comparisons(mod, variables = "am", by = "cyl", hypothesis = "pairwise")
```

In other contexts, we are interested in a "cross-contrast" or "cross-comparisons"; we would like to know what happens when two (or more) predictors change at the same time. To assess this, we can specify the regressors of interest in the `variables` argument, and set the `cross=TRUE`:

```{r}
avg_comparisons(mod, variables = c("cyl", "am"), cross = TRUE)
```

# Quantities of interest

This section compares 4 quantities:

1. Unit-Level Contrasts
2. Average Contrast
3. Contrast at the Mean
4. Contrast Between Marginal Means

The ideas discussed in this section focus on contrasts, but they carry over directly to analogous types of marginal effects.

## Unit-level contrasts

In models with interactions or non-linear components (e.g., link function), the value of a contrast or marginal effect can depend on the value of all the predictors in the model. As a result, contrasts and marginal effects are fundamentally *unit-level* quantities. The effect of a 1 unit increase in $X$ can be different for Mary or John. Every row of a dataset has a different contrast and marginal effect.

The `mtcars` dataset has 32 rows, so the `comparisons()` function produces 32 contrast estimates:

```{r, warning = FALSE}
library(marginaleffects)
mod <- glm(vs ~ factor(gear) + mpg, family = binomial, data = mtcars)
cmp <- comparisons(mod, variables = "mpg")
nrow(cmp)
```

## Average contrasts

By default, the `slopes()` and `comparisons()` functions compute marginal effects and contrasts for every row of the original dataset. These unit-level estimates can be of great interest, as discussed in [another vignette](https://vincentarelbundock.github.io/marginaleffects/articles/logistic_comparisons.html). Nevertheless, one may want to focus on one-number summaries: the `avg_*()` functions or the `by` argument compute the "Average Marginal Effect" or "Average Contrast," by taking the mean of all the unit-level estimates.

```{r}
avg_comparisons(mod, variables = "mpg")

comparisons(mod, variables = "mpg", by = TRUE)
```

which are equivalent to:

```{r}
mean(cmp$estimate)
```

We could also show the full distribution of contrasts across our dataset with a histogram:

```{r}
#| fig.asp = .4
library(ggplot2)

cmp <- comparisons(mod, variables = "gear")

ggplot(cmp, aes(estimate)) +
    geom_histogram(bins = 30) +
    facet_wrap(~contrast, scale = "free_x") +
    labs(x = "Distribution of unit-level contrasts")
```

This graph display the effect of a change of 1 unit in the `mpg` variable, for each individual in the observed data.

## Contrasts at the mean

An alternative which used to be very common but has now fallen into a bit of disfavor is to compute "Contrasts at the mean." The idea is to create a "synthetic" or "hypothetical" individual (row of the dataset) whose characteristics are completely average. Then, we compute and report the contrast for this specific hypothetical individual. 

This can be achieved by setting `newdata="mean"` or to `newdata=datagrid()`, both of which fix variables to their means or modes:

```{r}
comparisons(mod, variables = "mpg", newdata = "mean")
```

Contrasts at the mean can differ substantially from average contrasts.

The advantage of this approach is that it is very cheap and fast computationally. The disadvantage is that the interpretation is somewhat ambiguous. Often times, there simply does not exist an individual who is perfectly average across all dimensions of the dataset. It is also not clear why the analyst should be particularly interested in the contrast for this one, synthetic, perfectly average individual.

## Contrasts between marginal means

Yet another type of contrast is the "Contrast between marginal means." This type of contrast is closely related to the "Contrast at the mean", with a few wrinkles. It is the default approach used by the `emmeans` package for `R`.

Roughly speaking, the procedure is as follows: 

1. Create a prediction grid with one cell for each combination of categorical predictors in the model, and all numeric variables held at their means.
2. Make adjusted predictions in each cell of the prediction grid.
3. Take the average of those predictions (marginal means) for each combination of `btype` (focal variable) and `resp` (group `by` variable).
4. Compute pairwise differences (contrasts) in marginal means across different levels of the focal variable `btype`.

The contrast obtained through this approach has two critical characteristics:

a) It is the contrast for a synthetic individual with perfectly average qualities on every (numeric) predictor.
b) It is a weighted average of unit-level contrasts, where weights assume a perfectly balanced dataset across every categorical predictor.

With respect to (a), the analyst should ask themselves: Is my quantity of interest the contrast for a perfectly average hypothetical individual? With respect to (b), the analyst should ask themselves: Is my quantity of interest the contrast in a model estimated using (potentially) unbalanced data, but interpreted *as if* the data were perfectly balanced? 

For example, imagine that one of the control variables in your model is a variable measuring educational attainment in 4 categories: No high school, High school, Some college, Completed college. The contrast between marginal is a weighted average of contrasts estimated in the 4 cells, and each of those contrasts will be weighted equally in the overall estimate. If the population of interest is highly unbalanced in the educational categories, then the estimate computed in this way will not be most useful.

If the contrasts between marginal means is really the quantity of interest, it is easy to use the `comparisons()` to estimate contrasts between marginal means. The `newdata` determines the values of the predictors at which we want to compute contrasts. We can set `newdata="marginalmeans"` to emulate the `emmeans` behavior. For example, here we compute contrasts in a model with an interaction:

```{r}
dat <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv")
mod <- lm(bill_length_mm ~ species * sex + island + body_mass_g, data = dat)

avg_comparisons(
    mod,
    newdata = "marginalmeans",
    variables = c("species", "island"))
```

Which is equivalent to this in `emmeans`:

```{r}
emm <- emmeans(
    mod,
    specs = c("species", "island"))
contrast(emm, method = "trt.vs.ctrl1")
```

The [`emmeans` section of the Alternative Software vignette](https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html#emmeans) shows further examples.

The [excellent vignette of the `emmeans` package](https://CRAN.R-project.org/package=emmeans/vignettes/basics.html) discuss the same issues in a slightly different (and more positive) way:

> The point is that the marginal means of cell.means give equal weight to each cell. In many situations (especially with experimental data), that is a much fairer way to compute marginal means, in that they are not biased by imbalances in the data. We are, in a sense, estimating what the marginal means would be, had the experiment been balanced. Estimated marginal means (EMMs) serve that need.

> All this said, there are certainly situations where equal weighting is not appropriate. Suppose, for example, we have data on sales of a product given different packaging and features. The data could be unbalanced because customers are more attracted to some combinations than others. If our goal is to understand scientifically what packaging and features are inherently more profitable, then equally weighted EMMs may be appropriate; but if our goal is to predict or maximize profit, the ordinary marginal means provide better estimates of what we can expect in the marketplace.

# Conditional contrasts

Consider a model with an interaction term. What happens to the dependent variable when the `hp` variable increases by 10 units?

```{r}
library(marginaleffects)

mod <- lm(mpg ~ hp * wt, data = mtcars)

plot_comparisons(
    mod,
    effect = list(hp = 10),
    condition = "wt")
```

# Transformations

So far we have focused on simple differences between adjusted predictions. Now, we show how to use ratios, back transformations, and arbitrary functions to estimate a slew of quantities of interest. Powerful transformations and custom contrasts are made possible by using three arguments which act at different stages of the computation process:

* `transform_pre`
* `transform_post`

Consider the case of a model with a single predictor $x$. To compute average contrasts, we proceed as follows:

1. Compute adjusted predictions for each row of the dataset for the observed values $x$: $\hat{y}_x$
1. Compute adjusted predictions for each row of the dataset for the observed values $x + 1$: $\hat{y}_{x+1}$
1. `transform_pre`: Compute unit-level contrasts by taking the difference between (or some other function of) adjusted predictions: $\hat{y}_{x+1} - \hat{y}_x$
1. Compute the average contrast by taking the mean of unit-level contrasts: $1/N \sum_{i=1}^N \hat{y}_{x+1} - \hat{y}_x$
1. `transform_post`: Transform the average contrast or return them as-is.

The `transform_pre` argument of the `comparisons()` function determines how adjusted predictions are combined to create a contrast. By default, we take a simple difference between predictions with `hi` value of $x$, and predictions with a `lo` value of $x$: `function(hi, lo) hi-lo`.

The `transform_post` argument of the `comparisons()` function applies a custom transformation to the unit-level contrasts.

The `transform_post` argument applies a custom transformation to the final quantity, as would be returned if we evaluated the same call without `transform_post`.


# Differences

The default contrast calculate by the `comparisons()` function is a (untransformed) difference between two adjusted predictions. For instance, to estimate the effect of a change of 1 unit, we do:

```{r}
library(marginaleffects)

mod <- glm(vs ~ mpg, data = mtcars, family = binomial)

# construct data

mtcars_minus <- mtcars_plus <- mtcars
mtcars_minus$mpg <- mtcars_minus$mpg - 0.5
mtcars_plus$mpg <- mtcars_plus$mpg + 0.5

# adjusted predictions
yhat_minus <- predict(mod, newdata = mtcars_minus, type = "response")
yhat_plus <- predict(mod, newdata = mtcars_plus, type = "response")

# unit-level contrasts
con <- yhat_plus - yhat_minus

# average contrasts
mean(con)
```

We can use the `avg_comparisons()` function , or the `by` argument to obtain the same results:

```{r}
avg_comparisons(mod)

comparisons(mod, by = TRUE)
```

# Difference-in-Differences(-in-Differences)

Going back to our Titanic example:

```{r}
dat <- "https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv"
dat <- read.csv(dat)
titanic <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial)
```

In this case, a contrast is a difference between predicted probabilities. We can compute that contrast for different types of individuals:

```{r}
comparisons(
  titanic,
  variables = "SexCode",
  newdata = datagrid(PClass = c("1st", "3rd")))
```

One we can notice above, is that the gap in predicted probabilities of survival between men and women is larger in 1st class than in 3rd class. Being a woman matters more for your chances of survival if you travel in first class. Is the difference between those contrasts (diff-in-diff) statistically significant?

To answer this question, we can compute a difference-in-difference using the `hypothesis` argument ([see the Hypothesis vignette for details](https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html)). For example, using `b1` and `b2` to refer to the contrasts in the first and second rows of the output above, we can test if the difference between the two quantities is different from 0:

```{r}
comparisons(
  titanic,
  hypothesis = "b1 - b2 = 0",
  variables = "SexCode",
  newdata = datagrid(PClass = c("1st", "3rd")))
```

Now, let's say we consider more types of individuals:

```{r}
comparisons(
  titanic,
  variables = "SexCode",
  newdata = datagrid(PClass = c("1st", "3rd"), Age = range))
```

With these results, we could compute a triple difference:

```{r}
comparisons(
  titanic,
  hypothesis = "(b1 - b3) - (b2 - b4) = 0",
  variables = "SexCode",
  newdata = datagrid(PClass = c("1st", "3rd"), Age = range))
```

# Ratios

Instead of taking simple differences between adjusted predictions, it can sometimes be useful to compute ratios or other functions of predictions. For example, [the `adjrr` function the `Stata` software package](https://journals.sagepub.com/doi/pdf/10.1177/1536867X1301300304) can compute "adjusted risk ratios", which are ratios of adjusted predictions. To do this in `R`, we use the `transform_pre` argument:

```{r}
avg_comparisons(mod, transform_pre = "ratio")
```

This result is the average adjusted risk ratio, that is, the adjusted predictions when the `mpg` are incremented by 1, divided by the adjusted predictions when `mpg` is at its original value.

The `transform_pre` accepts different values for common types of contrasts: 'difference', 'ratio', 'lnratio', 'ratioavg', 'lnratioavg', 'lnoravg', 'differenceavg'. These strings are shortcuts for functions that accept two vectors of adjusted predictions and returns a single vector of contrasts. For example, these two commands yield identical results:

```{r}
avg_comparisons(mod, transform_pre = "ratio")

avg_comparisons(mod, transform_pre = function(hi, lo) hi / lo)
```

This mechanism is powerful, because it lets users create fully customized contrasts. Here is a non-sensical example:

```{r}
avg_comparisons(mod, transform_pre = function(hi, lo) sqrt(hi) / log(lo + 10))
```

The same arguments work in the plotting function `plot_comparisons()` as well, which allows us to plot various custom contrasts. Here is a comparison of Adjusted Risk Ratio and Adjusted Risk Difference in a model of the probability of survival aboard the Titanic:

```{r}
library(ggplot2)
library(patchwork)
titanic <- "https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv"
titanic <- read.csv(titanic)
mod_titanic <- glm(
    Survived ~ Sex * PClass + Age + I(Age^2),
    family = binomial,
    data = titanic)

avg_comparisons(mod_titanic)

p1 <- plot_comparisons(
    mod_titanic,
    effect = "Age",
    condition = "Age",
    transform_pre = "ratio") +
    ylab("Adjusted Risk Ratio\nP(Survival | Age + 1) / P(Survival | Age)")

p2 <- plot_comparisons(
    mod_titanic,
    effect = "Age",
    condition = "Age") +
    ylab("Adjusted Risk Difference\nP(Survival | Age + 1) - P(Survival | Age)")

p1 + p2
```

By default, the standard errors around contrasts are computed using the delta method on the scale determined by the `type` argument (e.g., "link" or "response"). Some analysts may prefer to proceed differently. For example, in `Stata`, the `adjrr` computes adjusted risk ratios (ARR) in two steps:

1. Compute the natural log of the ratio between the mean of adjusted predictions with $x+1$ and the mean of adjusted predictions with $x$.
2. Exponentiate the estimate and confidence interval bounds.

Step 1 is easy to achieve with the `transform_pre` argument described above. Step 2 can be achieved with the `transform_post` argument:

```{r}
avg_comparisons(
    mod,
    transform_pre = function(hi, lo) log(hi / lo),
    transform_post = exp)
```

````{comment}
Note that we can use the `lnratioavg` shortcut instead of defining the function ourselves.

The order of operations in previous command was:

1. Compute the custom unit-level log ratios
2. Exponentiate them
3. Take the average using the `avg_comparisons()`

There is a very subtle difference between the procedure above and this code:

```{r}
avg_comparisons(
    mod,
    transform_pre = function(hi, lo) log(hi / lo),
    transform_post = exp)
```

Since the `exp` function is now passed to the `transform_post` argument of the `comparisons()` function, the exponentiation is now done only *after* unit-level contrasts have been averaged. This is what `Stata` appears to do under the hood, and the results are slightly different.

```{r}
comparisons(
    mod,
    transform_pre = function(hi, lo) log(mean(hi) / mean(lo)),
    transform_post = exp)
```
````

Note that equivalent results can be obtained using shortcut strings in the `transform_pre` argument: "ratio", "lnratio", "lnratioavg".

```{r}
comparisons(
    mod,
    transform_pre = "lnratioavg",
    transform_post = exp)
```

All the same arguments apply to the plotting functions of the `marginaleffects` package as well. For example we can plot the Adjusted Risk Ratio in a model with a quadratic term:

```{r}
library(ggplot2)

mod2 <- glm(vs ~ mpg + mpg^2, data = mtcars, family = binomial)

plot_comparisons(
    mod2,
    effect = list("mpg" = 10),
    condition = "mpg",
    transformation_pre = "ratio") +
    ylab("Adjusted Risk Ratio\nP(vs = 1 | mpg + 10) / P(vs = 1 | mpg)")
```

# Forward, Backward, Centered, and Custom Differences

By default, the `comparisons()` function computes a "centered" difference. For example, if we ask `comparisons()` to estimate the effect of a 10-unit change in predictor `x` on outcome `y`, `comparisons()` will compare the predicted values with `x-5` and `x+5`. 

```{r}
dat <- mtcars
dat$new_hp <- 49 * (mtcars$hp - min(mtcars$hp)) / (max(mtcars$hp) - min(mtcars$hp)) + 1
mod <- lm(mpg ~ log(new_hp), data = dat)

avg_comparisons(
  mod,
  variables = list(new_hp = 10))
```

Since version 0.7.2 of `marginaleffects`, we can supply arbitrary functions to create custom differences. These functions must accept a vector of values for the predictor of interest, and return a data frame with the same number of rows as the length, and two columns with the values to compare. For example, we can do:

```{r}
forward_diff <- \(x) data.frame(x, x + 10)
backward_diff <- \(x) data.frame(x - 10, x)
center_diff <- \(x) data.frame(x - 5, x + 5)

avg_comparisons(
  mod,
  variables = list(new_hp = forward_diff))

avg_comparisons(
  mod,
  variables = list(new_hp = backward_diff))

avg_comparisons(
  mod,
  variables = list(new_hp = center_diff))
```

Notice that the last "centered" difference gives the same results as the default `comparisons()` call.


# Lognormal hurdle model

With hurdle models, we can fit two separate models simultaneously: 

1. A model that predicts if the outcome is zero or not zero
2. If the outcome is not zero, a model that predicts what the value of the outcome is

We can calculate predictions and marginal effects for each of these hurdle model processes, but doing so requires some variable transformation since the stages of these models use different link functions.

The `hurdle_lognormal()` family in `brms` uses logistic regression (with a logit link) for the hurdle part of the model and lognormal regression (where the outcome is logged before getting used in the model) for the non-hurdled part. Let's look at an example of predicting GDP per capita (which is distributed exponentially) using life expectancy. We'll add some artificial zeros so that we can work with a hurdle stage of the model.

```{r run-hurdle-lognormal-fake, eval=FALSE}
library(dplyr)
library(ggplot2)
library(patchwork)
library(brms)
library(marginaleffects)
library(gapminder)

# Build some 0s into the GDP column
set.seed(1234)
gapminder <- gapminder::gapminder |> 
  filter(continent != "Oceania") |> 
  # Make a bunch of GDP values 0
  mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),
         will_be_zero = rbinom(n(), 1, prob = prob_zero),
         gdpPercap0 = ifelse(will_be_zero, 0, gdpPercap)) |> 
  select(-prob_zero, -will_be_zero)

mod <- brm(
  bf(gdpPercap0 ~ lifeExp,
     hu ~ lifeExp),
  data = gapminder,
  family = hurdle_lognormal(),
  chains = 4, cores = 4, seed = 1234)
```

```{r load-model-real, include=FALSE}
library(dplyr)
library(ggplot2)
library(patchwork)
library(marginaleffects)
set.seed(1234)

source(here::here("inst/tinytest/helpers.R"))
mod <- marginaleffects:::modelarchive_model("brms_lognormal_hurdle")
```

We have two different sets of coefficients here for the two different processes. The hurdle part (`hu`) uses a logit link, and the non-hurdle part (`mu`) uses an identity link. However, that's a slight misnomer—a true identity link would show the coefficients on a non-logged dollar value scale. Because we're using a `lognormal` family, GDP per capita is pre-logged, so the "original" identity scale is actually logged dollars.

```{r model-summary-fake, eval=FALSE}
summary(mod)
```

```{r model-summary-truncated, echo=FALSE}
cat(c(capture.output(summary(mod))[1:14], "..."), sep = "\n")
```

We can get predictions for the `hu` part of the model on the link (logit) scale:

```{r}
predictions(mod, dpar = "hu", type = "link",
            newdata = datagrid(lifeExp = seq(40, 80, 20)))
```

…or on the response (percentage point) scale:

```{r}
predictions(mod, dpar = "hu", type = "response",
            newdata = datagrid(lifeExp = seq(40, 80, 20)))
```

We can also get slopes for the `hu` part of the model on the link (logit) or response (percentage point) scales:

```{r}
slopes(mod, dpar = "hu", type = "link",
                newdata = datagrid(lifeExp = seq(40, 80, 20)))

slopes(mod, dpar = "hu", type = "response",
                newdata = datagrid(lifeExp = seq(40, 80, 20)))
```

Working with the `mu` part of the model is trickier. Switching between `type = "link"` and `type = "response"` doesn't change anything, since the outcome is pre-logged:

```{r}
predictions(mod, dpar = "mu", type = "link",
            newdata = datagrid(lifeExp = seq(40, 80, 20)))
predictions(mod, dpar = "mu", type = "response",
            newdata = datagrid(lifeExp = seq(40, 80, 20)))
```

For **predictions**, we need to exponentiate the results to scale them back up to dollar amounts. We can do this by post-processing the results (e.g. with `dplyr::mutate(predicted = exp(predicted))`), or we can use the `transform_post` argument in `predictions()` to pass the results to `exp()` after getting calculated:

```{r}
predictions(mod, dpar = "mu", 
            newdata = datagrid(lifeExp = seq(40, 80, 20)),
            transform_post = exp)
```

We can pass `transform_post = exp` to `plot_predictions()` too:

```{r plot-hurdle-parts, fig.width=8, fig.asp=0.618}
plot_predictions(
  mod,
  dpar = "hu",
  type = "link",
  condition = "lifeExp") +
  labs(y = "hu",
       title = "Hurdle part (hu)",
       subtitle = "Logit-scale predictions") +
plot_predictions(
  mod,
  dpar = "hu",
  type = "response",
  condition = "lifeExp") +
  labs(y = "hu",
       subtitle = "Percentage point-scale predictions") +
plot_predictions(
  mod,
  dpar = "mu",
  condition = "lifeExp") +
  labs(y = "mu",
       title = "Non-hurdle part (mu)",
       subtitle = "Log-scale predictions") +
plot_predictions(
  mod,
  dpar = "mu",
  transform_post = exp,
  condition = "lifeExp") +
  labs(y = "mu",
       subtitle = "Dollar-scale predictions")
```

For **marginal effects**, we need to transform the predictions *before* calculating the instantaneous slopes. We also can't use the `slopes()` function directly—we need to use `comparisons()` and compute the numerical derivative ourselves (i.e. predict `gdpPercap` at `lifeExp` of 40 and 40.001 and calculate the slope between those predictions). We can use the `transform_pre` argument to pass the pair of predicted values to `exp()` before calculating the slopes:

```{r}
# step size of the numerical derivative
eps <- 0.001

comparisons(
  mod,
  dpar = "mu",
  variables = list(lifeExp = eps),
  newdata = datagrid(lifeExp = seq(40, 80, 20)),
  # rescale the elements of the slope
  # (exp(40.001) - exp(40)) / exp(0.001)
  transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps
)
```

We can visually confirm that these are the instantaneous slopes at each of these levels of life expectancy:

```{r hurdle-dollar-slopes, fig.width=7, fig.asp=0.618}
predictions_data <- predictions(
  mod,
  newdata = datagrid(lifeExp = seq(30, 80, 1)),
  dpar = "mu",
  transform_post = exp) |>
  select(lifeExp, prediction = estimate)

slopes_data <- comparisons(
  mod,
  dpar = "mu",
  variables = list(lifeExp = eps),
  newdata = datagrid(lifeExp = seq(40, 80, 20)),
  transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps) |>
  select(lifeExp, estimate) |>
  left_join(predictions_data, by = "lifeExp") |>
  # Point-slope formula: (y - y1) = m(x - x1)
  mutate(intercept = estimate * (-lifeExp) + prediction)

ggplot(predictions_data, aes(x = lifeExp, y = prediction)) +
  geom_line(size = 1) + 
  geom_abline(data = slopes_data, aes(slope = estimate, intercept = intercept), 
              size = 0.5, color = "red") +
  geom_point(data = slopes_data) +
  geom_label(data = slopes_data, aes(label = paste0("Slope: ", round(estimate, 1))),
             nudge_x = -1, hjust = 1) +
  theme_minimal()
```
