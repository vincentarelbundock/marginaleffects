---
title: "Marginal Means" 
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Marginal Means}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .4,
  warning = FALSE,
  message = FALSE,
  comment = "#>"
)
library("tidyverse")
library("kableExtra")
```

In the context of this package, "marginal means" refer to the values obtained by this three step process:

1. Construct a "grid" of predictor values with all combinations of categorical variables, and where numeric variables are held at their means.
2. Calculate adjusted predictions for each cell in that grid.
3. Take the average of those adjusted predictions across one dimension of the grid to obtain the marginal means.

For example, consider a model with a numeric, a factor, and a logical predictor:

```{r}
library(marginaleffects)

dat <- mtcars
dat$cyl <- as.factor(dat$cyl)
dat$am <- as.logical(dat$am)
mod <- lm(mpg ~ hp + cyl + am, data = dat)
```

Using the `predictions` function, we set the `hp` variable at its mean and compute predictions for all combinations for `am` and `cyl`:

```{r}
p <- predictions(
    mod,
    newdata = datagrid(am = dat$am, cyl = dat$cyl))
```

For illustration purposes, it is useful to reshape the above results:

```{r, echo = FALSE}
pred <- p %>%
    select(cyl, am, predicted) %>%
    pivot_wider(names_from = "am", values_from = "predicted") %>%
    rowwise() %>%
    mutate(`Marginal means by cyl` = mean(c(`TRUE`, `FALSE`)))
row <- data.frame(x = "Marginal means by am",
                  y = mean(pred[["TRUE"]]),
                  z = mean(pred[["FALSE"]]))
colnames(row) <- colnames(pred)[1:3]
pred <- bind_rows(pred, row)
for (i in 2:ncol(pred)) {
    pred[[i]] <- sprintf("%.1f", pred[[i]])
}
pred[pred == "NA"] <- ""
kbl(pred) %>% 
    kable_styling() %>%
    add_header_above(c(" " = 1, "am" = 2, " " = 1))
```

The marginal means by `am` and `cyl` are obtained by taking the mean of the adjusted predictions across cells. The `marginalmeans` function gives us the same results easily:

```{r}
marginalmeans(mod)
```

The same results can be obtained using the [very powerful `emmeans` package](https://cran.r-project.org/package=emmeans):

```{r}
library(emmeans)
emmeans(mod, specs = "cyl")
emmeans(mod, specs = "am")
```

# Interactions

By default, the `marginalmeans()` function calculates marginal means for each categorical predictor one after the other. We can also compute marginal means for *combinations* of categories by setting `cross=TRUE`:

```{r, message = FALSE, warning = FALSE}
library(lme4)

dat <- "https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv"
dat <- read.csv(dat)
titanic <- glmer(
    Survived ~ Sex * PClass + Age + (1 | PClass),
    family = binomial,
    data = dat)
```

Regardless of the scale of the predictions (`type` argument), `marginalmeans()` always computes standard errors using the Delta Method: 

```{r}
marginalmeans(
    titanic,
    type = "response",
    variables = c("Sex", "PClass"))
```

When the model is linear or on the link scale, it also produces confidence intervals: 

```{r}
marginalmeans(
    titanic,
    type = "link",
    variables = c("Sex", "PClass"))
```

It is easy to transform those link-scale marginal means with arbitrary functions using the `transform_post` argument:

```{r}
marginalmeans(
    titanic,
    type = "link",
    transform_post = insight::link_inverse(titanic),
    variables = c("Sex", "PClass"))
```

`marginalmeans()` defaults to reporting EMMs for each category individually, without cross-margins:

```{r, warning = FALSE, message = FALSE}
titanic2 <- glmer(
    Survived ~ Sex + PClass + Age + (1 | PClass),
    family = binomial,
    data = dat)

marginalmeans(
    titanic2,
    variables = c("Sex", "PClass"))
```

We can force the cross:

```{r}
marginalmeans(
    titanic2,
    cross = TRUE,
    variables = c("Sex", "PClass"))
```

# Group averages with the `by` argument

We can collapse marginal means via averaging using the `by` argument:

```{r}
dat <- mtcars
dat$am <- factor(dat$am)
dat$vs <- factor(dat$vs)
dat$cyl <- factor(dat$cyl)

mod <- glm(gear ~ cyl + vs + am, data = dat, family = poisson)

by <- data.frame(
    by = c("(4 & 6)", "(4 & 6)", "(8)"),
    cyl = c(4, 6, 8))

marginalmeans(mod, by = by)
```

And we can use the `hypothesis` argument to compare those new collapsed subgroups:

```{r}
marginalmeans(mod, by = by, hypothesis = "pairwise")
```

# Custom Contrasts and Linear Combinations

See the vignette on [Custom Contrasts and Combinations](https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html)

# Tidy summaries

The `summary`, `tidy`, and `glance` functions are also available to summarize and manipulate the results:

```{r}
mm <- marginalmeans(mod)

tidy(mm)

glance(mm)

summary(mm)
```

Thanks to those tidiers, we can also present the results in the style of a regression table [using the `modelsummary` package.](https://vincentarelbundock.github.io/modelsummary/) For examples, see [the tables and plots vignette.](https://vincentarelbundock.github.io/marginaleffects/articles/modelsummary.html)


# Case study: Multinomial Logit

This example requires version 0.2.0 of the `marginaleffects` package.

To begin, we generate data and estimate a large model:

```{r}
library(nnet)
library(marginaleffects)

set.seed(1839)
n <- 1200
x <- factor(sample(letters[1:3], n, TRUE))
y <- vector(length = n)
y[x == "a"] <- sample(letters[4:6], sum(x == "a"), TRUE)
y[x == "b"] <- sample(letters[4:6], sum(x == "b"), TRUE, c(1 / 4, 2 / 4, 1 / 4))
y[x == "c"] <- sample(letters[4:6], sum(x == "c"), TRUE, c(1 / 5, 3 / 5, 2 / 5))

dat <- data.frame(x = x, y = factor(y))
tmp <- as.data.frame(replicate(20, factor(sample(letters[7:9], n, TRUE))))
dat <- cbind(dat, tmp)
void <- capture.output({
    mod <- multinom(y ~ ., dat)
})
```

Try to compute marginal means, but realize that your grid wonâ€™t fit in memory:

```{r, error = TRUE}
marginalmeans(mod, type = "probs")
```

Use the `variables` and `variables_grid` arguments to compute marginal means over a more reasonably sized grid:

```{r, eval = FALSE}
marginalmeans(mod,
              type = "probs",
              variables = c("x", "V1"),
              variables_grid = paste0("V", 2:3))
```


# Plot conditional marginal means

The `marginaleffects` package offers several functions to plot how some quantities vary as a function of others:

* `plot_cap`: Conditional adjusted predictions -- how does the predicted outcome change as a function of regressors?
* `plot_cco`: Conditional comparisons -- how do contrasts change as a function of regressors?
* `plot_cme`: Conditional marginal effects -- how does the slope change as a function of regressors?

There is no analogous function for marginal means. However, it is very easy to achieve a similar effect using the `predictions()` function, its `by` argument, and standard plotting functions. In the example below, we take these steps:

1. Estimate a model with one continuous (`hp`) and one categorical regressor (`cyl`).
1. Create a perfectly "balanced" data grid for each combination of `hp` and `cyl`. This is specified by the user in the `datagrid()` call.
1. Compute fitted values (aka "adjusted predictions") for each cell of the grid.
1. Use the `by` argument to take the average of predicted values for each value of `hp`, across margins of `cyl`.
1. Compute standard errors around the averaged predicted values (i.e., marginal means).
1. Create symmetric confidence intervals in the usual manner.
1. Plot the results.

```{r}
library(ggplot2)

mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)

p <- predictions(mod,
    by = "hp",
    newdata = datagrid(
        model = mod,
        hp = seq(100, 120, length.out = 10),
        cyl = mtcars$cyl))

ggplot(p) +
    geom_ribbon(aes(hp, ymin = conf.low, ymax = conf.high), alpha = .2) +
    geom_line(aes(hp, predicted))
```